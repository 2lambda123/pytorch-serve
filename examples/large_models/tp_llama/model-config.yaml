#frontend settings
minWorkers: 1
maxWorkers: 1
maxBatchDelay: 200
responseTimeout: 300
parallelType: "tp"
deviceType: "gpu"

torchrun:
    nproc-per-node: 8

handler:
    converted_ckpt_dir: "PATH/TO/converted_checkpoints"
    tokenizer_path: "/PATH/TO/MODEL/CHECKPOINTS/tokenizer.model"
    model_args_path: "PATH/TO/model_args.json"
    max_seq_len: 512
    max_batch_size: 6
    max_new_tokens: 200
    temperature: 0.6
    top_p: 0.9
    manual_seed: 40
    mode: "chat" #choices are text_completion, chat

