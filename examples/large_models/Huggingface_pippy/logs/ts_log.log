2023-05-09T02:54:37,534 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T02:54:37,534 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T02:54:37,623 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T02:54:37,623 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T02:54:37,888 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T02:54:37,888 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T02:54:37,901 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T02:54:37,901 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T02:54:37,925 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T02:54:37,925 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T02:54:37,929 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: opt.tar.gz
org.pytorch.serve.archive.model.ModelNotFoundException: Model not found at: opt.tar.gz
	at org.pytorch.serve.archive.model.ModelArchive.downloadModel(ModelArchive.java:95) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.ModelManager.createModelArchive(ModelManager.java:169) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:135) ~[model-server.jar:?]
	at org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:264) [model-server.jar:?]
	at org.pytorch.serve.ModelServer.startRESTserver(ModelServer.java:396) [model-server.jar:?]
	at org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:118) [model-server.jar:?]
	at org.pytorch.serve.ModelServer.main(ModelServer.java:99) [model-server.jar:?]
2023-05-09T02:54:37,929 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: opt.tar.gz
org.pytorch.serve.archive.model.ModelNotFoundException: Model not found at: opt.tar.gz
	at org.pytorch.serve.archive.model.ModelArchive.downloadModel(ModelArchive.java:95) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.ModelManager.createModelArchive(ModelManager.java:169) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:135) ~[model-server.jar:?]
	at org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:264) [model-server.jar:?]
	at org.pytorch.serve.ModelServer.startRESTserver(ModelServer.java:396) [model-server.jar:?]
	at org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:118) [model-server.jar:?]
	at org.pytorch.serve.ModelServer.main(ModelServer.java:99) [model-server.jar:?]
2023-05-09T02:54:37,940 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T02:54:37,940 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T02:54:38,013 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T02:54:38,013 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T02:54:38,013 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T02:54:38,013 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T02:54:38,015 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T02:54:38,015 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T02:54:38,015 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T02:54:38,015 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T02:54:38,016 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T02:54:38,016 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T02:54:39,727 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,731 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0768356323242|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,732 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2468032836914|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,732 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,732 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,732 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,732 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,733 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,733 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,733 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,733 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,733 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,734 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,734 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,734 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,734 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,734 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:378150.94140625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,735 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1578.55859375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:54:39,735 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.2|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600879
2023-05-09T02:55:27,269 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T02:55:27,269 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T02:55:27,322 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T02:55:27,322 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T02:55:27,556 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T02:55:27,556 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T02:55:27,562 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T02:55:27,562 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T02:55:27,578 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T02:55:27,578 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T02:55:27,615 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T02:55:27,615 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T02:55:27,615 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T02:55:27,615 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T02:55:27,615 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T02:55:27,615 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T02:55:27,615 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T02:55:27,615 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T02:55:27,615 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T02:55:27,615 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T02:55:27,628 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T02:55:27,628 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T02:55:27,628 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T02:55:27,628 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T02:55:27,688 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T02:55:27,688 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T02:55:27,688 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T02:55:27,688 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T02:55:27,690 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T02:55:27,690 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T02:55:27,690 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T02:55:27,690 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T02:55:27,691 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T02:55:27,691 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T02:55:27,871 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T02:55:27,871 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T02:55:29,107 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T02:55:29,112 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T02:55:29,112 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T02:55:29,112 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T02:55:29,112 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T02:55:29,112 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T02:55:29,113 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T02:55:29,113 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T02:55:29,113 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T02:55:29,113 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T02:55:29,113 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T02:55:29,113 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T02:55:29,114 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T02:55:29,114 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T02:55:29,114 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T02:55:29,114 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T02:55:29,114 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T02:55:29,114 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T02:55:29,115 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T02:55:29,115 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ebab1rd6
2023-05-09T02:55:29,115 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T02:55:29,115 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T02:55:29,290 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0768051147461|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24683380126953|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,292 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,292 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,293 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,293 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,293 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,293 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,294 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,294 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,294 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,294 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,294 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,294 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377959.6484375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1769.19140625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,295 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.2|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683600929
2023-05-09T02:55:29,392 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T02:55:29,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T02:55:29,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T02:55:29,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=49221
2023-05-09T02:55:29,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T02:55:29,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T02:55:29,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T02:55:29,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T02:55:29,394 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T02:55:29,394 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T02:55:29,394 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T02:55:29,394 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T02:55:29,394 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T02:55:29,394 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T02:55:29,394 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ebab1rd6/attempt_0/0/error.json
2023-05-09T02:55:29,394 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ebab1rd6/attempt_0/1/error.json
2023-05-09T02:55:29,395 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ebab1rd6/attempt_0/2/error.json
2023-05-09T02:55:29,395 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ebab1rd6/attempt_0/3/error.json
2023-05-09T02:55:30,594 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=40669
2023-05-09T02:55:30,595 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=40670
2023-05-09T02:55:30,595 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:30,595 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:30,596 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=40668
2023-05-09T02:55:30,596 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:30,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:30,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:30,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]40669
2023-05-09T02:55:30,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]40670
2023-05-09T02:55:30,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:30,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:30,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:30,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:30,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:30,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]40668
2023-05-09T02:55:30,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:30,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:30,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=40671
2023-05-09T02:55:30,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:30,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:30,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]40671
2023-05-09T02:55:30,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:30,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:30,630 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T02:55:30,630 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T02:55:30,635 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T02:55:30,635 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T02:55:30,643 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T02:55:30,644 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T02:55:30,644 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T02:55:30,647 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T02:55:30,647 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T02:55:30,647 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T02:55:30,648 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T02:55:30,648 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T02:55:30,649 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T02:55:30,650 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T02:55:30,653 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683600930653
2023-05-09T02:55:30,653 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683600930653
2023-05-09T02:55:30,678 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T02:55:30,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T02:55:30,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T02:55:30,712 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T02:55:31,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T02:55:31,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T02:55:31,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T02:55:31,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T02:55:31,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T02:55:31,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T02:55:31,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T02:55:31,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T02:55:31,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T02:55:31,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T02:55:31,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 40671/3
2023-05-09T02:55:31,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T02:55:31,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T02:55:31,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 40668/0
2023-05-09T02:55:31,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 40670/2
2023-05-09T02:55:31,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 40669/1
2023-05-09T02:55:33,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T02:55:33,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T02:55:33,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T02:55:33,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T02:55:33,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T02:55:33,035 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T02:55:33,035 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T02:55:33,035 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T02:55:33,035 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T02:55:33,035 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T02:55:33,035 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T02:55:33,036 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T02:55:33,036 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T02:55:33,036 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T02:55:33,036 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T02:55:33,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T02:55:33,037 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T02:55:33,037 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T02:55:33,037 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T02:55:33,037 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/b5d3231172ce4bb6902c644899132d6f/pippy_handler.py", line 55, in initialize
2023-05-09T02:55:33,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T02:55:33,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
2023-05-09T02:55:33,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2023-05-09T02:55:33,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 809, in from_pretrained
2023-05-09T02:55:33,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T02:55:33,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
2023-05-09T02:55:33,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T02:55:33,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 635, in _get_config_dict
2023-05-09T02:55:33,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise EnvironmentError(
2023-05-09T02:55:33,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - OSError: Can't load the configuration of '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546' is the correct path to a directory containing a config.json file
2023-05-09T02:55:33,043 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T02:55:33,044 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:33,044 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T02:55:33,044 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:33,045 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T02:55:33,045 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:33,045 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T02:55:33,045 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T02:55:33,045 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:33,045 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T02:55:33,045 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T02:55:33,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/b5d3231172ce4bb6902c644899132d6f/pippy_handler.py", line 55, in initialize
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 809, in from_pretrained
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 635, in _get_config_dict
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise EnvironmentError(
2023-05-09T02:55:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - OSError: Can't load the configuration of '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546' is the correct path to a directory containing a config.json file
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T02:55:33,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T02:55:33,037 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T02:55:33,037 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T02:55:33,049 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T02:55:33,049 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T02:55:33,049 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T02:55:33,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T02:55:33,049 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683600933050
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683600933050
2023-05-09T02:55:33,049 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T02:55:33,049 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:33,050 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T02:55:33,050 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/b5d3231172ce4bb6902c644899132d6f/pippy_handler.py", line 55, in initialize
2023-05-09T02:55:33,050 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T02:55:33,050 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T02:55:33,050 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T02:55:33,051 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T02:55:33,051 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T02:55:33,498 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T02:55:33,498 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T02:55:34,051 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T02:55:34,051 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T02:55:35,554 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T02:55:35,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T02:55:35,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T02:55:35,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T02:55:35,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T02:55:35,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T02:55:35,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T02:55:35,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T02:55:35,558 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T02:55:35,558 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_64ayfs1m
2023-05-09T02:55:35,558 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T02:55:35,558 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T02:55:35,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T02:55:35,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T02:55:35,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T02:55:35,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=33449
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_64ayfs1m/attempt_0/0/error.json
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_64ayfs1m/attempt_0/1/error.json
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_64ayfs1m/attempt_0/2/error.json
2023-05-09T02:55:35,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_64ayfs1m/attempt_0/3/error.json
2023-05-09T02:55:36,999 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=41618
2023-05-09T02:55:37,000 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:37,004 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=41620
2023-05-09T02:55:37,004 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:37,005 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=41619
2023-05-09T02:55:37,005 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:37,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:37,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]41618
2023-05-09T02:55:37,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:37,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:37,013 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:37,013 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]41620
2023-05-09T02:55:37,013 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:37,013 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:37,014 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:37,014 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]41619
2023-05-09T02:55:37,014 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:37,014 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:37,041 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=41621
2023-05-09T02:55:37,041 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:37,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:37,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]41621
2023-05-09T02:55:37,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:37,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:37,050 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T02:55:37,050 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T02:55:37,050 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T02:55:37,050 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T02:55:37,052 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T02:55:37,052 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T02:55:37,052 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:37,052 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:37,053 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T02:55:37,053 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T02:55:37,053 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T02:55:37,053 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method) ~[?:?]
	at java.lang.Object.wait(Object.java:328) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T02:55:37,053 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method) ~[?:?]
	at java.lang.Object.wait(Object.java:328) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T02:55:37,056 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T02:55:37,056 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T02:55:37,056 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T02:55:37,056 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T02:55:37,056 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T02:55:37,056 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T02:55:37,056 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T02:55:37,056 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T02:55:37,056 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T02:55:37,056 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T02:55:37,057 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T02:55:37,056 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T02:55:37,057 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T02:55:38,057 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T02:55:38,057 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T02:55:39,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T02:55:39,564 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T02:55:39,564 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T02:55:39,564 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T02:55:39,564 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T02:55:39,564 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T02:55:39,564 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T02:55:39,564 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T02:55:39,564 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T02:55:39,567 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T02:55:39,567 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0fwx3_vk
2023-05-09T02:55:39,567 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T02:55:39,567 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T02:55:39,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=36085
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0fwx3_vk/attempt_0/0/error.json
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0fwx3_vk/attempt_0/1/error.json
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0fwx3_vk/attempt_0/2/error.json
2023-05-09T02:55:39,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0fwx3_vk/attempt_0/3/error.json
2023-05-09T02:55:40,893 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=41703
2023-05-09T02:55:40,893 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:40,895 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=41701
2023-05-09T02:55:40,895 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:40,896 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=41702
2023-05-09T02:55:40,896 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:40,901 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:40,901 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]41703
2023-05-09T02:55:40,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:40,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:40,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:40,904 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]41701
2023-05-09T02:55:40,904 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:40,904 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:40,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:40,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]41702
2023-05-09T02:55:40,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:40,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:40,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=41704
2023-05-09T02:55:40,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:55:40,942 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:55:40,942 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]41704
2023-05-09T02:55:40,942 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:55:40,942 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:55:40,943 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T02:55:40,943 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T02:55:40,943 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T02:55:40,943 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T02:55:40,945 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T02:55:40,945 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:40,945 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T02:55:40,945 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T02:55:40,945 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T02:55:40,945 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T02:55:40,945 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T02:55:40,945 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@f61834a(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T02:55:40,945 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@f61834a(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T02:55:40,947 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T02:55:40,947 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T02:55:40,947 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T02:55:40,947 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T02:55:40,947 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T02:55:40,947 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T02:55:40,947 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T02:55:40,947 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T02:55:40,947 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T02:55:40,947 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T02:55:40,947 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T02:55:40,947 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T02:57:59,701 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T02:57:59,701 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T02:57:59,754 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T02:57:59,754 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T02:57:59,984 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T02:57:59,984 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T02:57:59,990 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T02:57:59,990 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T02:58:00,006 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T02:58:00,006 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T02:58:00,031 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T02:58:00,031 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T02:58:00,031 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T02:58:00,031 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T02:58:00,031 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T02:58:00,031 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T02:58:00,032 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T02:58:00,032 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T02:58:00,032 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T02:58:00,032 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T02:58:00,041 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T02:58:00,041 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T02:58:00,043 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T02:58:00,043 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T02:58:00,104 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T02:58:00,104 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T02:58:00,104 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T02:58:00,104 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T02:58:00,105 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T02:58:00,105 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T02:58:00,106 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T02:58:00,106 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T02:58:00,107 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T02:58:00,107 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T02:58:00,287 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T02:58:00,287 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T02:58:01,542 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T02:58:01,542 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T02:58:01,542 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T02:58:01,543 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T02:58:01,543 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T02:58:01,543 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T02:58:01,543 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T02:58:01,544 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T02:58:01,544 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T02:58:01,544 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T02:58:01,544 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T02:58:01,544 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T02:58:01,544 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T02:58:01,545 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T02:58:01,545 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T02:58:01,545 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T02:58:01,545 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T02:58:01,545 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T02:58:01,545 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T02:58:01,546 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_kcggwsku
2023-05-09T02:58:01,546 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T02:58:01,546 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T02:58:01,674 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,675 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.076717376709|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,675 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24692153930664|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,676 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,676 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,676 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,676 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,676 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,677 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,677 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,677 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,677 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,677 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,678 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,678 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,678 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,678 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377982.43359375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,678 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1745.69140625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,678 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.2|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601081
2023-05-09T02:58:01,830 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T02:58:01,830 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T02:58:01,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T02:58:01,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=56291
2023-05-09T02:58:01,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T02:58:01,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T02:58:01,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T02:58:01,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T02:58:01,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T02:58:01,832 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T02:58:01,832 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T02:58:01,832 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T02:58:01,832 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T02:58:01,832 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T02:58:01,832 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_kcggwsku/attempt_0/0/error.json
2023-05-09T02:58:01,832 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_kcggwsku/attempt_0/1/error.json
2023-05-09T02:58:01,833 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_kcggwsku/attempt_0/2/error.json
2023-05-09T02:58:01,833 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_kcggwsku/attempt_0/3/error.json
2023-05-09T02:58:03,042 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=42655
2023-05-09T02:58:03,043 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:58:03,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=42656
2023-05-09T02:58:03,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:58:03,051 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:58:03,051 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]42655
2023-05-09T02:58:03,051 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:58:03,051 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:58:03,054 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=42657
2023-05-09T02:58:03,055 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:58:03,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:58:03,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]42656
2023-05-09T02:58:03,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:58:03,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:58:03,063 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:58:03,063 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]42657
2023-05-09T02:58:03,063 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:58:03,063 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:58:03,081 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=42658
2023-05-09T02:58:03,081 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T02:58:03,090 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T02:58:03,090 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]42658
2023-05-09T02:58:03,090 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T02:58:03,090 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T02:58:03,090 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T02:58:03,090 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T02:58:03,093 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T02:58:03,093 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T02:58:03,101 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T02:58:03,102 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T02:58:03,102 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T02:58:03,104 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T02:58:03,104 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T02:58:03,104 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T02:58:03,106 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T02:58:03,106 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T02:58:03,106 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T02:58:03,108 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T02:58:03,110 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683601083110
2023-05-09T02:58:03,110 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683601083110
2023-05-09T02:58:03,133 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T02:58:03,145 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T02:58:03,156 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T02:58:03,168 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T02:58:03,996 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T02:58:03,996 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T02:58:03,996 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T02:58:03,997 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T02:58:03,998 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 42655/0
2023-05-09T02:58:03,999 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 42658/3
2023-05-09T02:58:03,999 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 42657/2
2023-05-09T02:58:03,999 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 42656/1
2023-05-09T02:59:01,270 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.9|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,270 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0766563415527|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,270 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2469825744629|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,272 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,272 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,272 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,272 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,272 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:346028.4296875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,272 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:33448.3515625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T02:59:01,272 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:9.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601141
2023-05-09T03:00:01,265 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:15.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,265 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0766487121582|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,265 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2469902038574|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,265 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,265 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,265 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,266 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,267 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,267 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:353351.76171875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,267 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:26116.84765625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:00:01,267 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:7.7|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601201
2023-05-09T03:01:01,276 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:15.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0766448974609|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2469940185547|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:360942.80859375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:18518.0546875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:01:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:5.7|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601261
2023-05-09T03:02:01,269 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:15.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,269 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0766372680664|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,269 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2470016479492|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,269 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,271 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,271 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:368550.03125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,271 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:10902.5234375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:02:01,271 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.7|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601321
2023-05-09T03:03:01,274 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.9|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0766296386719|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24700927734375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,275 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:338432.484375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:41012.10546875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:03:01,276 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:11.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601381
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:11.8|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0766258239746|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.247013092041|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,267 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:346026.94921875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:33409.7265625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:04:01,268 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:9.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601441
2023-05-09T03:05:01,268 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:15.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0766181945801|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24702072143555|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,269 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:353624.8984375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:25802.109375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:01,270 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:7.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601501
2023-05-09T03:05:40,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 456.02077395500055 seconds
2023-05-09T03:05:40,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 456.0320185949995 seconds
2023-05-09T03:05:40,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 456.02339128400035 seconds
2023-05-09T03:05:40,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 454.9761214279997 seconds
2023-05-09T03:05:40,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:05:40,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:05:40,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:05:40,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:05:40,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:05:40,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:05:40,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:05:40,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:05:40,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:05:40,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:05:40,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:05:40,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:05:41,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:05:41,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T03:05:41,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:05:41,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0016326709992427 seconds on rank 3
2023-05-09T03:05:41,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/19a6148fa571420184835480b9993f09 loaded successfully
2023-05-09T03:05:41,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:05:41,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:05:41,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T03:05:41,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:05:41,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0125878960006958 seconds on rank 1
2023-05-09T03:05:41,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/19a6148fa571420184835480b9993f09 loaded successfully
2023-05-09T03:05:41,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T03:05:41,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:05:41,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T03:05:41,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,539 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 458371
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 458371
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,540 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T03:05:41,540 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:461504.0|#WorkerName:W-29500-opt_1.0,Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601541
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:59.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601541
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T03:05:41,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T03:05:41,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T03:05:41,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T03:05:41,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,549 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T03:05:41,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T03:05:41,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:05:41,553 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0180902989995957 seconds on rank 2
2023-05-09T03:05:41,553 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/19a6148fa571420184835480b9993f09 loaded successfully
2023-05-09T03:05:41,553 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T03:05:41,554 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T03:05:41,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683601541.56 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T03:05:41,557 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T03:05:41,558 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T03:05:41,559 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683601541.56 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T03:05:41,559 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T03:05:41,560 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683601541.56 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T03:05:41,560 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683601541.56 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T03:05:52,100 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T03:05:56,280 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 0
2023-05-09T03:05:56,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T03:05:57,022 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T03:05:57,146 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:05:57,146 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 16.625492737999593 seconds on rank 0
2023-05-09T03:05:57,146 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/19a6148fa571420184835480b9993f09 loaded successfully
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764541625977|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24718475341797|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370900.1875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8290.72265625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:06:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601561
2023-05-09T03:07:01,280 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764503479004|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24718856811523|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370899.94921875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,282 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8291.01171875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:07:01,282 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601621
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:14.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764427185059|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24719619750977|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370888.5234375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8302.359375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:08:01,280 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601681
2023-05-09T03:09:01,277 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,277 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764389038086|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,277 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24720001220703|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,277 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,277 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370883.02734375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8308.1953125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:09:01,278 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601741
2023-05-09T03:10:01,278 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,278 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764274597168|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,278 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2472114562988|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,278 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,278 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370879.96875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8311.13671875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:10:01,279 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601801
2023-05-09T03:11:01,275 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764274597168|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2472114562988|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,276 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370877.64453125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,277 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8313.46875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:11:01,277 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601861
2023-05-09T03:12:01,275 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764198303223|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24721908569336|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,276 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370872.83203125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,277 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8318.125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:12:01,277 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601921
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.9|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764122009277|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2472267150879|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370871.77734375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8319.36328125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:13:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683601981
2023-05-09T03:14:01,281 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,281 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764083862305|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,281 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24723052978516|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370868.9140625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8322.26171875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:14:01,282 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602041
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764045715332|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2472343444824|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370864.67578125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8326.5546875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:15:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602101
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0764007568359|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2472381591797|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370869.41015625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8321.796875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:16:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602161
2023-05-09T03:17:01,279 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0763931274414|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2472457885742|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370863.55078125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,280 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8327.59375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:01,281 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602221
2023-05-09T03:17:50,911 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683602270
2023-05-09T03:17:50,913 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683602270913
2023-05-09T03:17:50,913 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683602270913
2023-05-09T03:17:50,914 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:17:50,914 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:17:50,914 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2023-05-09T03:17:50,914 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2023-05-09T03:17:50,914 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602270
2023-05-09T03:17:50,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend received inference at: 1683602270
2023-05-09T03:17:50,914 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
2023-05-09T03:17:50,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-09T03:17:50,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - '
2023-05-09T03:17:50,915 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
2023-05-09T03:17:50,915 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-09T03:17:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-05-09T03:17:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:17:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/service.py", line 134, in predict
2023-05-09T03:17:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-05-09T03:17:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 343, in handle
2023-05-09T03:17:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     output = self.inference(data_preprocess)
2023-05-09T03:17:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/19a6148fa571420184835480b9993f09/pippy_handler.py", line 132, in inference
2023-05-09T03:17:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     input_ids_batch = input_ids_batch.to(self.device)
2023-05-09T03:17:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - AttributeError: 'tuple' object has no attribute 'to'
2023-05-09T03:18:01,283 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0763816833496|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.247257232666|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.47802675004343|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14848.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370821.65234375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8369.3828125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:18:01,284 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602281
2023-05-09T03:19:27,647 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:19:27,647 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:19:27,701 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:19:27,701 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:19:27,952 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:19:27,952 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:19:27,958 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:19:27,958 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:19:27,974 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:19:27,974 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:19:27,998 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:19:27,998 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:19:27,999 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:19:27,999 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:19:27,999 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:19:27,999 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:19:27,999 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:19:27,999 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:19:27,999 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:19:27,999 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:19:28,008 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:19:28,008 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:19:28,010 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:19:28,010 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:19:28,068 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:19:28,068 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:19:28,068 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:19:28,068 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:19:28,070 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:19:28,070 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:19:28,070 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:19:28,070 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:19:28,071 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:19:28,071 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:19:28,252 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:19:28,252 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:19:29,506 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:19:29,506 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:19:29,507 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:19:29,507 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:19:29,507 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:19:29,507 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:19:29,507 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:19:29,508 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:19:29,508 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:19:29,508 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:19:29,508 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:19:29,508 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:19:29,508 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:19:29,509 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:19:29,509 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:19:29,509 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:19:29,509 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:19:29,509 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:19:29,509 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:19:29,510 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vrbaykkx
2023-05-09T03:19:29,510 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:19:29,510 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:19:29,649 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,651 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0763664245605|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,651 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2472724914551|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,652 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,652 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,652 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,652 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,652 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,653 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,653 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,653 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,653 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,653 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,654 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,654 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,654 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,654 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377889.62109375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,654 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1774.36328125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,654 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602369
2023-05-09T03:19:29,797 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:19:29,797 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:19:29,797 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:19:29,797 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=36913
2023-05-09T03:19:29,797 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:19:29,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:19:29,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:19:29,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:19:29,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:19:29,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:19:29,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:19:29,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:19:29,799 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:19:29,799 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:19:29,799 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vrbaykkx/attempt_0/0/error.json
2023-05-09T03:19:29,799 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vrbaykkx/attempt_0/1/error.json
2023-05-09T03:19:29,799 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vrbaykkx/attempt_0/2/error.json
2023-05-09T03:19:29,799 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vrbaykkx/attempt_0/3/error.json
2023-05-09T03:19:30,999 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=46548
2023-05-09T03:19:31,000 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:19:31,002 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=46549
2023-05-09T03:19:31,002 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:19:31,005 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=46547
2023-05-09T03:19:31,006 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:19:31,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:19:31,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]46548
2023-05-09T03:19:31,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:19:31,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:19:31,011 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:19:31,011 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]46549
2023-05-09T03:19:31,011 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:19:31,011 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:19:31,015 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:19:31,016 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]46547
2023-05-09T03:19:31,016 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:19:31,016 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:19:31,031 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=46550
2023-05-09T03:19:31,031 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:19:31,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:19:31,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]46550
2023-05-09T03:19:31,040 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:19:31,040 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:19:31,040 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:19:31,040 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:19:31,044 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:19:31,044 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:19:31,051 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:19:31,052 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:19:31,052 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:19:31,054 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:19:31,054 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:19:31,054 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:19:31,056 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:19:31,056 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:19:31,056 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T03:19:31,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T03:19:31,060 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683602371060
2023-05-09T03:19:31,060 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683602371060
2023-05-09T03:19:31,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:19:31,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:19:31,107 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:19:31,118 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:19:31,954 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:19:31,954 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:19:31,954 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:19:31,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:19:31,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:19:31,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:19:31,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:19:31,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:19:31,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:19:31,957 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:19:31,957 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:19:31,957 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:19:31,957 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 46549/2
2023-05-09T03:19:31,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 46548/1
2023-05-09T03:19:31,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 46547/0
2023-05-09T03:19:31,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 46550/3
2023-05-09T03:19:59,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.108066474000225 seconds
2023-05-09T03:19:59,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:19:59,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:19:59,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:19:59,685 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.243123002000175 seconds
2023-05-09T03:19:59,748 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:19:59,749 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:19:59,749 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:19:59,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.359863112999847 seconds
2023-05-09T03:19:59,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:19:59,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:19:59,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:20:00,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:20:00,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T03:20:00,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:20:00,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 0.9982658259996242 seconds on rank 1
2023-05-09T03:20:00,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/d6b5bab6ff8f427d9139fb49faad078c loaded successfully
2023-05-09T03:20:00,741 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:20:00,743 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T03:20:00,743 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:20:00,743 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 0.9957290279999143 seconds on rank 3
2023-05-09T03:20:00,743 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/d6b5bab6ff8f427d9139fb49faad078c loaded successfully
2023-05-09T03:20:00,868 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:20:00,870 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T03:20:00,870 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:20:00,871 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0092677519996869 seconds on rank 2
2023-05-09T03:20:00,871 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/d6b5bab6ff8f427d9139fb49faad078c loaded successfully
2023-05-09T03:20:01,287 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.763469370000166 seconds
2023-05-09T03:20:01,345 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:20:01,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:20:01,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:20:02,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:20:02,345 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T03:20:02,347 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T03:20:02,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T03:20:02,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T03:20:02,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T03:20:02,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T03:20:02,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T03:20:02,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683602402.37 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T03:20:02,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T03:20:02,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T03:20:02,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T03:20:02,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683602402.37 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T03:20:02,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683602402.37 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T03:20:02,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683602402.37 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T03:20:13,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T03:20:16,715 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 0
2023-05-09T03:20:17,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T03:20:17,761 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T03:20:17,885 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:20:17,885 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 16.539874717000203 seconds on rank 0
2023-05-09T03:20:17,885 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/d6b5bab6ff8f427d9139fb49faad078c loaded successfully
2023-05-09T03:20:17,886 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:20:17,886 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:20:17,886 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46768
2023-05-09T03:20:17,886 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46768
2023-05-09T03:20:17,886 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T03:20:17,886 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T03:20:17,886 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:49882.0|#WorkerName:W-29500-opt_1.0,Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602417
2023-05-09T03:20:17,887 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:59.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602417
2023-05-09T03:20:29,245 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,245 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0761528015137|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,245 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24748611450195|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,245 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,245 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,245 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370848.19921875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,246 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8343.07421875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:29,247 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602429
2023-05-09T03:20:43,439 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683602443
2023-05-09T03:20:43,441 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683602443441
2023-05-09T03:20:43,441 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683602443441
2023-05-09T03:20:43,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend received inference at: 1683602443
2023-05-09T03:20:43,442 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
2023-05-09T03:20:43,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-09T03:20:43,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - '
2023-05-09T03:20:43,442 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
2023-05-09T03:20:43,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-09T03:20:43,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:43,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py:1713: UserWarning: Received extra arguments: {'return_dict', 'past_key_values', 'output_hidden_states', 'use_cache', 'attention_mask', 'output_attentions'}. They might have already been given a concrete value during pipeline compilation via `concrete_args`. We will ignore the current inputs and use the values given during compilation.
2023-05-09T03:20:43,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-09T03:20:43,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:44,237 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:44,995 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:45,754 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:46,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:46,510 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:46,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:46,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:46,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:46,661 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:46,664 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:46,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:46,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:46,772 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:46,813 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:46,815 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:46,852 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:46,888 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:46,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:46,965 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:46,967 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:47,004 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:47,040 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:47,076 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:47,116 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:47,120 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:47,156 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:47,192 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:47,228 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:47,269 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:47,271 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:47,308 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:47,344 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:47,380 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:47,420 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:47,423 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:47,460 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:47,497 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:47,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:47,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:47,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:47,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:47,652 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:47,688 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:47,729 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:20:47,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:20:47,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:20:47,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:20:47,842 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:20:47,884 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI\n\nThe following\n\n\nThe\n']
2023-05-09T03:20:47,884 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:4442.27|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683602447,62d746ed-608b-4dda-83bd-4f6f93102c8a, pattern=[METRICS]
2023-05-09T03:20:47,884 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:4442.27|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683602447,62d746ed-608b-4dda-83bd-4f6f93102c8a, pattern=[METRICS]
2023-05-09T03:20:47,885 [INFO ] W-29500-opt_1.0-stdout MODEL_METRICS - HandlerTime.ms:4442.27|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,requestID:62d746ed-608b-4dda-83bd-4f6f93102c8a,timestamp:1683602447
2023-05-09T03:20:47,886 [INFO ] W-29500-opt_1.0 ACCESS_LOG - /127.0.0.1:45260 "PUT /predictions/opt HTTP/1.1" 200 4448
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4442.36|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683602447,62d746ed-608b-4dda-83bd-4f6f93102c8a, pattern=[METRICS]
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4442.36|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683602447,62d746ed-608b-4dda-83bd-4f6f93102c8a, pattern=[METRICS]
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602447
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0-stdout MODEL_METRICS - PredictionTime.ms:4442.36|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,requestID:62d746ed-608b-4dda-83bd-4f6f93102c8a,timestamp:1683602447
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4444894.939|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683602447
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:196.433|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683602447
2023-05-09T03:20:47,892 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.job.Job - Waiting time ns: 196433, Backend time ns: 4451367016
2023-05-09T03:20:47,892 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.job.Job - Waiting time ns: 196433, Backend time ns: 4451367016
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602447
2023-05-09T03:20:47,892 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:20:47,892 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4444
2023-05-09T03:20:47,892 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4444
2023-05-09T03:20:47,893 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602447
2023-05-09T03:21:29,236 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,237 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:566.0761222839355|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,237 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:403.2475166320801|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,237 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,237 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:68.264721208963|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,237 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15720.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,237 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:67.86520757338891|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15628.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:67.86520757338891|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15628.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:74.35296161195068|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:17122.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:367222.8671875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:11835.84765625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:21:29,238 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602489
2023-05-09T03:22:29,238 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:566.076114654541|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:403.2475242614746|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:68.264721208963|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15720.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:67.86520757338891|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15628.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:67.86520757338891|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15628.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,239 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:74.35296161195068|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,240 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:17122.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,240 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,240 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,240 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,240 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,240 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:367208.65234375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,240 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:11850.22265625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:22:29,240 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602549
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:5.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:566.0761070251465|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:403.24753189086914|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:68.264721208963|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15720.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:67.86520757338891|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15628.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:67.86520757338891|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:15628.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,234 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:74.35296161195068|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,235 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:17122.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,235 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,235 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,235 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,235 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,235 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:367202.7578125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,235 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:11856.3125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:29,235 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:4.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602609
2023-05-09T03:23:32,021 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683602612
2023-05-09T03:23:32,022 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683602612022
2023-05-09T03:23:32,022 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683602612022
2023-05-09T03:23:32,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend received inference at: 1683602612
2023-05-09T03:23:32,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-09T03:23:32,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - '
2023-05-09T03:23:32,024 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:32,027 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:32,065 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:32,100 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:32,136 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:32,176 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:32,180 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:32,217 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:32,252 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:32,288 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:32,329 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:32,331 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:32,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:32,404 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:32,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:32,480 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:32,483 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:32,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:32,555 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:32,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:32,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:32,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:32,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:32,707 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:32,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:32,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:32,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:32,823 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:32,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:32,895 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:32,935 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:32,938 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:32,975 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:33,011 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:33,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:33,087 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:33,090 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:33,127 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:33,163 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:33,200 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:33,241 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:33,243 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:33,281 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:33,317 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:33,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:33,395 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:23:33,397 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:23:33,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:23:33,472 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:23:33,508 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:23:33,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI\n\nThe following\n\n\nThe\n']
2023-05-09T03:23:33,550 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1527.27|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683602613,005530e1-69e9-41b3-8bd3-1a8f9ce6c316, pattern=[METRICS]
2023-05-09T03:23:33,550 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1527.27|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683602613,005530e1-69e9-41b3-8bd3-1a8f9ce6c316, pattern=[METRICS]
2023-05-09T03:23:33,550 [INFO ] W-29500-opt_1.0-stdout MODEL_METRICS - HandlerTime.ms:1527.27|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,requestID:005530e1-69e9-41b3-8bd3-1a8f9ce6c316,timestamp:1683602613
2023-05-09T03:23:33,550 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1527.34|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683602613,005530e1-69e9-41b3-8bd3-1a8f9ce6c316, pattern=[METRICS]
2023-05-09T03:23:33,550 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1527.34|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683602613,005530e1-69e9-41b3-8bd3-1a8f9ce6c316, pattern=[METRICS]
2023-05-09T03:23:33,550 [INFO ] W-29500-opt_1.0-stdout MODEL_METRICS - PredictionTime.ms:1527.34|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,requestID:005530e1-69e9-41b3-8bd3-1a8f9ce6c316,timestamp:1683602613
2023-05-09T03:23:33,551 [INFO ] W-29500-opt_1.0 ACCESS_LOG - /127.0.0.1:50192 "PUT /predictions/opt HTTP/1.1" 200 1530
2023-05-09T03:23:33,551 [INFO ] W-29500-opt_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602613
2023-05-09T03:23:33,551 [INFO ] W-29500-opt_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1528848.629|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683602613
2023-05-09T03:23:33,551 [INFO ] W-29500-opt_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:121.272|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683602613
2023-05-09T03:23:33,551 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.job.Job - Waiting time ns: 121272, Backend time ns: 1529604850
2023-05-09T03:23:33,551 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.job.Job - Waiting time ns: 121272, Backend time ns: 1529604850
2023-05-09T03:23:33,551 [INFO ] W-29500-opt_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602613
2023-05-09T03:23:33,552 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:23:33,552 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:23:33,552 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1528
2023-05-09T03:23:33,552 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1528
2023-05-09T03:23:33,552 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683602613
2023-05-09T03:35:38,058 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:35:38,058 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:35:38,111 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:35:38,111 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:35:38,332 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:35:38,332 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:35:38,338 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:35:38,338 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:35:38,354 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:35:38,354 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:35:38,380 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:35:38,380 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:35:38,380 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:35:38,380 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:35:38,380 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:35:38,380 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:35:38,380 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:35:38,380 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:35:38,380 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:35:38,380 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:35:38,389 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:35:38,389 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:35:38,392 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:38,392 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:38,450 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:35:38,450 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:35:38,450 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:35:38,450 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:35:38,452 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:35:38,452 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:35:38,452 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:35:38,452 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:35:38,453 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:35:38,453 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:35:38,633 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:35:38,633 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:35:39,923 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:35:39,924 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:35:39,924 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:35:39,924 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:35:39,924 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:35:39,925 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:35:39,925 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:35:39,925 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:35:39,925 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:35:39,925 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:35:39,925 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:35:39,926 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:35:39,926 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:35:39,926 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:35:39,926 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:35:39,926 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:35:39,926 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:35:39,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:35:39,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:39,928 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mwcqaawg
2023-05-09T03:35:39,928 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:35:39,928 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:35:40,052 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,054 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.075008392334|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,054 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24863052368164|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,055 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,055 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,055 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,055 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,056 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,056 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,056 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,056 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,056 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,057 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,057 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,057 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,057 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,058 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377882.33203125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,058 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1780.859375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,058 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603340
2023-05-09T03:35:40,202 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:35:40,202 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:35:40,202 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:35:40,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=36099
2023-05-09T03:35:40,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:35:40,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:35:40,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:35:40,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:35:40,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:35:40,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:35:40,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:35:40,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:40,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:35:40,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:35:40,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mwcqaawg/attempt_0/0/error.json
2023-05-09T03:35:40,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mwcqaawg/attempt_0/1/error.json
2023-05-09T03:35:40,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mwcqaawg/attempt_0/2/error.json
2023-05-09T03:35:40,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mwcqaawg/attempt_0/3/error.json
2023-05-09T03:35:41,397 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=49657
2023-05-09T03:35:41,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:41,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=49658
2023-05-09T03:35:41,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:41,406 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:41,406 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]49657
2023-05-09T03:35:41,406 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:41,407 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:41,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:41,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]49658
2023-05-09T03:35:41,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:41,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:41,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=49659
2023-05-09T03:35:41,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:41,424 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=49660
2023-05-09T03:35:41,425 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:41,431 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:41,431 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]49659
2023-05-09T03:35:41,431 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:41,431 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:41,433 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:41,433 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]49660
2023-05-09T03:35:41,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:41,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:41,434 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:35:41,434 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:35:41,438 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:35:41,438 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:35:41,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:35:41,446 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:35:41,446 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:35:41,448 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:35:41,448 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:35:41,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:35:41,450 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:35:41,450 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:35:41,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T03:35:41,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T03:35:41,454 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683603341454
2023-05-09T03:35:41,454 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683603341454
2023-05-09T03:35:41,476 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:35:41,488 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:35:41,500 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:35:41,511 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:35:42,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:35:42,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:35:42,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:35:42,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:35:42,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:35:42,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:35:42,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:35:42,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:35:42,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 49658/1
2023-05-09T03:35:42,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 49660/3
2023-05-09T03:35:42,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:35:42,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:35:42,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:35:42,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:35:42,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:35:42,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:35:42,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:35:42,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:35:42,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 49657/0
2023-05-09T03:35:42,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 49659/2
2023-05-09T03:35:43,848 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:35:43,848 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T03:35:43,849 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:35:43,849 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:35:43,849 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 257, in <module>
2023-05-09T03:35:43,850 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T03:35:43,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 257, in <module>
2023-05-09T03:35:43,850 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T03:35:43,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     os.remove(socket_name)
2023-05-09T03:35:43,850 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T03:35:43,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - FileNotFoundError    : os.remove(socket_name)[Errno 2] No such file or directory: '/tmp/.ts.sock.29500'
2023-05-09T03:35:43,851 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T03:35:43,851 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:43,851 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T03:35:43,851 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/.ts.sock.29500'
2023-05-09T03:35:43,851 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T03:35:43,851 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T03:35:43,851 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T03:35:43,851 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:43,851 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:43,851 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:43,852 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T03:35:43,851 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:43,851 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:43,852 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:35:43,851 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:43,852 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T03:35:43,852 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:35:43,852 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:35:43,852 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:35:43,853 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:35:43,853 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T03:35:43,855 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T03:35:43,855 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T03:35:43,855 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T03:35:43,855 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T03:35:43,856 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T03:35:43,856 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T03:35:43,856 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T03:35:43,856 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T03:35:43,857 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T03:35:43,857 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/77c1c6e116484a41a72fad8ddf461cfc/pippy_handler.py", line 68, in initialize
2023-05-09T03:35:43,857 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T03:35:43,857 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
2023-05-09T03:35:43,858 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2023-05-09T03:35:43,858 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 809, in from_pretrained
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 635, in _get_config_dict
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise EnvironmentError(
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - OSError: Can't load the configuration of '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546' is the correct path to a directory containing a config.json file
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:35:43,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:35:43,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/77c1c6e116484a41a72fad8ddf461cfc/pippy_handler.py", line 68, in initialize
2023-05-09T03:35:43,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T03:35:43,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
2023-05-09T03:35:43,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2023-05-09T03:35:43,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 809, in from_pretrained
2023-05-09T03:35:43,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:35:43,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
2023-05-09T03:35:43,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:35:43,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 635, in _get_config_dict
2023-05-09T03:35:43,862 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise EnvironmentError(
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - OSError: Can't load the configuration of '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546' is the correct path to a directory containing a config.json file
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:35:43,863 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T03:35:43,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T03:35:43,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T03:35:43,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T03:35:43,853 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:35:43,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T03:35:43,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/77c1c6e116484a41a72fad8ddf461cfc/pippy_handler.py", line 68, in initialize
2023-05-09T03:35:43,853 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:35:43,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T03:35:43,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
2023-05-09T03:35:43,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2023-05-09T03:35:43,865 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T03:35:43,865 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T03:35:43,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 809, in from_pretrained
2023-05-09T03:35:43,866 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:35:43,866 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:35:43,866 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683603343866
2023-05-09T03:35:43,866 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683603343866
2023-05-09T03:35:43,866 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:35:43,866 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
2023-05-09T03:35:43,866 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:43,866 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:35:43,866 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:35:43,866 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:35:43,866 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:35:43,866 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:35:43,866 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:43,866 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 635, in _get_config_dict
2023-05-09T03:35:43,867 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:35:43,867 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:35:43,867 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:35:43,867 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:35:44,293 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:35:44,293 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:35:44,868 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:44,868 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:46,372 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:35:46,373 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:35:46,374 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:35:46,374 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:35:46,374 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:35:46,374 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:35:46,374 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:35:46,374 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:35:46,374 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:35:46,374 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:35:46,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:46,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v3vigjsw
2023-05-09T03:35:46,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:35:46,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:35:46,597 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:35:46,597 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:35:46,597 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:35:46,597 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=38965
2023-05-09T03:35:46,597 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:35:46,597 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v3vigjsw/attempt_0/0/error.json
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v3vigjsw/attempt_0/1/error.json
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v3vigjsw/attempt_0/2/error.json
2023-05-09T03:35:46,598 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v3vigjsw/attempt_0/3/error.json
2023-05-09T03:35:47,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50595
2023-05-09T03:35:47,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:47,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:47,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50595
2023-05-09T03:35:47,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:47,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:47,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50596
2023-05-09T03:35:47,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:47,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50597
2023-05-09T03:35:47,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:47,813 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:47,813 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50596
2023-05-09T03:35:47,813 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:47,813 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:47,819 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:47,819 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50597
2023-05-09T03:35:47,819 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:47,819 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:47,825 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50598
2023-05-09T03:35:47,825 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:47,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:47,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50598
2023-05-09T03:35:47,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:47,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:47,834 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:35:47,834 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:35:47,834 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:35:47,834 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:35:47,836 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:35:47,836 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:47,836 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:35:47,836 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:47,836 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:35:47,836 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:35:47,836 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:35:47,836 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@345da357(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:35:47,836 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@345da357(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:35:47,838 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:35:47,838 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:35:47,838 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:35:47,838 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:35:47,838 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:35:47,838 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:35:47,838 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:35:47,838 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:35:47,838 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:35:47,838 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:35:47,838 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:35:47,839 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:35:47,839 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:35:48,839 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:48,839 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:50,323 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:35:50,324 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:35:50,325 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:35:50,327 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:50,327 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_hrnnakq2
2023-05-09T03:35:50,327 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:35:50,327 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=58539
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_hrnnakq2/attempt_0/0/error.json
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_hrnnakq2/attempt_0/1/error.json
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_hrnnakq2/attempt_0/2/error.json
2023-05-09T03:35:50,514 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_hrnnakq2/attempt_0/3/error.json
2023-05-09T03:35:51,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50693
2023-05-09T03:35:51,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:51,710 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:51,710 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50693
2023-05-09T03:35:51,710 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:51,710 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:51,718 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50691
2023-05-09T03:35:51,718 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:51,720 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50692
2023-05-09T03:35:51,720 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:51,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:51,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50691
2023-05-09T03:35:51,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:51,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:51,729 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:51,729 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50692
2023-05-09T03:35:51,729 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:51,729 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:51,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50694
2023-05-09T03:35:51,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:51,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:51,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50694
2023-05-09T03:35:51,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:51,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:51,753 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:35:51,753 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:35:51,753 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:35:51,753 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:35:51,756 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:35:51,756 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:35:51,756 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:51,756 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:51,756 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:35:51,756 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:35:51,756 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:35:51,756 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@f1007b3(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:35:51,756 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@f1007b3(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:35:51,757 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:35:51,757 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:35:51,757 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:35:51,757 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:35:51,757 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:35:51,757 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:35:51,758 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:35:51,758 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:35:51,758 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:35:51,758 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T03:35:51,758 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:35:51,758 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T03:35:53,759 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:53,759 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:55,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:35:55,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:35:55,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:35:55,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:35:55,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:35:55,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:35:55,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:35:55,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:35:55,252 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:55,253 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5dwzpe31
2023-05-09T03:35:55,253 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:35:55,253 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=46041
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:35:55,386 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:35:55,387 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:35:55,387 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5dwzpe31/attempt_0/0/error.json
2023-05-09T03:35:55,387 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5dwzpe31/attempt_0/1/error.json
2023-05-09T03:35:55,387 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5dwzpe31/attempt_0/2/error.json
2023-05-09T03:35:55,387 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5dwzpe31/attempt_0/3/error.json
2023-05-09T03:35:56,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50789
2023-05-09T03:35:56,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:56,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50790
2023-05-09T03:35:56,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:56,588 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:56,588 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50789
2023-05-09T03:35:56,588 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:56,589 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:56,592 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:56,592 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50790
2023-05-09T03:35:56,592 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:56,592 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:56,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50792
2023-05-09T03:35:56,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:56,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50791
2023-05-09T03:35:56,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:35:56,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:56,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50792
2023-05-09T03:35:56,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:56,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:56,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:35:56,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50791
2023-05-09T03:35:56,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:35:56,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:35:56,612 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:35:56,612 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:35:56,612 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:35:56,612 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:35:56,614 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:35:56,614 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:35:56,614 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:56,614 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:35:56,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:35:56,615 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:35:56,615 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:35:56,615 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@1406d47(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:35:56,615 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@1406d47(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:35:56,616 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:35:56,616 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:35:56,616 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:35:56,616 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:35:56,616 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:35:56,616 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:35:56,617 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:35:56,617 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:35:56,617 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:35:56,617 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T03:35:56,617 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:35:56,617 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T03:35:59,617 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:35:59,617 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:36:01,103 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:36:01,103 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:36:01,103 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:36:01,103 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:36:01,103 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:36:01,103 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:36:01,103 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:36:01,103 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:36:01,104 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:36:01,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:36:01,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_yb4kx4u7
2023-05-09T03:36:01,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:36:01,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:36:01,256 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=59023
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_yb4kx4u7/attempt_0/0/error.json
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_yb4kx4u7/attempt_0/1/error.json
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_yb4kx4u7/attempt_0/2/error.json
2023-05-09T03:36:01,257 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_yb4kx4u7/attempt_0/3/error.json
2023-05-09T03:36:02,431 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50886
2023-05-09T03:36:02,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:36:02,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50885
2023-05-09T03:36:02,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:36:02,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:36:02,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50886
2023-05-09T03:36:02,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:36:02,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:36:02,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:36:02,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50885
2023-05-09T03:36:02,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:36:02,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:36:02,471 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50887
2023-05-09T03:36:02,472 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:36:02,480 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:36:02,480 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50887
2023-05-09T03:36:02,480 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:36:02,480 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:36:02,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50888
2023-05-09T03:36:02,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:36:02,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:36:02,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50888
2023-05-09T03:36:02,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:36:02,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:36:02,507 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:36:02,507 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:36:02,507 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:36:02,507 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:36:02,510 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:36:02,510 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:36:02,510 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:36:02,510 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:36:02,510 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:36:02,510 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:36:02,510 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:36:02,510 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@57fc8804(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:36:02,510 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@57fc8804(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:36:02,512 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:36:02,512 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:36:02,512 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:36:02,512 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:36:02,512 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:36:02,512 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:36:02,512 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:36:02,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:36:02,512 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:36:02,512 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T03:36:02,512 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:36:02,512 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T03:36:02,512 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:36:07,512 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:36:07,512 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:36:08,996 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:36:08,999 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:36:08,999 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5oj7fxjk
2023-05-09T03:36:08,999 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:36:08,999 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:36:09,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:36:09,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:36:09,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:36:09,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=43045
2023-05-09T03:36:09,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:36:09,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:36:09,203 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5oj7fxjk/attempt_0/0/error.json
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5oj7fxjk/attempt_0/1/error.json
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5oj7fxjk/attempt_0/2/error.json
2023-05-09T03:36:09,204 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5oj7fxjk/attempt_0/3/error.json
2023-05-09T03:36:10,380 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50998
2023-05-09T03:36:10,381 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:36:10,388 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50996
2023-05-09T03:36:10,388 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:36:10,389 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:36:10,389 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50998
2023-05-09T03:36:10,389 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:36:10,389 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:36:10,396 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:36:10,396 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50996
2023-05-09T03:36:10,396 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:36:10,397 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:36:10,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50997
2023-05-09T03:36:10,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:36:10,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:36:10,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50997
2023-05-09T03:36:10,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:36:10,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:36:10,423 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=50999
2023-05-09T03:36:10,423 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:36:10,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:36:10,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]50999
2023-05-09T03:36:10,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:36:10,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:36:10,432 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:36:10,432 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:36:10,432 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:36:10,432 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:36:10,435 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:36:10,435 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:36:10,435 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:36:10,435 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:36:10,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:36:10,435 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:36:10,435 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:36:10,435 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@56127fba(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:36:10,435 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@56127fba(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:36:10,436 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:36:10,436 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:36:10,436 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:36:10,436 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:36:10,437 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:36:10,437 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:36:10,437 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:36:10,437 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:36:10,437 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 8 seconds.
2023-05-09T03:36:10,437 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 8 seconds.
2023-05-09T03:36:10,437 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:36:10,437 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:37:52,783 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:37:52,783 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:37:52,836 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:37:52,836 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:37:53,076 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:37:53,076 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:37:53,082 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:37:53,082 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:37:53,098 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:37:53,098 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:37:53,124 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:37:53,124 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:37:53,124 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:37:53,124 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:37:53,125 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:37:53,125 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:37:53,125 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:37:53,125 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:37:53,125 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:37:53,125 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:37:53,136 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:37:53,136 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:37:53,137 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:37:53,137 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:37:53,197 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:37:53,197 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:37:53,197 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:37:53,197 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:37:53,198 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:37:53,198 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:37:53,199 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:37:53,199 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:37:53,200 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:37:53,200 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:37:53,383 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:37:53,383 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:37:54,653 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:37:54,654 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:37:54,654 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:37:54,654 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:37:54,655 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:37:54,655 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:37:54,655 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:37:54,655 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:37:54,655 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:37:54,656 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:37:54,656 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:37:54,656 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:37:54,656 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:37:54,656 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:37:54,656 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:37:54,656 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:37:54,657 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:37:54,657 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:37:54,657 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:37:54,657 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_eyk474wb
2023-05-09T03:37:54,657 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:37:54,657 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:37:54,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:37:54,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:37:54,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:37:54,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=43835
2023-05-09T03:37:54,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:37:54,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:37:54,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:37:54,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:37:54,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:37:54,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:37:54,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:37:54,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:37:54,694 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:37:54,694 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:37:54,694 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_eyk474wb/attempt_0/0/error.json
2023-05-09T03:37:54,694 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_eyk474wb/attempt_0/1/error.json
2023-05-09T03:37:54,694 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_eyk474wb/attempt_0/2/error.json
2023-05-09T03:37:54,694 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_eyk474wb/attempt_0/3/error.json
2023-05-09T03:37:54,777 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,778 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0746841430664|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,779 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2489547729492|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,779 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,779 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,779 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,780 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,780 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,780 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,780 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,780 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,781 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,781 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,781 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,781 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,781 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,781 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377858.296875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,782 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1804.5234375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:54,782 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603474
2023-05-09T03:37:55,879 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=51738
2023-05-09T03:37:55,880 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:37:55,888 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:37:55,888 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]51738
2023-05-09T03:37:55,888 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:37:55,888 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:37:55,893 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=51736
2023-05-09T03:37:55,893 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:37:55,896 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=51737
2023-05-09T03:37:55,897 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:37:55,901 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:37:55,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]51736
2023-05-09T03:37:55,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:37:55,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:37:55,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:37:55,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]51737
2023-05-09T03:37:55,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:37:55,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:37:55,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=51739
2023-05-09T03:37:55,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:37:55,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:37:55,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]51739
2023-05-09T03:37:55,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:37:55,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:37:55,926 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:37:55,926 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:37:55,930 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:37:55,930 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:37:55,937 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:37:55,938 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:37:55,938 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:37:55,940 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:37:55,940 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:37:55,940 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:37:55,942 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:37:55,942 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:37:55,942 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T03:37:55,944 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T03:37:55,946 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683603475946
2023-05-09T03:37:55,946 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683603475946
2023-05-09T03:37:55,970 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:37:55,982 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:37:55,993 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:37:56,004 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:37:56,866 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:37:56,866 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:37:56,866 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:37:56,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:37:56,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:37:56,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:37:56,868 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:37:56,868 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:37:56,868 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:37:56,868 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 51737/1
2023-05-09T03:37:56,869 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:37:56,869 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:37:56,870 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 51738/2
2023-05-09T03:37:56,870 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:37:56,871 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 51739/3
2023-05-09T03:37:56,872 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 51736/0
2023-05-09T03:37:58,342 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T03:37:58,342 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:37:58,342 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T03:37:58,342 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T03:37:58,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/0f2f7ffdaf2a42f49781580fe07fa3f0/pippy_handler.py", line 44, in initialize
2023-05-09T03:37:58,344 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     torch.manual_seed(seed)
2023-05-09T03:37:58,344 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - NameError: name 'torch' is not defined
2023-05-09T03:37:58,344 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:37:58,344 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:37:58,344 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:37:58,344 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:37:58,352 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T03:37:58,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:37:58,353 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:37:58,353 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T03:37:58,353 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:37:58,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T03:37:58,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T03:37:58,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T03:37:58,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T03:37:58,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T03:37:58,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T03:37:58,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T03:37:58,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T03:37:58,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T03:37:58,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/0f2f7ffdaf2a42f49781580fe07fa3f0/pippy_handler.py", line 44, in initialize
2023-05-09T03:37:58,344 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:37:58,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     torch.manual_seed(seed)
2023-05-09T03:37:58,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - NameError: name 'torch' is not defined
2023-05-09T03:37:58,344 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:37:58,356 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T03:37:58,356 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T03:37:58,356 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:37:58,356 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:37:58,356 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683603478356
2023-05-09T03:37:58,356 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683603478356
2023-05-09T03:37:58,356 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:37:58,356 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:37:58,356 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:37:58,356 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:37:58,356 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:37:58,356 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:37:58,356 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:37:58,356 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:37:58,357 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:37:58,357 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:37:58,363 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:37:58,363 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:37:58,826 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:37:58,826 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:37:59,358 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:37:59,358 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:00,849 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:38:00,850 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:38:00,851 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:38:00,851 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:38:00,851 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:38:00,851 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:38:00,851 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:38:00,851 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:38:00,853 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:00,853 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w6lqltur
2023-05-09T03:38:00,853 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:38:00,853 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:38:00,955 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:38:00,955 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:38:00,955 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:38:00,955 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=51985
2023-05-09T03:38:00,955 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:38:00,955 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:38:00,955 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w6lqltur/attempt_0/0/error.json
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w6lqltur/attempt_0/1/error.json
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w6lqltur/attempt_0/2/error.json
2023-05-09T03:38:00,956 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w6lqltur/attempt_0/3/error.json
2023-05-09T03:38:02,154 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52677
2023-05-09T03:38:02,155 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:02,155 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52678
2023-05-09T03:38:02,155 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:02,163 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:02,163 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52677
2023-05-09T03:38:02,163 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:02,163 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:02,164 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:02,164 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52678
2023-05-09T03:38:02,164 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:02,164 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:02,171 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52679
2023-05-09T03:38:02,171 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:02,174 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52680
2023-05-09T03:38:02,174 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:02,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:02,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52679
2023-05-09T03:38:02,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:02,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:02,183 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:02,183 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52680
2023-05-09T03:38:02,183 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:02,183 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:02,183 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:02,183 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:02,183 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:02,183 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:02,185 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:02,185 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:02,185 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:02,185 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:02,185 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:38:02,186 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:02,186 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:02,186 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@76f04883(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:02,186 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@76f04883(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:02,188 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:02,188 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:02,188 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:02,188 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:02,188 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:02,188 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:02,189 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:02,189 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:02,189 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:38:02,189 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:38:02,189 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:38:02,189 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:02,189 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:03,189 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:03,189 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:04,673 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:38:04,674 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:38:04,677 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:04,677 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3mdi8to4
2023-05-09T03:38:04,677 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:38:04,677 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=46941
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3mdi8to4/attempt_0/0/error.json
2023-05-09T03:38:04,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3mdi8to4/attempt_0/1/error.json
2023-05-09T03:38:04,741 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3mdi8to4/attempt_0/2/error.json
2023-05-09T03:38:04,741 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3mdi8to4/attempt_0/3/error.json
2023-05-09T03:38:05,939 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52774
2023-05-09T03:38:05,940 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:05,941 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52773
2023-05-09T03:38:05,941 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:05,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:05,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52774
2023-05-09T03:38:05,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:05,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:05,949 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:05,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52773
2023-05-09T03:38:05,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:05,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:05,965 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52775
2023-05-09T03:38:05,965 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:05,974 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:05,974 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52775
2023-05-09T03:38:05,974 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:05,974 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:05,995 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52776
2023-05-09T03:38:05,995 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:06,003 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:06,004 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52776
2023-05-09T03:38:06,004 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:06,004 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:06,004 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:06,004 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:06,004 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:06,004 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:06,006 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:06,006 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:06,006 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:06,006 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:06,006 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:06,006 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:06,006 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:38:06,006 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2aa2ce9c(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:06,006 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2aa2ce9c(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:06,008 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:06,008 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:06,008 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:06,008 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:06,008 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:06,008 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:06,008 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:06,008 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:06,008 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:06,008 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T03:38:06,008 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:06,008 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T03:38:08,009 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:08,009 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:09,503 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:38:09,503 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:38:09,503 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:09,503 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:38:09,503 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:38:09,504 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:38:09,506 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:09,507 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wucxj059
2023-05-09T03:38:09,507 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:38:09,507 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=57529
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wucxj059/attempt_0/0/error.json
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wucxj059/attempt_0/1/error.json
2023-05-09T03:38:09,720 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wucxj059/attempt_0/2/error.json
2023-05-09T03:38:09,721 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wucxj059/attempt_0/3/error.json
2023-05-09T03:38:10,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52870
2023-05-09T03:38:10,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:10,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52871
2023-05-09T03:38:10,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:10,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52872
2023-05-09T03:38:10,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:10,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:10,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52870
2023-05-09T03:38:10,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:10,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:10,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:10,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52871
2023-05-09T03:38:10,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:10,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:10,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:10,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52872
2023-05-09T03:38:10,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:10,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:10,960 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52873
2023-05-09T03:38:10,960 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:10,969 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:10,969 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52873
2023-05-09T03:38:10,969 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:10,969 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:10,969 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:10,969 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:10,969 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:10,969 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:10,971 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:10,971 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:10,971 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:10,971 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:10,972 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:10,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:38:10,972 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:10,972 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3dd24e89(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:10,972 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3dd24e89(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:10,973 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:10,973 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:10,973 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:10,973 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:10,973 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:10,973 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:10,973 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:10,973 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:10,974 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:10,974 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T03:38:10,974 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:10,974 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T03:38:13,974 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:13,974 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:15,456 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:38:15,457 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:38:15,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:15,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fhls8yhy
2023-05-09T03:38:15,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:38:15,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=43723
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fhls8yhy/attempt_0/0/error.json
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fhls8yhy/attempt_0/1/error.json
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fhls8yhy/attempt_0/2/error.json
2023-05-09T03:38:15,479 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fhls8yhy/attempt_0/3/error.json
2023-05-09T03:38:16,676 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52971
2023-05-09T03:38:16,676 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:16,678 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52970
2023-05-09T03:38:16,678 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:16,678 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52969
2023-05-09T03:38:16,678 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:16,681 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=52968
2023-05-09T03:38:16,681 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:16,685 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:16,685 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52971
2023-05-09T03:38:16,685 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:16,685 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:16,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:16,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52970
2023-05-09T03:38:16,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:16,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:16,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:16,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52969
2023-05-09T03:38:16,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:16,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:16,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:16,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]52968
2023-05-09T03:38:16,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:16,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:16,690 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:16,690 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:16,690 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:16,690 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:16,692 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:16,692 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:16,692 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:16,692 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:16,692 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:16,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:38:16,692 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:16,692 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@75785c70(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:16,692 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@75785c70(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:16,694 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:16,694 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:16,694 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:16,694 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:16,694 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:16,694 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:16,694 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:16,694 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:16,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:38:16,695 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T03:38:16,695 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T03:38:16,695 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:16,695 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:21,695 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:21,695 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:23,176 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:38:23,176 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:38:23,176 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:23,176 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:38:23,176 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:23,176 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:38:23,176 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:38:23,177 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:38:23,179 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:23,180 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tkfr__3b
2023-05-09T03:38:23,180 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:38:23,180 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=57689
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tkfr__3b/attempt_0/0/error.json
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tkfr__3b/attempt_0/1/error.json
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tkfr__3b/attempt_0/2/error.json
2023-05-09T03:38:23,486 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tkfr__3b/attempt_0/3/error.json
2023-05-09T03:38:24,678 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=53087
2023-05-09T03:38:24,679 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:24,681 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=53085
2023-05-09T03:38:24,681 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:24,685 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=53084
2023-05-09T03:38:24,685 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:24,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:24,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]53087
2023-05-09T03:38:24,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:24,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:24,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:24,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]53085
2023-05-09T03:38:24,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:24,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:24,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=53086
2023-05-09T03:38:24,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:24,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:24,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]53084
2023-05-09T03:38:24,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:24,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:24,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:24,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]53086
2023-05-09T03:38:24,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:24,700 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:24,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:24,700 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:24,700 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:24,700 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:24,702 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:24,702 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:24,702 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:24,702 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:24,702 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:38:24,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:24,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:24,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@580d36c4(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:24,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@580d36c4(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:24,704 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:24,704 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:24,704 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:24,704 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:24,704 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:24,704 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:24,704 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:24,704 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:24,705 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:24,705 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 8 seconds.
2023-05-09T03:38:24,705 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 8 seconds.
2023-05-09T03:38:24,705 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:32,210 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:38:32,210 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:38:32,705 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:32,705 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:38:34,214 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:38:34,215 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:38:34,218 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:34,218 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0oi_61im
2023-05-09T03:38:34,218 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:38:34,218 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:38:34,392 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:38:34,392 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:38:34,392 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:38:34,392 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=36667
2023-05-09T03:38:34,392 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:38:34,392 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0oi_61im/attempt_0/0/error.json
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0oi_61im/attempt_0/1/error.json
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0oi_61im/attempt_0/2/error.json
2023-05-09T03:38:34,393 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0oi_61im/attempt_0/3/error.json
2023-05-09T03:38:35,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=53202
2023-05-09T03:38:35,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:35,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=53200
2023-05-09T03:38:35,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:35,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:35,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]53202
2023-05-09T03:38:35,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:35,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:35,590 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=53201
2023-05-09T03:38:35,590 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:35,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:35,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]53200
2023-05-09T03:38:35,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:35,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:35,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:35,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]53201
2023-05-09T03:38:35,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:35,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:35,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=53203
2023-05-09T03:38:35,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:38:35,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:38:35,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]53203
2023-05-09T03:38:35,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:38:35,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:38:35,621 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:35,621 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:38:35,621 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:35,621 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:38:35,623 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:35,623 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:35,623 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:38:35,623 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:38:35,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:38:35,623 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:35,623 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:38:35,623 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@60923daa(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:35,623 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@60923daa(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:38:35,624 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:35,624 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:38:35,624 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:35,624 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:38:35,625 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:35,625 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:38:35,625 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:35,625 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:38:35,625 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 13 seconds.
2023-05-09T03:38:35,625 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 13 seconds.
2023-05-09T03:38:35,625 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:35,625 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:38:36,006 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:38:36,006 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:38:40,958 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:38:40,958 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:41:16,891 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:41:16,891 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:41:16,944 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:41:16,944 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:41:17,152 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:41:17,152 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:41:17,158 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:41:17,158 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:41:17,174 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:41:17,174 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:41:17,199 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:41:17,199 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:41:17,199 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:41:17,199 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:41:17,199 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:41:17,199 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:41:17,200 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:41:17,200 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:41:17,200 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:41:17,200 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:41:17,210 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:41:17,210 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:41:17,212 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:41:17,212 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:41:17,269 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:41:17,269 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:41:17,269 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:41:17,269 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:41:17,271 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:41:17,271 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:41:17,272 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:41:17,272 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:41:17,273 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:41:17,273 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:41:17,452 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:41:17,452 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:41:18,712 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:41:18,713 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:41:18,713 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:41:18,714 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:41:18,714 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:41:18,714 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:41:18,714 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:41:18,714 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:41:18,715 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:41:18,715 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:41:18,715 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:41:18,715 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:41:18,715 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:41:18,715 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:41:18,716 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:41:18,716 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:41:18,716 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:41:18,716 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:41:18,716 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:41:18,716 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_x0ddjcpx
2023-05-09T03:41:18,717 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:41:18,717 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:41:18,802 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:41:18,802 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:41:18,802 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:41:18,802 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=51245
2023-05-09T03:41:18,802 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:41:18,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:41:18,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:41:18,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:41:18,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:41:18,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:41:18,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:41:18,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:41:18,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:41:18,804 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:41:18,804 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_x0ddjcpx/attempt_0/0/error.json
2023-05-09T03:41:18,804 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_x0ddjcpx/attempt_0/1/error.json
2023-05-09T03:41:18,804 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_x0ddjcpx/attempt_0/2/error.json
2023-05-09T03:41:18,804 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_x0ddjcpx/attempt_0/3/error.json
2023-05-09T03:41:18,864 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,866 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0743103027344|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,866 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24932861328125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,866 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,866 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,867 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,867 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,867 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,867 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,868 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,868 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,868 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,868 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,868 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,868 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,868 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,869 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377882.6328125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,869 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1779.88671875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:18,869 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603678
2023-05-09T03:41:19,998 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=54019
2023-05-09T03:41:20,000 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:41:20,000 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=54020
2023-05-09T03:41:20,000 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:41:20,003 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=54021
2023-05-09T03:41:20,003 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:41:20,007 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:41:20,007 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]54019
2023-05-09T03:41:20,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:41:20,008 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:41:20,010 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:41:20,010 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]54020
2023-05-09T03:41:20,010 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:41:20,010 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:41:20,011 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:41:20,011 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]54021
2023-05-09T03:41:20,011 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:41:20,012 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:41:20,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=54022
2023-05-09T03:41:20,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:41:20,042 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:41:20,042 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]54022
2023-05-09T03:41:20,042 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:41:20,042 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:41:20,043 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:41:20,043 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:41:20,046 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:41:20,046 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:41:20,054 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:41:20,055 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:41:20,055 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:41:20,057 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:41:20,057 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:41:20,057 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:41:20,059 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:41:20,059 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:41:20,059 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T03:41:20,060 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T03:41:20,063 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683603680063
2023-05-09T03:41:20,063 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683603680063
2023-05-09T03:41:20,086 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:41:20,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:41:20,110 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:41:20,121 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:41:20,946 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:41:20,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:41:20,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:41:20,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:41:20,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:41:20,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:41:20,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:41:20,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:41:20,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:41:20,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:41:20,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:41:20,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:41:20,949 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:41:20,949 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:41:20,949 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:41:20,949 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 54022/3
2023-05-09T03:41:20,949 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:41:20,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 54021/2
2023-05-09T03:41:20,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 54020/1
2023-05-09T03:41:20,951 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 54019/0
2023-05-09T03:41:48,343 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.95315654499973 seconds
2023-05-09T03:41:48,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.983727075000388 seconds
2023-05-09T03:41:48,403 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:41:48,405 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:41:48,405 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:41:48,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:41:48,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:41:48,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:41:48,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.133353029000318 seconds
2023-05-09T03:41:48,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:41:48,585 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:41:48,585 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:41:49,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:41:49,401 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T03:41:49,401 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:41:49,402 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 0.9982961870000508 seconds on rank 2
2023-05-09T03:41:49,402 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/243853b6373c4ef89a25b1f0b9a3648b loaded successfully
2023-05-09T03:41:49,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:41:49,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T03:41:49,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:41:49,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0024834700006977 seconds on rank 3
2023-05-09T03:41:49,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/243853b6373c4ef89a25b1f0b9a3648b loaded successfully
2023-05-09T03:41:49,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:41:49,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T03:41:49,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:41:49,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0039023919998726 seconds on rank 1
2023-05-09T03:41:49,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/243853b6373c4ef89a25b1f0b9a3648b loaded successfully
2023-05-09T03:41:49,849 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.39994333499999 seconds
2023-05-09T03:41:49,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:41:49,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:41:49,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:41:50,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:41:50,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T03:41:50,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T03:41:50,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T03:41:50,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T03:41:50,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T03:41:50,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T03:41:50,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,929 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,930 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T03:41:50,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,933 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T03:41:50,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T03:41:50,935 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T03:41:50,935 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T03:41:50,935 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T03:41:50,935 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683603710.94 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T03:41:50,936 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T03:41:50,937 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T03:41:50,938 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T03:41:50,938 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683603710.94 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T03:41:50,938 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683603710.94 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T03:41:50,939 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683603710.94 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T03:42:01,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T03:42:05,238 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 0
2023-05-09T03:42:05,684 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T03:42:06,430 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T03:42:06,553 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:42:06,554 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 16.643939149999824 seconds on rank 0
2023-05-09T03:42:06,554 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/243853b6373c4ef89a25b1f0b9a3648b loaded successfully
2023-05-09T03:42:06,554 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:42:06,554 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:42:06,554 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46433
2023-05-09T03:42:06,554 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46433
2023-05-09T03:42:06,555 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T03:42:06,555 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T03:42:06,555 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:49351.0|#WorkerName:W-29500-opt_1.0,Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603726
2023-05-09T03:42:06,556 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:60.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603726
2023-05-09T03:42:18,437 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.074104309082|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2495346069336|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,438 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370861.734375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8327.34765625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:18,439 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603738
2023-05-09T03:42:32,599 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683603752
2023-05-09T03:42:32,601 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683603752601
2023-05-09T03:42:32,601 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683603752601
2023-05-09T03:42:32,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend received inference at: 1683603752
2023-05-09T03:42:32,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-09T03:42:32,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - '
2023-05-09T03:42:32,602 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
2023-05-09T03:42:32,602 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
2023-05-09T03:42:32,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-09T03:42:32,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:32,607 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py:1713: UserWarning: Received extra arguments: {'attention_mask', 'return_dict', 'use_cache', 'past_key_values', 'output_attentions', 'output_hidden_states'}. They might have already been given a concrete value during pipeline compilation via `concrete_args`. We will ignore the current inputs and use the values given during compilation.
2023-05-09T03:42:32,607 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-09T03:42:32,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:33,385 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:34,149 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:34,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:35,681 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:35,684 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:35,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:35,759 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:35,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:35,836 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:35,839 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:35,876 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:35,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:35,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:35,988 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:35,990 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:36,028 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:36,064 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:36,099 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:36,140 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:36,143 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:36,180 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:36,216 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:36,252 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:36,293 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:36,295 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:36,332 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:36,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:36,404 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:36,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:36,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:36,484 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:36,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:36,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:36,596 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:36,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:36,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:36,673 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:36,710 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:36,751 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:36,754 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:36,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:36,827 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:36,864 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:36,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:42:36,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:42:36,946 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:42:36,982 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:42:37,019 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:42:37,061 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI\n\nThe following\n\n\nThe\n']
2023-05-09T03:42:37,062 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:4459.56|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683603757,faba8f89-3a5b-4ec8-99b1-8cf8c4c96ef3, pattern=[METRICS]
2023-05-09T03:42:37,062 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:4459.56|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683603757,faba8f89-3a5b-4ec8-99b1-8cf8c4c96ef3, pattern=[METRICS]
2023-05-09T03:42:37,062 [INFO ] W-29500-opt_1.0-stdout MODEL_METRICS - HandlerTime.ms:4459.56|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,requestID:faba8f89-3a5b-4ec8-99b1-8cf8c4c96ef3,timestamp:1683603757
2023-05-09T03:42:37,062 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4459.65|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683603757,faba8f89-3a5b-4ec8-99b1-8cf8c4c96ef3, pattern=[METRICS]
2023-05-09T03:42:37,062 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4459.65|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683603757,faba8f89-3a5b-4ec8-99b1-8cf8c4c96ef3, pattern=[METRICS]
2023-05-09T03:42:37,062 [INFO ] W-29500-opt_1.0-stdout MODEL_METRICS - PredictionTime.ms:4459.65|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,requestID:faba8f89-3a5b-4ec8-99b1-8cf8c4c96ef3,timestamp:1683603757
2023-05-09T03:42:37,063 [INFO ] W-29500-opt_1.0 ACCESS_LOG - /127.0.0.1:36768 "PUT /predictions/opt HTTP/1.1" 200 4465
2023-05-09T03:42:37,064 [INFO ] W-29500-opt_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603757
2023-05-09T03:42:37,064 [INFO ] W-29500-opt_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4461835.608|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683603757
2023-05-09T03:42:37,064 [INFO ] W-29500-opt_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:227.583|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683603757
2023-05-09T03:42:37,064 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.job.Job - Waiting time ns: 227583, Backend time ns: 4463163439
2023-05-09T03:42:37,064 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.job.Job - Waiting time ns: 227583, Backend time ns: 4463163439
2023-05-09T03:42:37,064 [INFO ] W-29500-opt_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603757
2023-05-09T03:42:37,064 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:42:37,064 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:42:37,064 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4460
2023-05-09T03:42:37,064 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4460
2023-05-09T03:42:37,064 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683603757
2023-05-09T03:52:13,585 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:52:13,585 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:52:13,638 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:52:13,638 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:52:13,847 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:52:13,847 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:52:13,853 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:52:13,853 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:52:13,869 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:52:13,869 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:52:13,894 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:52:13,894 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:52:13,894 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:52:13,894 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:52:13,894 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:52:13,894 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:52:13,894 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:52:13,894 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:52:13,895 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:52:13,895 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:52:13,904 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:52:13,904 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:52:13,906 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:52:13,906 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:52:13,964 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:52:13,964 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:52:13,964 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:52:13,964 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:52:13,966 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:52:13,966 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:52:13,967 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:52:13,967 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:52:13,968 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:52:13,968 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:52:14,146 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:52:14,146 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:52:15,380 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:52:15,380 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:52:15,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:52:15,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:52:15,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:52:15,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:52:15,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:52:15,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:52:15,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:52:15,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:52:15,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:52:15,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:52:15,383 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:52:15,383 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:52:15,383 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:52:15,383 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:52:15,383 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:52:15,383 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:52:15,384 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:52:15,384 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7qtr4hwx
2023-05-09T03:52:15,384 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:52:15,384 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:52:15,424 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:52:15,424 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:52:15,424 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:52:15,424 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=52601
2023-05-09T03:52:15,424 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:52:15,424 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:52:15,424 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:52:15,425 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:52:15,425 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:52:15,425 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:52:15,425 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:52:15,425 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:52:15,425 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:52:15,425 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:52:15,426 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7qtr4hwx/attempt_0/0/error.json
2023-05-09T03:52:15,426 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7qtr4hwx/attempt_0/1/error.json
2023-05-09T03:52:15,426 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7qtr4hwx/attempt_0/2/error.json
2023-05-09T03:52:15,426 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7qtr4hwx/attempt_0/3/error.json
2023-05-09T03:52:15,551 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,552 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0740051269531|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,553 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2496337890625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,553 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,553 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,553 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,554 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,554 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,554 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,554 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,554 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,554 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,555 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,555 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,555 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,555 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,555 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377692.9609375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,555 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1969.30078125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:15,556 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604335
2023-05-09T03:52:16,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=56990
2023-05-09T03:52:16,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:16,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=56988
2023-05-09T03:52:16,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=56989
2023-05-09T03:52:16,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:16,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:16,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:16,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]56990
2023-05-09T03:52:16,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:16,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:16,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:16,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]56988
2023-05-09T03:52:16,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:16,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:16,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:16,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]56989
2023-05-09T03:52:16,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:16,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:16,683 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=56991
2023-05-09T03:52:16,684 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:16,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:16,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]56991
2023-05-09T03:52:16,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:16,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:16,693 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:52:16,693 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:52:16,697 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:52:16,697 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:52:16,704 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:52:16,705 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:52:16,705 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:52:16,707 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:52:16,707 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:52:16,707 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:52:16,709 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:52:16,709 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:52:16,709 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T03:52:16,711 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T03:52:16,713 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683604336713
2023-05-09T03:52:16,713 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683604336713
2023-05-09T03:52:16,737 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:52:16,749 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:52:16,760 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:52:16,772 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:52:17,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:52:17,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:52:17,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:52:17,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:52:17,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:52:17,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:52:17,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:52:17,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:52:17,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 56990/2
2023-05-09T03:52:17,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 56988/0
2023-05-09T03:52:17,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 56991/3
2023-05-09T03:52:17,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 56989/1
2023-05-09T03:52:18,080 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T03:52:18,080 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:52:18,081 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:52:18,081 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:52:18,081 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 257, in <module>
2023-05-09T03:52:18,081 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T03:52:18,081 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T03:52:18,081 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 257, in <module>
2023-05-09T03:52:18,082 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T03:52:18,082 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     os.remove(socket_name)
2023-05-09T03:52:18,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T03:52:18,083 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/.ts.sock.29500'
2023-05-09T03:52:18,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T03:52:18,083 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     os.remove(socket_name)
2023-05-09T03:52:18,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T03:52:18,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T03:52:18,083 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/.ts.sock.29500'
2023-05-09T03:52:18,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T03:52:18,084 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T03:52:18,083 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:18,083 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:18,084 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:52:18,083 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:18,083 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:18,084 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T03:52:18,083 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:18,084 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:52:18,083 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:18,085 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:52:18,085 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:52:18,085 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:52:18,086 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T03:52:18,086 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T03:52:18,087 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T03:52:18,087 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T03:52:18,087 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T03:52:18,087 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T03:52:18,088 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T03:52:18,088 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T03:52:18,088 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T03:52:18,089 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T03:52:18,089 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/c18ecf1488134f76990dbedd38134bca/pippy_handler.py", line 60, in initialize
2023-05-09T03:52:18,089 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T03:52:18,089 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
2023-05-09T03:52:18,089 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2023-05-09T03:52:18,090 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 809, in from_pretrained
2023-05-09T03:52:18,091 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:52:18,091 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
2023-05-09T03:52:18,091 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:52:18,091 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 635, in _get_config_dict
2023-05-09T03:52:18,091 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise EnvironmentError(
2023-05-09T03:52:18,091 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - OSError: Can't load the configuration of '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546' is the correct path to a directory containing a config.json file
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T03:52:18,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T03:52:18,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/c18ecf1488134f76990dbedd38134bca/pippy_handler.py", line 60, in initialize
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 809, in from_pretrained
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:52:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 635, in _get_config_dict
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise EnvironmentError(
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - OSError: Can't load the configuration of '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546' is the correct path to a directory containing a config.json file
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_config_file = cached_file(
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/utils/hub.py", line 409, in cached_file
2023-05-09T03:52:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     resolved_file = hf_hub_download(
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 112, in _inner_fn
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     validate_repo_id(arg_value)
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 160, in validate_repo_id
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise HFValidationError(
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. Use `repo_type` argument if needed.
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T03:52:18,096 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T03:52:18,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T03:52:18,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T03:52:18,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T03:52:18,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T03:52:18,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T03:52:18,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T03:52:18,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/c18ecf1488134f76990dbedd38134bca/pippy_handler.py", line 60, in initialize
2023-05-09T03:52:18,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = AutoModelForCausalLM.from_pretrained(
2023-05-09T03:52:18,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
2023-05-09T03:52:18,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config, kwargs = AutoConfig.from_pretrained(
2023-05-09T03:52:18,086 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:52:18,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 809, in from_pretrained
2023-05-09T03:52:18,086 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:52:18,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:52:18,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
2023-05-09T03:52:18,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2023-05-09T03:52:18,098 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T03:52:18,098 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T03:52:18,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/configuration_utils.py", line 635, in _get_config_dict
2023-05-09T03:52:18,099 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:52:18,099 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:52:18,099 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683604338099
2023-05-09T03:52:18,099 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise EnvironmentError(
2023-05-09T03:52:18,099 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683604338099
2023-05-09T03:52:18,099 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:18,099 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:52:18,099 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:52:18,099 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:18,099 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:52:18,099 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:52:18,099 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - OSError: Can't load the configuration of '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/ubuntu/serve/examples/large_models/Huggingface_pippy/model/models--facebook--opt-30b/snapshots/ceea0a90ac0f6fae7c2c34bcb40477438c152546' is the correct path to a directory containing a config.json file
2023-05-09T03:52:18,100 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:52:18,100 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:52:18,100 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:52:18,100 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:52:18,490 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:52:18,490 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T03:52:19,101 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:52:19,101 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:52:20,602 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:52:20,603 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:52:20,604 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:52:20,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:52:20,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ndrj2iwg
2023-05-09T03:52:20,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:52:20,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:52:20,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:52:20,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:52:20,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:52:20,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=36743
2023-05-09T03:52:20,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:52:20,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:52:20,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:52:20,692 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ndrj2iwg/attempt_0/0/error.json
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ndrj2iwg/attempt_0/1/error.json
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ndrj2iwg/attempt_0/2/error.json
2023-05-09T03:52:20,693 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_ndrj2iwg/attempt_0/3/error.json
2023-05-09T03:52:21,880 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=57928
2023-05-09T03:52:21,881 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:21,883 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=57929
2023-05-09T03:52:21,883 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:21,889 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:21,889 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]57928
2023-05-09T03:52:21,889 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:21,889 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:21,892 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:21,892 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]57929
2023-05-09T03:52:21,892 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:21,892 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:21,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=57930
2023-05-09T03:52:21,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:21,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:21,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]57930
2023-05-09T03:52:21,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:21,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:21,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=57931
2023-05-09T03:52:21,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:21,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:21,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]57931
2023-05-09T03:52:21,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:21,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:21,959 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:52:21,959 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:52:21,959 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:52:21,959 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:52:21,962 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:52:21,962 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:52:21,962 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:21,962 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:21,963 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:52:21,962 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:52:21,963 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:52:21,963 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method) ~[?:?]
	at java.lang.Object.wait(Object.java:328) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:52:21,963 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method) ~[?:?]
	at java.lang.Object.wait(Object.java:328) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:52:21,964 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:52:21,964 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:52:21,964 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:52:21,964 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:52:21,964 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:52:21,964 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:52:21,964 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:52:21,964 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:52:21,965 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:52:21,965 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T03:52:21,965 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:52:21,965 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:52:22,965 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:52:22,965 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:52:24,465 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:52:24,465 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:52:24,465 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:52:24,465 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:52:24,465 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:52:24,466 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:52:24,468 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:52:24,469 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xfa8sfvs
2023-05-09T03:52:24,469 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:52:24,469 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=53239
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xfa8sfvs/attempt_0/0/error.json
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xfa8sfvs/attempt_0/1/error.json
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xfa8sfvs/attempt_0/2/error.json
2023-05-09T03:52:24,553 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xfa8sfvs/attempt_0/3/error.json
2023-05-09T03:52:25,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=58028
2023-05-09T03:52:25,754 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:25,755 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=58025
2023-05-09T03:52:25,755 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=58027
2023-05-09T03:52:25,755 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:25,755 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:25,757 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=58026
2023-05-09T03:52:25,757 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:52:25,762 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:25,762 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]58028
2023-05-09T03:52:25,762 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:25,762 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:25,764 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:25,764 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]58027
2023-05-09T03:52:25,764 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:25,764 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:25,764 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:25,764 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]58025
2023-05-09T03:52:25,764 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:25,764 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:25,766 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:52:25,766 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]58026
2023-05-09T03:52:25,766 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:52:25,766 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:52:25,766 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:52:25,766 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T03:52:25,766 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:52:25,766 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:52:25,768 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:52:25,768 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:52:25,768 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:25,768 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T03:52:25,769 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:52:25,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:52:25,769 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T03:52:25,769 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3531e584(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:52:25,769 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3531e584(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T03:52:25,770 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:52:25,770 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T03:52:25,770 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:52:25,770 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T03:52:25,770 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:52:25,770 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T03:52:25,770 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:52:25,770 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T03:52:25,771 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:52:25,771 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T03:52:25,771 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T03:52:25,771 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T03:52:27,771 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:52:27,771 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:53:17,020 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:53:17,020 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T03:53:17,074 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:53:17,074 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T03:53:17,292 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:53:17,292 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T03:53:17,298 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:53:17,298 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T03:53:17,314 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:53:17,314 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T03:53:17,339 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:53:17,339 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T03:53:17,339 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:53:17,339 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T03:53:17,340 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:53:17,340 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T03:53:17,340 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:53:17,340 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T03:53:17,340 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:53:17,340 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T03:53:17,349 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:53:17,349 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T03:53:17,352 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:53:17,352 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T03:53:17,410 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:53:17,410 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T03:53:17,410 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:53:17,410 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T03:53:17,412 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:53:17,412 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T03:53:17,412 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:53:17,412 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T03:53:17,413 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:53:17,413 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T03:53:17,593 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:53:17,593 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T03:53:18,904 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T03:53:18,904 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T03:53:18,904 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:53:18,905 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T03:53:18,905 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T03:53:18,905 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T03:53:18,905 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T03:53:18,905 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T03:53:18,906 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T03:53:18,906 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T03:53:18,906 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T03:53:18,906 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T03:53:18,906 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T03:53:18,906 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T03:53:18,907 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T03:53:18,907 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T03:53:18,907 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T03:53:18,907 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T03:53:18,907 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:53:18,907 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_redvkq_k
2023-05-09T03:53:18,908 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T03:53:18,908 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T03:53:19,010 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,011 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.073787689209|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,011 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.24985122680664|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,012 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,012 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,012 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,012 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,012 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,013 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,013 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,013 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,013 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,013 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,013 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,014 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,014 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,014 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377898.08203125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,014 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1763.8046875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,014 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604399
2023-05-09T03:53:19,015 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T03:53:19,015 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T03:53:19,015 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T03:53:19,015 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=42451
2023-05-09T03:53:19,015 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T03:53:19,015 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T03:53:19,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T03:53:19,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T03:53:19,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T03:53:19,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T03:53:19,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T03:53:19,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T03:53:19,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T03:53:19,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T03:53:19,017 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_redvkq_k/attempt_0/0/error.json
2023-05-09T03:53:19,017 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_redvkq_k/attempt_0/1/error.json
2023-05-09T03:53:19,017 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_redvkq_k/attempt_0/2/error.json
2023-05-09T03:53:19,017 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_redvkq_k/attempt_0/3/error.json
2023-05-09T03:53:20,225 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=58861
2023-05-09T03:53:20,226 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:53:20,226 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=58858
2023-05-09T03:53:20,226 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:53:20,234 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:53:20,234 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]58861
2023-05-09T03:53:20,234 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:53:20,234 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:53:20,235 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:53:20,235 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]58858
2023-05-09T03:53:20,235 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:53:20,235 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:53:20,237 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=58860
2023-05-09T03:53:20,238 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:53:20,238 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=58859
2023-05-09T03:53:20,239 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T03:53:20,246 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:53:20,246 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]58860
2023-05-09T03:53:20,246 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:53:20,246 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:53:20,247 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T03:53:20,247 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]58859
2023-05-09T03:53:20,248 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T03:53:20,248 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T03:53:20,248 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:53:20,248 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T03:53:20,252 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:53:20,252 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T03:53:20,259 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T03:53:20,260 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:53:20,260 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T03:53:20,262 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:53:20,262 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T03:53:20,263 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T03:53:20,264 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:53:20,264 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T03:53:20,264 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T03:53:20,266 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T03:53:20,268 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683604400268
2023-05-09T03:53:20,268 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683604400268
2023-05-09T03:53:20,292 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:53:20,304 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:53:20,315 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:53:20,327 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T03:53:21,175 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:53:21,175 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:53:21,175 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:53:21,176 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:53:21,176 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:53:21,176 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:53:21,176 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:53:21,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T03:53:21,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 58858/0
2023-05-09T03:53:21,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 58860/2
2023-05-09T03:53:21,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 58859/1
2023-05-09T03:53:21,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 58861/3
2023-05-09T03:53:47,717 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.081252604999463 seconds
2023-05-09T03:53:47,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:53:47,782 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:53:47,782 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:53:47,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.182430599001236 seconds
2023-05-09T03:53:47,892 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:53:47,894 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:53:47,894 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:53:47,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.312976915000036 seconds
2023-05-09T03:53:48,018 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:53:48,020 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:53:48,020 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:53:48,782 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:53:48,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T03:53:48,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:53:48,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.004819886000405 seconds on rank 1
2023-05-09T03:53:48,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/01747e32b22f49be9e6ef542bcefeede loaded successfully
2023-05-09T03:53:48,891 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:53:48,893 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T03:53:48,894 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:53:48,894 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0016029870002967 seconds on rank 2
2023-05-09T03:53:48,894 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/01747e32b22f49be9e6ef542bcefeede loaded successfully
2023-05-09T03:53:49,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:53:49,025 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T03:53:49,025 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:53:49,026 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0071014599998307 seconds on rank 3
2023-05-09T03:53:49,026 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/01747e32b22f49be9e6ef542bcefeede loaded successfully
2023-05-09T03:53:49,289 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.57768652300001 seconds
2023-05-09T03:53:49,349 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T03:53:49,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T03:53:49,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T03:53:50,354 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T03:53:50,356 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T03:53:50,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T03:53:50,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T03:53:50,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T03:53:50,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T03:53:50,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T03:53:50,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T03:53:50,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683604430.38 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T03:53:50,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T03:53:50,380 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T03:53:50,380 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683604430.38 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T03:53:50,380 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T03:53:50,381 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683604430.38 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T03:53:50,382 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683604430.38 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T03:54:00,871 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T03:54:04,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 0
2023-05-09T03:54:05,197 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T03:54:05,763 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T03:54:05,901 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T03:54:05,901 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 16.552065551999476 seconds on rank 0
2023-05-09T03:54:05,901 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/01747e32b22f49be9e6ef542bcefeede loaded successfully
2023-05-09T03:54:05,902 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:54:05,902 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:54:05,902 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 45575
2023-05-09T03:54:05,902 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 45575
2023-05-09T03:54:05,902 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T03:54:05,902 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T03:54:05,903 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:48558.0|#WorkerName:W-29500-opt_1.0,Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604445
2023-05-09T03:54:05,903 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:60.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604445
2023-05-09T03:54:12,108 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683604452
2023-05-09T03:54:12,109 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683604452109
2023-05-09T03:54:12,109 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683604452109
2023-05-09T03:54:12,110 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend received inference at: 1683604452
2023-05-09T03:54:12,110 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-09T03:54:12,110 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - '
2023-05-09T03:54:12,110 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
2023-05-09T03:54:12,110 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
2023-05-09T03:54:12,111 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-09T03:54:12,114 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:12,115 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py:1713: UserWarning: Received extra arguments: {'use_cache', 'return_dict', 'output_attentions', 'output_hidden_states', 'past_key_values', 'attention_mask'}. They might have already been given a concrete value during pipeline compilation via `concrete_args`. We will ignore the current inputs and use the values given during compilation.
2023-05-09T03:54:12,115 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-09T03:54:12,117 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:12,883 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:13,646 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:14,408 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:15,168 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:15,171 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:15,209 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:15,246 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:15,282 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:15,323 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:15,326 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:15,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:15,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:15,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:15,475 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:15,477 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:15,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:15,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:15,586 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:15,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:15,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:15,667 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:15,703 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:15,739 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:15,779 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:15,783 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:15,819 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:15,856 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:15,891 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:15,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:15,934 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:15,971 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:16,007 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:16,043 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:16,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:16,085 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:16,123 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:16,160 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:16,196 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:16,237 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:16,241 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:16,278 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:16,315 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:16,351 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:16,392 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-09T03:54:16,395 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-09T03:54:16,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-09T03:54:16,469 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-09T03:54:16,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-09T03:54:16,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI\n\nThe following\n\n\nThe\n']
2023-05-09T03:54:16,548 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:4438.02|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683604456,4a06728f-f197-4a12-b4c8-6fc2e670f21d, pattern=[METRICS]
2023-05-09T03:54:16,548 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:4438.02|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683604456,4a06728f-f197-4a12-b4c8-6fc2e670f21d, pattern=[METRICS]
2023-05-09T03:54:16,548 [INFO ] W-29500-opt_1.0-stdout MODEL_METRICS - HandlerTime.ms:4438.02|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,requestID:4a06728f-f197-4a12-b4c8-6fc2e670f21d,timestamp:1683604456
2023-05-09T03:54:16,549 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4438.11|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683604456,4a06728f-f197-4a12-b4c8-6fc2e670f21d, pattern=[METRICS]
2023-05-09T03:54:16,549 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4438.11|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,1683604456,4a06728f-f197-4a12-b4c8-6fc2e670f21d, pattern=[METRICS]
2023-05-09T03:54:16,549 [INFO ] W-29500-opt_1.0-stdout MODEL_METRICS - PredictionTime.ms:4438.11|#ModelName:opt,Level:Model|#hostname:ip-172-31-5-255,requestID:4a06728f-f197-4a12-b4c8-6fc2e670f21d,timestamp:1683604456
2023-05-09T03:54:16,550 [INFO ] W-29500-opt_1.0 ACCESS_LOG - /127.0.0.1:54418 "PUT /predictions/opt HTTP/1.1" 200 4444
2023-05-09T03:54:16,550 [INFO ] W-29500-opt_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604456
2023-05-09T03:54:16,550 [INFO ] W-29500-opt_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4440015.189|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683604456
2023-05-09T03:54:16,550 [INFO ] W-29500-opt_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:175.712|#model_name:opt,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683604456
2023-05-09T03:54:16,550 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.job.Job - Waiting time ns: 175712, Backend time ns: 4441362019
2023-05-09T03:54:16,550 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.job.Job - Waiting time ns: 175712, Backend time ns: 4441362019
2023-05-09T03:54:16,550 [INFO ] W-29500-opt_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604456
2023-05-09T03:54:16,550 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:54:16,550 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T03:54:16,550 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4439
2023-05-09T03:54:16,550 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4439
2023-05-09T03:54:16,551 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604456
2023-05-09T03:54:18,583 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,583 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0735626220703|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,583 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2500762939453|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,583 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,583 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:68.264721208963|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:15720.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:67.85652249435469|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:15626.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:67.89126281049158|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:15634.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.37901684905333|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:17128.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,584 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:367227.16796875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,585 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11829.3828125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T03:54:18,585 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683604458
2023-05-09T04:37:02,831 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:37:02,831 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:37:02,885 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:37:02,885 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:37:03,083 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:37:03,083 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:37:03,089 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:37:03,089 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:37:03,108 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:37:03,108 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:37:03,133 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:37:03,133 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:37:03,133 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:37:03,133 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:37:03,133 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:37:03,133 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:37:03,134 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:37:03,134 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:37:03,134 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:37:03,134 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:37:03,144 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:37:03,144 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:37:03,145 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:37:03,145 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:37:03,208 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:37:03,208 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:37:03,208 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:37:03,208 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:37:03,210 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:37:03,210 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:37:03,210 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:37:03,210 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:37:03,211 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:37:03,211 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:37:03,393 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:37:03,393 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:37:04,695 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:37:04,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:37:04,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:37:04,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:37:04,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:37:04,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:37:04,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:37:04,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:37:04,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:37:04,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:37:04,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:37:04,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:37:04,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:37:04,700 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:37:04,700 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:37:04,700 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:37:04,700 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:37:04,700 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:37:04,701 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:37:04,702 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_s6epdled
2023-05-09T04:37:04,702 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:37:04,702 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:37:04,748 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:37:04,748 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:37:04,748 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:37:04,748 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=37809
2023-05-09T04:37:04,749 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:37:04,749 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:37:04,749 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:37:04,749 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:37:04,749 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:37:04,749 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:37:04,749 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:37:04,749 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:37:04,750 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:37:04,750 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:37:04,750 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_s6epdled/attempt_0/0/error.json
2023-05-09T04:37:04,750 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_s6epdled/attempt_0/1/error.json
2023-05-09T04:37:04,750 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_s6epdled/attempt_0/2/error.json
2023-05-09T04:37:04,750 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_s6epdled/attempt_0/3/error.json
2023-05-09T04:37:05,475 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,477 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0735321044922|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,477 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25010681152344|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,478 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,478 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,478 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,478 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,480 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,480 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,480 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,480 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,480 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:376615.40625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,480 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3211.01953125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,481 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607025
2023-05-09T04:37:05,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4709
2023-05-09T04:37:05,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:05,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4712
2023-05-09T04:37:05,950 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:05,951 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4710
2023-05-09T04:37:05,951 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:05,951 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4711
2023-05-09T04:37:05,952 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:05,955 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:05,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4709
2023-05-09T04:37:05,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:05,956 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:05,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:05,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:05,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4712
2023-05-09T04:37:05,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:05,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4710
2023-05-09T04:37:05,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:05,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:05,960 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:05,960 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:05,960 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4711
2023-05-09T04:37:05,960 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:05,960 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:05,961 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:37:05,961 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:37:05,964 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:37:05,964 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:37:05,971 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:37:05,972 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:37:05,972 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:37:05,974 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:37:05,974 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:37:05,975 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:37:05,976 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:37:05,976 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:37:05,976 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T04:37:05,978 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T04:37:05,980 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607025980
2023-05-09T04:37:05,980 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607025980
2023-05-09T04:37:06,001 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:37:06,012 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:37:06,021 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:37:06,031 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:37:06,720 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:37:06,721 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:37:06,721 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:37:06,721 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:37:06,721 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 257, in <module>
2023-05-09T04:37:06,721 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:37:06,721 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:37:06,721 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 257, in <module>
2023-05-09T04:37:06,721 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:37:06,722 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     os.remove(socket_name)
2023-05-09T04:37:06,722 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:37:06,722 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/.ts.sock.29500'
2023-05-09T04:37:06,723 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     os.remove(socket_name)
2023-05-09T04:37:06,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:37:06,723 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/.ts.sock.29500'
2023-05-09T04:37:06,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:37:06,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:37:06,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:37:06,724 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 100, in load
2023-05-09T04:37:06,724 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-05-09T04:37:06,724 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-05-09T04:37:06,724 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-05-09T04:37:06,724 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:06,724 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:06,724 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:06,724 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:06,724 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-05-09T04:37:06,724 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:06,724 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:06,724 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:06,725 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-05-09T04:37:06,724 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:06,726 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:37:06,726 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-05-09T04:37:06,726 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:37:06,726 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-05-09T04:37:06,726 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2023-05-09T04:37:06,726 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2023-05-09T04:37:06,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2023-05-09T04:37:06,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-05-09T04:37:06,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/3745b8354de04d36b415f7a779007e39/pippy_handler.py", line 11, in <module>
2023-05-09T04:37:06,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     from ts.handler_utils.distributed.pt_pippy import get_pipeline_driver
2023-05-09T04:37:06,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 81
2023-05-09T04:37:06,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     index_filename = ctx.model_yaml_config["handler"]["index_filename"]
2023-05-09T04:37:06,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     ^
2023-05-09T04:37:06,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - IndentationError: expected an indented block
2023-05-09T04:37:06,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:37:06,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:37:06,729 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:37:06,730 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:37:06,730 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:37:06,730 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:37:06,730 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:37:06,730 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:37:06,730 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:37:06,730 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:37:06,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 100, in load
2023-05-09T04:37:06,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-05-09T04:37:06,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-05-09T04:37:06,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/3745b8354de04d36b415f7a779007e39/pippy_handler.py", line 11, in <module>
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     from ts.handler_utils.distributed.pt_pippy import get_pipeline_driver
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 81
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     index_filename = ctx.model_yaml_config["handler"]["index_filename"]
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     ^
2023-05-09T04:37:06,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - IndentationError: expected an indented block
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 100, in load
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-05-09T04:37:06,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/3745b8354de04d36b415f7a779007e39/pippy_handler.py", line 11, in <module>
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     from ts.handler_utils.distributed.pt_pippy import get_pipeline_driver
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 81
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     index_filename = ctx.model_yaml_config["handler"]["index_filename"]
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     ^
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - IndentationError: expected an indented block
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:37:06,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 100, in load
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2023-05-09T04:37:06,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-05-09T04:37:06,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/3745b8354de04d36b415f7a779007e39/pippy_handler.py", line 11, in <module>
2023-05-09T04:37:06,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     from ts.handler_utils.distributed.pt_pippy import get_pipeline_driver
2023-05-09T04:37:06,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 81
2023-05-09T04:37:06,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     index_filename = ctx.model_yaml_config["handler"]["index_filename"]
2023-05-09T04:37:06,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     ^
2023-05-09T04:37:06,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - IndentationError: expected an indented block
2023-05-09T04:37:06,726 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:37:06,726 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:37:06,738 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T04:37:06,738 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T04:37:06,738 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:37:06,738 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:37:06,738 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683607026738
2023-05-09T04:37:06,738 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683607026738
2023-05-09T04:37:06,738 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:37:06,738 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:37:06,738 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:37:06,738 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:37:06,739 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:37:06,739 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:37:06,999 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:37:06,999 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:37:06,999 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:37:06,999 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:37:07,739 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:37:07,739 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:37:09,239 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:37:09,240 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:37:09,240 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:37:09,240 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:37:09,240 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:37:09,240 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:37:09,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:37:09,243 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:37:09,243 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_27hih5r9
2023-05-09T04:37:09,243 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:37:09,243 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=34665
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:37:09,363 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:37:09,364 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_27hih5r9/attempt_0/0/error.json
2023-05-09T04:37:09,364 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_27hih5r9/attempt_0/1/error.json
2023-05-09T04:37:09,364 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_27hih5r9/attempt_0/2/error.json
2023-05-09T04:37:09,364 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_27hih5r9/attempt_0/3/error.json
2023-05-09T04:37:10,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4808
2023-05-09T04:37:10,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:10,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:10,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4808
2023-05-09T04:37:10,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:10,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:10,553 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4807
2023-05-09T04:37:10,554 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:10,554 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4806
2023-05-09T04:37:10,554 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:10,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:10,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:10,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4807
2023-05-09T04:37:10,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4806
2023-05-09T04:37:10,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:10,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:10,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:10,563 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:10,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4809
2023-05-09T04:37:10,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:10,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:10,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4809
2023-05-09T04:37:10,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:10,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:10,583 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:37:10,583 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:37:10,583 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:37:10,583 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:37:10,585 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:37:10,585 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:37:10,585 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:10,585 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:10,585 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:37:10,585 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:37:10,585 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:37:10,585 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@5962f216(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:37:10,585 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@5962f216(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:37:10,587 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:37:10,587 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:37:10,587 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:37:10,587 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:37:10,587 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:37:10,587 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:37:10,587 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:37:10,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:37:10,587 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:37:10,587 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:37:10,587 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:37:10,587 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:37:10,587 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:37:11,588 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:37:11,588 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:37:13,088 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:37:13,089 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:37:13,093 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:37:13,094 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_q7u3ihqj
2023-05-09T04:37:13,094 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:37:13,094 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=58071
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_q7u3ihqj/attempt_0/0/error.json
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_q7u3ihqj/attempt_0/1/error.json
2023-05-09T04:37:13,209 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_q7u3ihqj/attempt_0/2/error.json
2023-05-09T04:37:13,210 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_q7u3ihqj/attempt_0/3/error.json
2023-05-09T04:37:14,391 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4905
2023-05-09T04:37:14,391 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:14,391 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4903
2023-05-09T04:37:14,391 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:14,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:14,399 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4905
2023-05-09T04:37:14,400 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:14,400 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:14,400 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:14,400 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4903
2023-05-09T04:37:14,400 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4904
2023-05-09T04:37:14,400 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:14,400 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:14,400 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:14,406 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4906
2023-05-09T04:37:14,406 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:14,409 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:14,409 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4904
2023-05-09T04:37:14,409 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:14,409 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:14,414 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:14,414 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4906
2023-05-09T04:37:14,415 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:14,415 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:14,415 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:37:14,415 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:37:14,415 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:37:14,415 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:37:14,417 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:37:14,417 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:14,417 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:37:14,417 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:14,417 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:37:14,418 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:37:14,418 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:37:14,418 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@7ba7321f(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:37:14,418 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@7ba7321f(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:37:14,419 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:37:14,419 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:37:14,419 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:37:14,419 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:37:14,419 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:37:14,419 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:37:14,419 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:37:14,419 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:37:14,419 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T04:37:14,419 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T04:37:14,420 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:37:14,420 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:37:16,420 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:37:16,420 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:37:17,909 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:37:17,910 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:37:17,910 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:37:17,910 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:37:17,910 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:37:17,910 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:37:17,910 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:37:17,910 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:37:17,910 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:37:17,911 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:37:17,913 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:37:17,913 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gbq0n7rf
2023-05-09T04:37:17,913 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:37:17,913 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=55811
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gbq0n7rf/attempt_0/0/error.json
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gbq0n7rf/attempt_0/1/error.json
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gbq0n7rf/attempt_0/2/error.json
2023-05-09T04:37:18,097 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gbq0n7rf/attempt_0/3/error.json
2023-05-09T04:37:19,274 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5001
2023-05-09T04:37:19,275 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:19,275 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=4999
2023-05-09T04:37:19,275 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:19,282 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5002
2023-05-09T04:37:19,282 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:19,283 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:19,283 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5001
2023-05-09T04:37:19,283 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:19,283 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:19,284 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:19,284 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]4999
2023-05-09T04:37:19,284 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:19,284 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:19,287 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5000
2023-05-09T04:37:19,287 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:37:19,290 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:19,290 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5002
2023-05-09T04:37:19,291 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:19,291 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:19,296 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:37:19,296 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5000
2023-05-09T04:37:19,296 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:37:19,296 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:37:19,296 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:37:19,296 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:37:19,296 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:37:19,296 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:37:19,298 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:37:19,298 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:37:19,298 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:19,298 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:37:19,298 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:37:19,298 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:37:19,298 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:37:19,298 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@547b76c9(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:37:19,298 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@547b76c9(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:37:19,300 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:37:19,300 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:37:19,300 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:37:19,300 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:37:19,300 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:37:19,300 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:37:19,300 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:37:19,300 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:37:19,300 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:37:19,300 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T04:37:19,300 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:37:19,300 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T04:39:05,526 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:39:05,526 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:39:05,581 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:39:05,581 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:39:05,779 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:39:05,779 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:39:05,785 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:39:05,785 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:39:05,801 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:39:05,801 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:39:05,827 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:39:05,827 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:39:05,827 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:39:05,827 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:39:05,827 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:39:05,827 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:39:05,827 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:39:05,827 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:39:05,828 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:39:05,828 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:39:05,837 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:39:05,837 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:39:05,840 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:39:05,840 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:39:05,902 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:39:05,902 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:39:05,902 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:39:05,902 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:39:05,904 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:39:05,904 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:39:05,904 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:39:05,904 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:39:05,905 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:39:05,905 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:39:06,086 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:39:06,086 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:39:07,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:39:07,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:39:07,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:39:07,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:39:07,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:39:07,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:39:07,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:39:07,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:39:07,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:39:07,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:39:07,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:39:07,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:39:07,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:39:07,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:39:07,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:39:07,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:39:07,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:39:07,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:39:07,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:39:07,332 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_de6qrpx2
2023-05-09T04:39:07,332 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:39:07,332 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:39:07,476 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,477 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0732765197754|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,478 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25036239624023|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,478 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,478 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,479 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,480 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,480 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,480 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,480 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,481 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,481 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,481 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377112.69140625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,481 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2712.3515625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,481 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607147
2023-05-09T04:39:07,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:39:07,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:39:07,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:39:07,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=59437
2023-05-09T04:39:07,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:39:07,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:39:07,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:39:07,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:39:07,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:39:07,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:39:07,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:39:07,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:39:07,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:39:07,590 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:39:07,590 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_de6qrpx2/attempt_0/0/error.json
2023-05-09T04:39:07,590 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_de6qrpx2/attempt_0/1/error.json
2023-05-09T04:39:07,590 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_de6qrpx2/attempt_0/2/error.json
2023-05-09T04:39:07,590 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_de6qrpx2/attempt_0/3/error.json
2023-05-09T04:39:08,770 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5805
2023-05-09T04:39:08,771 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:39:08,772 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5802
2023-05-09T04:39:08,772 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:39:08,779 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:39:08,779 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5805
2023-05-09T04:39:08,779 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:39:08,779 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:39:08,779 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:39:08,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5802
2023-05-09T04:39:08,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:39:08,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:39:08,782 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5804
2023-05-09T04:39:08,783 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:39:08,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5803
2023-05-09T04:39:08,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:39:08,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:39:08,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5804
2023-05-09T04:39:08,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:39:08,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:39:08,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:39:08,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5803
2023-05-09T04:39:08,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:39:08,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:39:08,793 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:39:08,793 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:39:08,797 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:39:08,797 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:39:08,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:39:08,805 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:39:08,805 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:39:08,807 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:39:08,807 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:39:08,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:39:08,809 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:39:08,809 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:39:08,809 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T04:39:08,811 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T04:39:08,813 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607148813
2023-05-09T04:39:08,813 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607148813
2023-05-09T04:39:08,835 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:39:08,845 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:39:08,855 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:39:08,865 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:39:09,035 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:39:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:39:09,037 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 100, in load
2023-05-09T04:39:09,037 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-05-09T04:39:09,037 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-05-09T04:39:09,037 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-05-09T04:39:09,037 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-05-09T04:39:09,038 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-05-09T04:39:09,038 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-05-09T04:39:09,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/d34fd276067e4b9a88ebe3a72d59c300/pippy_handler.py", line 11, in <module>
2023-05-09T04:39:09,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     from ts.handler_utils.distributed.pt_pippy import get_pipeline_driver
2023-05-09T04:39:09,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 81
2023-05-09T04:39:09,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     index_filename = ctx.model_yaml_config["handler"]["index_filename"]
2023-05-09T04:39:09,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     ^
2023-05-09T04:39:09,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - IndentationError: expected an indented block
2023-05-09T04:39:09,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:39:09,047 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:39:09,047 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:39:09,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 100, in load
2023-05-09T04:39:09,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-05-09T04:39:09,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-05-09T04:39:09,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-05-09T04:39:09,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-05-09T04:39:09,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-05-09T04:39:09,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-05-09T04:39:09,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/d34fd276067e4b9a88ebe3a72d59c300/pippy_handler.py", line 11, in <module>
2023-05-09T04:39:09,038 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     from ts.handler_utils.distributed.pt_pippy import get_pipeline_driver
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 81
2023-05-09T04:39:09,038 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     index_filename = ctx.model_yaml_config["handler"]["index_filename"]
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     ^
2023-05-09T04:39:09,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - IndentationError: expected an indented block
2023-05-09T04:39:09,049 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T04:39:09,049 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T04:39:09,050 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:39:09,050 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:39:09,050 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683607149050
2023-05-09T04:39:09,050 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683607149050
2023-05-09T04:39:09,050 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:09,050 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:09,050 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:39:09,050 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:39:09,050 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:39:09,050 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:09,050 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:39:09,050 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:09,051 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:39:09,051 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:39:09,054 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:39:09,054 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:39:09,064 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:39:09,064 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:39:10,051 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:39:10,051 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:39:11,531 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:39:11,531 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:39:11,531 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:39:11,531 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:39:11,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:39:11,534 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:39:11,534 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_md_835d0
2023-05-09T04:39:11,534 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:39:11,534 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=39843
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:39:11,619 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:39:11,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:39:11,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:39:11,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:39:11,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_md_835d0/attempt_0/0/error.json
2023-05-09T04:39:11,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_md_835d0/attempt_0/1/error.json
2023-05-09T04:39:11,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_md_835d0/attempt_0/2/error.json
2023-05-09T04:39:11,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_md_835d0/attempt_0/3/error.json
2023-05-09T04:39:12,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5892
2023-05-09T04:39:12,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:39:12,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5893
2023-05-09T04:39:12,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:39:12,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:39:12,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5892
2023-05-09T04:39:12,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:39:12,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:39:12,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:39:12,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5893
2023-05-09T04:39:12,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:39:12,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:39:12,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5891
2023-05-09T04:39:12,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:39:12,815 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=5894
2023-05-09T04:39:12,815 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:39:12,817 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:39:12,817 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5891
2023-05-09T04:39:12,817 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:39:12,817 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:39:12,824 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:39:12,824 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]5894
2023-05-09T04:39:12,824 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:39:12,824 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:39:12,824 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:39:12,824 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:39:12,824 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:39:12,824 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:39:12,826 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:12,826 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:39:12,826 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:39:12,826 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:39:12,826 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:39:12,827 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:39:12,827 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:39:12,827 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@7193580e(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:39:12,827 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@7193580e(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:39:12,829 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:39:12,829 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:39:12,829 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:39:12,829 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:39:12,829 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:39:12,829 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:39:12,829 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:39:12,829 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:39:12,829 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:39:12,829 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:39:12,829 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:39:13,830 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:39:13,830 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:40:38,322 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:40:38,322 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:40:38,375 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:40:38,375 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:40:38,607 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:40:38,607 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:40:38,612 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:40:38,612 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:40:38,628 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:40:38,628 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:40:38,653 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:40:38,653 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:40:38,653 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:40:38,653 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:40:38,654 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:40:38,654 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:40:38,654 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:40:38,654 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:40:38,654 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:40:38,654 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:40:38,664 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:40:38,664 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:40:38,665 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:40:38,665 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:40:38,723 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:40:38,723 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:40:38,723 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:40:38,723 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:40:38,725 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:40:38,725 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:40:38,726 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:40:38,726 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:40:38,727 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:40:38,727 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:40:38,904 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:40:38,904 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:40:40,165 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:40:40,165 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:40:40,165 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:40:40,166 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:40:40,166 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:40:40,166 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:40:40,166 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:40:40,166 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:40:40,167 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:40:40,167 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:40:40,167 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:40:40,167 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:40:40,167 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:40:40,167 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:40:40,168 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:40:40,168 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:40:40,168 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:40:40,168 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:40:40,168 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:40:40,168 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bmv22hdz
2023-05-09T04:40:40,169 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:40:40,169 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:40:40,303 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,304 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0731163024902|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,304 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2505226135254|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,305 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,305 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,305 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,305 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,306 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,306 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,306 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,306 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,306 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,306 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,307 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,307 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,307 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,307 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:377030.28515625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,307 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2793.37890625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,307 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607240
2023-05-09T04:40:40,375 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:40:40,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:40:40,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:40:40,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=34191
2023-05-09T04:40:40,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:40:40,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:40:40,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:40:40,376 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:40:40,377 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:40:40,377 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:40:40,377 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:40:40,377 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:40:40,377 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:40:40,377 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:40:40,378 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bmv22hdz/attempt_0/0/error.json
2023-05-09T04:40:40,378 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bmv22hdz/attempt_0/1/error.json
2023-05-09T04:40:40,378 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bmv22hdz/attempt_0/2/error.json
2023-05-09T04:40:40,378 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bmv22hdz/attempt_0/3/error.json
2023-05-09T04:40:41,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=7258
2023-05-09T04:40:41,567 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:40:41,569 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=7259
2023-05-09T04:40:41,569 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:40:41,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=7257
2023-05-09T04:40:41,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:40:41,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:40:41,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]7258
2023-05-09T04:40:41,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:40:41,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:40:41,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=7256
2023-05-09T04:40:41,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:40:41,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:40:41,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]7259
2023-05-09T04:40:41,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:40:41,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:40:41,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:40:41,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]7257
2023-05-09T04:40:41,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:40:41,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:40:41,586 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:40:41,586 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]7256
2023-05-09T04:40:41,586 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:40:41,586 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:40:41,587 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:40:41,587 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:40:41,591 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:40:41,591 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:40:41,598 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:40:41,599 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:40:41,599 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:40:41,601 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:40:41,601 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:40:41,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:40:41,603 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:40:41,603 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:40:41,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T04:40:41,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T04:40:41,607 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607241607
2023-05-09T04:40:41,607 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607241607
2023-05-09T04:40:41,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:40:41,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:40:41,648 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:40:41,657 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:40:41,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:40:41,831 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:40:41,831 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 100, in load
2023-05-09T04:40:41,831 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-05-09T04:40:41,831 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-05-09T04:40:41,831 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:41,831 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:41,832 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-05-09T04:40:41,832 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:40:41,832 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:40:41,832 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-05-09T04:40:41,832 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-05-09T04:40:41,832 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-05-09T04:40:41,832 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-05-09T04:40:41,833 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2023-05-09T04:40:41,833 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2023-05-09T04:40:41,833 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2023-05-09T04:40:41,833 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-05-09T04:40:41,833 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/8eb5c00a4659403ebb72856f4d52eced/pippy_handler.py", line 11, in <module>
2023-05-09T04:40:41,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     from ts.handler_utils.distributed.pt_pippy import get_pipeline_driver
2023-05-09T04:40:41,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 86
2023-05-09T04:40:41,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     if index_filename not None:
2023-05-09T04:40:41,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -                           ^
2023-05-09T04:40:41,834 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - SyntaxError: invalid syntax
2023-05-09T04:40:41,839 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:40:41,839 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:40:41,840 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:40:41,840 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:41,840 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:40:41,840 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:41,840 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:40:41,840 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:40:41,840 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:40:41,840 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:40:41,840 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 100, in load
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _load_handler_file
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2023-05-09T04:40:41,841 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-05-09T04:40:41,842 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/8eb5c00a4659403ebb72856f4d52eced/pippy_handler.py", line 11, in <module>
2023-05-09T04:40:41,842 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     from ts.handler_utils.distributed.pt_pippy import get_pipeline_driver
2023-05-09T04:40:41,842 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 86
2023-05-09T04:40:41,842 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     if index_filename not None:
2023-05-09T04:40:41,842 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -                           ^
2023-05-09T04:40:41,842 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - SyntaxError: invalid syntax
2023-05-09T04:40:41,832 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:40:41,832 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:40:41,843 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T04:40:41,843 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T04:40:41,844 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:40:41,844 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:40:41,844 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683607241844
2023-05-09T04:40:41,844 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683607241844
2023-05-09T04:40:41,844 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:40:41,844 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:40:41,844 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:41,844 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:40:41,844 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:41,844 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:40:41,844 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:41,844 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:41,845 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:40:41,845 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:40:41,848 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:40:41,848 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:40:41,859 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:40:41,859 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:40:42,846 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:40:42,846 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:40:44,327 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:40:44,328 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:40:44,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:40:44,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:40:44,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:40:44,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:40:44,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:40:44,329 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:40:44,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:40:44,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_f6f6l5jv
2023-05-09T04:40:44,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:40:44,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=56655
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:40:44,460 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:40:44,461 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_f6f6l5jv/attempt_0/0/error.json
2023-05-09T04:40:44,461 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_f6f6l5jv/attempt_0/1/error.json
2023-05-09T04:40:44,461 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_f6f6l5jv/attempt_0/2/error.json
2023-05-09T04:40:44,461 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_f6f6l5jv/attempt_0/3/error.json
2023-05-09T04:40:45,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=7349
2023-05-09T04:40:45,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:40:45,641 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:40:45,641 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]7349
2023-05-09T04:40:45,641 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:40:45,642 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:40:45,656 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=7348
2023-05-09T04:40:45,656 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:40:45,657 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=7351
2023-05-09T04:40:45,657 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:40:45,657 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=7350
2023-05-09T04:40:45,657 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:40:45,665 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:40:45,665 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]7348
2023-05-09T04:40:45,665 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:40:45,665 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:40:45,666 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:40:45,666 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]7351
2023-05-09T04:40:45,666 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:40:45,666 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:40:45,666 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:40:45,666 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]7350
2023-05-09T04:40:45,666 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:40:45,666 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:40:45,667 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:40:45,667 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:40:45,667 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:40:45,667 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:40:45,669 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:40:45,669 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:40:45,669 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:45,669 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:40:45,669 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:40:45,669 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:40:45,669 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:40:45,670 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@5773e7c5(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:40:45,670 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@5773e7c5(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:40:45,671 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:40:45,671 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:40:45,671 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:40:45,671 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:40:45,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:40:45,671 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:40:45,671 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:40:45,672 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:40:45,672 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:40:45,672 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:40:45,672 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:40:45,672 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:40:45,672 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:40:46,673 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:40:46,673 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:40:48,157 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:40:48,158 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:40:48,160 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:40:48,161 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_a8cflz07
2023-05-09T04:40:48,161 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:40:48,161 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=34819
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:40:48,330 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:40:48,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:40:48,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:40:48,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:40:48,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_a8cflz07/attempt_0/0/error.json
2023-05-09T04:40:48,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_a8cflz07/attempt_0/1/error.json
2023-05-09T04:40:48,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_a8cflz07/attempt_0/2/error.json
2023-05-09T04:40:48,331 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_a8cflz07/attempt_0/3/error.json
2023-05-09T04:42:58,002 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:42:58,002 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:42:58,054 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:42:58,054 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:42:58,263 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:42:58,263 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:42:58,268 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:42:58,268 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:42:58,284 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:42:58,284 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:42:58,309 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:42:58,309 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:42:58,309 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:42:58,309 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:42:58,309 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:42:58,309 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:42:58,309 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:42:58,309 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:42:58,310 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:42:58,310 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:42:58,319 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:42:58,319 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:42:58,320 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:42:58,320 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:42:58,377 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:42:58,377 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:42:58,377 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:42:58,377 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:42:58,379 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:42:58,379 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:42:58,379 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:42:58,379 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:42:58,381 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:42:58,381 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:42:58,556 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:42:58,556 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:42:59,808 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:42:59,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:42:59,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:42:59,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:42:59,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:42:59,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:42:59,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:42:59,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:42:59,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:42:59,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:42:59,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:42:59,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:42:59,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:42:59,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:42:59,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:42:59,812 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:42:59,812 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:42:59,812 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:42:59,812 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:42:59,812 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v6rb165g
2023-05-09T04:42:59,813 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:42:59,813 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:42:59,957 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,959 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0729217529297|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,959 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25071716308594|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,959 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,960 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,960 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,960 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,960 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,960 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,960 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,961 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,961 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,961 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,961 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,961 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,961 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,962 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:376926.84765625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,962 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2895.92578125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:42:59,962 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607379
2023-05-09T04:43:00,105 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:43:00,105 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:43:00,105 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:43:00,105 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=42299
2023-05-09T04:43:00,105 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:43:00,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:43:00,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:43:00,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:43:00,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:43:00,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:43:00,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:43:00,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:43:00,106 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:43:00,107 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:43:00,107 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v6rb165g/attempt_0/0/error.json
2023-05-09T04:43:00,107 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v6rb165g/attempt_0/1/error.json
2023-05-09T04:43:00,107 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v6rb165g/attempt_0/2/error.json
2023-05-09T04:43:00,107 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_v6rb165g/attempt_0/3/error.json
2023-05-09T04:43:01,280 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=8650
2023-05-09T04:43:01,281 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:43:01,288 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:43:01,289 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]8650
2023-05-09T04:43:01,289 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:43:01,289 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:43:01,293 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=8651
2023-05-09T04:43:01,293 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:43:01,297 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=8649
2023-05-09T04:43:01,298 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:43:01,298 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=8648
2023-05-09T04:43:01,298 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:43:01,301 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:43:01,302 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]8651
2023-05-09T04:43:01,302 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:43:01,302 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:43:01,306 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:43:01,306 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]8649
2023-05-09T04:43:01,306 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:43:01,306 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:43:01,307 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:43:01,307 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]8648
2023-05-09T04:43:01,307 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:43:01,307 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:43:01,307 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:43:01,307 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:43:01,311 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:43:01,311 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:43:01,318 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:43:01,319 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:43:01,319 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:43:01,321 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:43:01,321 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:43:01,322 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:43:01,323 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:43:01,323 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:43:01,324 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T04:43:01,325 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T04:43:01,327 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607381327
2023-05-09T04:43:01,327 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607381327
2023-05-09T04:43:01,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:43:01,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:43:01,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:43:01,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:43:02,590 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:43:02,590 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:43:02,590 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:43:02,590 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:43:02,590 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:43:02,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:43:02,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:43:02,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:43:02,592 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:43:02,592 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:43:02,592 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:43:02,592 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:43:02,593 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 8651/3
2023-05-09T04:43:02,593 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 8650/2
2023-05-09T04:43:02,593 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:43:02,594 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:43:02,594 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:43:02,594 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:43:02,594 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 8648/0
2023-05-09T04:43:02,596 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 8649/1
2023-05-09T04:43:59,536 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,536 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0728569030762|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,536 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25078201293945|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,536 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,536 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,536 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,537 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,537 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,537 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,537 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,537 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,537 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,537 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,537 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,538 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,538 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,538 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:346330.67578125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,538 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:33240.33203125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:43:59,538 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:9.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607439
2023-05-09T04:49:49,698 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:49:49,698 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:49:49,750 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:49:49,750 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:49:49,946 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:49:49,946 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:49:49,952 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:49:49,952 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:49:49,968 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:49:49,968 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:49:49,993 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:49:49,993 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:49:49,993 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:49:49,993 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:49:49,993 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:49:49,993 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:49:49,993 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:49:49,993 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:49:49,993 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:49:49,993 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:49:50,003 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:49:50,003 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:49:50,005 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:49:50,005 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:49:50,062 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:49:50,062 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:49:50,062 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:49:50,062 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:49:50,064 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:49:50,064 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:49:50,064 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:49:50,064 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:49:50,066 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:49:50,066 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:49:50,240 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:49:50,240 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:49:51,259 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:15.8|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,259 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0696029663086|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,260 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25403594970703|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,260 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,260 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:3.4566614556192463|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,260 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:796.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,260 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,261 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,261 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,261 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,261 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:1.1290602744484974|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,262 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:260.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,262 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,262 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,262 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,262 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,262 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:358363.08984375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,263 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:21157.25390625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,263 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607791
2023-05-09T04:49:51,536 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:49:51,537 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:49:51,537 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:49:51,538 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:49:51,538 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:49:51,538 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:49:51,538 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:49:51,538 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:49:51,538 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:49:51,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:49:51,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:49:51,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:49:51,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:49:51,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:49:51,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:49:51,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:49:51,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:49:51,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:49:51,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:49:51,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_6f590diw
2023-05-09T04:49:51,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:49:51,541 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:49:51,771 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:49:51,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:49:51,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:49:51,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=48231
2023-05-09T04:49:51,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:49:51,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:49:51,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:49:51,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:49:51,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:49:51,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:49:51,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:49:51,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:49:51,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:49:51,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:49:51,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_6f590diw/attempt_0/0/error.json
2023-05-09T04:49:51,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_6f590diw/attempt_0/1/error.json
2023-05-09T04:49:51,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_6f590diw/attempt_0/2/error.json
2023-05-09T04:49:51,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_6f590diw/attempt_0/3/error.json
2023-05-09T04:49:52,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=10910
2023-05-09T04:49:52,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:49:52,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=10908
2023-05-09T04:49:52,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:49:52,931 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:49:52,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:49:52,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]10910
2023-05-09T04:49:52,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:49:52,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:49:52,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]10908
2023-05-09T04:49:52,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:49:52,932 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:49:52,943 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=10909
2023-05-09T04:49:52,944 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:49:52,952 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:49:52,952 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]10909
2023-05-09T04:49:52,952 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:49:52,953 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:49:52,958 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=10911
2023-05-09T04:49:52,959 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:49:52,967 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:49:52,967 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]10911
2023-05-09T04:49:52,967 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:49:52,967 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:49:52,968 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:49:52,968 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:49:52,971 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:49:52,971 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:49:52,978 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:49:52,979 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:49:52,979 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:49:52,982 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:49:52,982 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:49:52,982 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:49:52,983 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:49:52,983 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:49:52,984 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T04:49:52,985 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T04:49:52,987 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607792987
2023-05-09T04:49:52,987 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607792987
2023-05-09T04:49:53,009 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:49:53,019 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:49:53,029 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:49:53,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:49:53,827 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:49:53,827 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:49:53,827 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:49:53,827 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:49:53,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:49:53,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:49:53,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:49:53,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:49:53,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:49:53,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:49:53,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:49:53,829 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:49:53,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 10909/1
2023-05-09T04:49:53,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 10910/2
2023-05-09T04:49:53,831 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 10908/0
2023-05-09T04:49:53,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:49:53,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:49:53,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:49:53,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:49:53,861 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 10911/3
2023-05-09T04:50:42,483 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 48.23468414299987 seconds
2023-05-09T04:50:42,484 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 47.21223684000006 seconds
2023-05-09T04:50:42,493 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 48.244586777999984 seconds
2023-05-09T04:50:42,493 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 48.24478486099997 seconds
2023-05-09T04:50:42,563 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:50:42,563 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:50:42,563 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:50:42,563 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:50:42,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T04:50:42,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T04:50:42,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T04:50:42,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T04:50:42,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T04:50:42,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T04:50:42,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T04:50:42,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T04:50:43,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T04:50:43,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T04:50:43,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T04:50:43,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0181380260000878 seconds on rank 2
2023-05-09T04:50:43,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/94f3b0d6bb154326b28a0c507306cdb5 loaded successfully
2023-05-09T04:50:43,588 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T04:50:43,590 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T04:50:43,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T04:50:43,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.028031202000193 seconds on rank 1
2023-05-09T04:50:43,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/94f3b0d6bb154326b28a0c507306cdb5 loaded successfully
2023-05-09T04:50:43,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T04:50:43,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T04:50:43,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T04:50:43,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0414764219999597 seconds on rank 3
2023-05-09T04:50:43,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/94f3b0d6bb154326b28a0c507306cdb5 loaded successfully
2023-05-09T04:50:43,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T04:50:43,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T04:50:43,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T04:50:43,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T04:50:43,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T04:50:43,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T04:50:43,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T04:50:43,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,620 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T04:50:43,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,627 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,628 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,629 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,630 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,631 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,633 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T04:50:43,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T04:50:43,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683607843.63 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683607843.63 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683607843.63 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T04:50:43,639 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683607843.63 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T04:50:51,253 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:23.8|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0725555419922|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25108337402344|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:44.0333507034914|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:10140.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:23.89265242313705|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:5502.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:44.31995831162064|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:10206.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,254 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:23.89265242313705|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,255 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:5502.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,255 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,255 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,255 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,255 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,255 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:356299.2578125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,255 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:23175.9296875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:51,255 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.9|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607851
2023-05-09T04:50:54,306 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T04:51:31,519 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:51:31,519 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:51:31,573 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:51:31,573 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:51:31,771 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:51:31,771 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:51:31,777 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:51:31,777 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:51:31,793 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:51:31,793 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:51:31,818 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:51:31,818 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:51:31,818 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:51:31,818 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:51:31,819 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:51:31,819 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:51:31,819 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:51:31,819 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:51:31,819 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:51:31,819 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:51:31,828 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:51:31,828 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:51:31,831 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:51:31,831 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:51:31,890 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:51:31,890 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:51:31,891 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:51:31,891 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:51:31,892 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:51:31,892 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:51:31,893 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:51:31,893 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:51:31,894 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:51:31,894 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:51:32,077 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:51:32,077 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:51:33,340 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:51:33,341 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:51:33,341 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:51:33,342 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:51:33,342 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:51:33,342 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:51:33,342 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:51:33,342 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:51:33,343 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:51:33,343 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:51:33,343 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:51:33,343 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:51:33,343 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:51:33,344 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:51:33,344 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:51:33,344 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:51:33,344 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:51:33,344 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:51:33,344 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:51:33,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_izu3fljt
2023-05-09T04:51:33,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:51:33,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:51:33,377 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,378 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0725402832031|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,378 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2510986328125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,378 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,379 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,379 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,379 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,379 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,379 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,379 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,380 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,380 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,380 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,380 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,380 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,381 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,381 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:374819.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,381 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4781.2109375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,381 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:2.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607893
2023-05-09T04:51:33,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:51:33,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:51:33,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:51:33,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=53765
2023-05-09T04:51:33,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:51:33,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:51:33,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:51:33,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:51:33,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:51:33,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:51:33,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:51:33,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:51:33,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:51:33,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:51:33,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_izu3fljt/attempt_0/0/error.json
2023-05-09T04:51:33,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_izu3fljt/attempt_0/1/error.json
2023-05-09T04:51:33,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_izu3fljt/attempt_0/2/error.json
2023-05-09T04:51:33,447 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_izu3fljt/attempt_0/3/error.json
2023-05-09T04:51:34,647 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=12662
2023-05-09T04:51:34,648 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:51:34,655 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:51:34,655 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]12662
2023-05-09T04:51:34,656 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:51:34,656 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:51:34,656 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=12660
2023-05-09T04:51:34,656 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:51:34,662 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=12661
2023-05-09T04:51:34,663 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:51:34,665 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:51:34,665 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]12660
2023-05-09T04:51:34,665 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:51:34,665 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:51:34,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:51:34,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]12661
2023-05-09T04:51:34,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:51:34,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:51:34,707 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=12663
2023-05-09T04:51:34,707 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:51:34,715 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:51:34,716 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]12663
2023-05-09T04:51:34,716 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:51:34,716 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:51:34,716 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:51:34,716 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:51:34,720 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:51:34,720 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:51:34,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:51:34,728 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:51:34,728 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:51:34,731 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:51:34,731 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:51:34,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:51:34,733 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:51:34,733 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:51:34,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T04:51:34,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T04:51:34,736 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607894736
2023-05-09T04:51:34,736 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683607894736
2023-05-09T04:51:34,758 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:51:34,770 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:51:34,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:51:34,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:51:35,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:51:35,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:51:35,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:51:35,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:51:35,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 12661/1
2023-05-09T04:51:35,560 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:51:35,560 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:51:35,560 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:51:35,560 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:51:35,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 12660/0
2023-05-09T04:51:35,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:51:35,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:51:35,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:51:35,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:51:35,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 12663/3
2023-05-09T04:51:35,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:51:35,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:51:35,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:51:35,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:51:35,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 12662/2
2023-05-09T04:52:02,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.894181366999874 seconds
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T04:52:02,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T04:52:02,973 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T04:52:02,973 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T04:52:02,973 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/23afe2bde5004ee6877ab7e15a7fb42e/pippy_handler.py", line 77, in initialize
2023-05-09T04:52:02,973 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = get_pipeline_driver(self.model, self.world_size, ctx)
2023-05-09T04:52:02,973 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 90, in get_pipeline_driver
2023-05-09T04:52:02,973 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     index_file = index_file_path if model_type == "HF" else None
2023-05-09T04:52:02,973 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - UnboundLocalError: local variable 'index_file_path' referenced before assignment
2023-05-09T04:52:02,980 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:02,980 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:02,980 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:02,980 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:02,981 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:02,981 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:02,992 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T04:52:02,992 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T04:52:02,993 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:02,993 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:02,993 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683607922993
2023-05-09T04:52:02,993 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683607922993
2023-05-09T04:52:02,993 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.975940665000053 seconds
2023-05-09T04:52:02,993 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:02,993 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:02,993 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:02,993 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:02,993 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:02,993 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:02,993 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:02,993 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:02,993 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:02,993 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:02,994 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:52:02,994 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:52:03,055 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:52:03,055 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:03,055 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:52:03,055 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:03,994 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:03,994 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:05,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:52:05,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:52:05,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:05,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:52:05,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:05,539 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:52:05,540 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:52:05,542 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:05,542 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gyuqmvo_
2023-05-09T04:52:05,542 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:52:05,543 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=59563
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:05,680 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:52:05,681 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:52:05,681 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gyuqmvo_/attempt_0/0/error.json
2023-05-09T04:52:05,681 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gyuqmvo_/attempt_0/1/error.json
2023-05-09T04:52:05,681 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gyuqmvo_/attempt_0/2/error.json
2023-05-09T04:52:05,681 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_gyuqmvo_/attempt_0/3/error.json
2023-05-09T04:52:06,893 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13631
2023-05-09T04:52:06,894 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:06,894 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13632
2023-05-09T04:52:06,894 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:06,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:06,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13631
2023-05-09T04:52:06,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:06,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:06,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:06,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13632
2023-05-09T04:52:06,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:06,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:06,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13629
2023-05-09T04:52:06,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:06,904 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13630
2023-05-09T04:52:06,904 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:06,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:06,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13629
2023-05-09T04:52:06,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:06,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:06,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:06,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13630
2023-05-09T04:52:06,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:06,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:06,913 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:06,913 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:06,914 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:06,914 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:06,915 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:06,915 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:06,915 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:06,915 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:06,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:52:06,916 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:06,916 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:06,916 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method) ~[?:?]
	at java.lang.Object.wait(Object.java:328) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:06,916 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method) ~[?:?]
	at java.lang.Object.wait(Object.java:328) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:06,919 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:06,919 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:06,919 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:06,919 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:06,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:52:06,919 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:06,919 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:06,920 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:06,920 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:06,920 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:06,920 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:06,920 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:52:06,920 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:52:07,920 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:07,920 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:09,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:52:09,445 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:52:09,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:52:09,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:52:09,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:52:09,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:52:09,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:52:09,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:52:09,446 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:52:09,448 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:09,448 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_k4k9rrfd
2023-05-09T04:52:09,448 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:52:09,448 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=58531
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_k4k9rrfd/attempt_0/0/error.json
2023-05-09T04:52:09,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_k4k9rrfd/attempt_0/1/error.json
2023-05-09T04:52:09,522 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_k4k9rrfd/attempt_0/2/error.json
2023-05-09T04:52:09,522 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_k4k9rrfd/attempt_0/3/error.json
2023-05-09T04:52:10,714 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13719
2023-05-09T04:52:10,715 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:10,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:10,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13719
2023-05-09T04:52:10,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:10,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:10,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13718
2023-05-09T04:52:10,728 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:10,737 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:10,737 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13718
2023-05-09T04:52:10,737 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:10,737 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:10,760 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13721
2023-05-09T04:52:10,760 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:10,763 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13720
2023-05-09T04:52:10,763 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:10,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:10,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13721
2023-05-09T04:52:10,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:10,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:10,771 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:10,772 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13720
2023-05-09T04:52:10,772 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:10,772 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:10,772 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:10,772 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:10,772 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:10,772 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:10,774 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:10,774 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:10,774 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:10,774 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:10,774 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:52:10,774 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:10,774 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:10,775 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@40e4cc54(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:10,775 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@40e4cc54(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:10,776 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:10,776 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:10,776 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:10,776 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:10,776 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:10,776 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:10,776 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:10,776 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:10,776 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T04:52:10,776 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:52:10,776 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T04:52:10,777 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:10,777 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:12,777 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:12,777 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:52:14,311 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:52:14,312 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:52:14,312 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:52:14,312 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:52:14,312 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:52:14,312 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:52:14,314 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:14,314 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lo149hy0
2023-05-09T04:52:14,314 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:52:14,314 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:52:14,451 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=53805
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lo149hy0/attempt_0/0/error.json
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lo149hy0/attempt_0/1/error.json
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lo149hy0/attempt_0/2/error.json
2023-05-09T04:52:14,452 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lo149hy0/attempt_0/3/error.json
2023-05-09T04:52:15,653 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13814
2023-05-09T04:52:15,654 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:15,654 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13815
2023-05-09T04:52:15,654 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:15,662 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:15,662 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13814
2023-05-09T04:52:15,662 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:15,662 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:15,663 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:15,663 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13815
2023-05-09T04:52:15,663 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:15,663 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:15,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13817
2023-05-09T04:52:15,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:15,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13816
2023-05-09T04:52:15,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:15,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:15,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13817
2023-05-09T04:52:15,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:15,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:15,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:15,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13816
2023-05-09T04:52:15,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:15,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:15,701 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:15,701 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:15,701 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:15,701 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:15,703 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:15,703 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:15,703 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:15,703 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:15,703 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:52:15,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:15,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:15,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3c8749e4(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:15,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3c8749e4(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:15,705 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:15,705 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:15,705 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:15,705 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:15,705 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:15,705 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:15,706 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:15,706 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:15,706 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:15,706 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:15,706 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T04:52:15,706 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T04:52:18,707 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:18,707 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:20,241 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:52:20,242 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:52:20,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:20,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_grmtvarx
2023-05-09T04:52:20,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:52:20,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:52:20,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:52:20,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:52:20,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:52:20,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=47639
2023-05-09T04:52:20,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:52:20,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:52:20,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:52:20,443 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_grmtvarx/attempt_0/0/error.json
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_grmtvarx/attempt_0/1/error.json
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_grmtvarx/attempt_0/2/error.json
2023-05-09T04:52:20,444 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_grmtvarx/attempt_0/3/error.json
2023-05-09T04:52:21,650 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13923
2023-05-09T04:52:21,651 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:21,659 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:21,659 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13923
2023-05-09T04:52:21,659 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:21,659 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:21,661 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13922
2023-05-09T04:52:21,661 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:21,670 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:21,670 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13922
2023-05-09T04:52:21,670 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:21,670 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:21,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13924
2023-05-09T04:52:21,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:21,680 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:21,680 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13924
2023-05-09T04:52:21,680 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:21,680 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:21,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=13925
2023-05-09T04:52:21,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:21,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:21,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]13925
2023-05-09T04:52:21,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:21,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:21,699 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:21,699 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:21,699 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:21,699 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:21,702 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:21,702 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:21,702 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:21,702 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:21,702 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:52:21,702 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:21,702 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:21,702 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@43c80734(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:21,702 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@43c80734(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:21,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:21,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:21,703 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:21,703 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:21,703 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:21,703 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:21,703 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:21,703 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:21,704 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T04:52:21,704 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T04:52:21,704 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:21,704 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:26,704 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:26,704 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:28,219 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:52:28,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:52:28,223 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:28,223 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5tcbddcx
2023-05-09T04:52:28,223 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:52:28,223 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:52:28,304 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=51489
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5tcbddcx/attempt_0/0/error.json
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5tcbddcx/attempt_0/1/error.json
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5tcbddcx/attempt_0/2/error.json
2023-05-09T04:52:28,305 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5tcbddcx/attempt_0/3/error.json
2023-05-09T04:52:29,496 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=14019
2023-05-09T04:52:29,497 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:29,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=14020
2023-05-09T04:52:29,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:29,505 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:29,505 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]14019
2023-05-09T04:52:29,505 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:29,505 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:29,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:29,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]14020
2023-05-09T04:52:29,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:29,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:29,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=14022
2023-05-09T04:52:29,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:29,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=14021
2023-05-09T04:52:29,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:29,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:29,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]14022
2023-05-09T04:52:29,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:29,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:29,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:29,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]14021
2023-05-09T04:52:29,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:29,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:29,541 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:29,541 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:29,542 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:29,542 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:29,544 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:29,544 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:29,544 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:29,544 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:29,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:52:29,544 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:29,544 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:29,544 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@6e3e6710(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:29,544 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@6e3e6710(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:29,546 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:29,546 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:29,546 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:29,546 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:29,546 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:29,546 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:29,546 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:29,546 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:29,546 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 8 seconds.
2023-05-09T04:52:29,546 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 8 seconds.
2023-05-09T04:52:29,546 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:29,546 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:33,353 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,353 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0722312927246|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,353 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.251407623291|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,353 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,354 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,355 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,355 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:371041.0625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,355 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8559.69140625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:33,355 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683607953
2023-05-09T04:52:36,934 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:52:36,934 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:52:37,547 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:37,547 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:52:39,043 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:52:39,044 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:52:39,048 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:39,048 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5zgbx4mm
2023-05-09T04:52:39,048 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:52:39,048 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=51565
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:52:39,290 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:52:39,291 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5zgbx4mm/attempt_0/0/error.json
2023-05-09T04:52:39,291 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5zgbx4mm/attempt_0/1/error.json
2023-05-09T04:52:39,291 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5zgbx4mm/attempt_0/2/error.json
2023-05-09T04:52:39,291 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_5zgbx4mm/attempt_0/3/error.json
2023-05-09T04:52:40,489 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=14217
2023-05-09T04:52:40,490 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:40,490 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=14218
2023-05-09T04:52:40,490 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:40,497 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=14215
2023-05-09T04:52:40,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:40,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:40,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]14217
2023-05-09T04:52:40,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:40,498 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:40,499 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:40,499 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]14218
2023-05-09T04:52:40,499 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:40,499 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:40,505 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=14216
2023-05-09T04:52:40,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:52:40,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:40,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]14215
2023-05-09T04:52:40,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:40,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:40,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:52:40,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]14216
2023-05-09T04:52:40,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:52:40,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:52:40,515 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:40,515 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:52:40,515 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:40,515 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:52:40,517 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:40,517 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:40,517 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:52:40,517 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:52:40,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:52:40,518 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:40,518 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:52:40,518 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@610917e2(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:40,518 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@610917e2(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:52:40,519 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:40,519 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:52:40,519 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:40,519 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:52:40,519 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:40,519 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:52:40,519 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:40,519 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:52:40,520 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 13 seconds.
2023-05-09T04:52:40,520 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 13 seconds.
2023-05-09T04:52:40,520 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:40,520 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:52:40,800 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:52:40,800 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:52:45,726 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:52:45,726 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:55:17,766 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:55:17,766 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T04:55:17,820 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:55:17,820 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T04:55:18,011 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:55:18,011 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T04:55:18,017 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:55:18,017 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T04:55:18,033 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:55:18,033 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T04:55:18,059 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:55:18,059 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T04:55:18,059 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:55:18,059 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T04:55:18,059 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:55:18,059 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T04:55:18,059 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:55:18,059 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T04:55:18,059 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:55:18,059 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T04:55:18,070 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:55:18,070 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T04:55:18,071 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:55:18,071 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:55:18,128 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:55:18,128 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T04:55:18,129 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:55:18,129 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T04:55:18,130 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:55:18,130 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T04:55:18,131 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:55:18,131 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T04:55:18,132 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:55:18,132 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T04:55:18,314 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:55:18,314 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T04:55:19,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:55:19,585 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:55:19,585 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:55:19,585 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:55:19,586 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:55:19,586 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:55:19,586 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:55:19,586 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:55:19,586 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:55:19,587 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:55:19,587 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:55:19,587 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:55:19,587 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:55:19,587 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:55:19,587 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:55:19,587 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:55:19,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:55:19,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:55:19,588 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:19,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bta11h90
2023-05-09T04:55:19,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:55:19,589 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:55:19,599 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0689735412598|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25466537475586|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,602 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,602 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,602 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,602 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,602 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,602 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,603 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:374744.66796875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,603 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4854.8125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,603 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:2.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608119
2023-05-09T04:55:19,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:55:19,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:55:19,772 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:55:19,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=58873
2023-05-09T04:55:19,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:55:19,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:55:19,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:55:19,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:55:19,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:55:19,773 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:55:19,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:55:19,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:19,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:55:19,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:55:19,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bta11h90/attempt_0/0/error.json
2023-05-09T04:55:19,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bta11h90/attempt_0/1/error.json
2023-05-09T04:55:19,774 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bta11h90/attempt_0/2/error.json
2023-05-09T04:55:19,775 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_bta11h90/attempt_0/3/error.json
2023-05-09T04:55:20,981 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=15442
2023-05-09T04:55:20,983 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:55:20,990 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:55:20,990 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]15442
2023-05-09T04:55:20,990 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:55:20,991 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:55:21,003 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=15441
2023-05-09T04:55:21,004 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:55:21,012 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:55:21,013 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]15441
2023-05-09T04:55:21,013 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:55:21,013 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:55:21,014 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=15443
2023-05-09T04:55:21,014 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:55:21,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:55:21,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]15443
2023-05-09T04:55:21,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:55:21,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:55:21,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=15444
2023-05-09T04:55:21,023 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:55:21,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:55:21,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]15444
2023-05-09T04:55:21,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:55:21,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:55:21,033 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:55:21,033 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T04:55:21,036 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:55:21,036 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:55:21,044 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:55:21,045 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:55:21,045 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:55:21,047 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:55:21,047 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T04:55:21,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:55:21,049 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:55:21,049 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T04:55:21,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T04:55:21,051 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T04:55:21,053 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683608121053
2023-05-09T04:55:21,053 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683608121053
2023-05-09T04:55:21,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:55:21,087 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:55:21,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:55:21,107 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T04:55:21,871 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:55:21,871 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:55:21,871 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:55:21,871 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:55:21,873 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 15442/1
2023-05-09T04:55:21,887 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:55:21,887 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:55:21,887 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:55:21,887 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:55:21,889 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 15441/0
2023-05-09T04:55:21,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:55:21,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:55:21,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:55:21,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:55:21,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 15443/2
2023-05-09T04:55:21,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T04:55:21,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T04:55:21,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T04:55:21,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T04:55:21,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 15444/3
2023-05-09T04:55:49,457 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.15994977199989 seconds
2023-05-09T04:55:49,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.20894151399989 seconds
2023-05-09T04:55:49,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:55:49,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T04:55:49,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T04:55:49,570 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:55:49,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T04:55:49,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T04:55:50,046 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.748789105000014 seconds
2023-05-09T04:55:50,107 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:55:50,108 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T04:55:50,108 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T04:55:50,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T04:55:50,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T04:55:50,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T04:55:50,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0167928790001497 seconds on rank 1
2023-05-09T04:55:50,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/71ba75d010fb4fd7b1c5a10a0180f44a loaded successfully
2023-05-09T04:55:50,595 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T04:55:50,598 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T04:55:50,598 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T04:55:50,598 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0281048060001012 seconds on rank 2
2023-05-09T04:55:50,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/71ba75d010fb4fd7b1c5a10a0180f44a loaded successfully
2023-05-09T04:55:51,123 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T04:55:51,126 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T04:55:51,126 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T04:55:51,126 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0195791680002912 seconds on rank 3
2023-05-09T04:55:51,126 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/71ba75d010fb4fd7b1c5a10a0180f44a loaded successfully
2023-05-09T04:55:51,426 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.922330450000118 seconds
2023-05-09T04:55:51,487 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T04:55:51,489 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T04:55:51,489 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T04:55:52,507 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T04:55:52,509 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T04:55:52,511 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T04:55:52,511 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T04:55:52,511 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T04:55:52,511 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,511 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,511 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,511 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,512 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T04:55:52,514 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T04:55:52,515 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T04:55:52,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,522 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T04:55:52,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T04:55:52,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T04:55:52,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T04:55:52,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_fc1.weight is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_fc1.weight is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_fc1.weight is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_fc1.bias is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_fc1.bias is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_fc1.bias is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_fc2.weight is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_fc2.weight is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_fc2.weight is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_fc2.bias is a meta tensor
2023-05-09T04:55:52,571 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_fc2.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_fc2.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_fc1.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_fc1.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_fc1.weight is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_fc1.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_fc1.bias is a meta tensor
2023-05-09T04:55:52,572 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_fc1.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_fc2.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_fc2.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_fc2.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_24_fc2.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_36_fc2.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_12_fc2.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,573 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_fc1.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_fc1.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_fc1.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_fc1.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_fc1.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_fc1.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_fc2.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_fc2.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_fc2.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_25_fc2.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_37_fc2.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_13_fc2.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,574 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_fc1.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_fc1.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_fc1.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_fc1.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_fc1.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_fc2.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_fc1.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_fc2.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_38_fc2.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_fc2.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_26_fc2.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_14_fc2.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,575 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_fc1.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_fc1.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_fc1.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_fc1.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_fc1.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_fc2.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_fc1.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_fc2.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_39_fc2.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_27_fc2.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_fc2.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_15_fc2.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_fc1.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_fc1.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_fc1.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_fc1.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_fc2.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_fc1.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_40_fc2.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_fc2.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_fc1.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_28_fc2.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_fc2.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_16_fc2.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,577 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_fc1.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_fc1.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_fc1.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_fc2.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_fc1.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_41_fc2.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_fc1.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_fc1.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_fc2.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_fc2.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_29_fc2.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_17_fc2.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,578 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_fc1.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_fc1.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_fc2.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_42_fc2.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_fc1.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_fc1.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_fc1.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_fc1.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_fc2.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_fc2.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_30_fc2.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_18_fc2.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,579 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_fc1.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_fc1.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_fc2.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_43_fc2.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_fc1.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_fc1.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_fc1.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_fc1.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_fc2.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_fc2.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_31_fc2.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_19_fc2.bias is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,580 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_fc1.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_fc1.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_fc2.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_44_fc2.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_fc1.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_fc1.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_fc1.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_fc1.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_fc2.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_fc2.weight is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_32_fc2.bias is a meta tensor
2023-05-09T04:55:52,581 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_20_fc2.bias is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - On WorkerInfo(id=1, name=worker1):
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - NotImplementedError('Cannot copy out of meta tensor; no data!')
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/internal.py", line 207, in _run_function
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     result = python_udf.func(*python_udf.args, **python_udf.kwargs)
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/rref_proxy.py", line 11, in _local_invoke
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return getattr(rref.local_value(), func_name)(*args, **kwargs)
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py", line 282, in create_stage_executor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     mod=mod or Pipe.materialize_stage(mod_name),  # type: ignore[attr-defined]
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/IR.py", line 1105, in materialize_stage
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     submodule.to(device)
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_fc1.weight is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1145, in to
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return self._apply(convert)
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_fc1.bias is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,582 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     module._apply(fn)
2023-05-09T04:55:52,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 820, in _apply
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_fc2.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     param_applied = fn(param)
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1143, in convert
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_45_fc2.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - NotImplementedError: Cannot copy out of meta tensor; no data!
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - On WorkerInfo(id=3, name=worker3):
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - NotImplementedError('Cannot copy out of meta tensor; no data!')
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/internal.py", line 207, in _run_function
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     result = python_udf.func(*python_udf.args, **python_udf.kwargs)
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_fc1.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/rref_proxy.py", line 11, in _local_invoke
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_fc1.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return getattr(rref.local_value(), func_name)(*args, **kwargs)
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_fc1.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py", line 282, in create_stage_executor
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     mod=mod or Pipe.materialize_stage(mod_name),  # type: ignore[attr-defined]
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_fc1.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/IR.py", line 1105, in materialize_stage
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     submodule.to(device)
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_fc2.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1145, in to
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_fc2.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return self._apply(convert)
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_21_fc2.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     module._apply(fn)
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 820, in _apply
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_33_fc2.bias is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     param_applied = fn(param)
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1143, in convert
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,583 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,583 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - NotImplementedError: Cannot copy out of meta tensor; no data!
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - On WorkerInfo(id=2, name=worker2):
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - NotImplementedError('Cannot copy out of meta tensor; no data!')
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/internal.py", line 207, in _run_function
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     result = python_udf.func(*python_udf.args, **python_udf.kwargs)
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/rref_proxy.py", line 11, in _local_invoke
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return getattr(rref.local_value(), func_name)(*args, **kwargs)
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py", line 282, in create_stage_executor
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     mod=mod or Pipe.materialize_stage(mod_name),  # type: ignore[attr-defined]
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/IR.py", line 1105, in materialize_stage
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     submodule.to(device)
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1145, in to
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_fc1.weight is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return self._apply(convert)
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     module._apply(fn)
2023-05-09T04:55:52,586 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T04:55:52,670 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:55:52,584 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_fc1.bias is a meta tensor
2023-05-09T04:55:52,670 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,584 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 820, in _apply
2023-05-09T04:55:52,586 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     param_applied = fn(param)
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1143, in convert
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_fc2.weight is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31479
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31479
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - NotImplementedError: Cannot copy out of meta tensor; no data!
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_46_fc2.bias is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - On WorkerInfo(id=0, name=worker0):
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - NotImplementedError('Cannot copy out of meta tensor; no data!')
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/internal.py", line 207, in _run_function
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     result = python_udf.func(*python_udf.args, **python_udf.kwargs)
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/rref_proxy.py", line 11, in _local_invoke
2023-05-09T04:55:52,689 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return getattr(rref.local_value(), func_name)(*args, **kwargs)
2023-05-09T04:55:52,689 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py", line 282, in create_stage_executor
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     mod=mod or Pipe.materialize_stage(mod_name),  # type: ignore[attr-defined]
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/IR.py", line 1105, in materialize_stage
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_fc1.weight is a meta tensor
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     submodule.to(device)
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_fc1.weight is a meta tensor
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1145, in to
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return self._apply(convert)
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_fc1.bias is a meta tensor
2023-05-09T04:55:52,689 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:157.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608152
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_fc1.bias is a meta tensor
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,690 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     module._apply(fn)
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_fc2.weight is a meta tensor
2023-05-09T04:55:52,690 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_fc2.weight is a meta tensor
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 820, in _apply
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     param_applied = fn(param)
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1143, in convert
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_22_fc2.bias is a meta tensor
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_34_fc2.bias is a meta tensor
2023-05-09T04:55:52,690 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - NotImplementedError: Cannot copy out of meta tensor; no data!
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,690 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_fc1.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_fc1.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_fc2.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_47_fc2.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_35_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_23_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - lm_head.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - moved_model_decoder_embed_positions_weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_embed_tokens.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_fc1.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_fc1.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_fc2.weight is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_0_fc2.bias is a meta tensor
2023-05-09T04:55:52,691 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_fc1.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_fc1.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_fc2.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_1_fc2.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_fc1.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_fc1.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_fc2.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_2_fc2.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_fc1.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_fc1.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_fc2.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_3_fc2.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_fc1.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_fc1.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_fc2.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_4_fc2.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_fc1.weight is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_fc1.bias is a meta tensor
2023-05-09T04:55:52,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_fc2.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_5_fc2.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_fc1.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_fc1.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_fc2.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_6_fc2.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_fc1.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_fc1.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_fc2.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_7_fc2.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_fc1.weight is a meta tensor
2023-05-09T04:55:52,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_fc1.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_fc2.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_8_fc2.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_fc1.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_fc1.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_fc2.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_9_fc2.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_fc1.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_fc1.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_fc2.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_10_fc2.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_q_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_q_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_k_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_k_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_v_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_v_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_out_proj.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_self_attn_out_proj.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_final_layer_norm.weight is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_decoder_layers_11_final_layer_norm.bias is a meta tensor
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T04:55:52,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T04:55:52,696 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T04:55:52,696 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T04:55:52,696 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T04:55:52,696 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 180, in handle_connection
2023-05-09T04:55:52,696 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise RuntimeError("{} - {}".format(code, result))
2023-05-09T04:55:52,696 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - RuntimeError: 500 - Unknown exception
2023-05-09T04:55:52,690 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1261) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:317) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:256) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:55:52,690 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1261) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:317) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:256) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:55:52,700 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T04:55:52,700 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T04:55:52,701 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683608152700
2023-05-09T04:55:52,701 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683608152700
2023-05-09T04:55:52,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T04:55:52,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T04:55:52,701 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T04:55:52,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T04:55:52,701 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T04:55:52,701 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T04:55:52,701 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T04:55:52,702 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:55:52,701 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T04:55:52,702 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:55:52,701 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T04:55:52,702 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:55:52,702 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:55:52,702 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:55:52,702 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:55:53,106 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:55:53,106 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:55:53,177 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:55:53,177 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:55:53,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:55:53,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:55:55,220 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:55:55,221 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:55:55,224 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:55,224 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_71r0nczo
2023-05-09T04:55:55,224 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:55:55,224 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=59937
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:55:55,286 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:55:55,287 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_71r0nczo/attempt_0/0/error.json
2023-05-09T04:55:55,287 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_71r0nczo/attempt_0/1/error.json
2023-05-09T04:55:55,287 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_71r0nczo/attempt_0/2/error.json
2023-05-09T04:55:55,287 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_71r0nczo/attempt_0/3/error.json
2023-05-09T04:55:56,472 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16408
2023-05-09T04:55:56,472 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:55:56,480 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:55:56,481 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16408
2023-05-09T04:55:56,481 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:55:56,481 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:55:56,487 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16407
2023-05-09T04:55:56,487 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:55:56,494 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16409
2023-05-09T04:55:56,494 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:55:56,495 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:55:56,495 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16407
2023-05-09T04:55:56,495 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:55:56,495 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:55:56,502 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:55:56,502 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16409
2023-05-09T04:55:56,503 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:55:56,503 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:55:56,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16410
2023-05-09T04:55:56,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:55:56,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:55:56,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16410
2023-05-09T04:55:56,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:55:56,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:55:56,548 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:55:56,548 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:55:56,548 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:55:56,548 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:55:56,550 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:55:56,550 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:55:56,550 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:55:56,550 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:55:56,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:55:56,550 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:55:56,550 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:55:56,550 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@79fad010(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:55:56,550 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@79fad010(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:55:56,552 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:55:56,552 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:55:56,552 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:55:56,552 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:55:56,552 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:55:56,552 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:55:56,552 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:55:56,552 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:55:56,552 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:55:56,553 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:55:56,553 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:55:56,553 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T04:55:56,553 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:55:57,553 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:55:57,553 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:55:59,073 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:55:59,074 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:55:59,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:59,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xcyt9i1q
2023-05-09T04:55:59,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:55:59,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=50127
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xcyt9i1q/attempt_0/0/error.json
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xcyt9i1q/attempt_0/1/error.json
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xcyt9i1q/attempt_0/2/error.json
2023-05-09T04:55:59,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_xcyt9i1q/attempt_0/3/error.json
2023-05-09T04:56:00,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16503
2023-05-09T04:56:00,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:00,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16504
2023-05-09T04:56:00,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:00,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16502
2023-05-09T04:56:00,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:00,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:00,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16503
2023-05-09T04:56:00,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:00,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:00,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:00,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16504
2023-05-09T04:56:00,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:00,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:00,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:00,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16502
2023-05-09T04:56:00,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:00,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:00,482 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16505
2023-05-09T04:56:00,482 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:00,491 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:00,491 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16505
2023-05-09T04:56:00,491 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:00,491 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:00,491 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:00,491 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:00,492 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:00,492 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:00,494 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:00,494 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:00,494 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:00,494 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:00,494 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:56:00,494 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:00,494 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:00,494 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2bddee1(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:00,494 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2bddee1(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:00,495 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:00,495 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:00,495 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:00,495 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:00,495 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:00,495 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:00,495 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:00,495 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:00,496 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T04:56:00,496 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T04:56:00,496 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:00,496 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:02,496 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:02,496 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:04,012 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:56:04,013 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:56:04,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:04,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500__vxn44l8
2023-05-09T04:56:04,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:56:04,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=38721
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:04,138 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:04,139 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:04,139 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:56:04,139 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:56:04,139 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500__vxn44l8/attempt_0/0/error.json
2023-05-09T04:56:04,139 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500__vxn44l8/attempt_0/1/error.json
2023-05-09T04:56:04,139 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500__vxn44l8/attempt_0/2/error.json
2023-05-09T04:56:04,139 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500__vxn44l8/attempt_0/3/error.json
2023-05-09T04:56:05,341 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16598
2023-05-09T04:56:05,342 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:05,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:05,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16598
2023-05-09T04:56:05,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:05,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:05,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16600
2023-05-09T04:56:05,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:05,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16599
2023-05-09T04:56:05,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:05,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:05,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16600
2023-05-09T04:56:05,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:05,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:05,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:05,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16599
2023-05-09T04:56:05,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:05,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:05,386 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16601
2023-05-09T04:56:05,386 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:05,395 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:05,395 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16601
2023-05-09T04:56:05,395 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:05,395 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:05,395 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:05,395 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:05,396 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:05,396 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:05,398 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:05,398 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:05,398 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:05,398 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:05,398 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:56:05,398 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:05,398 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:05,398 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@6e2c3d7b(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:05,398 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@6e2c3d7b(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:05,399 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:05,399 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:05,399 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:05,399 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:05,400 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:05,400 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:05,400 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:05,400 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:05,400 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:05,400 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T04:56:05,400 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:05,400 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T04:56:08,401 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:08,401 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:09,916 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:56:09,916 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:56:09,917 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:56:09,920 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:09,920 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vc6fx0jv
2023-05-09T04:56:09,920 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:56:09,920 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=34771
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vc6fx0jv/attempt_0/0/error.json
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vc6fx0jv/attempt_0/1/error.json
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vc6fx0jv/attempt_0/2/error.json
2023-05-09T04:56:10,052 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_vc6fx0jv/attempt_0/3/error.json
2023-05-09T04:56:11,251 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16694
2023-05-09T04:56:11,252 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:11,256 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16696
2023-05-09T04:56:11,256 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:11,260 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16695
2023-05-09T04:56:11,260 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:11,260 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:11,260 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16694
2023-05-09T04:56:11,260 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:11,260 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:11,265 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:11,265 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16696
2023-05-09T04:56:11,265 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:11,265 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:11,269 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:11,269 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16695
2023-05-09T04:56:11,269 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:11,269 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:11,319 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16697
2023-05-09T04:56:11,319 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:11,328 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:11,328 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16697
2023-05-09T04:56:11,328 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:11,328 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:11,328 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:11,328 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:11,328 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:11,328 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:11,330 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:11,330 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:11,330 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:11,330 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:11,331 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:56:11,331 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:11,331 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:11,331 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2ddf8ee6(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:11,331 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2ddf8ee6(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:11,332 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:11,332 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:11,332 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:11,332 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:11,332 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:11,332 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:11,332 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:11,332 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:11,332 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T04:56:11,333 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T04:56:11,333 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:11,333 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T04:56:11,333 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:16,333 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:16,333 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:17,830 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:56:17,831 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:56:17,835 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:17,835 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_geas_gp5
2023-05-09T04:56:17,835 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:56:17,835 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:56:18,015 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:56:18,015 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=33589
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_geas_gp5/attempt_0/0/error.json
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_geas_gp5/attempt_0/1/error.json
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_geas_gp5/attempt_0/2/error.json
2023-05-09T04:56:18,016 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_geas_gp5/attempt_0/3/error.json
2023-05-09T04:56:19,212 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16810
2023-05-09T04:56:19,212 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:19,220 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:19,221 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16810
2023-05-09T04:56:19,221 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:19,221 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:19,232 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16811
2023-05-09T04:56:19,232 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:19,241 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:19,241 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16811
2023-05-09T04:56:19,241 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:19,241 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:19,249 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16812
2023-05-09T04:56:19,249 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:19,258 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:19,258 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16812
2023-05-09T04:56:19,258 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:19,258 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:19,259 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16813
2023-05-09T04:56:19,260 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:19,268 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:19,268 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16813
2023-05-09T04:56:19,268 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:19,268 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:19,269 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:19,269 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:19,269 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:19,269 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:19,271 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:19,271 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:19,271 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:19,271 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:19,271 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:56:19,271 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:19,271 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:19,271 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@690558e5(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:19,271 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@690558e5(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:19,273 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:19,273 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:19,273 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:19,273 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:19,273 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:19,273 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:19,273 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:19,273 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:19,273 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:19,273 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:19,273 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 8 seconds.
2023-05-09T04:56:19,273 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 8 seconds.
2023-05-09T04:56:19,599 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:15.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0683288574219|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25531005859375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:370982.54296875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8616.54296875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:19,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608179
2023-05-09T04:56:26,534 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:26,534 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:27,274 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:27,274 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:56:28,795 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:56:28,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:28,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mtckaely
2023-05-09T04:56:28,798 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:56:28,799 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:56:28,889 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=40717
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mtckaely/attempt_0/0/error.json
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mtckaely/attempt_0/1/error.json
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mtckaely/attempt_0/2/error.json
2023-05-09T04:56:28,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_mtckaely/attempt_0/3/error.json
2023-05-09T04:56:30,088 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16995
2023-05-09T04:56:30,089 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:30,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:30,097 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16995
2023-05-09T04:56:30,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:30,098 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:30,102 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16996
2023-05-09T04:56:30,102 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:30,102 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16994
2023-05-09T04:56:30,102 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:30,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:30,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16996
2023-05-09T04:56:30,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:30,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:30,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:30,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16994
2023-05-09T04:56:30,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:30,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:30,130 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=16997
2023-05-09T04:56:30,130 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:30,139 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:30,139 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]16997
2023-05-09T04:56:30,139 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:30,139 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:30,139 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:30,139 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:30,139 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:30,139 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:30,141 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:30,141 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:30,141 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:30,141 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:30,141 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:56:30,142 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:30,142 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:30,142 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3cae03f2(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:30,142 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3cae03f2(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:30,143 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:30,143 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:30,143 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:30,143 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:30,143 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:30,143 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:30,143 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:30,143 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:30,143 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 13 seconds.
2023-05-09T04:56:30,143 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 13 seconds.
2023-05-09T04:56:30,143 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:30,143 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:30,482 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:30,482 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:35,396 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:35,396 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:41,296 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:41,296 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:43,144 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:43,144 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:56:44,668 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:56:44,668 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:56:44,668 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:44,668 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:56:44,668 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:56:44,668 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:56:44,668 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:56:44,669 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:56:44,672 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:44,672 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zgk8vc8q
2023-05-09T04:56:44,672 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:56:44,672 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=39099
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zgk8vc8q/attempt_0/0/error.json
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zgk8vc8q/attempt_0/1/error.json
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zgk8vc8q/attempt_0/2/error.json
2023-05-09T04:56:44,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zgk8vc8q/attempt_0/3/error.json
2023-05-09T04:56:46,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17131
2023-05-09T04:56:46,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:46,102 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:46,102 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17131
2023-05-09T04:56:46,102 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:46,103 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:46,125 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17132
2023-05-09T04:56:46,125 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:46,133 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:46,133 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17132
2023-05-09T04:56:46,134 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:46,134 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:46,141 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17130
2023-05-09T04:56:46,141 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:46,148 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17133
2023-05-09T04:56:46,148 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:56:46,150 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:46,150 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17130
2023-05-09T04:56:46,150 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:46,150 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:46,157 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:56:46,157 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17133
2023-05-09T04:56:46,157 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:56:46,157 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:56:46,157 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:46,157 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:56:46,157 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:46,157 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:56:46,159 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:46,159 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:56:46,159 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:46,159 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:56:46,159 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:56:46,159 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:46,159 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:56:46,159 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@7f2fb6f2(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:46,159 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@7f2fb6f2(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:56:46,161 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:46,161 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:56:46,161 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:46,161 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:56:46,161 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:46,161 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:56:46,161 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:46,161 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:56:46,162 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:46,162 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 21 seconds.
2023-05-09T04:56:46,162 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:56:46,162 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 21 seconds.
2023-05-09T04:56:49,283 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:56:49,283 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:57:00,142 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:57:00,142 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:57:07,162 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:57:07,162 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:57:08,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:57:08,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:57:08,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:57:08,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:57:08,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:57:08,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:57:08,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:57:08,685 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:57:08,686 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:57:08,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:57:08,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tj3nvc_f
2023-05-09T04:57:08,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:57:08,689 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=44095
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tj3nvc_f/attempt_0/0/error.json
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tj3nvc_f/attempt_0/1/error.json
2023-05-09T04:57:08,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tj3nvc_f/attempt_0/2/error.json
2023-05-09T04:57:08,826 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_tj3nvc_f/attempt_0/3/error.json
2023-05-09T04:57:10,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17287
2023-05-09T04:57:10,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:57:10,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17288
2023-05-09T04:57:10,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:57:10,041 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:57:10,041 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17287
2023-05-09T04:57:10,042 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:57:10,042 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:57:10,044 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:57:10,045 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17288
2023-05-09T04:57:10,045 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:57:10,045 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:57:10,057 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17289
2023-05-09T04:57:10,057 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:57:10,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17286
2023-05-09T04:57:10,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:57:10,066 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:57:10,066 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17289
2023-05-09T04:57:10,066 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:57:10,066 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:57:10,067 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:57:10,067 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17286
2023-05-09T04:57:10,067 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:57:10,067 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:57:10,067 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:57:10,067 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:57:10,067 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:57:10,067 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:57:10,084 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:57:10,084 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:57:10,084 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:57:10,084 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:57:10,084 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:57:10,084 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:57:10,084 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:57:10,084 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@b771c5f(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:57:10,084 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@b771c5f(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:57:10,086 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:57:10,086 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:57:10,086 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:57:10,086 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:57:10,087 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:57:10,087 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:57:10,087 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:57:10,087 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:57:10,087 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:57:10,087 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 34 seconds.
2023-05-09T04:57:10,087 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:57:10,087 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 34 seconds.
2023-05-09T04:57:16,165 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:57:16,165 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:57:19,607 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,607 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0681648254395|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,607 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2554740905762|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,607 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,607 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,607 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,607 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:371307.44140625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8291.84375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:19,608 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608239
2023-05-09T04:57:40,076 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:57:40,076 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:57:44,088 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:57:44,088 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:57:45,606 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:57:45,607 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:57:45,607 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:57:45,607 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:57:45,610 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:57:45,610 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wcgtpj_u
2023-05-09T04:57:45,610 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:57:45,610 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=49237
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:57:45,903 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:57:45,904 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wcgtpj_u/attempt_0/0/error.json
2023-05-09T04:57:45,904 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wcgtpj_u/attempt_0/1/error.json
2023-05-09T04:57:45,904 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wcgtpj_u/attempt_0/2/error.json
2023-05-09T04:57:45,904 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_wcgtpj_u/attempt_0/3/error.json
2023-05-09T04:57:47,099 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17522
2023-05-09T04:57:47,099 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:57:47,108 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:57:47,108 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17522
2023-05-09T04:57:47,108 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:57:47,108 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:57:47,115 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17523
2023-05-09T04:57:47,115 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:57:47,124 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:57:47,124 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17523
2023-05-09T04:57:47,124 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:57:47,124 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:57:47,131 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17525
2023-05-09T04:57:47,131 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:57:47,135 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17524
2023-05-09T04:57:47,136 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:57:47,140 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:57:47,140 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17525
2023-05-09T04:57:47,140 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:57:47,140 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:57:47,144 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:57:47,144 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17524
2023-05-09T04:57:47,144 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:57:47,144 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:57:47,145 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:57:47,145 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:57:47,145 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:57:47,145 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:57:47,146 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:57:47,146 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:57:47,146 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:57:47,146 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:57:47,147 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:57:47,147 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:57:47,147 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:57:47,147 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@669de9df(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:57:47,147 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@669de9df(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:57:47,148 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:57:47,148 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:57:47,148 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:57:47,148 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:57:47,148 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:57:47,148 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:57:47,148 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:57:47,148 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:57:47,149 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:57:47,149 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 55 seconds.
2023-05-09T04:57:47,149 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:57:47,149 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 55 seconds.
2023-05-09T04:58:17,156 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:58:17,156 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:58:19,600 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.3|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0681076049805|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25553131103516|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,600 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,600 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:371306.9921875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8292.27734375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:19,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608299
2023-05-09T04:58:42,150 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:58:42,150 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T04:58:43,643 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T04:58:43,644 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T04:58:43,647 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:58:43,647 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_pg5hkt57
2023-05-09T04:58:43,647 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T04:58:43,647 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=36715
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_pg5hkt57/attempt_0/0/error.json
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_pg5hkt57/attempt_0/1/error.json
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_pg5hkt57/attempt_0/2/error.json
2023-05-09T04:58:43,930 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_pg5hkt57/attempt_0/3/error.json
2023-05-09T04:58:45,122 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17769
2023-05-09T04:58:45,122 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:58:45,128 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17771
2023-05-09T04:58:45,129 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:58:45,130 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17770
2023-05-09T04:58:45,130 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:58:45,131 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:58:45,131 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17769
2023-05-09T04:58:45,131 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:58:45,131 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:58:45,137 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:58:45,137 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17771
2023-05-09T04:58:45,137 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:58:45,137 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:58:45,138 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:58:45,138 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17770
2023-05-09T04:58:45,139 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:58:45,139 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:58:45,170 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=17772
2023-05-09T04:58:45,171 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T04:58:45,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T04:58:45,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]17772
2023-05-09T04:58:45,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T04:58:45,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T04:58:45,179 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:58:45,179 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T04:58:45,179 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:58:45,179 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T04:58:45,181 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:58:45,181 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T04:58:45,181 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:58:45,181 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T04:58:45,181 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T04:58:45,181 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:58:45,181 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T04:58:45,181 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2a60c76d(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:58:45,181 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2a60c76d(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T04:58:45,182 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:58:45,182 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T04:58:45,182 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:58:45,182 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T04:58:45,182 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:58:45,182 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T04:58:45,182 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:58:45,182 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T04:58:45,183 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 89 seconds.
2023-05-09T04:58:45,183 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 89 seconds.
2023-05-09T04:58:45,183 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:58:45,183 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T04:59:15,168 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T04:59:15,168 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:00:42,913 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:00:42,913 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:00:42,966 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:00:42,966 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:00:43,175 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:00:43,175 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:00:43,181 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:00:43,181 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:00:43,197 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:00:43,197 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:00:43,223 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:00:43,223 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:00:43,223 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:00:43,223 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:00:43,223 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:00:43,223 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:00:43,223 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:00:43,223 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:00:43,223 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:00:43,223 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:00:43,232 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:00:43,232 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:00:43,235 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:00:43,235 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:00:43,292 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:00:43,292 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:00:43,293 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:00:43,293 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:00:43,294 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:00:43,294 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:00:43,295 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:00:43,295 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:00:43,296 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:00:43,296 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:00:43,474 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:00:43,474 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:00:44,786 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,788 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0680351257324|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,788 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2556037902832|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,788 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,788 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,789 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,789 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,789 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,789 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,789 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,790 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,790 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,790 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,790 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,790 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,791 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,791 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:374754.1875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,791 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4844.58203125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,791 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:2.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608444
2023-05-09T05:00:44,808 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:00:44,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:00:44,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:00:44,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:00:44,809 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:00:44,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:00:44,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:00:44,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:00:44,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:00:44,810 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:00:44,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:00:44,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:00:44,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:00:44,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:00:44,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:00:44,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:00:44,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:00:44,811 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:00:44,812 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:00:44,813 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zz8rlc8b
2023-05-09T05:00:44,813 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:00:44,813 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:00:45,076 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:00:45,076 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:00:45,076 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:00:45,076 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=41895
2023-05-09T05:00:45,076 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:00:45,076 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:00:45,076 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:00:45,076 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:00:45,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:00:45,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:00:45,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:00:45,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:00:45,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:00:45,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:00:45,077 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zz8rlc8b/attempt_0/0/error.json
2023-05-09T05:00:45,078 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zz8rlc8b/attempt_0/1/error.json
2023-05-09T05:00:45,078 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zz8rlc8b/attempt_0/2/error.json
2023-05-09T05:00:45,078 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_zz8rlc8b/attempt_0/3/error.json
2023-05-09T05:00:46,275 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=18452
2023-05-09T05:00:46,276 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:00:46,279 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=18453
2023-05-09T05:00:46,279 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:00:46,284 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:00:46,284 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]18452
2023-05-09T05:00:46,284 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:00:46,284 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:00:46,288 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:00:46,288 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]18453
2023-05-09T05:00:46,288 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:00:46,288 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:00:46,306 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=18455
2023-05-09T05:00:46,307 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:00:46,314 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=18454
2023-05-09T05:00:46,314 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:00:46,315 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:00:46,315 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]18455
2023-05-09T05:00:46,315 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:00:46,315 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:00:46,322 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:00:46,323 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]18454
2023-05-09T05:00:46,323 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:00:46,323 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:00:46,323 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:00:46,323 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:00:46,327 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:00:46,327 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:00:46,334 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:00:46,335 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:00:46,335 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:00:46,338 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:00:46,338 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:00:46,338 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:00:46,339 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:00:46,339 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:00:46,339 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T05:00:46,342 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T05:00:46,343 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683608446343
2023-05-09T05:00:46,343 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683608446343
2023-05-09T05:00:46,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:00:46,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:00:46,387 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:00:46,398 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:00:47,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:00:47,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:00:47,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:00:47,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:00:47,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:00:47,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:00:47,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:00:47,178 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:00:47,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:00:47,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:00:47,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:00:47,179 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:00:47,180 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 18453/1
2023-05-09T05:00:47,180 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 18454/2
2023-05-09T05:00:47,180 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 18452/0
2023-05-09T05:00:47,180 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:00:47,181 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:00:47,181 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:00:47,181 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:00:47,183 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 18455/3
2023-05-09T05:01:13,655 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.026236788999995 seconds
2023-05-09T05:01:13,715 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:01:13,717 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:01:13,717 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:01:13,878 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.249378663000243 seconds
2023-05-09T05:01:13,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.278402586000084 seconds
2023-05-09T05:01:13,938 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:01:13,940 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:01:13,940 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:01:13,967 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:01:13,969 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:01:13,969 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:01:14,718 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:01:14,721 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T05:01:14,721 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:01:14,721 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0056681189998926 seconds on rank 3
2023-05-09T05:01:14,721 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/48613e251c4544ef92569f29f10e87a3 loaded successfully
2023-05-09T05:01:14,945 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:01:14,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T05:01:14,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:01:14,947 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0097521550001147 seconds on rank 1
2023-05-09T05:01:14,948 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/48613e251c4544ef92569f29f10e87a3 loaded successfully
2023-05-09T05:01:14,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:01:14,974 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T05:01:14,975 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:01:14,975 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0077182019999782 seconds on rank 2
2023-05-09T05:01:14,975 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/48613e251c4544ef92569f29f10e87a3 loaded successfully
2023-05-09T05:01:15,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.970433601999957 seconds
2023-05-09T05:01:15,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:01:15,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:01:15,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:01:16,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:01:16,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,789 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,790 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T05:01:16,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,792 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T05:01:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,798 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,799 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T05:01:16,800 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,802 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,803 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,805 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,806 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T05:01:16,807 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T05:01:16,808 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683608476.81 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T05:01:16,809 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T05:01:16,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T05:01:16,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683608476.81 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T05:01:16,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T05:01:16,811 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683608476.81 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T05:01:16,812 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683608476.81 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - On WorkerInfo(id=0, name=worker0):
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - OutOfMemoryError('CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 22.19 GiB total capacity; 6.83 GiB already allocated; 90.50 MiB free; 6.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/internal.py", line 207, in _run_function
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     result = python_udf.func(*python_udf.args, **python_udf.kwargs)
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/rref_proxy.py", line 11, in _local_invoke
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return getattr(rref.local_value(), func_name)(*args, **kwargs)
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py", line 282, in create_stage_executor
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     mod=mod or Pipe.materialize_stage(mod_name),  # type: ignore[attr-defined]
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/IR.py", line 1097, in materialize_stage
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     submodule = load_checkpoint(
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/LoadModule.py", line 54, in load_checkpoint
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     _set_module_tensor_to_device(
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/LoadModule.py", line 210, in _set_module_tensor_to_device
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     new_value = value.to(device=device, dtype=dtype)
2023-05-09T05:01:22,927 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 22.19 GiB total capacity; 6.83 GiB already allocated; 90.50 MiB free; 6.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-05-09T05:01:27,207 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T05:01:31,383 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T05:01:31,902 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 180, in handle_connection
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise RuntimeError("{} - {}".format(code, result))
2023-05-09T05:01:31,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - RuntimeError: 507 - System out of memory
2023-05-09T05:01:31,904 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:01:31,904 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:01:31,904 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 45506
2023-05-09T05:01:31,904 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 45506
2023-05-09T05:01:31,904 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T05:01:31,904 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T05:01:31,904 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:55.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608491
2023-05-09T05:01:31,986 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_ERROR
2023-05-09T05:01:31,986 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_ERROR
2023-05-09T05:01:31,987 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T05:01:31,987 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T05:01:31,987 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:513) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:675) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:260) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:01:31,987 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:513) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:675) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:260) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:01:31,998 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T05:01:31,998 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T05:01:31,999 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683608491998
2023-05-09T05:01:31,999 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683608491998
2023-05-09T05:01:31,999 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T05:01:31,999 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T05:01:31,999 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T05:01:31,999 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:01:31,999 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:01:31,999 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:01:31,999 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:01:31,999 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:01:32,000 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:01:32,000 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:01:32,000 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:01:31,999 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:01:32,000 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:01:31,999 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:01:31,999 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:01:32,001 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:01:32,001 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:01:32,621 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:01:32,621 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:01:33,001 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:01:33,001 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:01:34,531 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:01:34,532 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:01:34,535 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:01:34,535 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_t9zlde3h
2023-05-09T05:01:34,535 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:01:34,535 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=49829
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:01:34,620 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_t9zlde3h/attempt_0/0/error.json
2023-05-09T05:01:34,621 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_t9zlde3h/attempt_0/1/error.json
2023-05-09T05:01:34,621 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_t9zlde3h/attempt_0/2/error.json
2023-05-09T05:01:34,621 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_t9zlde3h/attempt_0/3/error.json
2023-05-09T05:02:20,859 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:02:20,859 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:02:20,913 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:02:20,913 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:02:21,159 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:02:21,159 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:02:21,165 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:02:21,165 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:02:21,181 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:02:21,181 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:02:21,206 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:02:21,206 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:02:21,207 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:02:21,207 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:02:21,207 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:02:21,207 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:02:21,207 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:02:21,207 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:02:21,207 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:02:21,207 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:02:21,218 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:02:21,218 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:02:21,219 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:02:21,219 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:02:21,278 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:02:21,278 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:02:21,278 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:02:21,278 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:02:21,280 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:02:21,280 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:02:21,280 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:02:21,280 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:02:21,281 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:02:21,281 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:02:21,462 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:02:21,462 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:02:22,737 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:02:22,738 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:02:22,738 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:02:22,738 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:02:22,739 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:02:22,739 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:02:22,739 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:02:22,739 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:02:22,739 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:02:22,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:02:22,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:02:22,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:02:22,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:02:22,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:02:22,740 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:02:22,741 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:02:22,741 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:02:22,741 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:02:22,741 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:02:22,741 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0di9zx41
2023-05-09T05:02:22,741 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:02:22,742 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:02:22,791 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,793 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0677604675293|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,793 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2558784484863|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,793 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,794 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,794 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,794 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,794 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,795 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,795 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,795 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,795 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,795 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,795 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,796 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,796 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,796 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:374701.4296875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,796 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4896.7265625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,796 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:2.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608542
2023-05-09T05:02:22,868 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:02:22,869 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:02:22,869 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:02:22,869 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=33441
2023-05-09T05:02:22,869 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:02:22,869 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:02:22,869 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:02:22,869 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:02:22,869 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:02:22,870 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:02:22,870 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:02:22,870 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:02:22,870 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:02:22,870 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:02:22,870 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0di9zx41/attempt_0/0/error.json
2023-05-09T05:02:22,870 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0di9zx41/attempt_0/1/error.json
2023-05-09T05:02:22,871 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0di9zx41/attempt_0/2/error.json
2023-05-09T05:02:22,871 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_0di9zx41/attempt_0/3/error.json
2023-05-09T05:02:24,091 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=20749
2023-05-09T05:02:24,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:02:24,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=20748
2023-05-09T05:02:24,093 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:02:24,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=20747
2023-05-09T05:02:24,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:02:24,100 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:02:24,100 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]20749
2023-05-09T05:02:24,100 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:02:24,100 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:02:24,100 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:02:24,101 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]20748
2023-05-09T05:02:24,101 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:02:24,101 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:02:24,105 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:02:24,106 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]20747
2023-05-09T05:02:24,106 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:02:24,106 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:02:24,124 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=20750
2023-05-09T05:02:24,125 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:02:24,133 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:02:24,133 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]20750
2023-05-09T05:02:24,133 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:02:24,134 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:02:24,134 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:02:24,134 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:02:24,138 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:02:24,138 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:02:24,145 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:02:24,146 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:02:24,146 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:02:24,148 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:02:24,148 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:02:24,149 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:02:24,150 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:02:24,150 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:02:24,150 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T05:02:24,152 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T05:02:24,154 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683608544154
2023-05-09T05:02:24,154 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683608544154
2023-05-09T05:02:24,177 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:02:24,188 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:02:24,200 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:02:24,211 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:02:25,031 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:02:25,031 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:02:25,031 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:02:25,031 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:02:25,031 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:02:25,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:02:25,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:02:25,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:02:25,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:02:25,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:02:25,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:02:25,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:02:25,032 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:02:25,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:02:25,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:02:25,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:02:25,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 20748/1
2023-05-09T05:02:25,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 20749/2
2023-05-09T05:02:25,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 20747/0
2023-05-09T05:02:25,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 20750/3
2023-05-09T05:02:51,483 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.987879471999804 seconds
2023-05-09T05:02:51,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:02:51,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:02:51,548 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:02:51,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.12154499899998 seconds
2023-05-09T05:02:51,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:02:51,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:02:51,689 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:02:51,708 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.203944390999823 seconds
2023-05-09T05:02:51,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:02:51,770 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:02:51,770 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:02:52,560 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:02:52,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T05:02:52,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:02:52,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.016477815000144 seconds on rank 1
2023-05-09T05:02:52,562 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/69f0d8214f3c4c7fa19a3e7667e78d1b loaded successfully
2023-05-09T05:02:52,697 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:02:52,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T05:02:52,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:02:52,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0130408089999037 seconds on rank 3
2023-05-09T05:02:52,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/69f0d8214f3c4c7fa19a3e7667e78d1b loaded successfully
2023-05-09T05:02:52,777 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:02:52,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T05:02:52,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:02:52,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0115010029999212 seconds on rank 2
2023-05-09T05:02:52,780 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/69f0d8214f3c4c7fa19a3e7667e78d1b loaded successfully
2023-05-09T05:02:53,357 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.767107732000113 seconds
2023-05-09T05:02:53,418 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:02:53,419 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:02:53,419 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:02:54,430 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:02:54,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,434 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,435 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,436 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,438 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,440 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,445 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,446 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,447 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,448 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,449 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,450 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,451 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,452 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T05:02:54,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T05:02:54,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T05:02:54,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T05:02:54,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T05:02:54,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T05:02:54,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T05:02:54,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683608574.45 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T05:02:54,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T05:02:54,455 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T05:02:54,455 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683608574.46 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T05:02:54,455 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T05:02:54,457 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683608574.46 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T05:02:54,458 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683608574.46 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - On WorkerInfo(id=0, name=worker0):
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - OutOfMemoryError('CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 22.19 GiB total capacity; 6.83 GiB already allocated; 90.50 MiB free; 6.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/internal.py", line 207, in _run_function
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     result = python_udf.func(*python_udf.args, **python_udf.kwargs)
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/rref_proxy.py", line 11, in _local_invoke
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return getattr(rref.local_value(), func_name)(*args, **kwargs)
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py", line 282, in create_stage_executor
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     mod=mod or Pipe.materialize_stage(mod_name),  # type: ignore[attr-defined]
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/IR.py", line 1097, in materialize_stage
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     submodule = load_checkpoint(
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/LoadModule.py", line 54, in load_checkpoint
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     _set_module_tensor_to_device(
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/LoadModule.py", line 210, in _set_module_tensor_to_device
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     new_value = value.to(device=device, dtype=dtype)
2023-05-09T05:03:00,592 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 22.19 GiB total capacity; 6.83 GiB already allocated; 90.50 MiB free; 6.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-05-09T05:03:05,110 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T05:03:08,968 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T05:03:09,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T05:03:09,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T05:03:09,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:03:09,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T05:03:09,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T05:03:09,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T05:03:09,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T05:03:09,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 180, in handle_connection
2023-05-09T05:03:09,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise RuntimeError("{} - {}".format(code, result))
2023-05-09T05:03:09,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - RuntimeError: 507 - System out of memory
2023-05-09T05:03:09,701 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:03:09,701 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:03:09,701 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 45490
2023-05-09T05:03:09,701 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 45490
2023-05-09T05:03:09,701 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T05:03:09,701 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T05:03:09,701 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:57.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683608589
2023-05-09T05:03:09,783 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_ERROR
2023-05-09T05:03:09,783 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_ERROR
2023-05-09T05:03:09,784 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T05:03:09,784 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T05:03:09,784 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:513) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:675) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:260) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:03:09,784 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:513) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:675) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:260) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:03:09,794 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T05:03:09,794 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T05:03:09,794 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683608589794
2023-05-09T05:03:09,794 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683608589794
2023-05-09T05:03:09,794 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T05:03:09,795 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:03:09,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T05:03:09,795 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:03:09,794 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:03:09,795 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:03:09,795 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:03:09,795 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:03:09,795 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:03:09,794 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:03:09,795 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:03:09,795 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:03:09,795 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:03:09,796 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:03:09,796 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:03:09,795 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:03:10,425 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:03:10,425 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:03:10,797 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:03:10,797 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:03:12,315 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:03:12,316 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:03:12,316 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:03:12,316 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:03:12,316 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:03:12,318 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:03:12,318 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_2yodnicr
2023-05-09T05:03:12,318 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:03:12,318 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:03:12,562 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=45727
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_2yodnicr/attempt_0/0/error.json
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_2yodnicr/attempt_0/1/error.json
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_2yodnicr/attempt_0/2/error.json
2023-05-09T05:03:12,563 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_2yodnicr/attempt_0/3/error.json
2023-05-09T05:03:13,759 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=21798
2023-05-09T05:03:13,760 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:03:13,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:03:13,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]21798
2023-05-09T05:03:13,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:03:13,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:03:13,776 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=21799
2023-05-09T05:03:13,776 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:03:13,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=21800
2023-05-09T05:03:13,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:03:13,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:03:13,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]21799
2023-05-09T05:03:13,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:03:13,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:03:13,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:03:13,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]21800
2023-05-09T05:03:13,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:03:13,793 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:03:13,814 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=21801
2023-05-09T05:03:13,814 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:03:13,822 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:03:13,822 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]21801
2023-05-09T05:03:13,823 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:03:13,823 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:03:13,823 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:03:13,823 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:03:13,823 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:03:13,823 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:03:13,825 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:03:13,825 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:03:13,825 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:03:13,825 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:03:13,825 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:03:13,825 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:03:13,825 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:03:13,825 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@28ca45b(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:03:13,825 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@28ca45b(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:03:13,827 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:03:13,827 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:03:13,827 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:03:13,827 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:03:13,827 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:03:13,827 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:03:13,827 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:03:13,827 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:03:13,828 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:03:13,828 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:03:13,828 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:03:13,828 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:14:38,820 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:14:38,820 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:14:38,874 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:14:38,874 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:14:39,071 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:14:39,071 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:14:39,077 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:14:39,077 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:14:39,093 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:14:39,093 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:14:39,118 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:14:39,118 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:14:39,119 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:14:39,119 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:14:39,119 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:14:39,119 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:14:39,119 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:14:39,119 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:14:39,119 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:14:39,119 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:14:39,129 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:14:39,129 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:14:39,131 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:14:39,131 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:14:39,189 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:14:39,189 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:14:39,189 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:14:39,189 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:14:39,190 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:14:39,190 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:14:39,191 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:14:39,191 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:14:39,193 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:14:39,193 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:14:39,371 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:14:39,371 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:14:40,687 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,688 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0672645568848|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,688 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25637435913086|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,689 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,689 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,689 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,689 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,690 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,690 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,690 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,690 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,690 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,691 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,691 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,691 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,691 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,691 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:374526.7734375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,692 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5069.53515625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,692 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:2.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609280
2023-05-09T05:14:40,696 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:14:40,697 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:14:40,697 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:14:40,697 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:14:40,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:14:40,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:14:40,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:14:40,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:14:40,698 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:14:40,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:14:40,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:14:40,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:14:40,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:14:40,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:14:40,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:14:40,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:14:40,699 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:14:40,700 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:14:40,700 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:14:40,700 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_9b_yp241
2023-05-09T05:14:40,701 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:14:40,701 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:14:40,938 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:14:40,938 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:14:40,938 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:14:40,938 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=54961
2023-05-09T05:14:40,938 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:14:40,938 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:14:40,939 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:14:40,939 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:14:40,939 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:14:40,939 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:14:40,939 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:14:40,939 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:14:40,939 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:14:40,940 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:14:40,940 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_9b_yp241/attempt_0/0/error.json
2023-05-09T05:14:40,940 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_9b_yp241/attempt_0/1/error.json
2023-05-09T05:14:40,940 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_9b_yp241/attempt_0/2/error.json
2023-05-09T05:14:40,940 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_9b_yp241/attempt_0/3/error.json
2023-05-09T05:14:42,139 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=24382
2023-05-09T05:14:42,140 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:14:42,148 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:14:42,148 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]24382
2023-05-09T05:14:42,148 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:14:42,148 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:14:42,151 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=24380
2023-05-09T05:14:42,152 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:14:42,160 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:14:42,160 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]24380
2023-05-09T05:14:42,160 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:14:42,161 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:14:42,166 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=24381
2023-05-09T05:14:42,166 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:14:42,174 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:14:42,175 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]24381
2023-05-09T05:14:42,175 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:14:42,175 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:14:42,200 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=24383
2023-05-09T05:14:42,200 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:14:42,209 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:14:42,209 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]24383
2023-05-09T05:14:42,209 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:14:42,209 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:14:42,210 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:14:42,210 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:14:42,214 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:14:42,214 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:14:42,221 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:14:42,222 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:14:42,222 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:14:42,224 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:14:42,224 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:14:42,224 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:14:42,226 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:14:42,226 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:14:42,226 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T05:14:42,227 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T05:14:42,229 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683609282229
2023-05-09T05:14:42,229 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683609282229
2023-05-09T05:14:42,253 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:14:42,264 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:14:42,275 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:14:42,285 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:14:43,074 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:14:43,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:14:43,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:14:43,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:14:43,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:14:43,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:14:43,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:14:43,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:14:43,077 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 24382/2
2023-05-09T05:14:43,077 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 24381/1
2023-05-09T05:14:43,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:14:43,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:14:43,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:14:43,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:14:43,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:14:43,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:14:43,083 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:14:43,084 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:14:43,085 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 24383/3
2023-05-09T05:14:43,086 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 24380/0
2023-05-09T05:15:10,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.854805241999657 seconds
2023-05-09T05:15:10,419 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:15:10,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:15:10,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:15:10,487 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.996039507000205 seconds
2023-05-09T05:15:10,550 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:15:10,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:15:10,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:15:10,597 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.095875521999915 seconds
2023-05-09T05:15:10,657 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:15:10,658 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:15:10,659 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:15:11,429 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:15:11,431 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T05:15:11,431 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:15:11,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0123358000000735 seconds on rank 2
2023-05-09T05:15:11,432 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/990d7b8c076844d4a1cba8c69d737bd1 loaded successfully
2023-05-09T05:15:11,558 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:15:11,561 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T05:15:11,561 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:15:11,561 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0115473980004026 seconds on rank 1
2023-05-09T05:15:11,561 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/990d7b8c076844d4a1cba8c69d737bd1 loaded successfully
2023-05-09T05:15:11,671 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:15:11,674 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T05:15:11,674 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:15:11,674 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0175422960001015 seconds on rank 3
2023-05-09T05:15:11,674 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/990d7b8c076844d4a1cba8c69d737bd1 loaded successfully
2023-05-09T05:15:12,443 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.855560311999852 seconds
2023-05-09T05:15:12,504 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:15:12,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:15:12,506 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:15:13,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:15:13,521 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,523 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,528 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,529 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,530 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,531 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,532 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,533 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,534 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,535 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,536 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,537 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,539 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:15:13,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T05:15:13,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609313.54 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T05:15:13,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T05:15:13,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T05:15:13,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609313.54 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T05:15:13,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T05:15:13,545 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609313.55 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T05:15:13,546 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609313.55 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T05:15:19,802 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - On WorkerInfo(id=0, name=worker0):
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - OutOfMemoryError('CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 22.19 GiB total capacity; 6.83 GiB already allocated; 90.50 MiB free; 6.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/internal.py", line 207, in _run_function
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     result = python_udf.func(*python_udf.args, **python_udf.kwargs)
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/rref_proxy.py", line 11, in _local_invoke
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return getattr(rref.local_value(), func_name)(*args, **kwargs)
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py", line 282, in create_stage_executor
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     mod=mod or Pipe.materialize_stage(mod_name),  # type: ignore[attr-defined]
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/IR.py", line 1097, in materialize_stage
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     submodule = load_checkpoint(
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/LoadModule.py", line 54, in load_checkpoint
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     _set_module_tensor_to_device(
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/LoadModule.py", line 210, in _set_module_tensor_to_device
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     new_value = value.to(device=device, dtype=dtype)
2023-05-09T05:15:19,803 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 22.19 GiB total capacity; 6.83 GiB already allocated; 90.50 MiB free; 6.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-05-09T05:15:24,014 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T05:15:28,092 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T05:15:28,636 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 180, in handle_connection
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise RuntimeError("{} - {}".format(code, result))
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - RuntimeError: 507 - System out of memory
2023-05-09T05:15:28,637 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:15:28,637 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46352
2023-05-09T05:15:28,637 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46352
2023-05-09T05:15:28,638 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T05:15:28,638 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T05:15:28,638 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:57.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609328
2023-05-09T05:15:28,720 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_ERROR
2023-05-09T05:15:28,720 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_ERROR
2023-05-09T05:15:28,720 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T05:15:28,720 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T05:15:28,720 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:513) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:675) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:260) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:28,720 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:513) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:675) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:260) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:28,731 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T05:15:28,731 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T05:15:28,731 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683609328731
2023-05-09T05:15:28,731 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683609328731
2023-05-09T05:15:28,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T05:15:28,732 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T05:15:28,732 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:28,732 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:15:28,732 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:15:28,732 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:15:28,732 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:28,732 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:15:28,733 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:28,732 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:15:28,732 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:15:28,733 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:28,732 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:15:28,732 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:15:28,733 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:15:28,733 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:15:29,367 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:15:29,367 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:15:29,734 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:15:29,734 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:15:31,260 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:15:31,261 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:15:31,264 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:15:31,264 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3sbnty1i
2023-05-09T05:15:31,264 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:15:31,264 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=48405
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3sbnty1i/attempt_0/0/error.json
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3sbnty1i/attempt_0/1/error.json
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3sbnty1i/attempt_0/2/error.json
2023-05-09T05:15:31,449 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_3sbnty1i/attempt_0/3/error.json
2023-05-09T05:15:32,677 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25428
2023-05-09T05:15:32,677 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:32,678 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25427
2023-05-09T05:15:32,679 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:32,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:32,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25428
2023-05-09T05:15:32,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:32,686 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:32,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:32,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25427
2023-05-09T05:15:32,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:32,687 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:32,692 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25430
2023-05-09T05:15:32,693 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:32,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25429
2023-05-09T05:15:32,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:32,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:32,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25430
2023-05-09T05:15:32,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:32,701 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:32,702 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:32,702 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25429
2023-05-09T05:15:32,703 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:32,703 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:32,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:15:32,703 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:15:32,703 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:15:32,703 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:15:32,705 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:15:32,705 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:15:32,705 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:15:32,705 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:15:32,705 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:15:32,705 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:15:32,705 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:15:32,705 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@27265f19(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:32,705 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@27265f19(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:32,708 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:15:32,708 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:15:32,708 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:15:32,708 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:15:32,708 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:32,708 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:32,708 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:32,708 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:15:32,708 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:32,708 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:15:32,708 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:15:32,708 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:15:32,708 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:15:33,708 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:15:33,708 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:15:35,231 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:15:35,232 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:15:35,235 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:15:35,235 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4q44jzfv
2023-05-09T05:15:35,235 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:15:35,235 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:15:35,412 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=47759
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4q44jzfv/attempt_0/0/error.json
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4q44jzfv/attempt_0/1/error.json
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4q44jzfv/attempt_0/2/error.json
2023-05-09T05:15:35,413 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4q44jzfv/attempt_0/3/error.json
2023-05-09T05:15:36,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25512
2023-05-09T05:15:36,624 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:36,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25510
2023-05-09T05:15:36,626 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:36,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25511
2023-05-09T05:15:36,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:36,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:36,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25512
2023-05-09T05:15:36,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:36,632 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:36,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:36,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25510
2023-05-09T05:15:36,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:36,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:36,641 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:36,641 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25511
2023-05-09T05:15:36,641 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:36,641 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:36,664 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25513
2023-05-09T05:15:36,664 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:36,673 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:36,673 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25513
2023-05-09T05:15:36,673 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:36,673 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:36,673 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:15:36,673 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:15:36,673 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:15:36,673 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:15:36,675 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:15:36,675 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:15:36,675 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:15:36,675 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:15:36,675 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:15:36,676 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:15:36,676 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:15:36,676 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@5f1e9196(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:36,676 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@5f1e9196(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:36,677 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:15:36,677 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:15:36,677 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:15:36,677 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:15:36,678 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:36,678 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:36,678 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:36,678 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:36,678 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:15:36,678 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T05:15:36,678 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:15:36,678 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T05:15:38,679 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:15:38,679 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:15:40,181 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:15:40,182 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:15:40,185 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:15:40,186 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_cjucx_5j
2023-05-09T05:15:40,186 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:15:40,186 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=39333
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_cjucx_5j/attempt_0/0/error.json
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_cjucx_5j/attempt_0/1/error.json
2023-05-09T05:15:40,488 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_cjucx_5j/attempt_0/2/error.json
2023-05-09T05:15:40,489 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_cjucx_5j/attempt_0/3/error.json
2023-05-09T05:15:40,659 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,659 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:566.0669403076172|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,659 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:403.25669860839844|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,659 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,659 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,660 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:372671.19921875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,661 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:6924.61328125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:40,661 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:2.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609340
2023-05-09T05:15:41,673 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25675
2023-05-09T05:15:41,674 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:41,682 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:41,682 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25675
2023-05-09T05:15:41,682 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:41,682 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:41,694 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25676
2023-05-09T05:15:41,695 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:41,703 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:41,703 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25676
2023-05-09T05:15:41,703 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:41,703 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:41,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25677
2023-05-09T05:15:41,727 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:41,730 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25678
2023-05-09T05:15:41,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:41,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:41,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25677
2023-05-09T05:15:41,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:41,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:41,739 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:41,739 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25678
2023-05-09T05:15:41,739 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:41,739 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:41,739 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:15:41,739 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:15:41,740 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:15:41,740 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:15:41,742 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:15:41,742 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:15:41,742 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:15:41,742 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:15:41,742 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:15:41,742 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:15:41,742 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:15:41,742 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3725c198(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:41,742 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3725c198(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:41,743 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:15:41,743 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:15:41,743 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:15:41,743 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:15:41,744 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:41,744 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:41,744 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:41,744 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:41,744 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T05:15:41,744 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T05:15:41,744 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:15:41,744 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:15:44,744 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:15:44,744 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:15:46,266 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:15:46,267 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:15:46,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:15:46,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lgb_l_j9
2023-05-09T05:15:46,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:15:46,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=55147
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lgb_l_j9/attempt_0/0/error.json
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lgb_l_j9/attempt_0/1/error.json
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lgb_l_j9/attempt_0/2/error.json
2023-05-09T05:15:46,345 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_lgb_l_j9/attempt_0/3/error.json
2023-05-09T05:15:47,542 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25773
2023-05-09T05:15:47,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:47,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25770
2023-05-09T05:15:47,547 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:47,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:47,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25773
2023-05-09T05:15:47,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:47,551 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:47,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:47,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25770
2023-05-09T05:15:47,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:47,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:47,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25776
2023-05-09T05:15:47,582 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:47,589 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=25777
2023-05-09T05:15:47,589 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:15:47,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:47,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25776
2023-05-09T05:15:47,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:47,591 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:47,598 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:15:47,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]25777
2023-05-09T05:15:47,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:15:47,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:15:47,599 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:15:47,599 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:15:47,599 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:15:47,599 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:15:47,601 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:15:47,601 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:15:47,601 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:15:47,601 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:15:47,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:15:47,601 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:15:47,601 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:15:47,601 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@226e9ef2(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:47,601 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@226e9ef2(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:15:47,603 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:15:47,603 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:15:47,603 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:15:47,603 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:15:47,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:15:47,603 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:47,603 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:15:47,603 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:47,603 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:15:47,603 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T05:15:47,603 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 5 seconds.
2023-05-09T05:21:24,036 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:21:24,036 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:21:24,089 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:21:24,089 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:21:24,275 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:21:24,275 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:21:24,281 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:21:24,281 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:21:24,299 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:21:24,299 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:21:24,325 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:21:24,325 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:21:24,325 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:21:24,325 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:21:24,325 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:21:24,325 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:21:24,325 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:21:24,325 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:21:24,326 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:21:24,326 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:21:24,336 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:21:24,336 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:21:24,337 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:21:24,337 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:21:24,393 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:21:24,393 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:21:24,394 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:21:24,394 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:21:24,395 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:21:24,395 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:21:24,396 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:21:24,396 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:21:24,397 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:21:24,397 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:21:24,576 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:21:24,576 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:21:25,882 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,884 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0668106079102|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,884 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25682830810547|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,885 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,885 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,885 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:21:25,885 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,885 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:21:25,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:21:25,886 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:21:25,886 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:21:25,886 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,886 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:21:25,886 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,887 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:21:25,887 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:21:25,887 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,887 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:21:25,887 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:21:25,887 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,887 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:21:25,887 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:21:25,887 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,888 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:21:25,888 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:21:25,888 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,888 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:21:25,888 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,888 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:21:25,888 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:21:25,888 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,888 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:21:25,889 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:374522.64453125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,889 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5073.32421875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,889 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:2.1|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609685
2023-05-09T05:21:25,890 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:21:25,891 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_txjveybw
2023-05-09T05:21:25,891 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:21:25,891 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:21:26,189 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:21:26,189 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:21:26,189 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:21:26,189 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=33167
2023-05-09T05:21:26,189 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:21:26,189 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:21:26,190 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:21:26,190 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:21:26,190 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:21:26,190 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:21:26,190 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:21:26,190 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:21:26,190 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:21:26,191 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:21:26,191 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_txjveybw/attempt_0/0/error.json
2023-05-09T05:21:26,191 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_txjveybw/attempt_0/1/error.json
2023-05-09T05:21:26,191 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_txjveybw/attempt_0/2/error.json
2023-05-09T05:21:26,191 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_txjveybw/attempt_0/3/error.json
2023-05-09T05:21:27,411 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=26626
2023-05-09T05:21:27,412 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:21:27,412 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=26628
2023-05-09T05:21:27,412 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:21:27,412 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=26627
2023-05-09T05:21:27,412 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:21:27,415 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=26629
2023-05-09T05:21:27,416 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:21:27,419 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:21:27,420 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]26626
2023-05-09T05:21:27,420 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:21:27,420 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:21:27,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:21:27,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]26628
2023-05-09T05:21:27,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:21:27,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:21:27,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:21:27,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]26627
2023-05-09T05:21:27,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:21:27,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:21:27,425 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:21:27,426 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]26629
2023-05-09T05:21:27,426 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:21:27,426 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:21:27,426 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:21:27,426 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:21:27,430 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:21:27,430 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:21:27,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:21:27,438 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:21:27,438 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:21:27,440 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:21:27,440 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:21:27,441 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:21:27,442 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:21:27,442 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:21:27,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T05:21:27,444 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T05:21:27,446 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683609687446
2023-05-09T05:21:27,446 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683609687446
2023-05-09T05:21:27,468 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:21:27,480 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:21:27,490 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:21:27,500 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:21:28,244 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:21:28,244 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:21:28,244 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:21:28,244 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:21:28,246 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 26627/1
2023-05-09T05:21:28,252 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:21:28,252 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:21:28,252 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:21:28,252 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:21:28,254 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 26626/0
2023-05-09T05:21:28,263 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:21:28,263 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:21:28,264 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:21:28,264 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:21:28,266 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 26628/2
2023-05-09T05:21:28,279 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:21:28,279 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:21:28,279 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:21:28,279 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:21:28,281 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 26629/3
2023-05-09T05:21:55,561 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.869959912000013 seconds
2023-05-09T05:21:55,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:21:55,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:21:55,625 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:21:55,657 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.955982099000266 seconds
2023-05-09T05:21:55,718 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:21:55,720 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:21:55,720 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:21:55,754 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.05364674700013 seconds
2023-05-09T05:21:55,815 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:21:55,817 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:21:55,817 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:21:56,635 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:21:56,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T05:21:56,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:21:56,637 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.014463644999978 seconds on rank 1
2023-05-09T05:21:56,638 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/1ca07710d4fb4097b7285a6e1cf00792 loaded successfully
2023-05-09T05:21:56,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:21:56,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T05:21:56,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:21:56,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0181641359999958 seconds on rank 3
2023-05-09T05:21:56,736 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/1ca07710d4fb4097b7285a6e1cf00792 loaded successfully
2023-05-09T05:21:56,833 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:21:56,836 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T05:21:56,836 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:21:56,836 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.021413290000055 seconds on rank 2
2023-05-09T05:21:56,836 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/1ca07710d4fb4097b7285a6e1cf00792 loaded successfully
2023-05-09T05:21:57,524 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.740788280999823 seconds
2023-05-09T05:21:57,585 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:21:57,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:21:57,587 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:21:58,595 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:21:58,598 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T05:21:58,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T05:21:58,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T05:21:58,599 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,600 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,601 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,602 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,603 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,604 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,605 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T05:21:58,606 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T05:21:58,607 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,609 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,610 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,611 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,612 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,613 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:21:58,614 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T05:21:58,615 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,616 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:21:58,617 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T05:21:58,618 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T05:21:58,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609718.62 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T05:21:58,619 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T05:21:58,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T05:21:58,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609718.62 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T05:21:58,621 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T05:21:58,622 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609718.62 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T05:21:58,623 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609718.62 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - On WorkerInfo(id=0, name=worker0):
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - OutOfMemoryError('CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 22.19 GiB total capacity; 6.83 GiB already allocated; 90.50 MiB free; 6.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/internal.py", line 207, in _run_function
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     result = python_udf.func(*python_udf.args, **python_udf.kwargs)
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torch/distributed/rpc/rref_proxy.py", line 11, in _local_invoke
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     return getattr(rref.local_value(), func_name)(*args, **kwargs)
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py", line 282, in create_stage_executor
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     mod=mod or Pipe.materialize_stage(mod_name),  # type: ignore[attr-defined]
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/IR.py", line 1097, in materialize_stage
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     submodule = load_checkpoint(
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/LoadModule.py", line 54, in load_checkpoint
2023-05-09T05:22:04,786 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     _set_module_tensor_to_device(
2023-05-09T05:22:04,787 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/LoadModule.py", line 210, in _set_module_tensor_to_device
2023-05-09T05:22:04,787 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -     new_value = value.to(device=device, dtype=dtype)
2023-05-09T05:22:04,787 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 22.19 GiB total capacity; 6.83 GiB already allocated; 90.50 MiB free; 6.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-05-09T05:22:09,036 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T05:22:13,139 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T05:22:13,699 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 180, in handle_connection
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     raise RuntimeError("{} - {}".format(code, result))
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - RuntimeError: 507 - System out of memory
2023-05-09T05:22:13,700 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:22:13,700 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46200
2023-05-09T05:22:13,700 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46200
2023-05-09T05:22:13,701 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T05:22:13,701 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_ERROR
2023-05-09T05:22:13,701 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:55.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609733
2023-05-09T05:22:13,783 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_ERROR
2023-05-09T05:22:13,783 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_ERROR
2023-05-09T05:22:13,784 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T05:22:13,784 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_ERROR
2023-05-09T05:22:13,784 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:513) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:675) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:260) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:22:13,784 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:513) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:675) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:260) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:22:13,794 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T05:22:13,794 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_ERROR -> WORKER_STOPPED
2023-05-09T05:22:13,794 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683609733794
2023-05-09T05:22:13,794 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683609733794
2023-05-09T05:22:13,795 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-09T05:22:13,795 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:22:13,795 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:22:13,795 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:22:13,795 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:22:13,795 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:22:13,795 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:22:13,795 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:22:13,795 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:22:13,795 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:22:13,795 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:22:13,795 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:22:13,795 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STOPPED
2023-05-09T05:22:13,796 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:22:13,796 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:22:14,379 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:22:14,379 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:23:14,656 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:23:14,656 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:23:14,709 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:23:14,709 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:23:14,918 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:23:14,918 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:23:14,924 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:23:14,924 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:23:14,940 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:23:14,940 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:23:14,965 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:23:14,965 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:23:14,966 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:23:14,966 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:23:14,966 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:23:14,966 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:23:14,966 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:23:14,966 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:23:14,966 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:23:14,966 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:23:14,976 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:23:14,976 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:23:14,978 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:23:14,978 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:23:15,035 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:23:15,035 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:23:15,035 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:23:15,035 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:23:15,037 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:23:15,037 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:23:15,037 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:23:15,037 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:23:15,039 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:23:15,039 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:23:15,217 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:23:15,217 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:23:16,517 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:23:16,518 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:23:16,518 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:23:16,518 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:23:16,518 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:23:16,519 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:23:16,519 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:23:16,519 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:23:16,519 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:23:16,519 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:23:16,519 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:23:16,520 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:23:16,520 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:23:16,520 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:23:16,520 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:23:16,520 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:23:16,520 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:23:16,520 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:23:16,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:23:16,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w5ryj4z2
2023-05-09T05:23:16,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:23:16,521 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:23:16,634 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:5.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,635 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0697364807129|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,635 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25390243530273|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,635 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,635 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,636 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,636 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,636 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,636 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,636 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,636 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,637 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,637 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,637 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,637 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,637 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,637 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:376344.2421875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,638 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3406.48828125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,638 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.7|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609796
2023-05-09T05:23:16,825 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:23:16,826 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:23:16,826 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:23:16,826 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=58005
2023-05-09T05:23:16,826 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:23:16,826 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:23:16,826 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:23:16,826 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:23:16,827 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:23:16,827 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:23:16,827 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:23:16,827 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:23:16,827 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:23:16,827 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:23:16,827 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w5ryj4z2/attempt_0/0/error.json
2023-05-09T05:23:16,828 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w5ryj4z2/attempt_0/1/error.json
2023-05-09T05:23:16,828 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w5ryj4z2/attempt_0/2/error.json
2023-05-09T05:23:16,828 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_w5ryj4z2/attempt_0/3/error.json
2023-05-09T05:23:18,024 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=28557
2023-05-09T05:23:18,026 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:23:18,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:23:18,033 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]28557
2023-05-09T05:23:18,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:23:18,034 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:23:18,038 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=28559
2023-05-09T05:23:18,039 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:23:18,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:23:18,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]28559
2023-05-09T05:23:18,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:23:18,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:23:18,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=28558
2023-05-09T05:23:18,049 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:23:18,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:23:18,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]28558
2023-05-09T05:23:18,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:23:18,058 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:23:18,085 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=28560
2023-05-09T05:23:18,086 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:23:18,094 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:23:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]28560
2023-05-09T05:23:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:23:18,095 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:23:18,095 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:23:18,095 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:23:18,099 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:23:18,099 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:23:18,106 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:23:18,107 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:23:18,107 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:23:18,109 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:23:18,109 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:23:18,109 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:23:18,111 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:23:18,111 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:23:18,111 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T05:23:18,113 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T05:23:18,115 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683609798115
2023-05-09T05:23:18,115 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683609798115
2023-05-09T05:23:18,137 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:23:18,149 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:23:18,159 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:23:18,170 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:23:19,047 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:23:19,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:23:19,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:23:19,048 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:23:19,050 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 28559/2
2023-05-09T05:23:19,073 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:23:19,073 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:23:19,073 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:23:19,073 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:23:19,074 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:23:19,074 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:23:19,074 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:23:19,074 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:23:19,074 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:23:19,074 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:23:19,074 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:23:19,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:23:19,075 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 28558/1
2023-05-09T05:23:19,076 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 28557/0
2023-05-09T05:23:19,076 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 28560/3
2023-05-09T05:23:46,464 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.939711623999756 seconds
2023-05-09T05:23:46,481 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.956117996999637 seconds
2023-05-09T05:23:46,525 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:23:46,526 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:23:46,527 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:23:46,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:23:46,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:23:46,543 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:23:46,769 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.244640118999996 seconds
2023-05-09T05:23:46,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:23:46,832 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:23:46,832 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:23:47,538 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:23:47,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T05:23:47,540 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:23:47,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0158959870000217 seconds on rank 1
2023-05-09T05:23:47,541 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/30e52ca00d124adcb45c4ceac2b523d9 loaded successfully
2023-05-09T05:23:47,553 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:23:47,555 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T05:23:47,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:23:47,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0148927310001454 seconds on rank 3
2023-05-09T05:23:47,556 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/30e52ca00d124adcb45c4ceac2b523d9 loaded successfully
2023-05-09T05:23:47,843 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:23:47,846 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T05:23:47,846 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:23:47,846 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0159925289999592 seconds on rank 2
2023-05-09T05:23:47,846 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/30e52ca00d124adcb45c4ceac2b523d9 loaded successfully
2023-05-09T05:23:48,278 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.69857303400022 seconds
2023-05-09T05:23:48,339 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:23:48,341 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:23:48,341 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:23:49,355 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:23:49,358 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T05:23:49,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T05:23:49,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T05:23:49,359 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,360 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,362 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,365 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,366 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,367 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T05:23:49,368 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,369 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,370 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T05:23:49,371 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,372 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,373 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,374 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,375 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,376 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,377 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T05:23:49,378 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609829.38 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T05:23:49,379 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T05:23:49,380 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T05:23:49,380 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609829.38 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T05:23:49,381 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T05:23:49,381 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609829.38 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T05:23:49,382 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683609829.38 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T05:23:59,857 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T05:24:03,634 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 0
2023-05-09T05:24:04,090 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T05:24:04,646 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T05:24:04,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:24:04,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 16.405620918000295 seconds on rank 0
2023-05-09T05:24:04,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/30e52ca00d124adcb45c4ceac2b523d9 loaded successfully
2023-05-09T05:24:04,745 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:24:04,745 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:24:04,745 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46576
2023-05-09T05:24:04,745 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46576
2023-05-09T05:24:04,746 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T05:24:04,746 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T05:24:04,746 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:49775.0|#WorkerName:W-29500-opt_1.0,Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609844
2023-05-09T05:24:04,746 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:55.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609844
2023-05-09T05:24:16,213 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:10.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,213 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0695190429688|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,213 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.2541198730469|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,213 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,213 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.4693416710092|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,214 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14846.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,214 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,214 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,214 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.75594927913843|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,214 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:14912.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,214 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:71.14816744832378|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,215 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:16384.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,215 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,215 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,215 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,215 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,215 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:369303.71484375|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,215 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9973.625|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:24:16,215 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.5|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609856
2023-05-09T05:25:33,230 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:25:33,230 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:25:33,283 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:25:33,283 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:25:33,482 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:25:33,482 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:25:33,489 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:25:33,489 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:25:33,505 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:25:33,505 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:25:33,531 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:25:33,531 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:25:33,531 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:25:33,531 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:25:33,531 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:25:33,531 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:25:33,531 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:25:33,531 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:25:33,531 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:25:33,531 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:25:33,542 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:25:33,542 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:25:33,543 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:25:33,543 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:25:33,600 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:25:33,600 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:25:33,601 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:25:33,601 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:25:33,602 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:25:33,602 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:25:33,603 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:25:33,603 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:25:33,604 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:25:33,604 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:25:33,786 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:25:33,786 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:25:35,063 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:25:35,064 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:25:35,064 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:25:35,065 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:25:35,065 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:25:35,065 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:25:35,065 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:25:35,065 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:25:35,066 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:25:35,066 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:25:35,066 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:25:35,066 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:25:35,066 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:25:35,066 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:25:35,067 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:25:35,067 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:25:35,067 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:25:35,067 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:25:35,067 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:25:35,067 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1z_m81rf
2023-05-09T05:25:35,068 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:25:35,068 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:25:35,202 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,204 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0694808959961|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,204 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25415802001953|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,204 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,205 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,205 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,205 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,205 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,205 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,205 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,206 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,206 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,206 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,206 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,206 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,207 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,207 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:376317.01953125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,207 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3432.76171875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,207 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.7|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683609935
2023-05-09T05:25:35,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:25:35,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:25:35,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:25:35,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=48617
2023-05-09T05:25:35,245 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:25:35,246 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:25:35,246 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:25:35,246 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:25:35,246 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:25:35,246 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:25:35,246 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:25:35,246 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:25:35,247 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:25:35,247 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:25:35,247 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1z_m81rf/attempt_0/0/error.json
2023-05-09T05:25:35,247 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1z_m81rf/attempt_0/1/error.json
2023-05-09T05:25:35,247 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1z_m81rf/attempt_0/2/error.json
2023-05-09T05:25:35,247 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1z_m81rf/attempt_0/3/error.json
2023-05-09T05:25:36,453 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=30882
2023-05-09T05:25:36,454 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:25:36,456 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=30880
2023-05-09T05:25:36,456 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:25:36,462 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:25:36,462 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]30882
2023-05-09T05:25:36,463 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:25:36,463 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:25:36,465 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:25:36,465 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]30880
2023-05-09T05:25:36,465 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:25:36,465 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:25:36,492 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=30884
2023-05-09T05:25:36,492 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:25:36,492 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=30883
2023-05-09T05:25:36,493 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:25:36,501 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:25:36,501 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:25:36,501 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]30884
2023-05-09T05:25:36,501 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:25:36,501 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:25:36,501 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]30883
2023-05-09T05:25:36,501 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:25:36,502 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:25:36,502 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:25:36,502 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:25:36,505 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:25:36,505 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:25:36,513 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:25:36,514 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:25:36,514 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:25:36,515 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:25:36,515 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:25:36,516 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:25:36,517 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:25:36,517 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:25:36,518 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T05:25:36,519 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T05:25:36,521 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683609936521
2023-05-09T05:25:36,521 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683609936521
2023-05-09T05:25:36,544 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:25:36,555 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:25:36,565 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:25:36,576 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:25:37,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:25:37,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:25:37,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:25:37,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:25:37,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:25:37,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:25:37,421 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:25:37,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:25:37,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:25:37,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:25:37,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:25:37,422 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:25:37,423 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 30884/3
2023-05-09T05:25:37,424 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 30880/0
2023-05-09T05:25:37,424 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 30882/1
2023-05-09T05:25:37,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:25:37,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:25:37,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:25:37,439 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:25:37,442 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 30883/2
2023-05-09T05:26:03,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.842461215000185 seconds
2023-05-09T05:26:03,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:26:03,785 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Backend worker process died.
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 244, in <module>
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     worker.run_server()
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 212, in run_server
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 175, in handle_connection
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2023-05-09T05:26:03,786 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     service = model_loader.load(
2023-05-09T05:26:03,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-05-09T05:26:03,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2023-05-09T05:26:03,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/tmp/models/df5f96c787b146f09fca3857ca344c60/pippy_handler.py", line 76, in initialize
2023-05-09T05:26:03,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     self.model = get_pipeline_driver(self.model, self.world_size, ctx)
2023-05-09T05:26:03,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   File "/opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/handler_utils/distributed/pt_pippy.py", line 123, in get_pipeline_driver
2023-05-09T05:26:03,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     index_filename=index_file,
2023-05-09T05:26:03,787 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - NameError: name 'index_file' is not defined
2023-05-09T05:26:03,791 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 25.91000349900014 seconds
2023-05-09T05:26:03,793 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:03,793 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:03,794 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:26:03,794 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:26:03,795 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:26:03,795 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:26:03,806 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T05:26:03,806 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: opt, error: Worker died.
2023-05-09T05:26:03,807 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:26:03,807 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:26:03,807 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683609963807
2023-05-09T05:26:03,807 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1683609963807
2023-05-09T05:26:03,807 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:03,807 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:03,807 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:26:03,807 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:26:03,807 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:03,807 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:26:03,807 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:03,807 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:03,807 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:26:03,807 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:03,808 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:26:03,808 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:26:03,856 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:26:03,856 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:26:03,858 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:26:03,858 [INFO ] W-29500-opt_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stderr
2023-05-09T05:26:04,808 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:26:04,808 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:26:06,352 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:26:06,352 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:26:06,352 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:26:06,353 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:26:06,354 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:26:06,354 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:26:06,354 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:26:06,354 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:26:06,356 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:26:06,356 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4od9t0xg
2023-05-09T05:26:06,356 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:26:06,356 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:26:06,631 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=40097
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:26:06,632 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:26:06,633 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4od9t0xg/attempt_0/0/error.json
2023-05-09T05:26:06,633 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4od9t0xg/attempt_0/1/error.json
2023-05-09T05:26:06,633 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4od9t0xg/attempt_0/2/error.json
2023-05-09T05:26:06,633 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_4od9t0xg/attempt_0/3/error.json
2023-05-09T05:26:07,848 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=31845
2023-05-09T05:26:07,849 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:07,857 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:07,857 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]31845
2023-05-09T05:26:07,857 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:07,858 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:07,858 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=31844
2023-05-09T05:26:07,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:07,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=31842
2023-05-09T05:26:07,859 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:07,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=31843
2023-05-09T05:26:07,860 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:07,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:07,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]31844
2023-05-09T05:26:07,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:07,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:07,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:07,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]31842
2023-05-09T05:26:07,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:07,867 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:07,869 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:07,869 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]31843
2023-05-09T05:26:07,869 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:07,869 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:07,869 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:26:07,869 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:26:07,869 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:26:07,869 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:26:07,871 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:26:07,871 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:07,871 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:26:07,871 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:07,872 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:26:07,872 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:26:07,872 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:26:07,872 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@63f7544f(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:26:07,872 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@63f7544f(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:26:07,874 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:26:07,874 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:26:07,874 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:26:07,874 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:26:07,874 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:26:07,875 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:26:07,875 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:26:07,875 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:26:07,875 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:26:07,875 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:26:07,875 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 1 seconds.
2023-05-09T05:26:08,875 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:26:08,875 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:26:10,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:26:10,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:26:10,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:26:10,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:26:10,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:26:10,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:26:10,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:26:10,381 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:26:10,382 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:26:10,385 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:26:10,385 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1otzj3p6
2023-05-09T05:26:10,385 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:26:10,385 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=50937
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1otzj3p6/attempt_0/0/error.json
2023-05-09T05:26:10,516 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1otzj3p6/attempt_0/1/error.json
2023-05-09T05:26:10,517 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1otzj3p6/attempt_0/2/error.json
2023-05-09T05:26:10,517 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_1otzj3p6/attempt_0/3/error.json
2023-05-09T05:26:11,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=31934
2023-05-09T05:26:11,723 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:11,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:11,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]31934
2023-05-09T05:26:11,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:11,731 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:11,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=31931
2023-05-09T05:26:11,734 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:11,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=31932
2023-05-09T05:26:11,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:11,740 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=31933
2023-05-09T05:26:11,740 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:11,743 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:11,743 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]31931
2023-05-09T05:26:11,743 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:11,743 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:11,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:11,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]31932
2023-05-09T05:26:11,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:11,744 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:11,749 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:11,749 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]31933
2023-05-09T05:26:11,749 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:11,749 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:11,749 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:26:11,749 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:26:11,749 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:26:11,749 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:26:11,752 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:26:11,752 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:11,752 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:26:11,752 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:11,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:26:11,752 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:26:11,752 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:26:11,752 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3c0d045e(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:26:11,752 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@3c0d045e(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:26:11,754 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:26:11,754 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:26:11,754 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:26:11,754 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:26:11,754 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:26:11,754 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:26:11,754 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:26:11,754 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:26:11,754 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:26:11,754 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T05:26:11,754 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:26:11,754 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 2 seconds.
2023-05-09T05:26:13,755 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:26:13,755 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:26:15,269 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:26:15,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:26:15,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:26:15,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:26:15,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:26:15,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:26:15,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:26:15,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:26:15,270 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:26:15,271 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:26:15,274 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:26:15,274 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fsqsq8ch
2023-05-09T05:26:15,274 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:26:15,274 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=59685
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:26:15,570 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:26:15,571 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fsqsq8ch/attempt_0/0/error.json
2023-05-09T05:26:15,571 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fsqsq8ch/attempt_0/1/error.json
2023-05-09T05:26:15,571 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fsqsq8ch/attempt_0/2/error.json
2023-05-09T05:26:15,571 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_fsqsq8ch/attempt_0/3/error.json
2023-05-09T05:26:16,775 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=32028
2023-05-09T05:26:16,776 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:16,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:16,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]32028
2023-05-09T05:26:16,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:16,784 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:16,788 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=32029
2023-05-09T05:26:16,788 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:16,796 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]32029
2023-05-09T05:26:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:16,797 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:16,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=32030
2023-05-09T05:26:16,811 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:16,817 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=32031
2023-05-09T05:26:16,817 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:26:16,819 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:16,820 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]32030
2023-05-09T05:26:16,820 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:16,820 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:16,825 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:26:16,826 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]32031
2023-05-09T05:26:16,826 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:26:16,826 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:26:16,826 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:26:16,826 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2023-05-09T05:26:16,826 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:26:16,826 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:26:16,828 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:26:16,828 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:26:16,828 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:16,828 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_STARTED
2023-05-09T05:26:16,829 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:26:16,828 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:26:16,829 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-05-09T05:26:16,829 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2d5ca625(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:26:16,829 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@2d5ca625(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:243) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:131) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:403) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:119) ~[model-server.jar:?]
	at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:30) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-05-09T05:26:16,830 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:26:16,830 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2023-05-09T05:26:16,830 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:26:16,830 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2023-05-09T05:26:16,831 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:26:16,831 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stderr
2023-05-09T05:26:16,831 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:26:16,830 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:26:16,831 [WARN ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-opt_1.0-stdout
2023-05-09T05:26:16,831 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T05:26:16,831 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 29500 in 3 seconds.
2023-05-09T05:26:16,831 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:26:16,831 [INFO ] W-29500-opt_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-opt_1.0-stdout
2023-05-09T05:27:04,382 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:27:04,382 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-09T05:27:04,435 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:27:04,435 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-09T05:27:04,623 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:27:04,623 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve/examples/large_models/Huggingface_pippy
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 30688 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Initial Models: opt.tar.gz
Log dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Metrics dir: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/model_store
Model config: N/A
2023-05-09T05:27:04,629 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:27:04,629 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-09T05:27:04,645 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:27:04,645 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: opt.tar.gz
2023-05-09T05:27:04,671 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:27:04,671 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model opt
2023-05-09T05:27:04,671 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:27:04,671 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model opt
2023-05-09T05:27:04,671 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:27:04,671 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model opt loaded.
2023-05-09T05:27:04,672 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:27:04,672 [INFO ] main org.pytorch.serve.wlm.ModelManager - model opt set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-09T05:27:04,672 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:27:04,672 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: opt, count: 1
2023-05-09T05:27:04,682 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:27:04,682 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-09T05:27:04,684 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:27:04,684 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, opt_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-09T05:27:04,741 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:27:04,741 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-05-09T05:27:04,741 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:27:04,741 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-09T05:27:04,743 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:27:04,743 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-05-09T05:27:04,743 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:27:04,743 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-09T05:27:04,745 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:27:04,745 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-09T05:27:04,926 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:27:04,926 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-05-09T05:27:06,247 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-09T05:27:06,248 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-09T05:27:06,248 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:27:06,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-09T05:27:06,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - *****************************************
2023-05-09T05:27:06,249 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-09T05:27:06,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-09T05:27:06,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-09T05:27:06,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-09T05:27:06,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-09T05:27:06,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   run_id           : opt_29500
2023-05-09T05:27:06,250 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-09T05:27:06,251 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-09T05:27:06,251 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-09T05:27:06,251 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-09T05:27:06,251 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-09T05:27:06,251 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts
2023-05-09T05:27:06,251 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-09T05:27:06,252 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:27:06,252 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7l1jqskm
2023-05-09T05:27:06,252 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-09T05:27:06,252 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-09T05:27:06,346 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,348 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0692481994629|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,348 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.25439071655273|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,348 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,349 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,349 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,349 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,349 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,349 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,349 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,350 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,350 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,350 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,350 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,350 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,350 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,351 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:376295.55078125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,351 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3453.23046875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,351 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.7|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610026
2023-05-09T05:27:06,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-09T05:27:06,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-09T05:27:06,555 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-09T05:27:06,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   master_port=48651
2023-05-09T05:27:06,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-09T05:27:06,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-09T05:27:06,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-09T05:27:06,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-09T05:27:06,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-09T05:27:06,556 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-09T05:27:06,557 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-09T05:27:06,557 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG -
2023-05-09T05:27:06,557 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-09T05:27:06,557 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-09T05:27:06,557 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7l1jqskm/attempt_0/0/error.json
2023-05-09T05:27:06,557 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7l1jqskm/attempt_0/1/error.json
2023-05-09T05:27:06,557 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7l1jqskm/attempt_0/2/error.json
2023-05-09T05:27:06,558 [WARN ] W-29500-opt_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/examples/large_models/Huggingface_pippy/logs/torchelastic_ts/opt_29500_7l1jqskm/attempt_0/3/error.json
2023-05-09T05:27:07,761 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=33263
2023-05-09T05:27:07,762 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:27:07,765 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=33262
2023-05-09T05:27:07,766 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:27:07,770 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:27:07,770 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]33263
2023-05-09T05:27:07,770 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:27:07,770 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:27:07,774 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:27:07,774 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]33262
2023-05-09T05:27:07,775 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:27:07,775 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:27:07,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=33264
2023-05-09T05:27:07,801 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:27:07,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=33265
2023-05-09T05:27:07,804 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-09T05:27:07,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:27:07,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]33264
2023-05-09T05:27:07,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:27:07,810 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:27:07,812 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-09T05:27:07,812 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PID]33265
2023-05-09T05:27:07,813 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-09T05:27:07,813 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-09T05:27:07,813 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:27:07,813 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change null -> WORKER_STARTED
2023-05-09T05:27:07,816 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:27:07,816 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-09T05:27:07,824 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-09T05:27:07,825 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:27:07,825 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-09T05:27:07,827 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:27:07,827 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-09T05:27:07,827 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-09T05:27:07,829 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:27:07,829 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-09T05:27:07,829 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-09T05:27:07,831 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-09T05:27:07,833 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683610027833
2023-05-09T05:27:07,833 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683610027833
2023-05-09T05:27:07,855 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:27:07,866 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:27:07,877 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:27:07,888 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - model_name: opt, batchSize: 1
2023-05-09T05:27:08,751 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:27:08,752 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-09T05:27:08,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:27:08,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:27:08,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:27:08,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformers version 4.25.1
2023-05-09T05:27:08,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:27:08,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - PyTorch version is 2.0.0 or greater
2023-05-09T05:27:08,754 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 3 pid/device = 33265/3
2023-05-09T05:27:08,754 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 1 pid/device = 33263/1
2023-05-09T05:27:08,755 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 0 pid/device = 33262/0
2023-05-09T05:27:08,755 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - rank = 2 pid/device = 33264/2
2023-05-09T05:27:35,285 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.102321400000164 seconds
2023-05-09T05:27:35,348 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:27:35,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:27:35,350 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:27:35,437 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.244428166000034 seconds
2023-05-09T05:27:35,497 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:27:35,499 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:27:35,499 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:27:35,673 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.480085898000198 seconds
2023-05-09T05:27:35,733 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:27:35,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:27:35,735 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:27:36,361 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:27:36,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-09T05:27:36,363 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:27:36,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0157258050003293 seconds on rank 1
2023-05-09T05:27:36,364 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/b0850ebbcb1340fbab86e630f3fd5a37 loaded successfully
2023-05-09T05:27:36,517 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:27:36,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-09T05:27:36,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:27:36,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0225426279998828 seconds on rank 3
2023-05-09T05:27:36,520 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/b0850ebbcb1340fbab86e630f3fd5a37 loaded successfully
2023-05-09T05:27:36,751 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:27:36,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-09T05:27:36,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:27:36,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 1.0201343680000718 seconds on rank 2
2023-05-09T05:27:36,753 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/b0850ebbcb1340fbab86e630f3fd5a37 loaded successfully
2023-05-09T05:27:36,826 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  init model time on meta device took 26.56965369799991 seconds
2023-05-09T05:27:36,887 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-09T05:27:36,889 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-09T05:27:36,889 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-09T05:27:37,901 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-09T05:27:37,903 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - GraphModule(
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 7168, padding_idx=1)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,905 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,906 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,907 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,908 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,909 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,910 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,911 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,912 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,913 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,914 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,915 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,916 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,917 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,918 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,919 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,920 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_activation_fn): ReLU()
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_40_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_activation_fn): ReLU()
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_41_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,921 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_activation_fn): ReLU()
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_42_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_activation_fn): ReLU()
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_43_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_activation_fn): ReLU()
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_44_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_activation_fn): ReLU()
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_45_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,922 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_activation_fn): ReLU()
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_46_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_q_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_k_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_v_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_self_attn_out_proj): Linear(in_features=7168, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc1): Linear(in_features=7168, out_features=28672, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_activation_fn): ReLU()
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_layers_47_fc2): Linear(in_features=28672, out_features=7168, bias=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((7168,), eps=1e-05, elementwise_affine=True)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=7168, out_features=50272, bias=False)
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -   )
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - )
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-09T05:27:37,923 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-09T05:27:37,924 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683610057.92 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00007.bin', 'pytorch_model-00002-of-00007.bin'])
2023-05-09T05:27:37,925 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-09T05:27:37,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-09T05:27:37,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683610057.93 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00007.bin', 'pytorch_model-00003-of-00007.bin', 'pytorch_model-00004-of-00007.bin'])
2023-05-09T05:27:37,926 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-09T05:27:37,927 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683610057.93 Opening checkpoint: dict_keys(['pytorch_model-00004-of-00007.bin', 'pytorch_model-00005-of-00007.bin'])
2023-05-09T05:27:37,928 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Timestamp 1683610057.93 Opening checkpoint: dict_keys(['pytorch_model-00005-of-00007.bin', 'pytorch_model-00006-of-00007.bin', 'pytorch_model-00007-of-00007.bin', 'pytorch_model-00001-of-00007.bin'])
2023-05-09T05:27:48,393 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-09T05:27:52,314 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 0
2023-05-09T05:27:52,972 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-09T05:27:53,495 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-09T05:27:53,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-09T05:27:53,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG -  pippy compile time took 16.721493665000253 seconds on rank 0
2023-05-09T05:27:53,608 [INFO ] W-29500-opt_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/b0850ebbcb1340fbab86e630f3fd5a37 loaded successfully
2023-05-09T05:27:53,609 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:27:53,609 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-09T05:27:53,609 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 45722
2023-05-09T05:27:53,609 [INFO ] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 45722
2023-05-09T05:27:53,609 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T05:27:53,609 [DEBUG] W-29500-opt_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-opt_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-09T05:27:53,610 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:48933.0|#WorkerName:W-29500-opt_1.0,Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610073
2023-05-09T05:27:53,610 [INFO ] W-29500-opt_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:55.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683610073
