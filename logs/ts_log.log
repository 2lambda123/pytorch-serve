2023-05-08T18:28:43,192 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-08T18:28:43,192 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-05-08T18:28:43,245 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-08T18:28:43,245 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
2023-05-08T18:28:43,446 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 4096 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: /tmp/benchmark/conf/config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://127.0.0.1:8082
Model Store: /tmp/model_store
Initial Models: N/A
Log dir: /home/ubuntu/serve/logs
Metrics dir: /home/ubuntu/serve/logs
Netty threads: 32
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: True
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /tmp/wf_store
Model config: N/A
2023-05-08T18:28:43,446 [INFO ] main org.pytorch.serve.ModelServer -
Torchserve version: 0.7.1
TS Home: /opt/conda/envs/benchmarks/lib/python3.9/site-packages
Current directory: /home/ubuntu/serve
Temp directory: /tmp
Metrics config path: /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 4
Number of CPUs: 96
Max heap size: 4096 M
Python executable: /opt/conda/envs/benchmarks/bin/python3.9
Config file: /tmp/benchmark/conf/config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://127.0.0.1:8082
Model Store: /tmp/model_store
Initial Models: N/A
Log dir: /home/ubuntu/serve/logs
Metrics dir: /home/ubuntu/serve/logs
Netty threads: 32
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: True
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /tmp/wf_store
Model config: N/A
2023-05-08T18:28:43,452 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-08T18:28:43,452 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-05-08T18:28:43,470 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-08T18:28:43,470 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-05-08T18:28:43,522 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-05-08T18:28:43,522 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-05-08T18:28:43,523 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-08T18:28:43,523 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-05-08T18:28:43,524 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-05-08T18:28:43,524 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-05-08T18:28:43,525 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-08T18:28:43,525 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-05-08T18:28:43,526 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-08T18:28:43,526 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-05-08T18:28:44,822 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,825 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.1365852355957|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,825 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.1870536804199|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,825 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,826 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,826 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,826 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,826 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,827 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.00868507903421921|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,827 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:2.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,827 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:55.87979850616641|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,827 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:12868.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,827 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,828 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,828 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,828 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,828 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:375961.85546875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,828 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3429.796875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:44,828 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:1.8|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570524
2023-05-08T18:28:45,561 [INFO ] pool-2-thread-1 ACCESS_LOG - /127.0.0.1:51220 "GET /ping HTTP/1.1" 200 6
2023-05-08T18:28:45,562 [INFO ] pool-2-thread-1 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570525
2023-05-08T18:28:45,600 [DEBUG] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model benchmark
2023-05-08T18:28:45,600 [DEBUG] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model benchmark
2023-05-08T18:28:45,600 [DEBUG] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model benchmark
2023-05-08T18:28:45,600 [DEBUG] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model benchmark
2023-05-08T18:28:55,146 [INFO ] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelManager - Model benchmark loaded.
2023-05-08T18:28:55,146 [INFO ] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelManager - Model benchmark loaded.
2023-05-08T18:28:55,147 [INFO ] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelManager - model benchmark set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-08T18:28:55,147 [INFO ] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelManager - model benchmark set minWorkers: 1, maxWorkers: 1 for parallelLevel: 4
2023-05-08T18:28:55,147 [DEBUG] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelManager - updateModel: benchmark, count: 1
2023-05-08T18:28:55,147 [DEBUG] epollEventLoopGroup-3-2 org.pytorch.serve.wlm.ModelManager - updateModel: benchmark, count: 1
2023-05-08T18:28:55,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, benchmark_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-08T18:28:55,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [torchrun, --nnodes, 1, --nproc_per_node, 4, --max_restarts, 3, --log_dir, /home/ubuntu/serve/logs/torchelastic_ts, --rdzv_backend, c10d, --rdzv_endpoint, localhost:29500, --rdzv_id, benchmark_29500, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.29500, --metrics-config, /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-05-08T18:28:56,662 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2023-05-08T18:28:56,663 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - WARNING:torch.distributed.run:
2023-05-08T18:28:56,663 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - *****************************************
2023-05-08T18:28:56,663 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
2023-05-08T18:28:56,664 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - *****************************************
2023-05-08T18:28:56,664 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
2023-05-08T18:28:56,664 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   entrypoint       : /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/model_service_worker.py
2023-05-08T18:28:56,664 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   min_nodes        : 1
2023-05-08T18:28:56,664 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   max_nodes        : 1
2023-05-08T18:28:56,665 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   nproc_per_node   : 4
2023-05-08T18:28:56,665 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   run_id           : benchmark_29500
2023-05-08T18:28:56,665 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   rdzv_backend     : c10d
2023-05-08T18:28:56,665 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   rdzv_endpoint    : localhost:29500
2023-05-08T18:28:56,665 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   rdzv_configs     : {'timeout': 900}
2023-05-08T18:28:56,665 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   max_restarts     : 3
2023-05-08T18:28:56,665 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   monitor_interval : 5
2023-05-08T18:28:56,665 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   log_dir          : /home/ubuntu/serve/logs/torchelastic_ts
2023-05-08T18:28:56,666 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   metrics_cfg      : {}
2023-05-08T18:28:56,666 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -
2023-05-08T18:28:56,666 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /home/ubuntu/serve/logs/torchelastic_ts/benchmark_29500_3eo7bd1i
2023-05-08T18:28:56,666 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
2023-05-08T18:28:56,666 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
2023-05-08T18:28:56,855 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
2023-05-08T18:28:56,855 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   restart_count=0
2023-05-08T18:28:56,855 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   master_addr=ip-172-31-5-255.us-west-2.compute.internal
2023-05-08T18:28:56,855 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   master_port=35937
2023-05-08T18:28:56,856 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   group_rank=0
2023-05-08T18:28:56,856 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   group_world_size=1
2023-05-08T18:28:56,856 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   local_ranks=[0, 1, 2, 3]
2023-05-08T18:28:56,856 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   role_ranks=[0, 1, 2, 3]
2023-05-08T18:28:56,856 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   global_ranks=[0, 1, 2, 3]
2023-05-08T18:28:56,856 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   role_world_sizes=[4, 4, 4, 4]
2023-05-08T18:28:56,856 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   global_world_sizes=[4, 4, 4, 4]
2023-05-08T18:28:56,857 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -
2023-05-08T18:28:56,857 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
2023-05-08T18:28:56,857 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
2023-05-08T18:28:56,857 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /home/ubuntu/serve/logs/torchelastic_ts/benchmark_29500_3eo7bd1i/attempt_0/0/error.json
2023-05-08T18:28:56,857 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /home/ubuntu/serve/logs/torchelastic_ts/benchmark_29500_3eo7bd1i/attempt_0/1/error.json
2023-05-08T18:28:56,857 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /home/ubuntu/serve/logs/torchelastic_ts/benchmark_29500_3eo7bd1i/attempt_0/2/error.json
2023-05-08T18:28:56,858 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /home/ubuntu/serve/logs/torchelastic_ts/benchmark_29500_3eo7bd1i/attempt_0/3/error.json
2023-05-08T18:28:58,054 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=82637
2023-05-08T18:28:58,055 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-08T18:28:58,063 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-08T18:28:58,063 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PID]82637
2023-05-08T18:28:58,064 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-08T18:28:58,064 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-08T18:28:58,066 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=82636
2023-05-08T18:28:58,066 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-08T18:28:58,066 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=82638
2023-05-08T18:28:58,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-08T18:28:58,074 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-08T18:28:58,074 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PID]82636
2023-05-08T18:28:58,075 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-08T18:28:58,075 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-08T18:28:58,075 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-08T18:28:58,075 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PID]82638
2023-05-08T18:28:58,075 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-08T18:28:58,075 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-08T18:28:58,093 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=29500, pid=82639
2023-05-08T18:28:58,093 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.29500
2023-05-08T18:28:58,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/envs/benchmarks/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-05-08T18:28:58,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PID]82639
2023-05-08T18:28:58,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Torch worker started.
2023-05-08T18:28:58,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Python runtime: 3.9.16
2023-05-08T18:28:58,103 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-benchmark_1.0 State change null -> WORKER_STARTED
2023-05-08T18:28:58,103 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-benchmark_1.0 State change null -> WORKER_STARTED
2023-05-08T18:28:58,105 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-08T18:28:58,105 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29500
2023-05-08T18:28:58,110 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29500.
2023-05-08T18:28:58,111 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-08T18:28:58,111 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29501
2023-05-08T18:28:58,114 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-08T18:28:58,114 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29502
2023-05-08T18:28:58,114 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29501.
2023-05-08T18:28:58,116 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-08T18:28:58,116 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.29503
2023-05-08T18:28:58,116 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29502.
2023-05-08T18:28:58,118 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.29503.
2023-05-08T18:28:58,119 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683570538119
2023-05-08T18:28:58,119 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1683570538119
2023-05-08T18:28:58,124 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - model_name: benchmark, batchSize: 56
2023-05-08T18:28:58,130 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - model_name: benchmark, batchSize: 56
2023-05-08T18:28:58,135 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - model_name: benchmark, batchSize: 56
2023-05-08T18:28:58,141 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - model_name: benchmark, batchSize: 56
2023-05-08T18:28:59,013 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-08T18:28:59,013 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-08T18:28:59,013 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-08T18:28:59,013 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-08T18:28:59,013 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Transformers version 4.28.1
2023-05-08T18:28:59,013 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Transformers version 4.28.1
2023-05-08T18:28:59,015 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - rank = 2 pid/device = 82638/2
2023-05-08T18:28:59,016 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - rank = 3 pid/device = 82639/3
2023-05-08T18:28:59,025 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-08T18:28:59,025 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-08T18:28:59,025 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Enabled tensor cores
2023-05-08T18:28:59,025 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2023-05-08T18:28:59,025 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Transformers version 4.28.1
2023-05-08T18:28:59,025 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Transformers version 4.28.1
2023-05-08T18:28:59,027 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - rank = 1 pid/device = 82637/1
2023-05-08T18:28:59,028 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - rank = 0 pid/device = 82636/0
2023-05-08T18:29:00,672 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -
2023-05-08T18:29:00,674 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2023-05-08T18:29:00,676 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2023-05-08T18:29:01,693 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2023-05-08T18:29:04,769 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
2023-05-08T18:29:04,794 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.10s/it]
2023-05-08T18:29:04,813 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.12s/it]
2023-05-08T18:29:05,970 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.14s/it]
2023-05-08T18:29:08,996 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.28s/it]
2023-05-08T18:29:09,017 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.17s/it]
2023-05-08T18:29:09,038 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.18s/it]
2023-05-08T18:29:10,274 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.19s/it]
2023-05-08T18:29:11,629 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.29s/it]
2023-05-08T18:29:11,629 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.47s/it]
2023-05-08T18:29:11,629 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]
2023-05-08T18:29:11,632 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -  init model time on meta device took 11.22035732600034 seconds
2023-05-08T18:29:11,646 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -
2023-05-08T18:29:11,646 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.47s/it]
2023-05-08T18:29:11,646 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.66s/it]
2023-05-08T18:29:11,649 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -  init model time on meta device took 11.23760421499992 seconds
2023-05-08T18:29:11,670 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -
2023-05-08T18:29:11,670 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.48s/it]
2023-05-08T18:29:11,670 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.66s/it]
2023-05-08T18:29:11,673 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -  init model time on meta device took 11.261733215000277 seconds
2023-05-08T18:29:11,737 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-08T18:29:11,739 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-08T18:29:11,739 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-08T18:29:11,756 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-08T18:29:11,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-08T18:29:11,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-08T18:29:11,779 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-08T18:29:11,781 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-08T18:29:11,781 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-08T18:29:12,591 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-08T18:29:12,593 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Found device cuda:1 for rank 1
2023-05-08T18:29:12,593 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-08T18:29:12,593 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -  pippy compile time took 0.8558536389991787 seconds on rank 1
2023-05-08T18:29:12,593 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/94f76ed1394c435a907f2683ae58d7fa loaded successfully
2023-05-08T18:29:12,614 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-08T18:29:12,616 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Found device cuda:3 for rank 3
2023-05-08T18:29:12,616 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-08T18:29:12,616 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -  pippy compile time took 0.8604749859996446 seconds on rank 3
2023-05-08T18:29:12,616 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/94f76ed1394c435a907f2683ae58d7fa loaded successfully
2023-05-08T18:29:12,640 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-08T18:29:12,642 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Found device cuda:2 for rank 2
2023-05-08T18:29:12,642 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-08T18:29:12,642 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -  pippy compile time took 0.863029717000245 seconds on rank 2
2023-05-08T18:29:12,642 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/94f76ed1394c435a907f2683ae58d7fa loaded successfully
2023-05-08T18:29:12,864 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -
2023-05-08T18:29:12,864 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.52s/it]
2023-05-08T18:29:12,865 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.72s/it]
2023-05-08T18:29:12,867 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -  init model time on meta device took 11.428823169999305 seconds
2023-05-08T18:29:12,975 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Instantiating model Pipeline
2023-05-08T18:29:12,977 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Initializing the model pipeline
2023-05-08T18:29:12,977 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PiPPy] Tracing model ...
2023-05-08T18:29:13,833 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Pipeline is in evaluation mode, backward pass not generated
2023-05-08T18:29:13,835 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Found device cuda:0 for rank 0
2023-05-08T18:29:13,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - GraphModule(
2023-05-08T18:29:13,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -   (submod_0): PipeStageModule(
2023-05-08T18:29:13,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_embed_tokens): Embedding(50272, 5120, padding_idx=1)
2023-05-08T18:29:13,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_activation_fn): ReLU()
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_0_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,837 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_activation_fn): ReLU()
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_1_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_activation_fn): ReLU()
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_2_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,838 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_activation_fn): ReLU()
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_3_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_activation_fn): ReLU()
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_4_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,839 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_activation_fn): ReLU()
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_5_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_activation_fn): ReLU()
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_6_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,840 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_activation_fn): ReLU()
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_7_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_activation_fn): ReLU()
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_8_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,841 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -   )
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -   (submod_1): PipeStageModule(
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_activation_fn): ReLU()
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_9_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,842 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_activation_fn): ReLU()
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_10_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_activation_fn): ReLU()
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_11_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,843 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_activation_fn): ReLU()
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_12_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_activation_fn): ReLU()
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_13_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,844 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_activation_fn): ReLU()
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_14_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_activation_fn): ReLU()
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_15_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_activation_fn): ReLU()
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_16_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_activation_fn): ReLU()
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_17_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_activation_fn): ReLU()
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_18_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -   )
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -   (submod_2): PipeStageModule(
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_activation_fn): ReLU()
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_19_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_activation_fn): ReLU()
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_20_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_activation_fn): ReLU()
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_21_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_activation_fn): ReLU()
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_22_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_activation_fn): ReLU()
2023-05-08T18:29:13,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_23_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_activation_fn): ReLU()
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_24_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_activation_fn): ReLU()
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_25_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_activation_fn): ReLU()
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_26_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_activation_fn): ReLU()
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_27_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_activation_fn): ReLU()
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_28_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -   )
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -   (submod_3): PipeStageModule(
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_activation_fn): ReLU()
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_29_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_activation_fn): ReLU()
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_30_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_activation_fn): ReLU()
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_31_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_activation_fn): ReLU()
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_32_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_activation_fn): ReLU()
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_33_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_activation_fn): ReLU()
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_34_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_activation_fn): ReLU()
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_35_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_activation_fn): ReLU()
2023-05-08T18:29:13,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_36_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_activation_fn): ReLU()
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_37_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_activation_fn): ReLU()
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_38_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_q_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_k_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_v_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_self_attn_out_proj): Linear(in_features=5120, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc1): Linear(in_features=5120, out_features=20480, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_activation_fn): ReLU()
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_layers_39_fc2): Linear(in_features=20480, out_features=5120, bias=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (model_decoder_final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     (lm_head): Linear(in_features=5120, out_features=50272, bias=False)
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -   )
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - )
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - def forward(self, input_ids : torch.Tensor):
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     submod_0 = self.submod_0(input_ids);  input_ids = None
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem = submod_0[0]
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_1 = submod_0[1]
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_2 = submod_0[2]
2023-05-08T18:29:13,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_3 = submod_0[3];  submod_0 = None
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     submod_1 = self.submod_1(getitem, getitem_1, getitem_2, getitem_3);  getitem = getitem_1 = getitem_2 = None
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_4 = submod_1[0]
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_5 = submod_1[1]
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_6 = submod_1[2];  submod_1 = None
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     submod_2 = self.submod_2(getitem_4, getitem_5, getitem_6, getitem_3);  getitem_4 = getitem_5 = getitem_6 = None
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_7 = submod_2[0]
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_8 = submod_2[1]
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     getitem_9 = submod_2[2];  submod_2 = None
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     submod_3 = self.submod_3(getitem_7, getitem_8, getitem_9, getitem_3);  getitem_7 = getitem_8 = getitem_9 = getitem_3 = None
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -     return {'logits': submod_3}
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - # To see more debug info, please use `graph_module.print_readable()`
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [PiPPy] Creating pipeline driver ...
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated output_chunk_spec for loss_spec None: None
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Creating pipeline driver with 4 workers: [0, 1, 2, 3]
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Instantiating RankWorker
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Instantiating RankWorker
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Instantiating RankWorker
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Instantiating RankWorker
2023-05-08T18:29:13,854 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Materializing submod_0 on cuda:0
2023-05-08T18:29:13,855 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Timestamp 1683570553.86 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00003.bin'])
2023-05-08T18:29:13,856 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Materializing submod_1 on cuda:1
2023-05-08T18:29:13,856 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Materializing submod_2 on cuda:2
2023-05-08T18:29:13,857 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Timestamp 1683570553.86 Opening checkpoint: dict_keys(['pytorch_model-00001-of-00003.bin', 'pytorch_model-00002-of-00003.bin'])
2023-05-08T18:29:13,857 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Materializing submod_3 on cuda:3
2023-05-08T18:29:13,858 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Timestamp 1683570553.86 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00003.bin'])
2023-05-08T18:29:13,858 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Timestamp 1683570553.86 Opening checkpoint: dict_keys(['pytorch_model-00002-of-00003.bin', 'pytorch_model-00003-of-00003.bin', 'pytorch_model-00001-of-00003.bin'])
2023-05-08T18:29:19,384 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 2
2023-05-08T18:29:22,767 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 0
2023-05-08T18:29:23,578 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 1
2023-05-08T18:29:26,088 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Instantiating PipeStageExecutor for stage 3
2023-05-08T18:29:26,198 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Inserting PiPPy pipeline forward into model OPTForCausalLM
2023-05-08T18:29:26,198 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG -  pippy compile time took 13.223356829000295 seconds on rank 0
2023-05-08T18:29:26,199 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Transformer model from path /tmp/models/94f76ed1394c435a907f2683ae58d7fa loaded successfully
2023-05-08T18:29:26,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:26,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:26,199 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28059
2023-05-08T18:29:26,199 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28059
2023-05-08T18:29:26,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-benchmark_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-08T18:29:26,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-benchmark_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-05-08T18:29:26,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:31049.0|#WorkerName:W-29500-benchmark_1.0,Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570566
2023-05-08T18:29:26,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:22.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570566
2023-05-08T18:29:26,200 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /127.0.0.1:57992 "POST /models?model_name=benchmark&url=file%3A%2F%2F%2Fhome%2Fubuntu%2Fserve%2Fexamples%2Flarge_models%2FHuggingface_pippy%2Fopt.tar.gz&batch_delay=300000&batch_size=56&initial_workers=1&synchronous=true HTTP/1.1" 200 40623
2023-05-08T18:29:26,201 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570566
2023-05-08T18:29:26,221 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570566
2023-05-08T18:29:28,222 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570568222
2023-05-08T18:29:28,222 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570568222
2023-05-08T18:29:28,223 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570568
2023-05-08T18:29:28,223 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:28,223 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:28,223 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
2023-05-08T18:29:28,224 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - /tmp/models/94f76ed1394c435a907f2683ae58d7fa/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
2023-05-08T18:29:28,224 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-08T18:29:28,232 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([1, 50])
2023-05-08T18:29:28,232 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - /tmp/models/94f76ed1394c435a907f2683ae58d7fa/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)
2023-05-08T18:29:28,232 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-08T18:29:28,234 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:28,235 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/microbatch.py:95: UserWarning: Tensor size on chunking dimension is 1, downsizing the number of chunks from 8 to 1.
2023-05-08T18:29:28,235 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-08T18:29:28,235 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-08T18:29:28,235 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py:2111: UserWarning: Reducing micro-batch numbers from 8 to 1.
2023-05-08T18:29:28,235 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-08T18:29:28,236 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - /opt/conda/envs/benchmarks/lib/python3.9/site-packages/torchpippy-0.1.0+9a9895b-py3.9.egg/pippy/PipelineDriver.py:1713: UserWarning: Received extra arguments: {'use_cache', 'past_key_values', 'output_attentions', 'attention_mask', 'return_dict', 'output_hidden_states'}. They might have already been given a concrete value during pipeline compilation via `concrete_args`. We will ignore the current inputs and use the values given during compilation.
2023-05-08T18:29:28,236 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG -   warnings.warn(
2023-05-08T18:29:28,238 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:28,977 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:29,697 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:30,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:31,135 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:31,135 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:2911.21|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570571,d97f63e5-6a37-4e1e-b59c-f443e48cc8a2, pattern=[METRICS]
2023-05-08T18:29:31,135 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:2911.21|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570571,d97f63e5-6a37-4e1e-b59c-f443e48cc8a2, pattern=[METRICS]
2023-05-08T18:29:31,135 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:2911.21|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:d97f63e5-6a37-4e1e-b59c-f443e48cc8a2,timestamp:1683570571
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2911.3|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570571,d97f63e5-6a37-4e1e-b59c-f443e48cc8a2, pattern=[METRICS]
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2911.3|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570571,d97f63e5-6a37-4e1e-b59c-f443e48cc8a2, pattern=[METRICS]
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:2911.3|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:d97f63e5-6a37-4e1e-b59c-f443e48cc8a2,timestamp:1683570571
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41594 "POST /predictions/benchmark HTTP/1.0" 200 4916
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4913694.655|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2000381.588|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,136 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2000381588, Backend time ns: 2913926941
2023-05-08T18:29:31,136 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2000381588, Backend time ns: 2913926941
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2000.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,136 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:31,136 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2912
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2912
2023-05-08T18:29:31,136 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,141 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,164 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,164 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,170 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,180 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,186 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,186 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,175 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,187 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,187 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,187 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,204 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,204 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,211 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,217 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,222 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,217 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,228 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,228 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,235 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,235 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,242 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,243 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,243 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,243 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,244 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,264 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,264 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,264 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,264 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,264 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,264 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,265 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,265 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,265 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,265 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,265 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,266 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,266 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,266 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,266 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,266 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,266 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,266 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,266 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,267 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570571268
2023-05-08T18:29:31,268 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570571268
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,268 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,269 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,270 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,270 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,270 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,270 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,270 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,270 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,271 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,271 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,271 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,271 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,271 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,271 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,271 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,272 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,272 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,272 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,272 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,272 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,273 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,276 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570571
2023-05-08T18:29:31,276 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,276 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,278 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,279 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,280 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:31,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:31,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:31,285 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:31,285 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:31,292 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:31,334 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:31,356 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:31,367 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:31,393 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:31,399 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:31,407 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:31,432 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:31,439 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:31,442 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:31,445 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:31,471 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:31,479 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:31,482 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:31,483 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:31,510 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:31,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:31,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:31,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:31,549 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:31,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:31,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:31,563 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:31,588 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:31,600 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:31,603 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:31,626 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:31,641 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:31,643 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:31,681 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:31,684 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:31,727 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:31,822 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:31,822 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:545.15|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570571,87817a87-e8cb-4cf0-88be-720b6e08d86e,0b51aa8f-c379-49f7-9a9d-ebce06dca701,ad17d479-92cb-4ec3-a4b4-661d06926008,ae200ed5-ba4f-4734-8023-a9ea41ad4ca8,ace1bc91-8ad1-40d6-a4b8-fcc4b8a4a012,9f286bbd-2bb2-4715-9115-f5258b04ff87,ae6e0239-017e-418e-87e9-3af849114c41,9abe8eb0-6ac4-4017-8f65-086a23c84a3b,281d5e4a-4cec-42ed-a0c8-ed36fa4137fc,c4d0d653-b639-435c-9ed7-248ca823b71a,a6adf74c-d694-4c7e-b019-424e044ab087,4e9eaca3-87b0-46f9-8fa1-a42836f9ba03,33acfa16-2ff4-4e72-980a-41ec8237c1ca,18bcd777-15e5-47d6-a667-7b05fd07cf0c,8ef44357-9073-4964-912e-3299cdeaf046,db18272d-8b6c-4537-a744-b1ad34ce736c,3e3e7dd1-7fe8-4db6-a3bf-9b2ab80beabc,1d0302f6-26ed-4c67-8b03-4c1243587a06,6c93dae8-9fde-48da-9aa7-292da7ac4556,e319e60d-2ee8-44ba-ab16-c8cb709f6ce4,0564d16f-6c60-4ec2-ab6f-6b5d597602cc,466c49f5-89f0-477a-a4bd-4f22be4430fa,2dd1bbdb-6885-4c47-8482-1779defea19f,b71db9d0-89c9-4a4d-a93f-c783ed7af530,8d8622f0-49b9-4d84-996f-ad99fbe04e52,90f4fc10-93ba-47b1-8e89-2444dd92e2d1,762bd05f-7b68-4a84-b6ff-a70d46671622,2510cf3d-b8b0-4323-899f-3823ab847a9c,9007e9da-8c84-4e30-ada8-ad20a3bf2ce1,22eec774-0843-4412-9a96-fc06fd2b5c44,f13f40ab-b3bb-40f3-b9ff-02c40710251f,6cd1a6c3-ef5a-4da5-b475-4b25b122e59b,604f044b-386c-4595-8594-d5f5425efb29,22c80d79-cdda-4362-b48c-9d17a708483d,a52f853f-00d4-4a65-b3cf-6b8790fbfd99,50214e8b-29a8-4966-bbd2-eef6d4179ed7,dc62674b-2f57-4165-bfed-2838c68ec497,8bef03b4-da2a-436a-bfcc-fec625e15785,d5ba349f-f39c-4af2-b059-2783d50d8122,a2890fa4-051b-453c-b407-af326d991b57,9574b4c2-fdda-49e8-bfe1-e6afa1a5a990,36b2f5e7-f174-420c-b80c-432772943118,22f3ba0f-26f7-46e7-bafe-44d0bee4471b,b3e671f2-79b3-4f25-83ec-f046c4a459ff,f2b1d905-882f-4c9f-ae69-d55106bfde8e,22c1dda9-1da6-474d-b1ab-fb17f9b89742,1952561e-d2fa-4516-9d7a-c7aa44ede4ca,c3738152-9017-4657-a257-63da0e811d90,e75000c6-d021-4f91-aa16-33cf5615f8f9,cd672f56-f2a7-4176-95b5-1544818e4d49,a5d612f3-8ae3-49de-8340-ce67c9ed0d3a,f80e3c77-5222-4a55-bf92-15f86452c601,d2020b96-4cfd-47d4-b9f0-f89cfb1e9abc,e5650f50-8284-423b-aa3a-424f057a2ba3,687fd0c2-b33b-4efe-9806-bb02a720853f,0fd27e55-1de9-4ba9-9d48-3e46856cddd0, pattern=[METRICS]
2023-05-08T18:29:31,822 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:545.15|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570571,87817a87-e8cb-4cf0-88be-720b6e08d86e,0b51aa8f-c379-49f7-9a9d-ebce06dca701,ad17d479-92cb-4ec3-a4b4-661d06926008,ae200ed5-ba4f-4734-8023-a9ea41ad4ca8,ace1bc91-8ad1-40d6-a4b8-fcc4b8a4a012,9f286bbd-2bb2-4715-9115-f5258b04ff87,ae6e0239-017e-418e-87e9-3af849114c41,9abe8eb0-6ac4-4017-8f65-086a23c84a3b,281d5e4a-4cec-42ed-a0c8-ed36fa4137fc,c4d0d653-b639-435c-9ed7-248ca823b71a,a6adf74c-d694-4c7e-b019-424e044ab087,4e9eaca3-87b0-46f9-8fa1-a42836f9ba03,33acfa16-2ff4-4e72-980a-41ec8237c1ca,18bcd777-15e5-47d6-a667-7b05fd07cf0c,8ef44357-9073-4964-912e-3299cdeaf046,db18272d-8b6c-4537-a744-b1ad34ce736c,3e3e7dd1-7fe8-4db6-a3bf-9b2ab80beabc,1d0302f6-26ed-4c67-8b03-4c1243587a06,6c93dae8-9fde-48da-9aa7-292da7ac4556,e319e60d-2ee8-44ba-ab16-c8cb709f6ce4,0564d16f-6c60-4ec2-ab6f-6b5d597602cc,466c49f5-89f0-477a-a4bd-4f22be4430fa,2dd1bbdb-6885-4c47-8482-1779defea19f,b71db9d0-89c9-4a4d-a93f-c783ed7af530,8d8622f0-49b9-4d84-996f-ad99fbe04e52,90f4fc10-93ba-47b1-8e89-2444dd92e2d1,762bd05f-7b68-4a84-b6ff-a70d46671622,2510cf3d-b8b0-4323-899f-3823ab847a9c,9007e9da-8c84-4e30-ada8-ad20a3bf2ce1,22eec774-0843-4412-9a96-fc06fd2b5c44,f13f40ab-b3bb-40f3-b9ff-02c40710251f,6cd1a6c3-ef5a-4da5-b475-4b25b122e59b,604f044b-386c-4595-8594-d5f5425efb29,22c80d79-cdda-4362-b48c-9d17a708483d,a52f853f-00d4-4a65-b3cf-6b8790fbfd99,50214e8b-29a8-4966-bbd2-eef6d4179ed7,dc62674b-2f57-4165-bfed-2838c68ec497,8bef03b4-da2a-436a-bfcc-fec625e15785,d5ba349f-f39c-4af2-b059-2783d50d8122,a2890fa4-051b-453c-b407-af326d991b57,9574b4c2-fdda-49e8-bfe1-e6afa1a5a990,36b2f5e7-f174-420c-b80c-432772943118,22f3ba0f-26f7-46e7-bafe-44d0bee4471b,b3e671f2-79b3-4f25-83ec-f046c4a459ff,f2b1d905-882f-4c9f-ae69-d55106bfde8e,22c1dda9-1da6-474d-b1ab-fb17f9b89742,1952561e-d2fa-4516-9d7a-c7aa44ede4ca,c3738152-9017-4657-a257-63da0e811d90,e75000c6-d021-4f91-aa16-33cf5615f8f9,cd672f56-f2a7-4176-95b5-1544818e4d49,a5d612f3-8ae3-49de-8340-ce67c9ed0d3a,f80e3c77-5222-4a55-bf92-15f86452c601,d2020b96-4cfd-47d4-b9f0-f89cfb1e9abc,e5650f50-8284-423b-aa3a-424f057a2ba3,687fd0c2-b33b-4efe-9806-bb02a720853f,0fd27e55-1de9-4ba9-9d48-3e46856cddd0, pattern=[METRICS]
2023-05-08T18:29:31,823 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:545.15|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:87817a87-e8cb-4cf0-88be-720b6e08d86e,0b51aa8f-c379-49f7-9a9d-ebce06dca701,ad17d479-92cb-4ec3-a4b4-661d06926008,ae200ed5-ba4f-4734-8023-a9ea41ad4ca8,ace1bc91-8ad1-40d6-a4b8-fcc4b8a4a012,9f286bbd-2bb2-4715-9115-f5258b04ff87,ae6e0239-017e-418e-87e9-3af849114c41,9abe8eb0-6ac4-4017-8f65-086a23c84a3b,281d5e4a-4cec-42ed-a0c8-ed36fa4137fc,c4d0d653-b639-435c-9ed7-248ca823b71a,a6adf74c-d694-4c7e-b019-424e044ab087,4e9eaca3-87b0-46f9-8fa1-a42836f9ba03,33acfa16-2ff4-4e72-980a-41ec8237c1ca,18bcd777-15e5-47d6-a667-7b05fd07cf0c,8ef44357-9073-4964-912e-3299cdeaf046,db18272d-8b6c-4537-a744-b1ad34ce736c,3e3e7dd1-7fe8-4db6-a3bf-9b2ab80beabc,1d0302f6-26ed-4c67-8b03-4c1243587a06,6c93dae8-9fde-48da-9aa7-292da7ac4556,e319e60d-2ee8-44ba-ab16-c8cb709f6ce4,0564d16f-6c60-4ec2-ab6f-6b5d597602cc,466c49f5-89f0-477a-a4bd-4f22be4430fa,2dd1bbdb-6885-4c47-8482-1779defea19f,b71db9d0-89c9-4a4d-a93f-c783ed7af530,8d8622f0-49b9-4d84-996f-ad99fbe04e52,90f4fc10-93ba-47b1-8e89-2444dd92e2d1,762bd05f-7b68-4a84-b6ff-a70d46671622,2510cf3d-b8b0-4323-899f-3823ab847a9c,9007e9da-8c84-4e30-ada8-ad20a3bf2ce1,22eec774-0843-4412-9a96-fc06fd2b5c44,f13f40ab-b3bb-40f3-b9ff-02c40710251f,6cd1a6c3-ef5a-4da5-b475-4b25b122e59b,604f044b-386c-4595-8594-d5f5425efb29,22c80d79-cdda-4362-b48c-9d17a708483d,a52f853f-00d4-4a65-b3cf-6b8790fbfd99,50214e8b-29a8-4966-bbd2-eef6d4179ed7,dc62674b-2f57-4165-bfed-2838c68ec497,8bef03b4-da2a-436a-bfcc-fec625e15785,d5ba349f-f39c-4af2-b059-2783d50d8122,a2890fa4-051b-453c-b407-af326d991b57,9574b4c2-fdda-49e8-bfe1-e6afa1a5a990,36b2f5e7-f174-420c-b80c-432772943118,22f3ba0f-26f7-46e7-bafe-44d0bee4471b,b3e671f2-79b3-4f25-83ec-f046c4a459ff,f2b1d905-882f-4c9f-ae69-d55106bfde8e,22c1dda9-1da6-474d-b1ab-fb17f9b89742,1952561e-d2fa-4516-9d7a-c7aa44ede4ca,c3738152-9017-4657-a257-63da0e811d90,e75000c6-d021-4f91-aa16-33cf5615f8f9,cd672f56-f2a7-4176-95b5-1544818e4d49,a5d612f3-8ae3-49de-8340-ce67c9ed0d3a,f80e3c77-5222-4a55-bf92-15f86452c601,d2020b96-4cfd-47d4-b9f0-f89cfb1e9abc,e5650f50-8284-423b-aa3a-424f057a2ba3,687fd0c2-b33b-4efe-9806-bb02a720853f,0fd27e55-1de9-4ba9-9d48-3e46856cddd0,timestamp:1683570571
2023-05-08T18:29:31,823 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:545.23|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570571,87817a87-e8cb-4cf0-88be-720b6e08d86e,0b51aa8f-c379-49f7-9a9d-ebce06dca701,ad17d479-92cb-4ec3-a4b4-661d06926008,ae200ed5-ba4f-4734-8023-a9ea41ad4ca8,ace1bc91-8ad1-40d6-a4b8-fcc4b8a4a012,9f286bbd-2bb2-4715-9115-f5258b04ff87,ae6e0239-017e-418e-87e9-3af849114c41,9abe8eb0-6ac4-4017-8f65-086a23c84a3b,281d5e4a-4cec-42ed-a0c8-ed36fa4137fc,c4d0d653-b639-435c-9ed7-248ca823b71a,a6adf74c-d694-4c7e-b019-424e044ab087,4e9eaca3-87b0-46f9-8fa1-a42836f9ba03,33acfa16-2ff4-4e72-980a-41ec8237c1ca,18bcd777-15e5-47d6-a667-7b05fd07cf0c,8ef44357-9073-4964-912e-3299cdeaf046,db18272d-8b6c-4537-a744-b1ad34ce736c,3e3e7dd1-7fe8-4db6-a3bf-9b2ab80beabc,1d0302f6-26ed-4c67-8b03-4c1243587a06,6c93dae8-9fde-48da-9aa7-292da7ac4556,e319e60d-2ee8-44ba-ab16-c8cb709f6ce4,0564d16f-6c60-4ec2-ab6f-6b5d597602cc,466c49f5-89f0-477a-a4bd-4f22be4430fa,2dd1bbdb-6885-4c47-8482-1779defea19f,b71db9d0-89c9-4a4d-a93f-c783ed7af530,8d8622f0-49b9-4d84-996f-ad99fbe04e52,90f4fc10-93ba-47b1-8e89-2444dd92e2d1,762bd05f-7b68-4a84-b6ff-a70d46671622,2510cf3d-b8b0-4323-899f-3823ab847a9c,9007e9da-8c84-4e30-ada8-ad20a3bf2ce1,22eec774-0843-4412-9a96-fc06fd2b5c44,f13f40ab-b3bb-40f3-b9ff-02c40710251f,6cd1a6c3-ef5a-4da5-b475-4b25b122e59b,604f044b-386c-4595-8594-d5f5425efb29,22c80d79-cdda-4362-b48c-9d17a708483d,a52f853f-00d4-4a65-b3cf-6b8790fbfd99,50214e8b-29a8-4966-bbd2-eef6d4179ed7,dc62674b-2f57-4165-bfed-2838c68ec497,8bef03b4-da2a-436a-bfcc-fec625e15785,d5ba349f-f39c-4af2-b059-2783d50d8122,a2890fa4-051b-453c-b407-af326d991b57,9574b4c2-fdda-49e8-bfe1-e6afa1a5a990,36b2f5e7-f174-420c-b80c-432772943118,22f3ba0f-26f7-46e7-bafe-44d0bee4471b,b3e671f2-79b3-4f25-83ec-f046c4a459ff,f2b1d905-882f-4c9f-ae69-d55106bfde8e,22c1dda9-1da6-474d-b1ab-fb17f9b89742,1952561e-d2fa-4516-9d7a-c7aa44ede4ca,c3738152-9017-4657-a257-63da0e811d90,e75000c6-d021-4f91-aa16-33cf5615f8f9,cd672f56-f2a7-4176-95b5-1544818e4d49,a5d612f3-8ae3-49de-8340-ce67c9ed0d3a,f80e3c77-5222-4a55-bf92-15f86452c601,d2020b96-4cfd-47d4-b9f0-f89cfb1e9abc,e5650f50-8284-423b-aa3a-424f057a2ba3,687fd0c2-b33b-4efe-9806-bb02a720853f,0fd27e55-1de9-4ba9-9d48-3e46856cddd0, pattern=[METRICS]
2023-05-08T18:29:31,823 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:545.23|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570571,87817a87-e8cb-4cf0-88be-720b6e08d86e,0b51aa8f-c379-49f7-9a9d-ebce06dca701,ad17d479-92cb-4ec3-a4b4-661d06926008,ae200ed5-ba4f-4734-8023-a9ea41ad4ca8,ace1bc91-8ad1-40d6-a4b8-fcc4b8a4a012,9f286bbd-2bb2-4715-9115-f5258b04ff87,ae6e0239-017e-418e-87e9-3af849114c41,9abe8eb0-6ac4-4017-8f65-086a23c84a3b,281d5e4a-4cec-42ed-a0c8-ed36fa4137fc,c4d0d653-b639-435c-9ed7-248ca823b71a,a6adf74c-d694-4c7e-b019-424e044ab087,4e9eaca3-87b0-46f9-8fa1-a42836f9ba03,33acfa16-2ff4-4e72-980a-41ec8237c1ca,18bcd777-15e5-47d6-a667-7b05fd07cf0c,8ef44357-9073-4964-912e-3299cdeaf046,db18272d-8b6c-4537-a744-b1ad34ce736c,3e3e7dd1-7fe8-4db6-a3bf-9b2ab80beabc,1d0302f6-26ed-4c67-8b03-4c1243587a06,6c93dae8-9fde-48da-9aa7-292da7ac4556,e319e60d-2ee8-44ba-ab16-c8cb709f6ce4,0564d16f-6c60-4ec2-ab6f-6b5d597602cc,466c49f5-89f0-477a-a4bd-4f22be4430fa,2dd1bbdb-6885-4c47-8482-1779defea19f,b71db9d0-89c9-4a4d-a93f-c783ed7af530,8d8622f0-49b9-4d84-996f-ad99fbe04e52,90f4fc10-93ba-47b1-8e89-2444dd92e2d1,762bd05f-7b68-4a84-b6ff-a70d46671622,2510cf3d-b8b0-4323-899f-3823ab847a9c,9007e9da-8c84-4e30-ada8-ad20a3bf2ce1,22eec774-0843-4412-9a96-fc06fd2b5c44,f13f40ab-b3bb-40f3-b9ff-02c40710251f,6cd1a6c3-ef5a-4da5-b475-4b25b122e59b,604f044b-386c-4595-8594-d5f5425efb29,22c80d79-cdda-4362-b48c-9d17a708483d,a52f853f-00d4-4a65-b3cf-6b8790fbfd99,50214e8b-29a8-4966-bbd2-eef6d4179ed7,dc62674b-2f57-4165-bfed-2838c68ec497,8bef03b4-da2a-436a-bfcc-fec625e15785,d5ba349f-f39c-4af2-b059-2783d50d8122,a2890fa4-051b-453c-b407-af326d991b57,9574b4c2-fdda-49e8-bfe1-e6afa1a5a990,36b2f5e7-f174-420c-b80c-432772943118,22f3ba0f-26f7-46e7-bafe-44d0bee4471b,b3e671f2-79b3-4f25-83ec-f046c4a459ff,f2b1d905-882f-4c9f-ae69-d55106bfde8e,22c1dda9-1da6-474d-b1ab-fb17f9b89742,1952561e-d2fa-4516-9d7a-c7aa44ede4ca,c3738152-9017-4657-a257-63da0e811d90,e75000c6-d021-4f91-aa16-33cf5615f8f9,cd672f56-f2a7-4176-95b5-1544818e4d49,a5d612f3-8ae3-49de-8340-ce67c9ed0d3a,f80e3c77-5222-4a55-bf92-15f86452c601,d2020b96-4cfd-47d4-b9f0-f89cfb1e9abc,e5650f50-8284-423b-aa3a-424f057a2ba3,687fd0c2-b33b-4efe-9806-bb02a720853f,0fd27e55-1de9-4ba9-9d48-3e46856cddd0, pattern=[METRICS]
2023-05-08T18:29:31,823 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:545.23|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:87817a87-e8cb-4cf0-88be-720b6e08d86e,0b51aa8f-c379-49f7-9a9d-ebce06dca701,ad17d479-92cb-4ec3-a4b4-661d06926008,ae200ed5-ba4f-4734-8023-a9ea41ad4ca8,ace1bc91-8ad1-40d6-a4b8-fcc4b8a4a012,9f286bbd-2bb2-4715-9115-f5258b04ff87,ae6e0239-017e-418e-87e9-3af849114c41,9abe8eb0-6ac4-4017-8f65-086a23c84a3b,281d5e4a-4cec-42ed-a0c8-ed36fa4137fc,c4d0d653-b639-435c-9ed7-248ca823b71a,a6adf74c-d694-4c7e-b019-424e044ab087,4e9eaca3-87b0-46f9-8fa1-a42836f9ba03,33acfa16-2ff4-4e72-980a-41ec8237c1ca,18bcd777-15e5-47d6-a667-7b05fd07cf0c,8ef44357-9073-4964-912e-3299cdeaf046,db18272d-8b6c-4537-a744-b1ad34ce736c,3e3e7dd1-7fe8-4db6-a3bf-9b2ab80beabc,1d0302f6-26ed-4c67-8b03-4c1243587a06,6c93dae8-9fde-48da-9aa7-292da7ac4556,e319e60d-2ee8-44ba-ab16-c8cb709f6ce4,0564d16f-6c60-4ec2-ab6f-6b5d597602cc,466c49f5-89f0-477a-a4bd-4f22be4430fa,2dd1bbdb-6885-4c47-8482-1779defea19f,b71db9d0-89c9-4a4d-a93f-c783ed7af530,8d8622f0-49b9-4d84-996f-ad99fbe04e52,90f4fc10-93ba-47b1-8e89-2444dd92e2d1,762bd05f-7b68-4a84-b6ff-a70d46671622,2510cf3d-b8b0-4323-899f-3823ab847a9c,9007e9da-8c84-4e30-ada8-ad20a3bf2ce1,22eec774-0843-4412-9a96-fc06fd2b5c44,f13f40ab-b3bb-40f3-b9ff-02c40710251f,6cd1a6c3-ef5a-4da5-b475-4b25b122e59b,604f044b-386c-4595-8594-d5f5425efb29,22c80d79-cdda-4362-b48c-9d17a708483d,a52f853f-00d4-4a65-b3cf-6b8790fbfd99,50214e8b-29a8-4966-bbd2-eef6d4179ed7,dc62674b-2f57-4165-bfed-2838c68ec497,8bef03b4-da2a-436a-bfcc-fec625e15785,d5ba349f-f39c-4af2-b059-2783d50d8122,a2890fa4-051b-453c-b407-af326d991b57,9574b4c2-fdda-49e8-bfe1-e6afa1a5a990,36b2f5e7-f174-420c-b80c-432772943118,22f3ba0f-26f7-46e7-bafe-44d0bee4471b,b3e671f2-79b3-4f25-83ec-f046c4a459ff,f2b1d905-882f-4c9f-ae69-d55106bfde8e,22c1dda9-1da6-474d-b1ab-fb17f9b89742,1952561e-d2fa-4516-9d7a-c7aa44ede4ca,c3738152-9017-4657-a257-63da0e811d90,e75000c6-d021-4f91-aa16-33cf5615f8f9,cd672f56-f2a7-4176-95b5-1544818e4d49,a5d612f3-8ae3-49de-8340-ce67c9ed0d3a,f80e3c77-5222-4a55-bf92-15f86452c601,d2020b96-4cfd-47d4-b9f0-f89cfb1e9abc,e5650f50-8284-423b-aa3a-424f057a2ba3,687fd0c2-b33b-4efe-9806-bb02a720853f,0fd27e55-1de9-4ba9-9d48-3e46856cddd0,timestamp:1683570571
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41594 "POST /predictions/benchmark HTTP/1.0" 200 683
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:676713.554|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:120900.398|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,824 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 120900398, Backend time ns: 556469572
2023-05-08T18:29:31,824 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 120900398, Backend time ns: 556469572
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:120.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41600 "POST /predictions/benchmark HTTP/1.0" 200 666
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:648977.072|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:92415.766|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,824 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 92415766, Backend time ns: 556842622
2023-05-08T18:29:31,824 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 92415766, Backend time ns: 556842622
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:92.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,824 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41606 "POST /predictions/benchmark HTTP/1.0" 200 666
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:649307.611|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:92386.224|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 92386224, Backend time ns: 557195312
2023-05-08T18:29:31,825 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 92386224, Backend time ns: 557195312
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:92.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41618 "POST /predictions/benchmark HTTP/1.0" 200 661
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:638302.829|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81030.283|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 81030283, Backend time ns: 557548251
2023-05-08T18:29:31,825 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 81030283, Backend time ns: 557548251
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:81.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41630 "POST /predictions/benchmark HTTP/1.0" 200 650
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:638635.078|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81005.622|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,825 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 81005622, Backend time ns: 557928033
2023-05-08T18:29:31,825 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 81005622, Backend time ns: 557928033
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:81.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41660 "POST /predictions/benchmark HTTP/1.0" 200 646
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:638802.887|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80797.6|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 80797600, Backend time ns: 558286523
2023-05-08T18:29:31,826 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 80797600, Backend time ns: 558286523
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:80.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41656 "POST /predictions/benchmark HTTP/1.0" 200 646
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:638941.245|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80560.307|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 80560307, Backend time ns: 558641132
2023-05-08T18:29:31,826 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 80560307, Backend time ns: 558641132
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:80.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41644 "POST /predictions/benchmark HTTP/1.0" 200 656
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:634157.399|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,826 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:75437.962|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 75437962, Backend time ns: 558970501
2023-05-08T18:29:31,827 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 75437962, Backend time ns: 558970501
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:75.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41650 "POST /predictions/benchmark HTTP/1.0" 200 647
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:629415.206|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:70366.981|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 70366981, Backend time ns: 559284218
2023-05-08T18:29:31,827 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 70366981, Backend time ns: 559284218
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:70.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41662 "POST /predictions/benchmark HTTP/1.0" 200 640
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:629649.708|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:70289.576|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 70289576, Backend time ns: 559693261
2023-05-08T18:29:31,827 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 70289576, Backend time ns: 559693261
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:70.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41676 "POST /predictions/benchmark HTTP/1.0" 200 640
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,827 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:630041.22|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:70269.755|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 70269755, Backend time ns: 560029940
2023-05-08T18:29:31,828 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 70269755, Backend time ns: 560029940
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:70.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41684 "POST /predictions/benchmark HTTP/1.0" 200 631
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:623493.116|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:63478.557|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 63478557, Backend time ns: 560298345
2023-05-08T18:29:31,828 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 63478557, Backend time ns: 560298345
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:63.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41710 "POST /predictions/benchmark HTTP/1.0" 200 624
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:616011.94|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:55635.081|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 55635081, Backend time ns: 560621183
2023-05-08T18:29:31,828 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 55635081, Backend time ns: 560621183
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:55.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41716 "POST /predictions/benchmark HTTP/1.0" 200 624
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,828 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:616295.836|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:55597.309|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 55597309, Backend time ns: 560949301
2023-05-08T18:29:31,829 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 55597309, Backend time ns: 560949301
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:55.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41726 "POST /predictions/benchmark HTTP/1.0" 200 612
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:606087.939|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:44992.38|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 44992380, Backend time ns: 561365594
2023-05-08T18:29:31,829 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 44992380, Backend time ns: 561365594
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:44.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41748 "POST /predictions/benchmark HTTP/1.0" 200 612
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:601259.821|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:39820.022|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 39820022, Backend time ns: 561701263
2023-05-08T18:29:31,829 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 39820022, Backend time ns: 561701263
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:39.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41698 "POST /predictions/benchmark HTTP/1.0" 200 617
2023-05-08T18:29:31,829 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:601434.58|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:39656.864|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 39656864, Backend time ns: 562043041
2023-05-08T18:29:31,830 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 39656864, Backend time ns: 562043041
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:39.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41740 "POST /predictions/benchmark HTTP/1.0" 200 602
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:595028.725|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:32901.399|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32901399, Backend time ns: 562394511
2023-05-08T18:29:31,830 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32901399, Backend time ns: 562394511
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:32.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41704 "POST /predictions/benchmark HTTP/1.0" 200 608
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:595318.421|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:32831.585|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32831585, Backend time ns: 562750231
2023-05-08T18:29:31,830 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32831585, Backend time ns: 562750231
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:32.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,830 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41750 "POST /predictions/benchmark HTTP/1.0" 200 601
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:595436.608|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:32612.463|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32612463, Backend time ns: 563103280
2023-05-08T18:29:31,831 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32612463, Backend time ns: 563103280
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:32.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41756 "POST /predictions/benchmark HTTP/1.0" 200 596
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:595431.117|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:32253.863|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32253863, Backend time ns: 563503613
2023-05-08T18:29:31,831 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32253863, Backend time ns: 563503613
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:32.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41786 "POST /predictions/benchmark HTTP/1.0" 200 589
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:588409.587|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:24833.86|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,831 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24833860, Backend time ns: 563827511
2023-05-08T18:29:31,831 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24833860, Backend time ns: 563827511
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:24.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41776 "POST /predictions/benchmark HTTP/1.0" 200 590
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:588727.834|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:24821.109|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24821109, Backend time ns: 564177410
2023-05-08T18:29:31,832 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24821109, Backend time ns: 564177410
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:24.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41772 "POST /predictions/benchmark HTTP/1.0" 200 589
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:588598.477|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:24349.413|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24349413, Backend time ns: 564478707
2023-05-08T18:29:31,832 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24349413, Backend time ns: 564478707
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:24.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41766 "POST /predictions/benchmark HTTP/1.0" 200 589
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:588750.005|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:24189.834|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,832 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24189834, Backend time ns: 564835507
2023-05-08T18:29:31,832 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24189834, Backend time ns: 564835507
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:24.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41774 "POST /predictions/benchmark HTTP/1.0" 200 589
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:588487.611|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:23539.818|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 23539818, Backend time ns: 565220098
2023-05-08T18:29:31,833 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 23539818, Backend time ns: 565220098
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:23.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41866 "POST /predictions/benchmark HTTP/1.0" 200 569
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:568598.656|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:3256.511|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3256511, Backend time ns: 565571668
2023-05-08T18:29:31,833 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3256511, Backend time ns: 565571668
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41874 "POST /predictions/benchmark HTTP/1.0" 200 569
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,833 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:568858.27|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:3194.717|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3194717, Backend time ns: 565913147
2023-05-08T18:29:31,834 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3194717, Backend time ns: 565913147
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41860 "POST /predictions/benchmark HTTP/1.0" 200 570
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:569141.506|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:3149.875|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3149875, Backend time ns: 566315209
2023-05-08T18:29:31,834 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3149875, Backend time ns: 566315209
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41806 "POST /predictions/benchmark HTTP/1.0" 200 570
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:569489.125|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:3071.63|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3071630, Backend time ns: 566645888
2023-05-08T18:29:31,834 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3071630, Backend time ns: 566645888
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41848 "POST /predictions/benchmark HTTP/1.0" 200 570
2023-05-08T18:29:31,834 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:569758.18|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:3044.249|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3044249, Backend time ns: 566934074
2023-05-08T18:29:31,835 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3044249, Backend time ns: 566934074
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41842 "POST /predictions/benchmark HTTP/1.0" 200 571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:570037.276|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:3017.037|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3017037, Backend time ns: 567353807
2023-05-08T18:29:31,835 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3017037, Backend time ns: 567353807
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41886 "POST /predictions/benchmark HTTP/1.0" 200 571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:570461.41|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:3011.017|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3011017, Backend time ns: 567679575
2023-05-08T18:29:31,835 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 3011017, Backend time ns: 567679575
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:3.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,835 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41902 "POST /predictions/benchmark HTTP/1.0" 200 571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:570696.673|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2950.854|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2950854, Backend time ns: 568023704
2023-05-08T18:29:31,836 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2950854, Backend time ns: 568023704
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41906 "POST /predictions/benchmark HTTP/1.0" 200 571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:570519.722|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2427.804|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2427804, Backend time ns: 568316381
2023-05-08T18:29:31,836 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2427804, Backend time ns: 568316381
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41940 "POST /predictions/benchmark HTTP/1.0" 200 571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:570726.274|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2343.68|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2343680, Backend time ns: 568595796
2023-05-08T18:29:31,836 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2343680, Backend time ns: 568595796
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41932 "POST /predictions/benchmark HTTP/1.0" 200 571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:570950.427|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,836 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2288.077|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2288077, Backend time ns: 568869252
2023-05-08T18:29:31,837 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2288077, Backend time ns: 568869252
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41918 "POST /predictions/benchmark HTTP/1.0" 200 572
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:571010.45|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2072.705|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2072705, Backend time ns: 569139647
2023-05-08T18:29:31,837 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2072705, Backend time ns: 569139647
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41954 "POST /predictions/benchmark HTTP/1.0" 200 572
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:571266.004|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2063.694|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2063694, Backend time ns: 569411172
2023-05-08T18:29:31,837 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2063694, Backend time ns: 569411172
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41958 "POST /predictions/benchmark HTTP/1.0" 200 571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:571330.797|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1856.712|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1856712, Backend time ns: 569745320
2023-05-08T18:29:31,837 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1856712, Backend time ns: 569745320
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,837 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41966 "POST /predictions/benchmark HTTP/1.0" 200 571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:571600.112|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1784.089|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1784089, Backend time ns: 570018815
2023-05-08T18:29:31,838 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1784089, Backend time ns: 570018815
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41998 "POST /predictions/benchmark HTTP/1.0" 200 572
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:571580.702|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1499.824|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1499824, Backend time ns: 570307431
2023-05-08T18:29:31,838 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1499824, Backend time ns: 570307431
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41968 "POST /predictions/benchmark HTTP/1.0" 200 572
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:571819.335|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1446.651|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1446651, Backend time ns: 570571455
2023-05-08T18:29:31,838 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1446651, Backend time ns: 570571455
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41994 "POST /predictions/benchmark HTTP/1.0" 200 572
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:572085.53|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,838 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1436.26|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1436260, Backend time ns: 570875312
2023-05-08T18:29:31,839 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1436260, Backend time ns: 570875312
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42008 "POST /predictions/benchmark HTTP/1.0" 200 573
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:572227.468|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1288.832|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1288832, Backend time ns: 571128936
2023-05-08T18:29:31,839 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1288832, Backend time ns: 571128936
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41978 "POST /predictions/benchmark HTTP/1.0" 200 572
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:571813.365|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:622.095|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 622095, Backend time ns: 571413542
2023-05-08T18:29:31,839 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 622095, Backend time ns: 571413542
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42034 "POST /predictions/benchmark HTTP/1.0" 200 572
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:572065.559|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:591.353|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 591353, Backend time ns: 571693758
2023-05-08T18:29:31,839 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 591353, Backend time ns: 571693758
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,839 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42014 "POST /predictions/benchmark HTTP/1.0" 200 572
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:572313.903|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556.831|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556831, Backend time ns: 571986774
2023-05-08T18:29:31,840 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556831, Backend time ns: 571986774
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42026 "POST /predictions/benchmark HTTP/1.0" 200 573
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:572553.006|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:506.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 506548, Backend time ns: 572236288
2023-05-08T18:29:31,840 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 506548, Backend time ns: 572236288
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42116 "POST /predictions/benchmark HTTP/1.0" 200 573
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:572723.826|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:422.924|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 422924, Backend time ns: 572556576
2023-05-08T18:29:31,840 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 422924, Backend time ns: 572556576
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42058 "POST /predictions/benchmark HTTP/1.0" 200 573
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:572969.779|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:344.229|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,840 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 344229, Backend time ns: 572818211
2023-05-08T18:29:31,840 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 344229, Backend time ns: 572818211
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42044 "POST /predictions/benchmark HTTP/1.0" 200 574
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:573214.172|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:330.268|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 330268, Backend time ns: 573088816
2023-05-08T18:29:31,841 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 330268, Backend time ns: 573088816
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42056 "POST /predictions/benchmark HTTP/1.0" 200 574
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:573425.544|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:275.585|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 275585, Backend time ns: 573329839
2023-05-08T18:29:31,841 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 275585, Backend time ns: 573329839
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42066 "POST /predictions/benchmark HTTP/1.0" 200 574
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:573652.467|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:260.214|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 260214, Backend time ns: 573581663
2023-05-08T18:29:31,841 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 260214, Backend time ns: 573581663
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42132 "POST /predictions/benchmark HTTP/1.0" 200 574
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:573891.541|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:249.154|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,841 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 249154, Backend time ns: 573830927
2023-05-08T18:29:31,841 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 249154, Backend time ns: 573830927
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42114 "POST /predictions/benchmark HTTP/1.0" 200 575
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:574077.18|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:185.14|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,842 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 185140, Backend time ns: 574079951
2023-05-08T18:29:31,842 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 185140, Backend time ns: 574079951
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:31,842 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:31,842 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 549
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 549
2023-05-08T18:29:31,842 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:25.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570571
2023-05-08T18:29:33,842 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570573842
2023-05-08T18:29:33,842 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570573842
2023-05-08T18:29:33,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570573
2023-05-08T18:29:33,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,846 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,847 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,848 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,849 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:33,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([43, 50])
2023-05-08T18:29:33,852 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:33,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:33,858 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:33,899 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:33,919 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:33,926 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:33,957 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:33,960 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:33,964 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:33,995 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:34,000 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:34,002 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:34,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:34,020 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:34,027 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:34,040 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:34,042 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:34,045 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:34,056 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:34,066 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:34,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:34,080 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:34,081 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:34,092 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:34,097 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:34,108 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:34,119 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:34,122 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:34,134 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:34,145 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:34,160 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:34,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:34,186 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:34,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:34,298 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:34,298 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:452.37|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570574,8fbd7749-8b5e-4355-a19d-5931e2aabe8d,e30036ba-75cc-4b3e-abcd-7be51bddd41a,28780194-bddc-4a53-b1a7-ed32dccb217b,90bc6ef9-62ff-42a3-8515-8414cfe49505,e0039521-7a1d-4bfb-a4b9-836422a1674c,85957559-12e4-4a11-8caa-601c1a6e9148,c0f6bbb3-5a98-441f-99d5-87e4713b11b8,8ec1bbf7-24f3-4f6a-a7d4-c1b5b76a0e6c,278bd7c3-1941-43d4-9e09-c4d0bbb43925,338c6dd6-8596-41d9-ac78-dbfd0122f3d2,82b4f2da-8af2-4448-8167-56481b821090,14ae7c1f-ceea-4d1b-b126-5bad345f95d5,32303992-6e32-48f7-9552-ad60261790e8,cd11cb2b-1ae0-4f22-8fe6-ce1d1b84835d,50949d0d-31fb-40fb-afb9-6d3350ee35a5,ef64fee3-0c0d-4e4d-ae70-6757ac8f3490,85ad1aae-c792-4c63-a463-16ca0ed590d7,0baee984-4e06-4801-96aa-482ebd779327,9507edea-990a-476e-a6cd-74668261587c,d5d7df54-fa20-49be-8aa3-a72fefe27afd,340053c9-bdfd-4ccc-a9b4-d97ba81b1dfa,6853d950-d4fd-4f54-9ed1-7c33049d50fa,73e82364-4804-4727-bcfe-d7584710bc3b,cb27632d-bb28-4a9d-a055-5f07ff44a379,1c410ae5-339c-4acd-a852-7cd35687ea40,e8b8f3a2-f502-48bc-8c36-3b1956753fd2,cc3f8abc-1f3b-4bd5-a32e-4e981ab83a5e,d9f55c30-a447-4c0e-9c13-c1c19cc97094,25569d17-9677-4384-93e7-d95f39147d9f,6403364c-88e8-4b5c-9d62-7c22ec964fe2,eaaaa6c2-6e29-4a05-b470-72412f0f2ebb,0831fe21-afac-41f8-8394-4638b0b3a0c7,bebf63f8-4cd9-4975-b829-0b06d6ede904,241257a5-5427-42bf-a3de-2e46dcb96056,1498e7ba-0e89-4428-824a-db8c9c327772,e11a4bdb-e2ad-4dba-b21a-5200b1ae4291,09710a50-cde7-4579-adbd-911d86c3cb05,8d57aa87-a6f2-4343-8772-f71b4bd314ce,eafeb834-a6c4-4d34-9365-5bf83fe9bccd,ef3a2951-35c6-4ea7-a6a7-efe54a7b18d5,5f762590-2ab5-47d2-a0ae-3ecf6a326093,826a0cb2-3d37-429b-b047-224c5a3e0169,5fccf7e4-130b-48e6-8136-1a6f90442f8c, pattern=[METRICS]
2023-05-08T18:29:34,298 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:452.37|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570574,8fbd7749-8b5e-4355-a19d-5931e2aabe8d,e30036ba-75cc-4b3e-abcd-7be51bddd41a,28780194-bddc-4a53-b1a7-ed32dccb217b,90bc6ef9-62ff-42a3-8515-8414cfe49505,e0039521-7a1d-4bfb-a4b9-836422a1674c,85957559-12e4-4a11-8caa-601c1a6e9148,c0f6bbb3-5a98-441f-99d5-87e4713b11b8,8ec1bbf7-24f3-4f6a-a7d4-c1b5b76a0e6c,278bd7c3-1941-43d4-9e09-c4d0bbb43925,338c6dd6-8596-41d9-ac78-dbfd0122f3d2,82b4f2da-8af2-4448-8167-56481b821090,14ae7c1f-ceea-4d1b-b126-5bad345f95d5,32303992-6e32-48f7-9552-ad60261790e8,cd11cb2b-1ae0-4f22-8fe6-ce1d1b84835d,50949d0d-31fb-40fb-afb9-6d3350ee35a5,ef64fee3-0c0d-4e4d-ae70-6757ac8f3490,85ad1aae-c792-4c63-a463-16ca0ed590d7,0baee984-4e06-4801-96aa-482ebd779327,9507edea-990a-476e-a6cd-74668261587c,d5d7df54-fa20-49be-8aa3-a72fefe27afd,340053c9-bdfd-4ccc-a9b4-d97ba81b1dfa,6853d950-d4fd-4f54-9ed1-7c33049d50fa,73e82364-4804-4727-bcfe-d7584710bc3b,cb27632d-bb28-4a9d-a055-5f07ff44a379,1c410ae5-339c-4acd-a852-7cd35687ea40,e8b8f3a2-f502-48bc-8c36-3b1956753fd2,cc3f8abc-1f3b-4bd5-a32e-4e981ab83a5e,d9f55c30-a447-4c0e-9c13-c1c19cc97094,25569d17-9677-4384-93e7-d95f39147d9f,6403364c-88e8-4b5c-9d62-7c22ec964fe2,eaaaa6c2-6e29-4a05-b470-72412f0f2ebb,0831fe21-afac-41f8-8394-4638b0b3a0c7,bebf63f8-4cd9-4975-b829-0b06d6ede904,241257a5-5427-42bf-a3de-2e46dcb96056,1498e7ba-0e89-4428-824a-db8c9c327772,e11a4bdb-e2ad-4dba-b21a-5200b1ae4291,09710a50-cde7-4579-adbd-911d86c3cb05,8d57aa87-a6f2-4343-8772-f71b4bd314ce,eafeb834-a6c4-4d34-9365-5bf83fe9bccd,ef3a2951-35c6-4ea7-a6a7-efe54a7b18d5,5f762590-2ab5-47d2-a0ae-3ecf6a326093,826a0cb2-3d37-429b-b047-224c5a3e0169,5fccf7e4-130b-48e6-8136-1a6f90442f8c, pattern=[METRICS]
2023-05-08T18:29:34,298 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:452.37|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:8fbd7749-8b5e-4355-a19d-5931e2aabe8d,e30036ba-75cc-4b3e-abcd-7be51bddd41a,28780194-bddc-4a53-b1a7-ed32dccb217b,90bc6ef9-62ff-42a3-8515-8414cfe49505,e0039521-7a1d-4bfb-a4b9-836422a1674c,85957559-12e4-4a11-8caa-601c1a6e9148,c0f6bbb3-5a98-441f-99d5-87e4713b11b8,8ec1bbf7-24f3-4f6a-a7d4-c1b5b76a0e6c,278bd7c3-1941-43d4-9e09-c4d0bbb43925,338c6dd6-8596-41d9-ac78-dbfd0122f3d2,82b4f2da-8af2-4448-8167-56481b821090,14ae7c1f-ceea-4d1b-b126-5bad345f95d5,32303992-6e32-48f7-9552-ad60261790e8,cd11cb2b-1ae0-4f22-8fe6-ce1d1b84835d,50949d0d-31fb-40fb-afb9-6d3350ee35a5,ef64fee3-0c0d-4e4d-ae70-6757ac8f3490,85ad1aae-c792-4c63-a463-16ca0ed590d7,0baee984-4e06-4801-96aa-482ebd779327,9507edea-990a-476e-a6cd-74668261587c,d5d7df54-fa20-49be-8aa3-a72fefe27afd,340053c9-bdfd-4ccc-a9b4-d97ba81b1dfa,6853d950-d4fd-4f54-9ed1-7c33049d50fa,73e82364-4804-4727-bcfe-d7584710bc3b,cb27632d-bb28-4a9d-a055-5f07ff44a379,1c410ae5-339c-4acd-a852-7cd35687ea40,e8b8f3a2-f502-48bc-8c36-3b1956753fd2,cc3f8abc-1f3b-4bd5-a32e-4e981ab83a5e,d9f55c30-a447-4c0e-9c13-c1c19cc97094,25569d17-9677-4384-93e7-d95f39147d9f,6403364c-88e8-4b5c-9d62-7c22ec964fe2,eaaaa6c2-6e29-4a05-b470-72412f0f2ebb,0831fe21-afac-41f8-8394-4638b0b3a0c7,bebf63f8-4cd9-4975-b829-0b06d6ede904,241257a5-5427-42bf-a3de-2e46dcb96056,1498e7ba-0e89-4428-824a-db8c9c327772,e11a4bdb-e2ad-4dba-b21a-5200b1ae4291,09710a50-cde7-4579-adbd-911d86c3cb05,8d57aa87-a6f2-4343-8772-f71b4bd314ce,eafeb834-a6c4-4d34-9365-5bf83fe9bccd,ef3a2951-35c6-4ea7-a6a7-efe54a7b18d5,5f762590-2ab5-47d2-a0ae-3ecf6a326093,826a0cb2-3d37-429b-b047-224c5a3e0169,5fccf7e4-130b-48e6-8136-1a6f90442f8c,timestamp:1683570574
2023-05-08T18:29:34,298 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:452.48|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570574,8fbd7749-8b5e-4355-a19d-5931e2aabe8d,e30036ba-75cc-4b3e-abcd-7be51bddd41a,28780194-bddc-4a53-b1a7-ed32dccb217b,90bc6ef9-62ff-42a3-8515-8414cfe49505,e0039521-7a1d-4bfb-a4b9-836422a1674c,85957559-12e4-4a11-8caa-601c1a6e9148,c0f6bbb3-5a98-441f-99d5-87e4713b11b8,8ec1bbf7-24f3-4f6a-a7d4-c1b5b76a0e6c,278bd7c3-1941-43d4-9e09-c4d0bbb43925,338c6dd6-8596-41d9-ac78-dbfd0122f3d2,82b4f2da-8af2-4448-8167-56481b821090,14ae7c1f-ceea-4d1b-b126-5bad345f95d5,32303992-6e32-48f7-9552-ad60261790e8,cd11cb2b-1ae0-4f22-8fe6-ce1d1b84835d,50949d0d-31fb-40fb-afb9-6d3350ee35a5,ef64fee3-0c0d-4e4d-ae70-6757ac8f3490,85ad1aae-c792-4c63-a463-16ca0ed590d7,0baee984-4e06-4801-96aa-482ebd779327,9507edea-990a-476e-a6cd-74668261587c,d5d7df54-fa20-49be-8aa3-a72fefe27afd,340053c9-bdfd-4ccc-a9b4-d97ba81b1dfa,6853d950-d4fd-4f54-9ed1-7c33049d50fa,73e82364-4804-4727-bcfe-d7584710bc3b,cb27632d-bb28-4a9d-a055-5f07ff44a379,1c410ae5-339c-4acd-a852-7cd35687ea40,e8b8f3a2-f502-48bc-8c36-3b1956753fd2,cc3f8abc-1f3b-4bd5-a32e-4e981ab83a5e,d9f55c30-a447-4c0e-9c13-c1c19cc97094,25569d17-9677-4384-93e7-d95f39147d9f,6403364c-88e8-4b5c-9d62-7c22ec964fe2,eaaaa6c2-6e29-4a05-b470-72412f0f2ebb,0831fe21-afac-41f8-8394-4638b0b3a0c7,bebf63f8-4cd9-4975-b829-0b06d6ede904,241257a5-5427-42bf-a3de-2e46dcb96056,1498e7ba-0e89-4428-824a-db8c9c327772,e11a4bdb-e2ad-4dba-b21a-5200b1ae4291,09710a50-cde7-4579-adbd-911d86c3cb05,8d57aa87-a6f2-4343-8772-f71b4bd314ce,eafeb834-a6c4-4d34-9365-5bf83fe9bccd,ef3a2951-35c6-4ea7-a6a7-efe54a7b18d5,5f762590-2ab5-47d2-a0ae-3ecf6a326093,826a0cb2-3d37-429b-b047-224c5a3e0169,5fccf7e4-130b-48e6-8136-1a6f90442f8c, pattern=[METRICS]
2023-05-08T18:29:34,298 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:452.48|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570574,8fbd7749-8b5e-4355-a19d-5931e2aabe8d,e30036ba-75cc-4b3e-abcd-7be51bddd41a,28780194-bddc-4a53-b1a7-ed32dccb217b,90bc6ef9-62ff-42a3-8515-8414cfe49505,e0039521-7a1d-4bfb-a4b9-836422a1674c,85957559-12e4-4a11-8caa-601c1a6e9148,c0f6bbb3-5a98-441f-99d5-87e4713b11b8,8ec1bbf7-24f3-4f6a-a7d4-c1b5b76a0e6c,278bd7c3-1941-43d4-9e09-c4d0bbb43925,338c6dd6-8596-41d9-ac78-dbfd0122f3d2,82b4f2da-8af2-4448-8167-56481b821090,14ae7c1f-ceea-4d1b-b126-5bad345f95d5,32303992-6e32-48f7-9552-ad60261790e8,cd11cb2b-1ae0-4f22-8fe6-ce1d1b84835d,50949d0d-31fb-40fb-afb9-6d3350ee35a5,ef64fee3-0c0d-4e4d-ae70-6757ac8f3490,85ad1aae-c792-4c63-a463-16ca0ed590d7,0baee984-4e06-4801-96aa-482ebd779327,9507edea-990a-476e-a6cd-74668261587c,d5d7df54-fa20-49be-8aa3-a72fefe27afd,340053c9-bdfd-4ccc-a9b4-d97ba81b1dfa,6853d950-d4fd-4f54-9ed1-7c33049d50fa,73e82364-4804-4727-bcfe-d7584710bc3b,cb27632d-bb28-4a9d-a055-5f07ff44a379,1c410ae5-339c-4acd-a852-7cd35687ea40,e8b8f3a2-f502-48bc-8c36-3b1956753fd2,cc3f8abc-1f3b-4bd5-a32e-4e981ab83a5e,d9f55c30-a447-4c0e-9c13-c1c19cc97094,25569d17-9677-4384-93e7-d95f39147d9f,6403364c-88e8-4b5c-9d62-7c22ec964fe2,eaaaa6c2-6e29-4a05-b470-72412f0f2ebb,0831fe21-afac-41f8-8394-4638b0b3a0c7,bebf63f8-4cd9-4975-b829-0b06d6ede904,241257a5-5427-42bf-a3de-2e46dcb96056,1498e7ba-0e89-4428-824a-db8c9c327772,e11a4bdb-e2ad-4dba-b21a-5200b1ae4291,09710a50-cde7-4579-adbd-911d86c3cb05,8d57aa87-a6f2-4343-8772-f71b4bd314ce,eafeb834-a6c4-4d34-9365-5bf83fe9bccd,ef3a2951-35c6-4ea7-a6a7-efe54a7b18d5,5f762590-2ab5-47d2-a0ae-3ecf6a326093,826a0cb2-3d37-429b-b047-224c5a3e0169,5fccf7e4-130b-48e6-8136-1a6f90442f8c, pattern=[METRICS]
2023-05-08T18:29:34,298 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:452.48|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:8fbd7749-8b5e-4355-a19d-5931e2aabe8d,e30036ba-75cc-4b3e-abcd-7be51bddd41a,28780194-bddc-4a53-b1a7-ed32dccb217b,90bc6ef9-62ff-42a3-8515-8414cfe49505,e0039521-7a1d-4bfb-a4b9-836422a1674c,85957559-12e4-4a11-8caa-601c1a6e9148,c0f6bbb3-5a98-441f-99d5-87e4713b11b8,8ec1bbf7-24f3-4f6a-a7d4-c1b5b76a0e6c,278bd7c3-1941-43d4-9e09-c4d0bbb43925,338c6dd6-8596-41d9-ac78-dbfd0122f3d2,82b4f2da-8af2-4448-8167-56481b821090,14ae7c1f-ceea-4d1b-b126-5bad345f95d5,32303992-6e32-48f7-9552-ad60261790e8,cd11cb2b-1ae0-4f22-8fe6-ce1d1b84835d,50949d0d-31fb-40fb-afb9-6d3350ee35a5,ef64fee3-0c0d-4e4d-ae70-6757ac8f3490,85ad1aae-c792-4c63-a463-16ca0ed590d7,0baee984-4e06-4801-96aa-482ebd779327,9507edea-990a-476e-a6cd-74668261587c,d5d7df54-fa20-49be-8aa3-a72fefe27afd,340053c9-bdfd-4ccc-a9b4-d97ba81b1dfa,6853d950-d4fd-4f54-9ed1-7c33049d50fa,73e82364-4804-4727-bcfe-d7584710bc3b,cb27632d-bb28-4a9d-a055-5f07ff44a379,1c410ae5-339c-4acd-a852-7cd35687ea40,e8b8f3a2-f502-48bc-8c36-3b1956753fd2,cc3f8abc-1f3b-4bd5-a32e-4e981ab83a5e,d9f55c30-a447-4c0e-9c13-c1c19cc97094,25569d17-9677-4384-93e7-d95f39147d9f,6403364c-88e8-4b5c-9d62-7c22ec964fe2,eaaaa6c2-6e29-4a05-b470-72412f0f2ebb,0831fe21-afac-41f8-8394-4638b0b3a0c7,bebf63f8-4cd9-4975-b829-0b06d6ede904,241257a5-5427-42bf-a3de-2e46dcb96056,1498e7ba-0e89-4428-824a-db8c9c327772,e11a4bdb-e2ad-4dba-b21a-5200b1ae4291,09710a50-cde7-4579-adbd-911d86c3cb05,8d57aa87-a6f2-4343-8772-f71b4bd314ce,eafeb834-a6c4-4d34-9365-5bf83fe9bccd,ef3a2951-35c6-4ea7-a6a7-efe54a7b18d5,5f762590-2ab5-47d2-a0ae-3ecf6a326093,826a0cb2-3d37-429b-b047-224c5a3e0169,5fccf7e4-130b-48e6-8136-1a6f90442f8c,timestamp:1683570574
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42022 "POST /predictions/benchmark HTTP/1.0" 200 3032
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3031181.438|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574725.783|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,299 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574725783, Backend time ns: 456936332
2023-05-08T18:29:34,299 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574725783, Backend time ns: 456936332
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42074 "POST /predictions/benchmark HTTP/1.0" 200 3032
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3031702.756|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574681.22|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,299 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574681220, Backend time ns: 457210197
2023-05-08T18:29:34,299 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574681220, Backend time ns: 457210197
2023-05-08T18:29:34,299 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42088 "POST /predictions/benchmark HTTP/1.0" 200 3033
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3031920.828|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574648.539|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574648539, Backend time ns: 457456980
2023-05-08T18:29:34,300 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574648539, Backend time ns: 457456980
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42142 "POST /predictions/benchmark HTTP/1.0" 200 3033
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3032160.032|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574630.738|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574630738, Backend time ns: 457760087
2023-05-08T18:29:34,300 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574630738, Backend time ns: 457760087
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42150 "POST /predictions/benchmark HTTP/1.0" 200 3033
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3032398.895|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574565.764|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574565764, Backend time ns: 458035522
2023-05-08T18:29:34,300 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574565764, Backend time ns: 458035522
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42146 "POST /predictions/benchmark HTTP/1.0" 200 3032
2023-05-08T18:29:34,300 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3032548.544|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574447.108|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574447108, Backend time ns: 458498778
2023-05-08T18:29:34,301 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574447108, Backend time ns: 458498778
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42160 "POST /predictions/benchmark HTTP/1.0" 200 3033
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3032855.08|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574273.738|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574273738, Backend time ns: 458928832
2023-05-08T18:29:34,301 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574273738, Backend time ns: 458928832
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42186 "POST /predictions/benchmark HTTP/1.0" 200 3033
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3033143.386|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574147.601|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574147601, Backend time ns: 459175245
2023-05-08T18:29:34,301 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574147601, Backend time ns: 459175245
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,301 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42174 "POST /predictions/benchmark HTTP/1.0" 200 3033
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3033335.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574101.359|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574101359, Backend time ns: 459406818
2023-05-08T18:29:34,302 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574101359, Backend time ns: 459406818
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42206 "POST /predictions/benchmark HTTP/1.0" 200 3034
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3033511.927|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574039.955|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574039955, Backend time ns: 459686154
2023-05-08T18:29:34,302 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574039955, Backend time ns: 459686154
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42122 "POST /predictions/benchmark HTTP/1.0" 200 3034
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3033758.521|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2574011.534|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574011534, Backend time ns: 460026433
2023-05-08T18:29:34,302 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2574011534, Backend time ns: 460026433
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2574.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42192 "POST /predictions/benchmark HTTP/1.0" 200 3034
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,302 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3034012.835|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573930.429|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573930429, Backend time ns: 460291008
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573930429, Backend time ns: 460291008
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42222 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3034226.677|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573869.105|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573869105, Backend time ns: 460538472
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573869105, Backend time ns: 460538472
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42232 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3034332.863|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573738.628|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573738628, Backend time ns: 460797056
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573738628, Backend time ns: 460797056
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42238 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3034589.628|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573728.998|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573728998, Backend time ns: 461047290
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573728998, Backend time ns: 461047290
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42260 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3034693.873|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573594.5|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573594500, Backend time ns: 461252741
2023-05-08T18:29:34,303 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573594500, Backend time ns: 461252741
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42266 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3034722.964|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573416.18|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573416180, Backend time ns: 461460043
2023-05-08T18:29:34,304 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573416180, Backend time ns: 461460043
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42270 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3034899.914|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573388.368|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573388368, Backend time ns: 461674795
2023-05-08T18:29:34,304 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573388368, Backend time ns: 461674795
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42252 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035189.91|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573346.576|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573346576, Backend time ns: 461988152
2023-05-08T18:29:34,304 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573346576, Backend time ns: 461988152
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42282 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035344.469|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573308.284|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,304 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573308284, Backend time ns: 462177153
2023-05-08T18:29:34,304 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573308284, Backend time ns: 462177153
2023-05-08T18:29:34,304 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42286 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035378.061|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2573152.815|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573152815, Backend time ns: 462383104
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2573152815, Backend time ns: 462383104
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2573.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42302 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035353.049|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2572918.872|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572918872, Backend time ns: 462591516
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572918872, Backend time ns: 462591516
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2572.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42312 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035553.421|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2572911.213|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572911213, Backend time ns: 462775815
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572911213, Backend time ns: 462775815
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2572.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42316 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035638.595|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2572813.807|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572813807, Backend time ns: 462963556
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572813807, Backend time ns: 462963556
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2572.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42328 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035701.229|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2572689.17|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572689170, Backend time ns: 463172508
2023-05-08T18:29:34,305 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572689170, Backend time ns: 463172508
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2572.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,305 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42336 "POST /predictions/benchmark HTTP/1.0" 200 3035
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035735.981|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2572513.961|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572513961, Backend time ns: 463405901
2023-05-08T18:29:34,306 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572513961, Backend time ns: 463405901
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2572.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42338 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035894.28|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2572433.466|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572433466, Backend time ns: 463614812
2023-05-08T18:29:34,306 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2572433466, Backend time ns: 463614812
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2572.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42348 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035620.144|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2571932.788|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571932788, Backend time ns: 463820234
2023-05-08T18:29:34,306 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571932788, Backend time ns: 463820234
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2571.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42342 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035793.514|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2571879.795|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571879795, Backend time ns: 464065257
2023-05-08T18:29:34,306 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571879795, Backend time ns: 464065257
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2571.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42400 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035873.879|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,306 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2571759.119|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571759119, Backend time ns: 464264648
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571759119, Backend time ns: 464264648
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2571.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42384 "POST /predictions/benchmark HTTP/1.0" 200 3037
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3035985.625|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2571671.764|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571671764, Backend time ns: 464504712
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571671764, Backend time ns: 464504712
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2571.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42412 "POST /predictions/benchmark HTTP/1.0" 200 3037
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036187.147|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2571615.601|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571615601, Backend time ns: 464708283
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571615601, Backend time ns: 464708283
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2571.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42408 "POST /predictions/benchmark HTTP/1.0" 200 3037
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036238.269|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2571459.672|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571459672, Backend time ns: 464912495
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571459672, Backend time ns: 464912495
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2571.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42422 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036374.446|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2571415.069|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571415069, Backend time ns: 465106435
2023-05-08T18:29:34,307 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2571415069, Backend time ns: 465106435
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2571.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41798 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,307 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036112.272|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2570952.494|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570952494, Backend time ns: 465295336
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570952494, Backend time ns: 465295336
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2570.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41820 "POST /predictions/benchmark HTTP/1.0" 200 3037
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036085.35|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2570735.131|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570735131, Backend time ns: 465479226
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570735131, Backend time ns: 465479226
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2570.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:41834 "POST /predictions/benchmark HTTP/1.0" 200 3037
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036228.208|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2570690.619|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570690619, Backend time ns: 465679417
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570690619, Backend time ns: 465679417
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2570.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42082 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036062.369|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2570334.529|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570334529, Backend time ns: 465900150
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570334529, Backend time ns: 465900150
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2570.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42104 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036095.151|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2570147.579|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570147579, Backend time ns: 466070629
2023-05-08T18:29:34,308 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570147579, Backend time ns: 466070629
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2570.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42094 "POST /predictions/benchmark HTTP/1.0" 200 3036
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036247.939|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,308 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2570125.307|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570125307, Backend time ns: 466243219
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2570125307, Backend time ns: 466243219
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2570.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42346 "POST /predictions/benchmark HTTP/1.0" 200 3037
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036142.653|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2569852.762|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2569852762, Backend time ns: 466442330
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2569852762, Backend time ns: 466442330
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2569.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42374 "POST /predictions/benchmark HTTP/1.0" 200 3037
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036228.619|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2569721.745|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2569721745, Backend time ns: 466633081
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2569721745, Backend time ns: 466633081
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2569.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:42360 "POST /predictions/benchmark HTTP/1.0" 200 3037
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3036358.715|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2569675.062|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2569675062, Backend time ns: 466818561
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2569675062, Backend time ns: 466818561
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2569.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:34,309 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 456
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 456
2023-05-08T18:29:34,309 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:11.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:34,322 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570574
2023-05-08T18:29:36,322 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570576322
2023-05-08T18:29:36,322 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570576322
2023-05-08T18:29:36,322 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570576
2023-05-08T18:29:36,323 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,323 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,323 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([1, 50])
2023-05-08T18:29:36,324 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:36,324 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 1 micro-batches
2023-05-08T18:29:36,327 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:36,347 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:36,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:36,380 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:76.97|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570576,1b66651a-9972-43dc-86ae-0418970ea9bb, pattern=[METRICS]
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:76.97|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570576,1b66651a-9972-43dc-86ae-0418970ea9bb, pattern=[METRICS]
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:76.97|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:1b66651a-9972-43dc-86ae-0418970ea9bb,timestamp:1683570576
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:77.06|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570576,1b66651a-9972-43dc-86ae-0418970ea9bb, pattern=[METRICS]
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:77.06|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570576,1b66651a-9972-43dc-86ae-0418970ea9bb, pattern=[METRICS]
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:77.06|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:1b66651a-9972-43dc-86ae-0418970ea9bb,timestamp:1683570576
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 2078
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2078270.116|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2000180.437|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,400 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2000180437, Backend time ns: 78401786
2023-05-08T18:29:36,400 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2000180437, Backend time ns: 78401786
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2000.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,400 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:36,400 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 78
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 78
2023-05-08T18:29:36,400 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,403 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,403 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,403 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,403 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,403 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,403 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,404 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,405 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570576406
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570576406
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,406 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,407 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,408 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,408 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,408 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,408 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,408 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,408 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,408 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,408 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,409 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,410 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570576
2023-05-08T18:29:36,410 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,410 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,412 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,413 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,414 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,416 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,417 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,418 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,418 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,418 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:36,419 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:36,419 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:36,425 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:36,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:36,484 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:36,491 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:36,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:36,527 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:36,529 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:36,561 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:36,567 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:36,568 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:36,570 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:36,599 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:36,606 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:36,607 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:36,610 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:36,638 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:36,644 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:36,648 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:36,650 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:36,677 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:36,683 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:36,688 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:36,690 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:36,715 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:36,728 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:36,730 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:36,753 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:36,769 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:36,771 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:36,809 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:36,811 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:36,853 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:36,948 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:36,948 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:537.78|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570576,77d6ead4-427b-4af4-bd89-8d9ed0c0c250,8c316cf8-7dbe-4719-8840-3fa05bec35d4,9d847d3f-2d33-4b70-98a1-91b33fedca0c,91d0d130-02a5-41db-88e7-fa296bab82c3,f84d1bd6-5976-4ccd-a63e-d2de2f4b693b,774621fc-f7c0-4199-b81b-1891c587b822,30e042bc-4fc0-49a4-a633-2e56952270bd,9b6d724e-b131-40d7-8f09-8d6d25377111,1932e2e3-d152-43d1-b674-2c8d7272524c,02474443-ce8c-46ee-ac05-f8857f79d882,04ec6c5a-c1a7-4ddb-90da-0d272c11ffe2,5f032a72-5432-4c2f-8678-2808c1cf5cfd,b25ef565-dbae-4322-b73d-3c08e2adc242,52ee9321-82b3-421d-bcca-5448b44c7199,3e157b6a-0185-4e37-901a-2c9137490e98,780b5d8d-7da2-40cc-888d-3d6f60d8cee3,209bf017-84d2-4613-9738-000d943867cc,0a268d0e-fdf3-4668-bfb1-289b285bd78c,99e264fb-9643-4174-a4aa-380cda5a1d8a,dec247b8-fa98-4df0-b98e-3e785f685920,f9fc3786-da62-495b-ad8d-98656429c06a,e5a1bdf3-9881-4c81-b4f2-f31fe01febd0,b0d508c7-2e77-4651-a4fa-a1176f87f6a6,090109bb-21b1-4d85-949e-4b221de3e939,48913c8f-c95a-4f30-9075-1aa3ce185eb3,27eb1e10-10de-4a14-8845-b5f230683cdb,b2157309-7d24-4e9e-8fb0-2b3f5b9a7660,08a76727-6c4b-46b9-a4b5-95a58fb42225,fc5c051b-cd04-4a5a-be00-81c32de0cd69,f360ff62-d507-4546-8151-85637c6cea4f,ec215674-ce6d-41cb-b2c5-6839f600bb25,95fa5b28-6bea-4b06-a7fb-6d04f6b8a0a1,d7430300-0e24-474b-93ff-ad0a7cdf80ef,f49840a6-0dd4-4722-a0de-e43961b726a4,e484e599-083a-4daf-ab27-5129b2df680d,95316d1b-1a3d-46af-96c7-90ccbb54bbca,5e3f6c9e-22ef-4cea-92c9-e929de6065a7,1731cc4a-badf-4254-95e0-909ba27fb5f3,edbf2c84-af98-4376-89dc-d6f2c23e1678,01c6539e-f497-47ce-a4e1-7fbd45030b6e,ff97653e-1d56-4fec-afd9-4aaa91c3ac23,2f43af04-31ad-4ab8-b85f-5107eb0e6a87,e680ce61-2862-438a-b503-dd4013bf71d1,9fa26bf6-e1a4-462d-a4b8-7e4acb3fcede,4661b8a0-e902-40f1-8417-28f3d3624390,b393f092-c6bf-43d3-ae7b-1d6d121bc471,8303ef76-4c58-41de-831e-ee38767bc6bd,e35dc37f-6d6a-480b-ab9b-c4c536c89f2b,2769c02a-6f74-433f-8c54-2242e7dcad8c,d2457ab3-1419-40c5-a3ec-51bffbe603f3,24a67080-fd83-4b75-a0aa-cb2044d0f408,4fdd1c31-790f-4ab0-a578-1ea0696e9929,e4b16a66-e3c6-44db-a20f-456d3d26d928,a5810003-46c6-4d24-957b-ccb6c815270f,c6b4536e-0457-4628-b5eb-e405eff01b54,a7e0a771-0e64-43f9-b660-97551ce07825, pattern=[METRICS]
2023-05-08T18:29:36,948 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:537.78|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570576,77d6ead4-427b-4af4-bd89-8d9ed0c0c250,8c316cf8-7dbe-4719-8840-3fa05bec35d4,9d847d3f-2d33-4b70-98a1-91b33fedca0c,91d0d130-02a5-41db-88e7-fa296bab82c3,f84d1bd6-5976-4ccd-a63e-d2de2f4b693b,774621fc-f7c0-4199-b81b-1891c587b822,30e042bc-4fc0-49a4-a633-2e56952270bd,9b6d724e-b131-40d7-8f09-8d6d25377111,1932e2e3-d152-43d1-b674-2c8d7272524c,02474443-ce8c-46ee-ac05-f8857f79d882,04ec6c5a-c1a7-4ddb-90da-0d272c11ffe2,5f032a72-5432-4c2f-8678-2808c1cf5cfd,b25ef565-dbae-4322-b73d-3c08e2adc242,52ee9321-82b3-421d-bcca-5448b44c7199,3e157b6a-0185-4e37-901a-2c9137490e98,780b5d8d-7da2-40cc-888d-3d6f60d8cee3,209bf017-84d2-4613-9738-000d943867cc,0a268d0e-fdf3-4668-bfb1-289b285bd78c,99e264fb-9643-4174-a4aa-380cda5a1d8a,dec247b8-fa98-4df0-b98e-3e785f685920,f9fc3786-da62-495b-ad8d-98656429c06a,e5a1bdf3-9881-4c81-b4f2-f31fe01febd0,b0d508c7-2e77-4651-a4fa-a1176f87f6a6,090109bb-21b1-4d85-949e-4b221de3e939,48913c8f-c95a-4f30-9075-1aa3ce185eb3,27eb1e10-10de-4a14-8845-b5f230683cdb,b2157309-7d24-4e9e-8fb0-2b3f5b9a7660,08a76727-6c4b-46b9-a4b5-95a58fb42225,fc5c051b-cd04-4a5a-be00-81c32de0cd69,f360ff62-d507-4546-8151-85637c6cea4f,ec215674-ce6d-41cb-b2c5-6839f600bb25,95fa5b28-6bea-4b06-a7fb-6d04f6b8a0a1,d7430300-0e24-474b-93ff-ad0a7cdf80ef,f49840a6-0dd4-4722-a0de-e43961b726a4,e484e599-083a-4daf-ab27-5129b2df680d,95316d1b-1a3d-46af-96c7-90ccbb54bbca,5e3f6c9e-22ef-4cea-92c9-e929de6065a7,1731cc4a-badf-4254-95e0-909ba27fb5f3,edbf2c84-af98-4376-89dc-d6f2c23e1678,01c6539e-f497-47ce-a4e1-7fbd45030b6e,ff97653e-1d56-4fec-afd9-4aaa91c3ac23,2f43af04-31ad-4ab8-b85f-5107eb0e6a87,e680ce61-2862-438a-b503-dd4013bf71d1,9fa26bf6-e1a4-462d-a4b8-7e4acb3fcede,4661b8a0-e902-40f1-8417-28f3d3624390,b393f092-c6bf-43d3-ae7b-1d6d121bc471,8303ef76-4c58-41de-831e-ee38767bc6bd,e35dc37f-6d6a-480b-ab9b-c4c536c89f2b,2769c02a-6f74-433f-8c54-2242e7dcad8c,d2457ab3-1419-40c5-a3ec-51bffbe603f3,24a67080-fd83-4b75-a0aa-cb2044d0f408,4fdd1c31-790f-4ab0-a578-1ea0696e9929,e4b16a66-e3c6-44db-a20f-456d3d26d928,a5810003-46c6-4d24-957b-ccb6c815270f,c6b4536e-0457-4628-b5eb-e405eff01b54,a7e0a771-0e64-43f9-b660-97551ce07825, pattern=[METRICS]
2023-05-08T18:29:36,949 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:537.78|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:77d6ead4-427b-4af4-bd89-8d9ed0c0c250,8c316cf8-7dbe-4719-8840-3fa05bec35d4,9d847d3f-2d33-4b70-98a1-91b33fedca0c,91d0d130-02a5-41db-88e7-fa296bab82c3,f84d1bd6-5976-4ccd-a63e-d2de2f4b693b,774621fc-f7c0-4199-b81b-1891c587b822,30e042bc-4fc0-49a4-a633-2e56952270bd,9b6d724e-b131-40d7-8f09-8d6d25377111,1932e2e3-d152-43d1-b674-2c8d7272524c,02474443-ce8c-46ee-ac05-f8857f79d882,04ec6c5a-c1a7-4ddb-90da-0d272c11ffe2,5f032a72-5432-4c2f-8678-2808c1cf5cfd,b25ef565-dbae-4322-b73d-3c08e2adc242,52ee9321-82b3-421d-bcca-5448b44c7199,3e157b6a-0185-4e37-901a-2c9137490e98,780b5d8d-7da2-40cc-888d-3d6f60d8cee3,209bf017-84d2-4613-9738-000d943867cc,0a268d0e-fdf3-4668-bfb1-289b285bd78c,99e264fb-9643-4174-a4aa-380cda5a1d8a,dec247b8-fa98-4df0-b98e-3e785f685920,f9fc3786-da62-495b-ad8d-98656429c06a,e5a1bdf3-9881-4c81-b4f2-f31fe01febd0,b0d508c7-2e77-4651-a4fa-a1176f87f6a6,090109bb-21b1-4d85-949e-4b221de3e939,48913c8f-c95a-4f30-9075-1aa3ce185eb3,27eb1e10-10de-4a14-8845-b5f230683cdb,b2157309-7d24-4e9e-8fb0-2b3f5b9a7660,08a76727-6c4b-46b9-a4b5-95a58fb42225,fc5c051b-cd04-4a5a-be00-81c32de0cd69,f360ff62-d507-4546-8151-85637c6cea4f,ec215674-ce6d-41cb-b2c5-6839f600bb25,95fa5b28-6bea-4b06-a7fb-6d04f6b8a0a1,d7430300-0e24-474b-93ff-ad0a7cdf80ef,f49840a6-0dd4-4722-a0de-e43961b726a4,e484e599-083a-4daf-ab27-5129b2df680d,95316d1b-1a3d-46af-96c7-90ccbb54bbca,5e3f6c9e-22ef-4cea-92c9-e929de6065a7,1731cc4a-badf-4254-95e0-909ba27fb5f3,edbf2c84-af98-4376-89dc-d6f2c23e1678,01c6539e-f497-47ce-a4e1-7fbd45030b6e,ff97653e-1d56-4fec-afd9-4aaa91c3ac23,2f43af04-31ad-4ab8-b85f-5107eb0e6a87,e680ce61-2862-438a-b503-dd4013bf71d1,9fa26bf6-e1a4-462d-a4b8-7e4acb3fcede,4661b8a0-e902-40f1-8417-28f3d3624390,b393f092-c6bf-43d3-ae7b-1d6d121bc471,8303ef76-4c58-41de-831e-ee38767bc6bd,e35dc37f-6d6a-480b-ab9b-c4c536c89f2b,2769c02a-6f74-433f-8c54-2242e7dcad8c,d2457ab3-1419-40c5-a3ec-51bffbe603f3,24a67080-fd83-4b75-a0aa-cb2044d0f408,4fdd1c31-790f-4ab0-a578-1ea0696e9929,e4b16a66-e3c6-44db-a20f-456d3d26d928,a5810003-46c6-4d24-957b-ccb6c815270f,c6b4536e-0457-4628-b5eb-e405eff01b54,a7e0a771-0e64-43f9-b660-97551ce07825,timestamp:1683570576
2023-05-08T18:29:36,949 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.87|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570576,77d6ead4-427b-4af4-bd89-8d9ed0c0c250,8c316cf8-7dbe-4719-8840-3fa05bec35d4,9d847d3f-2d33-4b70-98a1-91b33fedca0c,91d0d130-02a5-41db-88e7-fa296bab82c3,f84d1bd6-5976-4ccd-a63e-d2de2f4b693b,774621fc-f7c0-4199-b81b-1891c587b822,30e042bc-4fc0-49a4-a633-2e56952270bd,9b6d724e-b131-40d7-8f09-8d6d25377111,1932e2e3-d152-43d1-b674-2c8d7272524c,02474443-ce8c-46ee-ac05-f8857f79d882,04ec6c5a-c1a7-4ddb-90da-0d272c11ffe2,5f032a72-5432-4c2f-8678-2808c1cf5cfd,b25ef565-dbae-4322-b73d-3c08e2adc242,52ee9321-82b3-421d-bcca-5448b44c7199,3e157b6a-0185-4e37-901a-2c9137490e98,780b5d8d-7da2-40cc-888d-3d6f60d8cee3,209bf017-84d2-4613-9738-000d943867cc,0a268d0e-fdf3-4668-bfb1-289b285bd78c,99e264fb-9643-4174-a4aa-380cda5a1d8a,dec247b8-fa98-4df0-b98e-3e785f685920,f9fc3786-da62-495b-ad8d-98656429c06a,e5a1bdf3-9881-4c81-b4f2-f31fe01febd0,b0d508c7-2e77-4651-a4fa-a1176f87f6a6,090109bb-21b1-4d85-949e-4b221de3e939,48913c8f-c95a-4f30-9075-1aa3ce185eb3,27eb1e10-10de-4a14-8845-b5f230683cdb,b2157309-7d24-4e9e-8fb0-2b3f5b9a7660,08a76727-6c4b-46b9-a4b5-95a58fb42225,fc5c051b-cd04-4a5a-be00-81c32de0cd69,f360ff62-d507-4546-8151-85637c6cea4f,ec215674-ce6d-41cb-b2c5-6839f600bb25,95fa5b28-6bea-4b06-a7fb-6d04f6b8a0a1,d7430300-0e24-474b-93ff-ad0a7cdf80ef,f49840a6-0dd4-4722-a0de-e43961b726a4,e484e599-083a-4daf-ab27-5129b2df680d,95316d1b-1a3d-46af-96c7-90ccbb54bbca,5e3f6c9e-22ef-4cea-92c9-e929de6065a7,1731cc4a-badf-4254-95e0-909ba27fb5f3,edbf2c84-af98-4376-89dc-d6f2c23e1678,01c6539e-f497-47ce-a4e1-7fbd45030b6e,ff97653e-1d56-4fec-afd9-4aaa91c3ac23,2f43af04-31ad-4ab8-b85f-5107eb0e6a87,e680ce61-2862-438a-b503-dd4013bf71d1,9fa26bf6-e1a4-462d-a4b8-7e4acb3fcede,4661b8a0-e902-40f1-8417-28f3d3624390,b393f092-c6bf-43d3-ae7b-1d6d121bc471,8303ef76-4c58-41de-831e-ee38767bc6bd,e35dc37f-6d6a-480b-ab9b-c4c536c89f2b,2769c02a-6f74-433f-8c54-2242e7dcad8c,d2457ab3-1419-40c5-a3ec-51bffbe603f3,24a67080-fd83-4b75-a0aa-cb2044d0f408,4fdd1c31-790f-4ab0-a578-1ea0696e9929,e4b16a66-e3c6-44db-a20f-456d3d26d928,a5810003-46c6-4d24-957b-ccb6c815270f,c6b4536e-0457-4628-b5eb-e405eff01b54,a7e0a771-0e64-43f9-b660-97551ce07825, pattern=[METRICS]
2023-05-08T18:29:36,949 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.87|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570576,77d6ead4-427b-4af4-bd89-8d9ed0c0c250,8c316cf8-7dbe-4719-8840-3fa05bec35d4,9d847d3f-2d33-4b70-98a1-91b33fedca0c,91d0d130-02a5-41db-88e7-fa296bab82c3,f84d1bd6-5976-4ccd-a63e-d2de2f4b693b,774621fc-f7c0-4199-b81b-1891c587b822,30e042bc-4fc0-49a4-a633-2e56952270bd,9b6d724e-b131-40d7-8f09-8d6d25377111,1932e2e3-d152-43d1-b674-2c8d7272524c,02474443-ce8c-46ee-ac05-f8857f79d882,04ec6c5a-c1a7-4ddb-90da-0d272c11ffe2,5f032a72-5432-4c2f-8678-2808c1cf5cfd,b25ef565-dbae-4322-b73d-3c08e2adc242,52ee9321-82b3-421d-bcca-5448b44c7199,3e157b6a-0185-4e37-901a-2c9137490e98,780b5d8d-7da2-40cc-888d-3d6f60d8cee3,209bf017-84d2-4613-9738-000d943867cc,0a268d0e-fdf3-4668-bfb1-289b285bd78c,99e264fb-9643-4174-a4aa-380cda5a1d8a,dec247b8-fa98-4df0-b98e-3e785f685920,f9fc3786-da62-495b-ad8d-98656429c06a,e5a1bdf3-9881-4c81-b4f2-f31fe01febd0,b0d508c7-2e77-4651-a4fa-a1176f87f6a6,090109bb-21b1-4d85-949e-4b221de3e939,48913c8f-c95a-4f30-9075-1aa3ce185eb3,27eb1e10-10de-4a14-8845-b5f230683cdb,b2157309-7d24-4e9e-8fb0-2b3f5b9a7660,08a76727-6c4b-46b9-a4b5-95a58fb42225,fc5c051b-cd04-4a5a-be00-81c32de0cd69,f360ff62-d507-4546-8151-85637c6cea4f,ec215674-ce6d-41cb-b2c5-6839f600bb25,95fa5b28-6bea-4b06-a7fb-6d04f6b8a0a1,d7430300-0e24-474b-93ff-ad0a7cdf80ef,f49840a6-0dd4-4722-a0de-e43961b726a4,e484e599-083a-4daf-ab27-5129b2df680d,95316d1b-1a3d-46af-96c7-90ccbb54bbca,5e3f6c9e-22ef-4cea-92c9-e929de6065a7,1731cc4a-badf-4254-95e0-909ba27fb5f3,edbf2c84-af98-4376-89dc-d6f2c23e1678,01c6539e-f497-47ce-a4e1-7fbd45030b6e,ff97653e-1d56-4fec-afd9-4aaa91c3ac23,2f43af04-31ad-4ab8-b85f-5107eb0e6a87,e680ce61-2862-438a-b503-dd4013bf71d1,9fa26bf6-e1a4-462d-a4b8-7e4acb3fcede,4661b8a0-e902-40f1-8417-28f3d3624390,b393f092-c6bf-43d3-ae7b-1d6d121bc471,8303ef76-4c58-41de-831e-ee38767bc6bd,e35dc37f-6d6a-480b-ab9b-c4c536c89f2b,2769c02a-6f74-433f-8c54-2242e7dcad8c,d2457ab3-1419-40c5-a3ec-51bffbe603f3,24a67080-fd83-4b75-a0aa-cb2044d0f408,4fdd1c31-790f-4ab0-a578-1ea0696e9929,e4b16a66-e3c6-44db-a20f-456d3d26d928,a5810003-46c6-4d24-957b-ccb6c815270f,c6b4536e-0457-4628-b5eb-e405eff01b54,a7e0a771-0e64-43f9-b660-97551ce07825, pattern=[METRICS]
2023-05-08T18:29:36,949 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:537.87|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:77d6ead4-427b-4af4-bd89-8d9ed0c0c250,8c316cf8-7dbe-4719-8840-3fa05bec35d4,9d847d3f-2d33-4b70-98a1-91b33fedca0c,91d0d130-02a5-41db-88e7-fa296bab82c3,f84d1bd6-5976-4ccd-a63e-d2de2f4b693b,774621fc-f7c0-4199-b81b-1891c587b822,30e042bc-4fc0-49a4-a633-2e56952270bd,9b6d724e-b131-40d7-8f09-8d6d25377111,1932e2e3-d152-43d1-b674-2c8d7272524c,02474443-ce8c-46ee-ac05-f8857f79d882,04ec6c5a-c1a7-4ddb-90da-0d272c11ffe2,5f032a72-5432-4c2f-8678-2808c1cf5cfd,b25ef565-dbae-4322-b73d-3c08e2adc242,52ee9321-82b3-421d-bcca-5448b44c7199,3e157b6a-0185-4e37-901a-2c9137490e98,780b5d8d-7da2-40cc-888d-3d6f60d8cee3,209bf017-84d2-4613-9738-000d943867cc,0a268d0e-fdf3-4668-bfb1-289b285bd78c,99e264fb-9643-4174-a4aa-380cda5a1d8a,dec247b8-fa98-4df0-b98e-3e785f685920,f9fc3786-da62-495b-ad8d-98656429c06a,e5a1bdf3-9881-4c81-b4f2-f31fe01febd0,b0d508c7-2e77-4651-a4fa-a1176f87f6a6,090109bb-21b1-4d85-949e-4b221de3e939,48913c8f-c95a-4f30-9075-1aa3ce185eb3,27eb1e10-10de-4a14-8845-b5f230683cdb,b2157309-7d24-4e9e-8fb0-2b3f5b9a7660,08a76727-6c4b-46b9-a4b5-95a58fb42225,fc5c051b-cd04-4a5a-be00-81c32de0cd69,f360ff62-d507-4546-8151-85637c6cea4f,ec215674-ce6d-41cb-b2c5-6839f600bb25,95fa5b28-6bea-4b06-a7fb-6d04f6b8a0a1,d7430300-0e24-474b-93ff-ad0a7cdf80ef,f49840a6-0dd4-4722-a0de-e43961b726a4,e484e599-083a-4daf-ab27-5129b2df680d,95316d1b-1a3d-46af-96c7-90ccbb54bbca,5e3f6c9e-22ef-4cea-92c9-e929de6065a7,1731cc4a-badf-4254-95e0-909ba27fb5f3,edbf2c84-af98-4376-89dc-d6f2c23e1678,01c6539e-f497-47ce-a4e1-7fbd45030b6e,ff97653e-1d56-4fec-afd9-4aaa91c3ac23,2f43af04-31ad-4ab8-b85f-5107eb0e6a87,e680ce61-2862-438a-b503-dd4013bf71d1,9fa26bf6-e1a4-462d-a4b8-7e4acb3fcede,4661b8a0-e902-40f1-8417-28f3d3624390,b393f092-c6bf-43d3-ae7b-1d6d121bc471,8303ef76-4c58-41de-831e-ee38767bc6bd,e35dc37f-6d6a-480b-ab9b-c4c536c89f2b,2769c02a-6f74-433f-8c54-2242e7dcad8c,d2457ab3-1419-40c5-a3ec-51bffbe603f3,24a67080-fd83-4b75-a0aa-cb2044d0f408,4fdd1c31-790f-4ab0-a578-1ea0696e9929,e4b16a66-e3c6-44db-a20f-456d3d26d928,a5810003-46c6-4d24-957b-ccb6c815270f,c6b4536e-0457-4628-b5eb-e405eff01b54,a7e0a771-0e64-43f9-b660-97551ce07825,timestamp:1683570576
2023-05-08T18:29:36,949 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 546
2023-05-08T18:29:36,949 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:546227.703|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2836.878|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2836878, Backend time ns: 544082114
2023-05-08T18:29:36,950 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2836878, Backend time ns: 544082114
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 547
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:546752.932|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2567.603|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2567603, Backend time ns: 544374560
2023-05-08T18:29:36,950 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2567603, Backend time ns: 544374560
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 547
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:546855.038|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2404.644|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,950 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2404644, Backend time ns: 544652475
2023-05-08T18:29:36,950 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2404644, Backend time ns: 544652475
2023-05-08T18:29:36,950 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 548
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:547117.593|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2351.881|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2351881, Backend time ns: 544975143
2023-05-08T18:29:36,951 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2351881, Backend time ns: 544975143
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 548
2023-05-08T18:29:36,951 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:547241.649|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2201.472|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2201472, Backend time ns: 545303782
2023-05-08T18:29:36,951 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2201472, Backend time ns: 545303782
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 548
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:547506.564|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2157.09|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2157090, Backend time ns: 545545195
2023-05-08T18:29:36,951 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2157090, Backend time ns: 545545195
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 548
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:547777.089|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2185.311|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2185311, Backend time ns: 545740806
2023-05-08T18:29:36,951 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2185311, Backend time ns: 545740806
2023-05-08T18:29:36,951 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,951 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 548
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:547874.325|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2067.295|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2067295, Backend time ns: 545975739
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2067295, Backend time ns: 545975739
2023-05-08T18:29:36,952 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:548152.78|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2114.507|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2114507, Backend time ns: 546168290
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2114507, Backend time ns: 546168290
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 548
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:548109.527|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1896.375|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1896375, Backend time ns: 546345030
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1896375, Backend time ns: 546345030
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 548
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:548263.186|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1876.264|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1876264, Backend time ns: 546536430
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1876264, Backend time ns: 546536430
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 548
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:548390.333|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1794.399|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1794399, Backend time ns: 546740652
2023-05-08T18:29:36,952 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1794399, Backend time ns: 546740652
2023-05-08T18:29:36,952 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:548528.4|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1741.326|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1741326, Backend time ns: 546934263
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1741326, Backend time ns: 546934263
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:548656.588|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1681.294|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1681294, Backend time ns: 547105731
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1681294, Backend time ns: 547105731
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:548869.509|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1704.695|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1704695, Backend time ns: 547326893
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1704695, Backend time ns: 547326893
2023-05-08T18:29:36,953 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549040.569|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1626.261|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1626261, Backend time ns: 547575907
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1626261, Backend time ns: 547575907
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549233.02|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1613.99|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1613990, Backend time ns: 547757527
2023-05-08T18:29:36,953 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1613990, Backend time ns: 547757527
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:36,954 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549456.692|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1656.422|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1656422, Backend time ns: 547995781
2023-05-08T18:29:36,954 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1656422, Backend time ns: 547995781
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549615.601|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1577.958|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1577958, Backend time ns: 548223863
2023-05-08T18:29:36,954 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1577958, Backend time ns: 548223863
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:36,954 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549765.67|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1497.434|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1497434, Backend time ns: 548420484
2023-05-08T18:29:36,954 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1497434, Backend time ns: 548420484
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:36,954 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549937.039|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1475.192|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1475192, Backend time ns: 548622806
2023-05-08T18:29:36,954 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1475192, Backend time ns: 548622806
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,954 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550074.326|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1407.788|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1407788, Backend time ns: 548816897
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1407788, Backend time ns: 548816897
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:36,955 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550164.022|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1302.493|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1302493, Backend time ns: 548991286
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1302493, Backend time ns: 548991286
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550284.969|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1252.31|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1252310, Backend time ns: 549188847
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1252310, Backend time ns: 549188847
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550470.078|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1231.418|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1231418, Backend time ns: 549408240
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1231418, Backend time ns: 549408240
2023-05-08T18:29:36,955 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:36,955 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550640.488|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1170.045|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1170045, Backend time ns: 549615301
2023-05-08T18:29:36,955 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1170045, Backend time ns: 549615301
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:36,955 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,955 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550813.958|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1144.314|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1144314, Backend time ns: 549860155
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1144314, Backend time ns: 549860155
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:551005.779|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1094.451|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1094451, Backend time ns: 550093148
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1094451, Backend time ns: 550093148
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:551224.791|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1083.48|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1083480, Backend time ns: 550280188
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1083480, Backend time ns: 550280188
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:551342.377|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1016.836|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1016836, Backend time ns: 550500871
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1016836, Backend time ns: 550500871
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:551588.591|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1041.148|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1041148, Backend time ns: 550705292
2023-05-08T18:29:36,956 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1041148, Backend time ns: 550705292
2023-05-08T18:29:36,956 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,956 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:551741.209|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:984.054|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 984054, Backend time ns: 550907993
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 984054, Backend time ns: 550907993
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:551904.718|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:956.763|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 956763, Backend time ns: 551119775
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 956763, Backend time ns: 551119775
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:36,957 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552099.909|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:924.721|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 924721, Backend time ns: 551317486
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 924721, Backend time ns: 551317486
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552307.06|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:948.022|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 948022, Backend time ns: 551529188
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 948022, Backend time ns: 551529188
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:36,957 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552453.519|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:882.429|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 882429, Backend time ns: 551716098
2023-05-08T18:29:36,957 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 882429, Backend time ns: 551716098
2023-05-08T18:29:36,957 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:36,958 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552574.526|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:810.625|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 810625, Backend time ns: 551957572
2023-05-08T18:29:36,958 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 810625, Backend time ns: 551957572
2023-05-08T18:29:36,958 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552764.856|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:723.62|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 723620, Backend time ns: 552338633
2023-05-08T18:29:36,958 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 723620, Backend time ns: 552338633
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553120.906|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:698.528|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 698528, Backend time ns: 552621099
2023-05-08T18:29:36,958 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 698528, Backend time ns: 552621099
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:36,958 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553379.05|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:676.078|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 676078, Backend time ns: 552831859
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 676078, Backend time ns: 552831859
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:36,959 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553528.429|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:655.587|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 655587, Backend time ns: 553038931
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 655587, Backend time ns: 553038931
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553682.327|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:602.654|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 602654, Backend time ns: 553271684
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 602654, Backend time ns: 553271684
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553889.298|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:574.752|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 574752, Backend time ns: 553471425
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 574752, Backend time ns: 553471425
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:36,959 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554047.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:528.17|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 528170, Backend time ns: 553674766
2023-05-08T18:29:36,959 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 528170, Backend time ns: 553674766
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,959 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554233.348|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:514.709|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 514709, Backend time ns: 553886768
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 514709, Backend time ns: 553886768
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554385.237|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:455.466|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 455466, Backend time ns: 554079349
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 455466, Backend time ns: 554079349
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554571.487|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:446.095|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 446095, Backend time ns: 554284050
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 446095, Backend time ns: 554284050
2023-05-08T18:29:36,960 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:36,960 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554775.258|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:421.184|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 421184, Backend time ns: 554510353
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 421184, Backend time ns: 554510353
2023-05-08T18:29:36,960 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554988.77|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:401.813|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 401813, Backend time ns: 554725565
2023-05-08T18:29:36,960 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 401813, Backend time ns: 554725565
2023-05-08T18:29:36,960 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555132.177|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:363.68|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 363680, Backend time ns: 554932487
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 363680, Backend time ns: 554932487
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555276.706|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:302.667|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 302667, Backend time ns: 555118067
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 302667, Backend time ns: 555118067
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:36,961 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555456.956|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:297.777|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 297777, Backend time ns: 555315578
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 297777, Backend time ns: 555315578
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555566.082|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:199.281|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 199281, Backend time ns: 555503608
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 199281, Backend time ns: 555503608
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555714.63|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:163.859|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 163859, Backend time ns: 555727231
2023-05-08T18:29:36,961 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 163859, Backend time ns: 555727231
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:36,962 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555939.013|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:154.019|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 154019, Backend time ns: 555986565
2023-05-08T18:29:36,962 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 154019, Backend time ns: 555986565
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556114.513|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:66.384|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 66384, Backend time ns: 556270701
2023-05-08T18:29:36,962 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 66384, Backend time ns: 556270701
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:36,962 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:14.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570576962
2023-05-08T18:29:36,962 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570576962
2023-05-08T18:29:36,962 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,962 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,963 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,963 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570576
2023-05-08T18:29:36,966 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570576
2023-05-08T18:29:36,966 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,966 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,966 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,966 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,966 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,966 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,968 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,970 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,971 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,972 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:36,973 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:36,974 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:36,975 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:36,975 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:36,982 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:37,017 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:37,038 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:37,044 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:37,076 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:37,081 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:37,083 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:37,115 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:37,121 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:37,122 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:37,123 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:37,154 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:37,161 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:37,161 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:37,163 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:37,193 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:37,200 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:37,202 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:37,204 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:37,232 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:37,238 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:37,242 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:37,244 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:37,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:37,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:37,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:37,308 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:37,322 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:37,325 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:37,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:37,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:37,407 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:37,502 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:37,502 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:535.89|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570577,7f056ebc-6eb6-4ed9-8cd6-39293d8ca94e,b84f302f-90f9-45ec-8591-070ba38244b8,43140f94-652a-480f-bf3a-d3b97c884759,9ab90822-d0b5-41c0-8fd6-20103325268d,ba221c9b-2e6f-44cb-8631-6ade50d80af5,6c60f9e6-77f8-4647-976a-52885dd9d496,b2818728-c56f-4e55-b0af-96d2098fe610,faf0fed1-999e-40d0-a99f-d7de120cbedc,01d5a063-31fe-4064-a7bf-948d636d93f5,fc3b5c38-79aa-4ab1-b88c-7e36c1f1bbfa,739f23c9-89d0-4306-9717-b23e314fbc79,27b5282f-028e-4427-baf9-961f40abdf14,24230fc6-d389-487c-b308-1597574f3fda,8057cf42-8d99-403a-ae6e-013141b96f09,c8d1dab0-ce76-4612-9d4c-e17c185db101,2b76aa43-8b65-447b-9748-e24015a7062d,1bc0cdd1-27fd-4fa3-8725-eae5eb396410,9408fda3-9bda-4508-b14f-bdeac41cf22a,8913cbc5-83b3-47e6-a96a-01909ad219c3,29c466e7-b6d9-4845-8fc4-7dc1aca853ab,b5da73c7-ab3e-45f3-840d-c5687f4cd12f,8dff823b-49f2-4495-b32a-f436a1c1bebd,8df3e8f0-616e-4581-9a42-f4498da49d86,30bd6563-a2c0-4f86-a91f-1b68fc6634e4,c3643d3f-956e-4be1-8c44-8481c42f3754,89d9ede3-0b26-49be-920e-0eb11b88f0d1,f19509d9-d8cf-4d50-872b-ea5f39a8e12c,519d88bc-69c5-476b-8e99-bd85ddf509b7,9fad3516-2142-4f0d-a6db-1e1bf5cd6e56,0fdd37f0-a83f-4df2-9b59-0e3db91e7aa8,10da3613-a47f-49e0-bb06-ef27e8a7e813,08b5b220-0b68-4586-bc9c-14b9c44c0e4a,71147971-9e54-4ac7-b1b5-c9eb6bf5313c,020783e8-26dd-4ef4-8d74-f0f8c0483f6e,30a5751d-a3cd-4dea-9780-009a73076a0d,6d19d455-e548-4337-823a-f6e34b9d751f,cf9ecb3a-1e53-4086-8de7-4077f0a5c205,fa1f7eae-5753-4dd3-aefb-f88d9b2e0e1f,fb11ebb3-17e7-4cd0-b3c7-4910cf0395af,b6c84208-6e08-4235-a9aa-9141cab2f4e7,33858bbb-9684-4204-b4c1-d96b7e3eeb94,b2e4b115-cd53-4e53-8f37-7d4f7d56e5a0,89ca5c84-8c2f-4293-b7d7-c943ecc3d444,82316724-b7c3-4343-bed3-341ad188b3fd,6284d42a-c7bf-4e0f-8473-9fa1035449e1,a17476f1-6e81-401a-8920-31adeac283c3,35d292ab-3fa9-4745-b983-3bdd358249f7,8e1386c5-2e3f-46c6-b1e9-d0a932ea312a,300ba110-7bdf-47ec-9f9e-963f92a997f3,7da08c4d-3437-43e9-b8b6-2a97876f44aa,3d8c3a80-0a17-425d-a156-40202fd20406,aa7e6f26-1cfa-4f19-bf39-d8f78e0537e7,58e2eba5-38b9-49e0-8eea-bbf17d3a32e3,c21cc01d-3cf6-4a4c-97d1-8a3edcffe07b,f5f1b65b-1d6e-444b-acac-d252d02f3b26,e1db52b8-602a-4341-bba7-5c8fe8be22cb, pattern=[METRICS]
2023-05-08T18:29:37,502 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:535.89|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570577,7f056ebc-6eb6-4ed9-8cd6-39293d8ca94e,b84f302f-90f9-45ec-8591-070ba38244b8,43140f94-652a-480f-bf3a-d3b97c884759,9ab90822-d0b5-41c0-8fd6-20103325268d,ba221c9b-2e6f-44cb-8631-6ade50d80af5,6c60f9e6-77f8-4647-976a-52885dd9d496,b2818728-c56f-4e55-b0af-96d2098fe610,faf0fed1-999e-40d0-a99f-d7de120cbedc,01d5a063-31fe-4064-a7bf-948d636d93f5,fc3b5c38-79aa-4ab1-b88c-7e36c1f1bbfa,739f23c9-89d0-4306-9717-b23e314fbc79,27b5282f-028e-4427-baf9-961f40abdf14,24230fc6-d389-487c-b308-1597574f3fda,8057cf42-8d99-403a-ae6e-013141b96f09,c8d1dab0-ce76-4612-9d4c-e17c185db101,2b76aa43-8b65-447b-9748-e24015a7062d,1bc0cdd1-27fd-4fa3-8725-eae5eb396410,9408fda3-9bda-4508-b14f-bdeac41cf22a,8913cbc5-83b3-47e6-a96a-01909ad219c3,29c466e7-b6d9-4845-8fc4-7dc1aca853ab,b5da73c7-ab3e-45f3-840d-c5687f4cd12f,8dff823b-49f2-4495-b32a-f436a1c1bebd,8df3e8f0-616e-4581-9a42-f4498da49d86,30bd6563-a2c0-4f86-a91f-1b68fc6634e4,c3643d3f-956e-4be1-8c44-8481c42f3754,89d9ede3-0b26-49be-920e-0eb11b88f0d1,f19509d9-d8cf-4d50-872b-ea5f39a8e12c,519d88bc-69c5-476b-8e99-bd85ddf509b7,9fad3516-2142-4f0d-a6db-1e1bf5cd6e56,0fdd37f0-a83f-4df2-9b59-0e3db91e7aa8,10da3613-a47f-49e0-bb06-ef27e8a7e813,08b5b220-0b68-4586-bc9c-14b9c44c0e4a,71147971-9e54-4ac7-b1b5-c9eb6bf5313c,020783e8-26dd-4ef4-8d74-f0f8c0483f6e,30a5751d-a3cd-4dea-9780-009a73076a0d,6d19d455-e548-4337-823a-f6e34b9d751f,cf9ecb3a-1e53-4086-8de7-4077f0a5c205,fa1f7eae-5753-4dd3-aefb-f88d9b2e0e1f,fb11ebb3-17e7-4cd0-b3c7-4910cf0395af,b6c84208-6e08-4235-a9aa-9141cab2f4e7,33858bbb-9684-4204-b4c1-d96b7e3eeb94,b2e4b115-cd53-4e53-8f37-7d4f7d56e5a0,89ca5c84-8c2f-4293-b7d7-c943ecc3d444,82316724-b7c3-4343-bed3-341ad188b3fd,6284d42a-c7bf-4e0f-8473-9fa1035449e1,a17476f1-6e81-401a-8920-31adeac283c3,35d292ab-3fa9-4745-b983-3bdd358249f7,8e1386c5-2e3f-46c6-b1e9-d0a932ea312a,300ba110-7bdf-47ec-9f9e-963f92a997f3,7da08c4d-3437-43e9-b8b6-2a97876f44aa,3d8c3a80-0a17-425d-a156-40202fd20406,aa7e6f26-1cfa-4f19-bf39-d8f78e0537e7,58e2eba5-38b9-49e0-8eea-bbf17d3a32e3,c21cc01d-3cf6-4a4c-97d1-8a3edcffe07b,f5f1b65b-1d6e-444b-acac-d252d02f3b26,e1db52b8-602a-4341-bba7-5c8fe8be22cb, pattern=[METRICS]
2023-05-08T18:29:37,502 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:535.89|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:7f056ebc-6eb6-4ed9-8cd6-39293d8ca94e,b84f302f-90f9-45ec-8591-070ba38244b8,43140f94-652a-480f-bf3a-d3b97c884759,9ab90822-d0b5-41c0-8fd6-20103325268d,ba221c9b-2e6f-44cb-8631-6ade50d80af5,6c60f9e6-77f8-4647-976a-52885dd9d496,b2818728-c56f-4e55-b0af-96d2098fe610,faf0fed1-999e-40d0-a99f-d7de120cbedc,01d5a063-31fe-4064-a7bf-948d636d93f5,fc3b5c38-79aa-4ab1-b88c-7e36c1f1bbfa,739f23c9-89d0-4306-9717-b23e314fbc79,27b5282f-028e-4427-baf9-961f40abdf14,24230fc6-d389-487c-b308-1597574f3fda,8057cf42-8d99-403a-ae6e-013141b96f09,c8d1dab0-ce76-4612-9d4c-e17c185db101,2b76aa43-8b65-447b-9748-e24015a7062d,1bc0cdd1-27fd-4fa3-8725-eae5eb396410,9408fda3-9bda-4508-b14f-bdeac41cf22a,8913cbc5-83b3-47e6-a96a-01909ad219c3,29c466e7-b6d9-4845-8fc4-7dc1aca853ab,b5da73c7-ab3e-45f3-840d-c5687f4cd12f,8dff823b-49f2-4495-b32a-f436a1c1bebd,8df3e8f0-616e-4581-9a42-f4498da49d86,30bd6563-a2c0-4f86-a91f-1b68fc6634e4,c3643d3f-956e-4be1-8c44-8481c42f3754,89d9ede3-0b26-49be-920e-0eb11b88f0d1,f19509d9-d8cf-4d50-872b-ea5f39a8e12c,519d88bc-69c5-476b-8e99-bd85ddf509b7,9fad3516-2142-4f0d-a6db-1e1bf5cd6e56,0fdd37f0-a83f-4df2-9b59-0e3db91e7aa8,10da3613-a47f-49e0-bb06-ef27e8a7e813,08b5b220-0b68-4586-bc9c-14b9c44c0e4a,71147971-9e54-4ac7-b1b5-c9eb6bf5313c,020783e8-26dd-4ef4-8d74-f0f8c0483f6e,30a5751d-a3cd-4dea-9780-009a73076a0d,6d19d455-e548-4337-823a-f6e34b9d751f,cf9ecb3a-1e53-4086-8de7-4077f0a5c205,fa1f7eae-5753-4dd3-aefb-f88d9b2e0e1f,fb11ebb3-17e7-4cd0-b3c7-4910cf0395af,b6c84208-6e08-4235-a9aa-9141cab2f4e7,33858bbb-9684-4204-b4c1-d96b7e3eeb94,b2e4b115-cd53-4e53-8f37-7d4f7d56e5a0,89ca5c84-8c2f-4293-b7d7-c943ecc3d444,82316724-b7c3-4343-bed3-341ad188b3fd,6284d42a-c7bf-4e0f-8473-9fa1035449e1,a17476f1-6e81-401a-8920-31adeac283c3,35d292ab-3fa9-4745-b983-3bdd358249f7,8e1386c5-2e3f-46c6-b1e9-d0a932ea312a,300ba110-7bdf-47ec-9f9e-963f92a997f3,7da08c4d-3437-43e9-b8b6-2a97876f44aa,3d8c3a80-0a17-425d-a156-40202fd20406,aa7e6f26-1cfa-4f19-bf39-d8f78e0537e7,58e2eba5-38b9-49e0-8eea-bbf17d3a32e3,c21cc01d-3cf6-4a4c-97d1-8a3edcffe07b,f5f1b65b-1d6e-444b-acac-d252d02f3b26,e1db52b8-602a-4341-bba7-5c8fe8be22cb,timestamp:1683570577
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:536.0|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570577,7f056ebc-6eb6-4ed9-8cd6-39293d8ca94e,b84f302f-90f9-45ec-8591-070ba38244b8,43140f94-652a-480f-bf3a-d3b97c884759,9ab90822-d0b5-41c0-8fd6-20103325268d,ba221c9b-2e6f-44cb-8631-6ade50d80af5,6c60f9e6-77f8-4647-976a-52885dd9d496,b2818728-c56f-4e55-b0af-96d2098fe610,faf0fed1-999e-40d0-a99f-d7de120cbedc,01d5a063-31fe-4064-a7bf-948d636d93f5,fc3b5c38-79aa-4ab1-b88c-7e36c1f1bbfa,739f23c9-89d0-4306-9717-b23e314fbc79,27b5282f-028e-4427-baf9-961f40abdf14,24230fc6-d389-487c-b308-1597574f3fda,8057cf42-8d99-403a-ae6e-013141b96f09,c8d1dab0-ce76-4612-9d4c-e17c185db101,2b76aa43-8b65-447b-9748-e24015a7062d,1bc0cdd1-27fd-4fa3-8725-eae5eb396410,9408fda3-9bda-4508-b14f-bdeac41cf22a,8913cbc5-83b3-47e6-a96a-01909ad219c3,29c466e7-b6d9-4845-8fc4-7dc1aca853ab,b5da73c7-ab3e-45f3-840d-c5687f4cd12f,8dff823b-49f2-4495-b32a-f436a1c1bebd,8df3e8f0-616e-4581-9a42-f4498da49d86,30bd6563-a2c0-4f86-a91f-1b68fc6634e4,c3643d3f-956e-4be1-8c44-8481c42f3754,89d9ede3-0b26-49be-920e-0eb11b88f0d1,f19509d9-d8cf-4d50-872b-ea5f39a8e12c,519d88bc-69c5-476b-8e99-bd85ddf509b7,9fad3516-2142-4f0d-a6db-1e1bf5cd6e56,0fdd37f0-a83f-4df2-9b59-0e3db91e7aa8,10da3613-a47f-49e0-bb06-ef27e8a7e813,08b5b220-0b68-4586-bc9c-14b9c44c0e4a,71147971-9e54-4ac7-b1b5-c9eb6bf5313c,020783e8-26dd-4ef4-8d74-f0f8c0483f6e,30a5751d-a3cd-4dea-9780-009a73076a0d,6d19d455-e548-4337-823a-f6e34b9d751f,cf9ecb3a-1e53-4086-8de7-4077f0a5c205,fa1f7eae-5753-4dd3-aefb-f88d9b2e0e1f,fb11ebb3-17e7-4cd0-b3c7-4910cf0395af,b6c84208-6e08-4235-a9aa-9141cab2f4e7,33858bbb-9684-4204-b4c1-d96b7e3eeb94,b2e4b115-cd53-4e53-8f37-7d4f7d56e5a0,89ca5c84-8c2f-4293-b7d7-c943ecc3d444,82316724-b7c3-4343-bed3-341ad188b3fd,6284d42a-c7bf-4e0f-8473-9fa1035449e1,a17476f1-6e81-401a-8920-31adeac283c3,35d292ab-3fa9-4745-b983-3bdd358249f7,8e1386c5-2e3f-46c6-b1e9-d0a932ea312a,300ba110-7bdf-47ec-9f9e-963f92a997f3,7da08c4d-3437-43e9-b8b6-2a97876f44aa,3d8c3a80-0a17-425d-a156-40202fd20406,aa7e6f26-1cfa-4f19-bf39-d8f78e0537e7,58e2eba5-38b9-49e0-8eea-bbf17d3a32e3,c21cc01d-3cf6-4a4c-97d1-8a3edcffe07b,f5f1b65b-1d6e-444b-acac-d252d02f3b26,e1db52b8-602a-4341-bba7-5c8fe8be22cb, pattern=[METRICS]
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:536.0|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570577,7f056ebc-6eb6-4ed9-8cd6-39293d8ca94e,b84f302f-90f9-45ec-8591-070ba38244b8,43140f94-652a-480f-bf3a-d3b97c884759,9ab90822-d0b5-41c0-8fd6-20103325268d,ba221c9b-2e6f-44cb-8631-6ade50d80af5,6c60f9e6-77f8-4647-976a-52885dd9d496,b2818728-c56f-4e55-b0af-96d2098fe610,faf0fed1-999e-40d0-a99f-d7de120cbedc,01d5a063-31fe-4064-a7bf-948d636d93f5,fc3b5c38-79aa-4ab1-b88c-7e36c1f1bbfa,739f23c9-89d0-4306-9717-b23e314fbc79,27b5282f-028e-4427-baf9-961f40abdf14,24230fc6-d389-487c-b308-1597574f3fda,8057cf42-8d99-403a-ae6e-013141b96f09,c8d1dab0-ce76-4612-9d4c-e17c185db101,2b76aa43-8b65-447b-9748-e24015a7062d,1bc0cdd1-27fd-4fa3-8725-eae5eb396410,9408fda3-9bda-4508-b14f-bdeac41cf22a,8913cbc5-83b3-47e6-a96a-01909ad219c3,29c466e7-b6d9-4845-8fc4-7dc1aca853ab,b5da73c7-ab3e-45f3-840d-c5687f4cd12f,8dff823b-49f2-4495-b32a-f436a1c1bebd,8df3e8f0-616e-4581-9a42-f4498da49d86,30bd6563-a2c0-4f86-a91f-1b68fc6634e4,c3643d3f-956e-4be1-8c44-8481c42f3754,89d9ede3-0b26-49be-920e-0eb11b88f0d1,f19509d9-d8cf-4d50-872b-ea5f39a8e12c,519d88bc-69c5-476b-8e99-bd85ddf509b7,9fad3516-2142-4f0d-a6db-1e1bf5cd6e56,0fdd37f0-a83f-4df2-9b59-0e3db91e7aa8,10da3613-a47f-49e0-bb06-ef27e8a7e813,08b5b220-0b68-4586-bc9c-14b9c44c0e4a,71147971-9e54-4ac7-b1b5-c9eb6bf5313c,020783e8-26dd-4ef4-8d74-f0f8c0483f6e,30a5751d-a3cd-4dea-9780-009a73076a0d,6d19d455-e548-4337-823a-f6e34b9d751f,cf9ecb3a-1e53-4086-8de7-4077f0a5c205,fa1f7eae-5753-4dd3-aefb-f88d9b2e0e1f,fb11ebb3-17e7-4cd0-b3c7-4910cf0395af,b6c84208-6e08-4235-a9aa-9141cab2f4e7,33858bbb-9684-4204-b4c1-d96b7e3eeb94,b2e4b115-cd53-4e53-8f37-7d4f7d56e5a0,89ca5c84-8c2f-4293-b7d7-c943ecc3d444,82316724-b7c3-4343-bed3-341ad188b3fd,6284d42a-c7bf-4e0f-8473-9fa1035449e1,a17476f1-6e81-401a-8920-31adeac283c3,35d292ab-3fa9-4745-b983-3bdd358249f7,8e1386c5-2e3f-46c6-b1e9-d0a932ea312a,300ba110-7bdf-47ec-9f9e-963f92a997f3,7da08c4d-3437-43e9-b8b6-2a97876f44aa,3d8c3a80-0a17-425d-a156-40202fd20406,aa7e6f26-1cfa-4f19-bf39-d8f78e0537e7,58e2eba5-38b9-49e0-8eea-bbf17d3a32e3,c21cc01d-3cf6-4a4c-97d1-8a3edcffe07b,f5f1b65b-1d6e-444b-acac-d252d02f3b26,e1db52b8-602a-4341-bba7-5c8fe8be22cb, pattern=[METRICS]
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:536.0|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:7f056ebc-6eb6-4ed9-8cd6-39293d8ca94e,b84f302f-90f9-45ec-8591-070ba38244b8,43140f94-652a-480f-bf3a-d3b97c884759,9ab90822-d0b5-41c0-8fd6-20103325268d,ba221c9b-2e6f-44cb-8631-6ade50d80af5,6c60f9e6-77f8-4647-976a-52885dd9d496,b2818728-c56f-4e55-b0af-96d2098fe610,faf0fed1-999e-40d0-a99f-d7de120cbedc,01d5a063-31fe-4064-a7bf-948d636d93f5,fc3b5c38-79aa-4ab1-b88c-7e36c1f1bbfa,739f23c9-89d0-4306-9717-b23e314fbc79,27b5282f-028e-4427-baf9-961f40abdf14,24230fc6-d389-487c-b308-1597574f3fda,8057cf42-8d99-403a-ae6e-013141b96f09,c8d1dab0-ce76-4612-9d4c-e17c185db101,2b76aa43-8b65-447b-9748-e24015a7062d,1bc0cdd1-27fd-4fa3-8725-eae5eb396410,9408fda3-9bda-4508-b14f-bdeac41cf22a,8913cbc5-83b3-47e6-a96a-01909ad219c3,29c466e7-b6d9-4845-8fc4-7dc1aca853ab,b5da73c7-ab3e-45f3-840d-c5687f4cd12f,8dff823b-49f2-4495-b32a-f436a1c1bebd,8df3e8f0-616e-4581-9a42-f4498da49d86,30bd6563-a2c0-4f86-a91f-1b68fc6634e4,c3643d3f-956e-4be1-8c44-8481c42f3754,89d9ede3-0b26-49be-920e-0eb11b88f0d1,f19509d9-d8cf-4d50-872b-ea5f39a8e12c,519d88bc-69c5-476b-8e99-bd85ddf509b7,9fad3516-2142-4f0d-a6db-1e1bf5cd6e56,0fdd37f0-a83f-4df2-9b59-0e3db91e7aa8,10da3613-a47f-49e0-bb06-ef27e8a7e813,08b5b220-0b68-4586-bc9c-14b9c44c0e4a,71147971-9e54-4ac7-b1b5-c9eb6bf5313c,020783e8-26dd-4ef4-8d74-f0f8c0483f6e,30a5751d-a3cd-4dea-9780-009a73076a0d,6d19d455-e548-4337-823a-f6e34b9d751f,cf9ecb3a-1e53-4086-8de7-4077f0a5c205,fa1f7eae-5753-4dd3-aefb-f88d9b2e0e1f,fb11ebb3-17e7-4cd0-b3c7-4910cf0395af,b6c84208-6e08-4235-a9aa-9141cab2f4e7,33858bbb-9684-4204-b4c1-d96b7e3eeb94,b2e4b115-cd53-4e53-8f37-7d4f7d56e5a0,89ca5c84-8c2f-4293-b7d7-c943ecc3d444,82316724-b7c3-4343-bed3-341ad188b3fd,6284d42a-c7bf-4e0f-8473-9fa1035449e1,a17476f1-6e81-401a-8920-31adeac283c3,35d292ab-3fa9-4745-b983-3bdd358249f7,8e1386c5-2e3f-46c6-b1e9-d0a932ea312a,300ba110-7bdf-47ec-9f9e-963f92a997f3,7da08c4d-3437-43e9-b8b6-2a97876f44aa,3d8c3a80-0a17-425d-a156-40202fd20406,aa7e6f26-1cfa-4f19-bf39-d8f78e0537e7,58e2eba5-38b9-49e0-8eea-bbf17d3a32e3,c21cc01d-3cf6-4a4c-97d1-8a3edcffe07b,f5f1b65b-1d6e-444b-acac-d252d02f3b26,e1db52b8-602a-4341-bba7-5c8fe8be22cb,timestamp:1683570577
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097081.113|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556529.756|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,503 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556529756, Backend time ns: 540891006
2023-05-08T18:29:37,503 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556529756, Backend time ns: 540891006
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097430.602|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556480.643|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,503 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556480643, Backend time ns: 541101518
2023-05-08T18:29:37,503 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556480643, Backend time ns: 541101518
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,503 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097454.084|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556318.214|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556318214, Backend time ns: 541251916
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556318214, Backend time ns: 541251916
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097520.497|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556233.259|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556233259, Backend time ns: 541397614
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556233259, Backend time ns: 541397614
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097655.425|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556216.218|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556216218, Backend time ns: 541553503
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556216218, Backend time ns: 541553503
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097790.932|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556203.107|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556203107, Backend time ns: 541703081
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556203107, Backend time ns: 541703081
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097833.514|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556094.471|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556094471, Backend time ns: 541856690
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556094471, Backend time ns: 541856690
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097940.631|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556049.279|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556049279, Backend time ns: 542146056
2023-05-08T18:29:37,504 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556049279, Backend time ns: 542146056
2023-05-08T18:29:37,504 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,504 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098428.577|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556012.006|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556012006, Backend time ns: 542552469
2023-05-08T18:29:37,505 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556012006, Backend time ns: 542552469
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098536.904|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555926.982|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555926982, Backend time ns: 542794562
2023-05-08T18:29:37,505 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555926982, Backend time ns: 542794562
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098722.504|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555877.299|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555877299, Backend time ns: 543064807
2023-05-08T18:29:37,505 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555877299, Backend time ns: 543064807
2023-05-08T18:29:37,505 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,505 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098863.132|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555741.941|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555741941, Backend time ns: 543302651
2023-05-08T18:29:37,506 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555741941, Backend time ns: 543302651
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098943.996|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555572.852|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555572852, Backend time ns: 543573306
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555572852, Backend time ns: 543573306
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099039.602|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555424.595|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555424595, Backend time ns: 543763615
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555424595, Backend time ns: 543763615
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099194.86|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555395.123|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555395123, Backend time ns: 543927864
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555395123, Backend time ns: 543927864
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099254.423|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555291.217|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555291217, Backend time ns: 544095144
2023-05-08T18:29:37,506 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555291217, Backend time ns: 544095144
2023-05-08T18:29:37,506 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099333.738|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555203.142|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555203142, Backend time ns: 544304255
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555203142, Backend time ns: 544304255
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099501.478|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555156.06|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555156060, Backend time ns: 544500286
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555156060, Backend time ns: 544500286
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,507 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099659.326|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555122.358|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555122358, Backend time ns: 544700428
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555122358, Backend time ns: 544700428
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099834.846|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555097.346|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555097346, Backend time ns: 544861707
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555097346, Backend time ns: 544861707
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099799.564|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554900.395|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554900395, Backend time ns: 545029636
2023-05-08T18:29:37,507 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554900395, Backend time ns: 545029636
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,507 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,507 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099950.902|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554877.884|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554877884, Backend time ns: 545216536
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554877884, Backend time ns: 545216536
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099964.733|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554711.105|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554711105, Backend time ns: 545386566
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554711105, Backend time ns: 545386566
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100015.906|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554588.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554588548, Backend time ns: 545543335
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554588548, Backend time ns: 545543335
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100145.023|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554567.086|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554567086, Backend time ns: 545700313
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554567086, Backend time ns: 545700313
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,508 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100263.659|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554527.654|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554527654, Backend time ns: 545858182
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554527654, Backend time ns: 545858182
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100292.891|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554395.947|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554395947, Backend time ns: 546027422
2023-05-08T18:29:37,508 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554395947, Backend time ns: 546027422
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,508 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100431.619|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554368.085|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554368085, Backend time ns: 546202441
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554368085, Backend time ns: 546202441
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 1101
2023-05-08T18:29:37,509 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100200.856|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553962.363|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553962363, Backend time ns: 546374781
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553962363, Backend time ns: 546374781
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 1101
2023-05-08T18:29:37,509 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100363.955|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553952.582|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553952582, Backend time ns: 546562622
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553952582, Backend time ns: 546562622
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100279.401|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553677.587|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553677587, Backend time ns: 546721740
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553677587, Backend time ns: 546721740
2023-05-08T18:29:37,509 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100420.158|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553648.045|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553648045, Backend time ns: 546889150
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553648045, Backend time ns: 546889150
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100453.89|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553521.208|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553521208, Backend time ns: 547077390
2023-05-08T18:29:37,509 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553521208, Backend time ns: 547077390
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,509 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:37,509 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100536.215|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553423.283|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553423283, Backend time ns: 547229949
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553423283, Backend time ns: 547229949
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 1101
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100648.161|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553383.481|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553383481, Backend time ns: 547404918
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553383481, Backend time ns: 547404918
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 1101
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100777.068|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553331.678|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553331678, Backend time ns: 547601139
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553331678, Backend time ns: 547601139
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 1101
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100915.316|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553277.785|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553277785, Backend time ns: 547756427
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553277785, Backend time ns: 547756427
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 1101
2023-05-08T18:29:37,510 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1101040.563|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553223.252|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553223252, Backend time ns: 547957469
2023-05-08T18:29:37,510 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553223252, Backend time ns: 547957469
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 1101
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1101119.157|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,510 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553117.956|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553117956, Backend time ns: 548148989
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553117956, Backend time ns: 548148989
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 1102
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1101291.047|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553103.435|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553103435, Backend time ns: 548329499
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553103435, Backend time ns: 548329499
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 1102
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1101430.435|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553059.893|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553059893, Backend time ns: 548548852
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553059893, Backend time ns: 548548852
2023-05-08T18:29:37,511 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 1102
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1101633.976|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552970.458|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552970458, Backend time ns: 548852599
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552970458, Backend time ns: 548852599
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 1102
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1101830.366|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552928.565|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552928565, Backend time ns: 549034919
2023-05-08T18:29:37,511 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552928565, Backend time ns: 549034919
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,511 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 1102
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1101955.184|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552880.063|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552880063, Backend time ns: 549215189
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552880063, Backend time ns: 549215189
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560779.942|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:11523.991|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 11523991, Backend time ns: 549416650
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 11523991, Backend time ns: 549416650
2023-05-08T18:29:37,512 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:11.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560975.772|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:11482.948|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 11482948, Backend time ns: 549675845
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 11482948, Backend time ns: 549675845
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:11.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560875.057|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:11150.14|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 11150140, Backend time ns: 549847564
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 11150140, Backend time ns: 549847564
2023-05-08T18:29:37,512 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:11.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560859.146|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:10947.118|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10947118, Backend time ns: 550023704
2023-05-08T18:29:37,512 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10947118, Backend time ns: 550023704
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,512 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,512 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560891.128|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:10829.072|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10829072, Backend time ns: 550201844
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10829072, Backend time ns: 550201844
2023-05-08T18:29:37,513 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 562
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560986.643|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:10691.114|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10691114, Backend time ns: 550417186
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10691114, Backend time ns: 550417186
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:561095.819|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:10639.431|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10639431, Backend time ns: 550593146
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10639431, Backend time ns: 550593146
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,513 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:561000.744|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:10367.506|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10367506, Backend time ns: 550761105
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10367506, Backend time ns: 550761105
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560955.621|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:10153.704|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10153704, Backend time ns: 550916434
2023-05-08T18:29:37,513 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 10153704, Backend time ns: 550916434
2023-05-08T18:29:37,513 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:10.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560942.111|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,513 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9965.034|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9965034, Backend time ns: 551108775
2023-05-08T18:29:37,514 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9965034, Backend time ns: 551108775
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 562
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560941.511|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9771.863|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9771863, Backend time ns: 551290205
2023-05-08T18:29:37,514 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9771863, Backend time ns: 551290205
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 561
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:560683.486|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9347.149|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9347149, Backend time ns: 551475655
2023-05-08T18:29:37,514 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9347149, Backend time ns: 551475655
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:37,514 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 540
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 540
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:12.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570577
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570577514
2023-05-08T18:29:37,514 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570577514
2023-05-08T18:29:37,517 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570577
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,520 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,521 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,522 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,523 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,524 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:37,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:37,526 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:37,526 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:37,532 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:37,569 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:37,590 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:37,596 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:37,628 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:37,632 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:37,634 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:37,666 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:37,672 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:37,672 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:37,674 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:37,704 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:37,711 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:37,713 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:37,715 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:37,743 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:37,750 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:37,753 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:37,755 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:37,781 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:37,788 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:37,793 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:37,795 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:37,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:37,833 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:37,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:37,858 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:37,874 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:37,876 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:37,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:37,916 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:37,958 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:38,052 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:534.51|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570578,817fc4c2-2a10-424d-980b-3267f9ae1cc5,f3ca505e-7e38-43ca-916e-f32d8c0f4da7,aae21f3d-a87c-481c-aab7-752ef0f5538a,a39487b6-8ac5-42b3-b185-18eae49da3b1,f6b39564-49cb-4b3b-be0f-b16e9b42ace8,f1e30fd0-e35d-4636-abc5-a86f858bb598,7625c24c-d76b-4341-9105-13aad5e7a607,7b4967f6-ea09-4466-9d23-981174f42f4a,2bc9bf4d-88d3-400f-9fdf-9f19a9c77cbd,e697d99a-e749-4944-9b45-2856b27c5b8c,cff3b20e-367b-430a-b993-b2b335087bcf,bf8da02e-e634-46c7-a05e-350eb431374c,5f697c7c-f2c8-4cda-acc1-fcccb1832947,5c6e2876-0fe1-4456-beda-65f18228a70d,9ab96299-08c8-49b2-ba64-5e118d3cef68,48add526-6ef2-4517-b16b-2e160d33d2f5,5b0b3ec8-8e2a-4db2-acf4-98b1a9ffaa58,9fff5632-73c4-4389-9825-60cc9a24babf,e03a6015-f6fe-46bc-81c9-4c3cc61ca337,2672ffcd-f3fb-437a-8403-6c0ac90b09fe,277b219d-ac2f-445b-ba81-021774b68870,e111f68a-e4f0-4954-98b9-58bcb6ab2882,af56e1ce-4ac1-4222-bc5c-5489adc66df5,03b49bfc-a068-495e-93cd-e92298e1cfe6,89aa4227-df88-45b1-bad9-d90e4b39838f,62b8d95c-c53d-45d5-b0df-34e551b2fe7a,f8ad2abc-76f5-492b-8ab3-77fc6f25d5eb,ad213d55-7249-4e76-bc2c-644bdc4ae25d,56b0391c-896b-435e-943d-57b6c8db502a,0a6a237f-9ea0-488b-be66-6ff5ee618f0d,1ded3a44-aa4b-4d63-87b2-4d516fa9b157,bdbe3bab-9749-49cf-b32f-c77a14a6e5b7,8b4165b6-9a76-47bc-9f87-1d14c0144054,04d38f27-663f-4c9a-8973-0a569cc4417a,a75dcf06-7cc0-4372-9bbd-2d48c6fa8fb5,b77c7548-7e9a-4ff6-bddc-262001928edf,2cbac340-0a77-46f4-9337-acac5dfe7917,9e97f63f-0bf7-4513-bfe9-d34a7dffcbd2,d94a6532-4f25-4864-bbd3-6509012a694b,7f8b7692-d29e-4873-a409-e4dd871c34ff,5bffd418-703c-4462-9de0-e16ff0c9d567,b6ed02ea-1b80-46bc-906c-9648a21511cb,e3bc8095-7d22-414e-9a64-1b0ffddbcbc5,432b60cf-9373-4600-bf70-1cf042dc2d07,178d34aa-e3b9-489d-9d92-58df448fbc04,222fc646-b623-469c-b85a-05df28c2e9b0,4be3f25a-baf6-4695-ad86-59b5d7773a62,c21d10cb-f781-483e-bc6d-1b73cf8b1b29,17aba007-4d69-498b-b0af-e7d4b7d6c940,0df8dbd7-bf92-476e-a410-a98bd1f141e0,ecd055f9-1459-47fc-a465-df9007751354,57e903ca-f316-49d6-9de1-de955a96b4bc,0183f756-d324-41d8-bef5-bf5fd251330a,14118bff-82b1-483a-970e-d08d89f75046,7680aebe-f22d-434f-a6ea-eae7befa6286,1a9ae285-a63f-45ad-b2a2-e5ed8a9cfe1e, pattern=[METRICS]
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:534.51|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570578,817fc4c2-2a10-424d-980b-3267f9ae1cc5,f3ca505e-7e38-43ca-916e-f32d8c0f4da7,aae21f3d-a87c-481c-aab7-752ef0f5538a,a39487b6-8ac5-42b3-b185-18eae49da3b1,f6b39564-49cb-4b3b-be0f-b16e9b42ace8,f1e30fd0-e35d-4636-abc5-a86f858bb598,7625c24c-d76b-4341-9105-13aad5e7a607,7b4967f6-ea09-4466-9d23-981174f42f4a,2bc9bf4d-88d3-400f-9fdf-9f19a9c77cbd,e697d99a-e749-4944-9b45-2856b27c5b8c,cff3b20e-367b-430a-b993-b2b335087bcf,bf8da02e-e634-46c7-a05e-350eb431374c,5f697c7c-f2c8-4cda-acc1-fcccb1832947,5c6e2876-0fe1-4456-beda-65f18228a70d,9ab96299-08c8-49b2-ba64-5e118d3cef68,48add526-6ef2-4517-b16b-2e160d33d2f5,5b0b3ec8-8e2a-4db2-acf4-98b1a9ffaa58,9fff5632-73c4-4389-9825-60cc9a24babf,e03a6015-f6fe-46bc-81c9-4c3cc61ca337,2672ffcd-f3fb-437a-8403-6c0ac90b09fe,277b219d-ac2f-445b-ba81-021774b68870,e111f68a-e4f0-4954-98b9-58bcb6ab2882,af56e1ce-4ac1-4222-bc5c-5489adc66df5,03b49bfc-a068-495e-93cd-e92298e1cfe6,89aa4227-df88-45b1-bad9-d90e4b39838f,62b8d95c-c53d-45d5-b0df-34e551b2fe7a,f8ad2abc-76f5-492b-8ab3-77fc6f25d5eb,ad213d55-7249-4e76-bc2c-644bdc4ae25d,56b0391c-896b-435e-943d-57b6c8db502a,0a6a237f-9ea0-488b-be66-6ff5ee618f0d,1ded3a44-aa4b-4d63-87b2-4d516fa9b157,bdbe3bab-9749-49cf-b32f-c77a14a6e5b7,8b4165b6-9a76-47bc-9f87-1d14c0144054,04d38f27-663f-4c9a-8973-0a569cc4417a,a75dcf06-7cc0-4372-9bbd-2d48c6fa8fb5,b77c7548-7e9a-4ff6-bddc-262001928edf,2cbac340-0a77-46f4-9337-acac5dfe7917,9e97f63f-0bf7-4513-bfe9-d34a7dffcbd2,d94a6532-4f25-4864-bbd3-6509012a694b,7f8b7692-d29e-4873-a409-e4dd871c34ff,5bffd418-703c-4462-9de0-e16ff0c9d567,b6ed02ea-1b80-46bc-906c-9648a21511cb,e3bc8095-7d22-414e-9a64-1b0ffddbcbc5,432b60cf-9373-4600-bf70-1cf042dc2d07,178d34aa-e3b9-489d-9d92-58df448fbc04,222fc646-b623-469c-b85a-05df28c2e9b0,4be3f25a-baf6-4695-ad86-59b5d7773a62,c21d10cb-f781-483e-bc6d-1b73cf8b1b29,17aba007-4d69-498b-b0af-e7d4b7d6c940,0df8dbd7-bf92-476e-a410-a98bd1f141e0,ecd055f9-1459-47fc-a465-df9007751354,57e903ca-f316-49d6-9de1-de955a96b4bc,0183f756-d324-41d8-bef5-bf5fd251330a,14118bff-82b1-483a-970e-d08d89f75046,7680aebe-f22d-434f-a6ea-eae7befa6286,1a9ae285-a63f-45ad-b2a2-e5ed8a9cfe1e, pattern=[METRICS]
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:534.51|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:817fc4c2-2a10-424d-980b-3267f9ae1cc5,f3ca505e-7e38-43ca-916e-f32d8c0f4da7,aae21f3d-a87c-481c-aab7-752ef0f5538a,a39487b6-8ac5-42b3-b185-18eae49da3b1,f6b39564-49cb-4b3b-be0f-b16e9b42ace8,f1e30fd0-e35d-4636-abc5-a86f858bb598,7625c24c-d76b-4341-9105-13aad5e7a607,7b4967f6-ea09-4466-9d23-981174f42f4a,2bc9bf4d-88d3-400f-9fdf-9f19a9c77cbd,e697d99a-e749-4944-9b45-2856b27c5b8c,cff3b20e-367b-430a-b993-b2b335087bcf,bf8da02e-e634-46c7-a05e-350eb431374c,5f697c7c-f2c8-4cda-acc1-fcccb1832947,5c6e2876-0fe1-4456-beda-65f18228a70d,9ab96299-08c8-49b2-ba64-5e118d3cef68,48add526-6ef2-4517-b16b-2e160d33d2f5,5b0b3ec8-8e2a-4db2-acf4-98b1a9ffaa58,9fff5632-73c4-4389-9825-60cc9a24babf,e03a6015-f6fe-46bc-81c9-4c3cc61ca337,2672ffcd-f3fb-437a-8403-6c0ac90b09fe,277b219d-ac2f-445b-ba81-021774b68870,e111f68a-e4f0-4954-98b9-58bcb6ab2882,af56e1ce-4ac1-4222-bc5c-5489adc66df5,03b49bfc-a068-495e-93cd-e92298e1cfe6,89aa4227-df88-45b1-bad9-d90e4b39838f,62b8d95c-c53d-45d5-b0df-34e551b2fe7a,f8ad2abc-76f5-492b-8ab3-77fc6f25d5eb,ad213d55-7249-4e76-bc2c-644bdc4ae25d,56b0391c-896b-435e-943d-57b6c8db502a,0a6a237f-9ea0-488b-be66-6ff5ee618f0d,1ded3a44-aa4b-4d63-87b2-4d516fa9b157,bdbe3bab-9749-49cf-b32f-c77a14a6e5b7,8b4165b6-9a76-47bc-9f87-1d14c0144054,04d38f27-663f-4c9a-8973-0a569cc4417a,a75dcf06-7cc0-4372-9bbd-2d48c6fa8fb5,b77c7548-7e9a-4ff6-bddc-262001928edf,2cbac340-0a77-46f4-9337-acac5dfe7917,9e97f63f-0bf7-4513-bfe9-d34a7dffcbd2,d94a6532-4f25-4864-bbd3-6509012a694b,7f8b7692-d29e-4873-a409-e4dd871c34ff,5bffd418-703c-4462-9de0-e16ff0c9d567,b6ed02ea-1b80-46bc-906c-9648a21511cb,e3bc8095-7d22-414e-9a64-1b0ffddbcbc5,432b60cf-9373-4600-bf70-1cf042dc2d07,178d34aa-e3b9-489d-9d92-58df448fbc04,222fc646-b623-469c-b85a-05df28c2e9b0,4be3f25a-baf6-4695-ad86-59b5d7773a62,c21d10cb-f781-483e-bc6d-1b73cf8b1b29,17aba007-4d69-498b-b0af-e7d4b7d6c940,0df8dbd7-bf92-476e-a410-a98bd1f141e0,ecd055f9-1459-47fc-a465-df9007751354,57e903ca-f316-49d6-9de1-de955a96b4bc,0183f756-d324-41d8-bef5-bf5fd251330a,14118bff-82b1-483a-970e-d08d89f75046,7680aebe-f22d-434f-a6ea-eae7befa6286,1a9ae285-a63f-45ad-b2a2-e5ed8a9cfe1e,timestamp:1683570578
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:534.59|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570578,817fc4c2-2a10-424d-980b-3267f9ae1cc5,f3ca505e-7e38-43ca-916e-f32d8c0f4da7,aae21f3d-a87c-481c-aab7-752ef0f5538a,a39487b6-8ac5-42b3-b185-18eae49da3b1,f6b39564-49cb-4b3b-be0f-b16e9b42ace8,f1e30fd0-e35d-4636-abc5-a86f858bb598,7625c24c-d76b-4341-9105-13aad5e7a607,7b4967f6-ea09-4466-9d23-981174f42f4a,2bc9bf4d-88d3-400f-9fdf-9f19a9c77cbd,e697d99a-e749-4944-9b45-2856b27c5b8c,cff3b20e-367b-430a-b993-b2b335087bcf,bf8da02e-e634-46c7-a05e-350eb431374c,5f697c7c-f2c8-4cda-acc1-fcccb1832947,5c6e2876-0fe1-4456-beda-65f18228a70d,9ab96299-08c8-49b2-ba64-5e118d3cef68,48add526-6ef2-4517-b16b-2e160d33d2f5,5b0b3ec8-8e2a-4db2-acf4-98b1a9ffaa58,9fff5632-73c4-4389-9825-60cc9a24babf,e03a6015-f6fe-46bc-81c9-4c3cc61ca337,2672ffcd-f3fb-437a-8403-6c0ac90b09fe,277b219d-ac2f-445b-ba81-021774b68870,e111f68a-e4f0-4954-98b9-58bcb6ab2882,af56e1ce-4ac1-4222-bc5c-5489adc66df5,03b49bfc-a068-495e-93cd-e92298e1cfe6,89aa4227-df88-45b1-bad9-d90e4b39838f,62b8d95c-c53d-45d5-b0df-34e551b2fe7a,f8ad2abc-76f5-492b-8ab3-77fc6f25d5eb,ad213d55-7249-4e76-bc2c-644bdc4ae25d,56b0391c-896b-435e-943d-57b6c8db502a,0a6a237f-9ea0-488b-be66-6ff5ee618f0d,1ded3a44-aa4b-4d63-87b2-4d516fa9b157,bdbe3bab-9749-49cf-b32f-c77a14a6e5b7,8b4165b6-9a76-47bc-9f87-1d14c0144054,04d38f27-663f-4c9a-8973-0a569cc4417a,a75dcf06-7cc0-4372-9bbd-2d48c6fa8fb5,b77c7548-7e9a-4ff6-bddc-262001928edf,2cbac340-0a77-46f4-9337-acac5dfe7917,9e97f63f-0bf7-4513-bfe9-d34a7dffcbd2,d94a6532-4f25-4864-bbd3-6509012a694b,7f8b7692-d29e-4873-a409-e4dd871c34ff,5bffd418-703c-4462-9de0-e16ff0c9d567,b6ed02ea-1b80-46bc-906c-9648a21511cb,e3bc8095-7d22-414e-9a64-1b0ffddbcbc5,432b60cf-9373-4600-bf70-1cf042dc2d07,178d34aa-e3b9-489d-9d92-58df448fbc04,222fc646-b623-469c-b85a-05df28c2e9b0,4be3f25a-baf6-4695-ad86-59b5d7773a62,c21d10cb-f781-483e-bc6d-1b73cf8b1b29,17aba007-4d69-498b-b0af-e7d4b7d6c940,0df8dbd7-bf92-476e-a410-a98bd1f141e0,ecd055f9-1459-47fc-a465-df9007751354,57e903ca-f316-49d6-9de1-de955a96b4bc,0183f756-d324-41d8-bef5-bf5fd251330a,14118bff-82b1-483a-970e-d08d89f75046,7680aebe-f22d-434f-a6ea-eae7befa6286,1a9ae285-a63f-45ad-b2a2-e5ed8a9cfe1e, pattern=[METRICS]
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:534.59|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570578,817fc4c2-2a10-424d-980b-3267f9ae1cc5,f3ca505e-7e38-43ca-916e-f32d8c0f4da7,aae21f3d-a87c-481c-aab7-752ef0f5538a,a39487b6-8ac5-42b3-b185-18eae49da3b1,f6b39564-49cb-4b3b-be0f-b16e9b42ace8,f1e30fd0-e35d-4636-abc5-a86f858bb598,7625c24c-d76b-4341-9105-13aad5e7a607,7b4967f6-ea09-4466-9d23-981174f42f4a,2bc9bf4d-88d3-400f-9fdf-9f19a9c77cbd,e697d99a-e749-4944-9b45-2856b27c5b8c,cff3b20e-367b-430a-b993-b2b335087bcf,bf8da02e-e634-46c7-a05e-350eb431374c,5f697c7c-f2c8-4cda-acc1-fcccb1832947,5c6e2876-0fe1-4456-beda-65f18228a70d,9ab96299-08c8-49b2-ba64-5e118d3cef68,48add526-6ef2-4517-b16b-2e160d33d2f5,5b0b3ec8-8e2a-4db2-acf4-98b1a9ffaa58,9fff5632-73c4-4389-9825-60cc9a24babf,e03a6015-f6fe-46bc-81c9-4c3cc61ca337,2672ffcd-f3fb-437a-8403-6c0ac90b09fe,277b219d-ac2f-445b-ba81-021774b68870,e111f68a-e4f0-4954-98b9-58bcb6ab2882,af56e1ce-4ac1-4222-bc5c-5489adc66df5,03b49bfc-a068-495e-93cd-e92298e1cfe6,89aa4227-df88-45b1-bad9-d90e4b39838f,62b8d95c-c53d-45d5-b0df-34e551b2fe7a,f8ad2abc-76f5-492b-8ab3-77fc6f25d5eb,ad213d55-7249-4e76-bc2c-644bdc4ae25d,56b0391c-896b-435e-943d-57b6c8db502a,0a6a237f-9ea0-488b-be66-6ff5ee618f0d,1ded3a44-aa4b-4d63-87b2-4d516fa9b157,bdbe3bab-9749-49cf-b32f-c77a14a6e5b7,8b4165b6-9a76-47bc-9f87-1d14c0144054,04d38f27-663f-4c9a-8973-0a569cc4417a,a75dcf06-7cc0-4372-9bbd-2d48c6fa8fb5,b77c7548-7e9a-4ff6-bddc-262001928edf,2cbac340-0a77-46f4-9337-acac5dfe7917,9e97f63f-0bf7-4513-bfe9-d34a7dffcbd2,d94a6532-4f25-4864-bbd3-6509012a694b,7f8b7692-d29e-4873-a409-e4dd871c34ff,5bffd418-703c-4462-9de0-e16ff0c9d567,b6ed02ea-1b80-46bc-906c-9648a21511cb,e3bc8095-7d22-414e-9a64-1b0ffddbcbc5,432b60cf-9373-4600-bf70-1cf042dc2d07,178d34aa-e3b9-489d-9d92-58df448fbc04,222fc646-b623-469c-b85a-05df28c2e9b0,4be3f25a-baf6-4695-ad86-59b5d7773a62,c21d10cb-f781-483e-bc6d-1b73cf8b1b29,17aba007-4d69-498b-b0af-e7d4b7d6c940,0df8dbd7-bf92-476e-a410-a98bd1f141e0,ecd055f9-1459-47fc-a465-df9007751354,57e903ca-f316-49d6-9de1-de955a96b4bc,0183f756-d324-41d8-bef5-bf5fd251330a,14118bff-82b1-483a-970e-d08d89f75046,7680aebe-f22d-434f-a6ea-eae7befa6286,1a9ae285-a63f-45ad-b2a2-e5ed8a9cfe1e, pattern=[METRICS]
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:534.59|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:817fc4c2-2a10-424d-980b-3267f9ae1cc5,f3ca505e-7e38-43ca-916e-f32d8c0f4da7,aae21f3d-a87c-481c-aab7-752ef0f5538a,a39487b6-8ac5-42b3-b185-18eae49da3b1,f6b39564-49cb-4b3b-be0f-b16e9b42ace8,f1e30fd0-e35d-4636-abc5-a86f858bb598,7625c24c-d76b-4341-9105-13aad5e7a607,7b4967f6-ea09-4466-9d23-981174f42f4a,2bc9bf4d-88d3-400f-9fdf-9f19a9c77cbd,e697d99a-e749-4944-9b45-2856b27c5b8c,cff3b20e-367b-430a-b993-b2b335087bcf,bf8da02e-e634-46c7-a05e-350eb431374c,5f697c7c-f2c8-4cda-acc1-fcccb1832947,5c6e2876-0fe1-4456-beda-65f18228a70d,9ab96299-08c8-49b2-ba64-5e118d3cef68,48add526-6ef2-4517-b16b-2e160d33d2f5,5b0b3ec8-8e2a-4db2-acf4-98b1a9ffaa58,9fff5632-73c4-4389-9825-60cc9a24babf,e03a6015-f6fe-46bc-81c9-4c3cc61ca337,2672ffcd-f3fb-437a-8403-6c0ac90b09fe,277b219d-ac2f-445b-ba81-021774b68870,e111f68a-e4f0-4954-98b9-58bcb6ab2882,af56e1ce-4ac1-4222-bc5c-5489adc66df5,03b49bfc-a068-495e-93cd-e92298e1cfe6,89aa4227-df88-45b1-bad9-d90e4b39838f,62b8d95c-c53d-45d5-b0df-34e551b2fe7a,f8ad2abc-76f5-492b-8ab3-77fc6f25d5eb,ad213d55-7249-4e76-bc2c-644bdc4ae25d,56b0391c-896b-435e-943d-57b6c8db502a,0a6a237f-9ea0-488b-be66-6ff5ee618f0d,1ded3a44-aa4b-4d63-87b2-4d516fa9b157,bdbe3bab-9749-49cf-b32f-c77a14a6e5b7,8b4165b6-9a76-47bc-9f87-1d14c0144054,04d38f27-663f-4c9a-8973-0a569cc4417a,a75dcf06-7cc0-4372-9bbd-2d48c6fa8fb5,b77c7548-7e9a-4ff6-bddc-262001928edf,2cbac340-0a77-46f4-9337-acac5dfe7917,9e97f63f-0bf7-4513-bfe9-d34a7dffcbd2,d94a6532-4f25-4864-bbd3-6509012a694b,7f8b7692-d29e-4873-a409-e4dd871c34ff,5bffd418-703c-4462-9de0-e16ff0c9d567,b6ed02ea-1b80-46bc-906c-9648a21511cb,e3bc8095-7d22-414e-9a64-1b0ffddbcbc5,432b60cf-9373-4600-bf70-1cf042dc2d07,178d34aa-e3b9-489d-9d92-58df448fbc04,222fc646-b623-469c-b85a-05df28c2e9b0,4be3f25a-baf6-4695-ad86-59b5d7773a62,c21d10cb-f781-483e-bc6d-1b73cf8b1b29,17aba007-4d69-498b-b0af-e7d4b7d6c940,0df8dbd7-bf92-476e-a410-a98bd1f141e0,ecd055f9-1459-47fc-a465-df9007751354,57e903ca-f316-49d6-9de1-de955a96b4bc,0183f756-d324-41d8-bef5-bf5fd251330a,14118bff-82b1-483a-970e-d08d89f75046,7680aebe-f22d-434f-a6ea-eae7befa6286,1a9ae285-a63f-45ad-b2a2-e5ed8a9cfe1e,timestamp:1683570578
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099872.578|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:561046.117|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,053 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 561046117, Backend time ns: 539174031
2023-05-08T18:29:38,053 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 561046117, Backend time ns: 539174031
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:561.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,053 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100213.797|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:560993.264|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560993264, Backend time ns: 539374322
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560993264, Backend time ns: 539374322
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:560.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 1101
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099950.533|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:560545.169|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560545169, Backend time ns: 539508229
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560545169, Backend time ns: 539508229
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:560.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1100072.779|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:560526.708|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560526708, Backend time ns: 539648367
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560526708, Backend time ns: 539648367
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:560.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099935.682|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:560257.143|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560257143, Backend time ns: 539797105
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560257143, Backend time ns: 539797105
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:560.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099929.451|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:560103.694|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560103694, Backend time ns: 540001137
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 560103694, Backend time ns: 540001137
2023-05-08T18:29:38,054 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:560.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099984.894|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:559928.064|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 559928064, Backend time ns: 540183127
2023-05-08T18:29:38,054 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 559928064, Backend time ns: 540183127
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:559.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,054 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,054 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099888.079|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:559670.14|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 559670140, Backend time ns: 540396099
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 559670140, Backend time ns: 540396099
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:559.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099951.213|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:559523.492|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 559523492, Backend time ns: 540541727
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 559523492, Backend time ns: 540541727
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:559.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099555.181|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:558986.112|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558986112, Backend time ns: 540681195
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558986112, Backend time ns: 540681195
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:558.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099623.774|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:558912.688|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558912688, Backend time ns: 540846254
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558912688, Backend time ns: 540846254
2023-05-08T18:29:38,055 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:558.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099563.52|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:558676.724|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558676724, Backend time ns: 541002643
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558676724, Backend time ns: 541002643
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:558.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099740.34|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:558658.323|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558658323, Backend time ns: 541183163
2023-05-08T18:29:38,055 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558658323, Backend time ns: 541183163
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:558.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,055 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,055 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099600.813|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:558365.147|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558365147, Backend time ns: 541371583
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 558365147, Backend time ns: 541371583
2023-05-08T18:29:38,056 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:558.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099453.294|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557994.507|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557994507, Backend time ns: 541569183
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557994507, Backend time ns: 541569183
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,056 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099590.792|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557976.166|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557976166, Backend time ns: 541760514
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557976166, Backend time ns: 541760514
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099579.842|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557788.306|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557788306, Backend time ns: 541903792
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557788306, Backend time ns: 541903792
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099610.193|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557645.698|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557645698, Backend time ns: 542085862
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557645698, Backend time ns: 542085862
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,056 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099492.877|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557379.033|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557379033, Backend time ns: 542231210
2023-05-08T18:29:38,056 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557379033, Backend time ns: 542231210
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,056 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099471.656|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557211.924|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557211924, Backend time ns: 542362608
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557211924, Backend time ns: 542362608
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099332.388|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556935.728|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556935728, Backend time ns: 542540408
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556935728, Backend time ns: 542540408
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099376.09|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556805.321|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556805321, Backend time ns: 542715617
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556805321, Backend time ns: 542715617
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099347.959|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556603.91|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556603910, Backend time ns: 542853365
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556603910, Backend time ns: 542853365
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,057 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099314.347|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556433.66|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556433660, Backend time ns: 543003203
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556433660, Backend time ns: 543003203
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099120.806|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556088.611|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556088611, Backend time ns: 543180463
2023-05-08T18:29:38,057 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556088611, Backend time ns: 543180463
2023-05-08T18:29:38,057 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,057 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099042.042|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555779.144|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555779144, Backend time ns: 543440008
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555779144, Backend time ns: 543440008
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098968.628|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555485.248|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555485248, Backend time ns: 543595726
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555485248, Backend time ns: 543595726
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,058 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098849.671|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555224.533|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555224533, Backend time ns: 543787747
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555224533, Backend time ns: 543787747
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098674.682|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554858.563|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554858563, Backend time ns: 543930255
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554858563, Backend time ns: 543930255
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,058 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098769.777|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554803.81|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554803810, Backend time ns: 544098884
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554803810, Backend time ns: 544098884
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098317.521|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554189.575|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554189575, Backend time ns: 544281435
2023-05-08T18:29:38,058 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554189575, Backend time ns: 544281435
2023-05-08T18:29:38,058 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,058 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098416.107|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554098.76|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554098760, Backend time ns: 544427213
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554098760, Backend time ns: 544427213
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,059 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098531.174|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554070.439|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554070439, Backend time ns: 544567151
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554070439, Backend time ns: 544567151
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098610.468|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554016.546|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554016546, Backend time ns: 544692268
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554016546, Backend time ns: 544692268
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098592.866|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553868.017|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553868017, Backend time ns: 544842786
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553868017, Backend time ns: 544842786
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098417.577|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553546.279|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553546279, Backend time ns: 544995135
2023-05-08T18:29:38,059 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553546279, Backend time ns: 544995135
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098478.031|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553427.133|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553427133, Backend time ns: 545234948
2023-05-08T18:29:38,059 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553427133, Backend time ns: 545234948
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,059 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098499.202|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553217.501|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553217501, Backend time ns: 545383766
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553217501, Backend time ns: 545383766
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098453.339|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553036.741|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553036741, Backend time ns: 545523784
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553036741, Backend time ns: 545523784
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098141.662|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552584.066|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552584066, Backend time ns: 545759597
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552584066, Backend time ns: 545759597
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097484.925|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551691.026|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551691026, Backend time ns: 545900865
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551691026, Backend time ns: 545900865
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097599.932|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551673.356|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551673356, Backend time ns: 546026731
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551673356, Backend time ns: 546026731
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097621.833|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551563.9|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551563900, Backend time ns: 546207071
2023-05-08T18:29:38,060 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551563900, Backend time ns: 546207071
2023-05-08T18:29:38,060 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:38,060 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097791.132|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551546.169|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551546169, Backend time ns: 546377901
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551546169, Backend time ns: 546377901
2023-05-08T18:29:38,061 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556218.269|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9790.935|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9790935, Backend time ns: 546533920
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9790935, Backend time ns: 546533920
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,061 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556302.973|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9729.281|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9729281, Backend time ns: 546687268
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9729281, Backend time ns: 546687268
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556476.813|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9762.633|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9762633, Backend time ns: 546807255
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9762633, Backend time ns: 546807255
2023-05-08T18:29:38,061 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556512.525|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9669.378|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9669378, Backend time ns: 546949583
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9669378, Backend time ns: 546949583
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,061 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556623.45|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9643.916|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9643916, Backend time ns: 547083460
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9643916, Backend time ns: 547083460
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556734.287|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9614.995|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9614995, Backend time ns: 547246789
2023-05-08T18:29:38,061 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9614995, Backend time ns: 547246789
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,061 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,062 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556824.202|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9549.551|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9549551, Backend time ns: 547406368
2023-05-08T18:29:38,062 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9549551, Backend time ns: 547406368
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556658.633|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:9189.531|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9189531, Backend time ns: 547565847
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 9189531, Backend time ns: 547565847
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556357.486|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8742.596|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8742596, Backend time ns: 547755888
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8742596, Backend time ns: 547755888
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556324.184|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8522.144|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8522144, Backend time ns: 547956059
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8522144, Backend time ns: 547956059
2023-05-08T18:29:38,062 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:38,062 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556439.37|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8421.288|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8421288, Backend time ns: 548183252
2023-05-08T18:29:38,062 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8421288, Backend time ns: 548183252
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,062 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556407.559|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,063 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8189.125|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,063 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8189125, Backend time ns: 548311549
2023-05-08T18:29:38,063 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8189125, Backend time ns: 548311549
2023-05-08T18:29:38,063 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,063 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:38,063 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:38,063 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 538
2023-05-08T18:29:38,063 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 538
2023-05-08T18:29:38,063 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,063 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:11.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,063 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,063 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570578063
2023-05-08T18:29:38,063 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570578063
2023-05-08T18:29:38,066 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570578
2023-05-08T18:29:38,066 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,066 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,067 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,069 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,070 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,071 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,072 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,074 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,074 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,074 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,074 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,074 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:38,075 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:38,075 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:38,081 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:38,117 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:38,142 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:38,147 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:38,180 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:38,184 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:38,186 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:38,218 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:38,224 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:38,225 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:38,226 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:38,256 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:38,263 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:38,265 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:38,266 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:38,295 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:38,301 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:38,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:38,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:38,333 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:38,340 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:38,345 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:38,347 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:38,372 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:38,386 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:38,388 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:38,410 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:38,426 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:38,428 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:38,466 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:38,468 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:38,510 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:38,604 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:537.89|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570578,d49473a1-335c-4a29-a888-938e5dd25c96,7d029703-7fad-4acd-b599-ba8b6260922c,3ed255cb-fd3d-4f13-83a9-3b4e4bdd401d,eb21bdac-655e-44a6-ab2a-b2e893642797,983504ad-78b9-4603-8905-eba65e97ecda,7601a0ae-adbf-4c8c-a42e-03c244582bd3,48148572-8ac6-4cb5-92fa-4ee4f8838944,9fa38db2-bf54-403f-81c0-61adca7a1c16,dac13ea0-d3e8-4ab4-b1ae-8d52af6bdcf3,4f36a6bc-79a2-4d27-9537-f83afa615172,e49dd02c-fda1-414f-8697-8f7dec5cbd18,d47d20f0-4d9e-442c-a5cd-ed6bd7565f48,d71e9499-ff04-4d37-a149-74ea03a92857,56b0d2cb-d710-4728-b687-5040794ba50e,7c383af1-c568-4899-b303-83138fc36fa8,6dcdc25e-b00a-4ca1-a179-adb0b997074e,0ad533a0-b7d4-457d-b4ad-95f57f0573b9,f73ea6fe-920d-45c3-8e20-404ce0e5305e,b86423ae-5ff2-4848-9727-c18d668b3915,77072b5f-a6d4-4ad0-a137-710074df8628,20865dc5-2fe2-4f43-bc4b-e94ffec99460,57936128-be92-4a5e-b9a0-8ac6b27eccea,6765fcb1-d633-4f4f-94a9-33c6f9e2de5e,19d69d07-2d6e-497e-a582-a6fd43072e3f,6df0d3a3-e992-47c8-84ec-3ce450625e26,5ddb0cc2-fd4a-4bfa-a3d2-cbaf04ea385c,8335846d-5fa2-4f8d-93eb-45b04d1e97a7,6e98389a-5ae0-48cc-a5f6-82e0a21f0796,afa3ac0c-c3dc-4f85-9f18-0a4ab8fa1365,75601f16-268c-4012-aa3d-f51de5f33451,afe2b118-1675-4a0c-ba0c-1f018dddda55,1a193e85-7ad0-4444-9a51-03b6f50364a6,cfd7cbb8-13aa-4c19-a02f-3544e5e4f617,4f2016e7-6207-412a-aa13-dea71601bc82,5750cebb-8d9c-43ae-a00a-50f0b4be8faa,92cef666-f5c4-479a-8ce2-7e1c3b700c1c,9de4b0da-45b7-4c46-9192-b735a8ce5bd6,ed3e6081-d8bf-4620-b17a-a9df7e396699,b8c6cc2b-b36b-48a9-b81d-66405b96fce2,585b6740-4053-4cc5-b6be-ac76492e38e2,96188424-9162-4f20-b5fb-e809e81d379d,10c8ebc0-2c9a-434a-892b-6e589aa13d19,de80b01b-eb36-401d-b996-9c03e51a6de0,d3743a17-3723-41c0-a201-b813cc0e65ef,21af32d6-af9b-4d68-b8c8-52922f45bf33,cef909c7-62b7-4f26-8bc7-d86d4867a322,d8aa7195-8b8d-4632-8aa8-24d88fbd05c5,4841b004-b3d5-4e5c-91d6-ffb291a383c9,64c6a6cc-2384-4e0f-ac89-d6dabd229a99,008e1c87-e014-485e-a6d6-d87d44650d00,44f083a4-4370-4204-9b08-3278f92d4a31,ce9145cd-39f2-40ee-87d5-f7000adbed42,d8c8df5a-1ff3-4ad8-acf7-f66aa381163e,37f2e259-d95e-4cc9-82fd-b5c3d98bae4c,0faa3013-2ec9-44aa-a6f0-7356ef432217,eaa0f4e1-8144-4a45-be61-a66b6f83002e, pattern=[METRICS]
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:537.89|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570578,d49473a1-335c-4a29-a888-938e5dd25c96,7d029703-7fad-4acd-b599-ba8b6260922c,3ed255cb-fd3d-4f13-83a9-3b4e4bdd401d,eb21bdac-655e-44a6-ab2a-b2e893642797,983504ad-78b9-4603-8905-eba65e97ecda,7601a0ae-adbf-4c8c-a42e-03c244582bd3,48148572-8ac6-4cb5-92fa-4ee4f8838944,9fa38db2-bf54-403f-81c0-61adca7a1c16,dac13ea0-d3e8-4ab4-b1ae-8d52af6bdcf3,4f36a6bc-79a2-4d27-9537-f83afa615172,e49dd02c-fda1-414f-8697-8f7dec5cbd18,d47d20f0-4d9e-442c-a5cd-ed6bd7565f48,d71e9499-ff04-4d37-a149-74ea03a92857,56b0d2cb-d710-4728-b687-5040794ba50e,7c383af1-c568-4899-b303-83138fc36fa8,6dcdc25e-b00a-4ca1-a179-adb0b997074e,0ad533a0-b7d4-457d-b4ad-95f57f0573b9,f73ea6fe-920d-45c3-8e20-404ce0e5305e,b86423ae-5ff2-4848-9727-c18d668b3915,77072b5f-a6d4-4ad0-a137-710074df8628,20865dc5-2fe2-4f43-bc4b-e94ffec99460,57936128-be92-4a5e-b9a0-8ac6b27eccea,6765fcb1-d633-4f4f-94a9-33c6f9e2de5e,19d69d07-2d6e-497e-a582-a6fd43072e3f,6df0d3a3-e992-47c8-84ec-3ce450625e26,5ddb0cc2-fd4a-4bfa-a3d2-cbaf04ea385c,8335846d-5fa2-4f8d-93eb-45b04d1e97a7,6e98389a-5ae0-48cc-a5f6-82e0a21f0796,afa3ac0c-c3dc-4f85-9f18-0a4ab8fa1365,75601f16-268c-4012-aa3d-f51de5f33451,afe2b118-1675-4a0c-ba0c-1f018dddda55,1a193e85-7ad0-4444-9a51-03b6f50364a6,cfd7cbb8-13aa-4c19-a02f-3544e5e4f617,4f2016e7-6207-412a-aa13-dea71601bc82,5750cebb-8d9c-43ae-a00a-50f0b4be8faa,92cef666-f5c4-479a-8ce2-7e1c3b700c1c,9de4b0da-45b7-4c46-9192-b735a8ce5bd6,ed3e6081-d8bf-4620-b17a-a9df7e396699,b8c6cc2b-b36b-48a9-b81d-66405b96fce2,585b6740-4053-4cc5-b6be-ac76492e38e2,96188424-9162-4f20-b5fb-e809e81d379d,10c8ebc0-2c9a-434a-892b-6e589aa13d19,de80b01b-eb36-401d-b996-9c03e51a6de0,d3743a17-3723-41c0-a201-b813cc0e65ef,21af32d6-af9b-4d68-b8c8-52922f45bf33,cef909c7-62b7-4f26-8bc7-d86d4867a322,d8aa7195-8b8d-4632-8aa8-24d88fbd05c5,4841b004-b3d5-4e5c-91d6-ffb291a383c9,64c6a6cc-2384-4e0f-ac89-d6dabd229a99,008e1c87-e014-485e-a6d6-d87d44650d00,44f083a4-4370-4204-9b08-3278f92d4a31,ce9145cd-39f2-40ee-87d5-f7000adbed42,d8c8df5a-1ff3-4ad8-acf7-f66aa381163e,37f2e259-d95e-4cc9-82fd-b5c3d98bae4c,0faa3013-2ec9-44aa-a6f0-7356ef432217,eaa0f4e1-8144-4a45-be61-a66b6f83002e, pattern=[METRICS]
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:537.89|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:d49473a1-335c-4a29-a888-938e5dd25c96,7d029703-7fad-4acd-b599-ba8b6260922c,3ed255cb-fd3d-4f13-83a9-3b4e4bdd401d,eb21bdac-655e-44a6-ab2a-b2e893642797,983504ad-78b9-4603-8905-eba65e97ecda,7601a0ae-adbf-4c8c-a42e-03c244582bd3,48148572-8ac6-4cb5-92fa-4ee4f8838944,9fa38db2-bf54-403f-81c0-61adca7a1c16,dac13ea0-d3e8-4ab4-b1ae-8d52af6bdcf3,4f36a6bc-79a2-4d27-9537-f83afa615172,e49dd02c-fda1-414f-8697-8f7dec5cbd18,d47d20f0-4d9e-442c-a5cd-ed6bd7565f48,d71e9499-ff04-4d37-a149-74ea03a92857,56b0d2cb-d710-4728-b687-5040794ba50e,7c383af1-c568-4899-b303-83138fc36fa8,6dcdc25e-b00a-4ca1-a179-adb0b997074e,0ad533a0-b7d4-457d-b4ad-95f57f0573b9,f73ea6fe-920d-45c3-8e20-404ce0e5305e,b86423ae-5ff2-4848-9727-c18d668b3915,77072b5f-a6d4-4ad0-a137-710074df8628,20865dc5-2fe2-4f43-bc4b-e94ffec99460,57936128-be92-4a5e-b9a0-8ac6b27eccea,6765fcb1-d633-4f4f-94a9-33c6f9e2de5e,19d69d07-2d6e-497e-a582-a6fd43072e3f,6df0d3a3-e992-47c8-84ec-3ce450625e26,5ddb0cc2-fd4a-4bfa-a3d2-cbaf04ea385c,8335846d-5fa2-4f8d-93eb-45b04d1e97a7,6e98389a-5ae0-48cc-a5f6-82e0a21f0796,afa3ac0c-c3dc-4f85-9f18-0a4ab8fa1365,75601f16-268c-4012-aa3d-f51de5f33451,afe2b118-1675-4a0c-ba0c-1f018dddda55,1a193e85-7ad0-4444-9a51-03b6f50364a6,cfd7cbb8-13aa-4c19-a02f-3544e5e4f617,4f2016e7-6207-412a-aa13-dea71601bc82,5750cebb-8d9c-43ae-a00a-50f0b4be8faa,92cef666-f5c4-479a-8ce2-7e1c3b700c1c,9de4b0da-45b7-4c46-9192-b735a8ce5bd6,ed3e6081-d8bf-4620-b17a-a9df7e396699,b8c6cc2b-b36b-48a9-b81d-66405b96fce2,585b6740-4053-4cc5-b6be-ac76492e38e2,96188424-9162-4f20-b5fb-e809e81d379d,10c8ebc0-2c9a-434a-892b-6e589aa13d19,de80b01b-eb36-401d-b996-9c03e51a6de0,d3743a17-3723-41c0-a201-b813cc0e65ef,21af32d6-af9b-4d68-b8c8-52922f45bf33,cef909c7-62b7-4f26-8bc7-d86d4867a322,d8aa7195-8b8d-4632-8aa8-24d88fbd05c5,4841b004-b3d5-4e5c-91d6-ffb291a383c9,64c6a6cc-2384-4e0f-ac89-d6dabd229a99,008e1c87-e014-485e-a6d6-d87d44650d00,44f083a4-4370-4204-9b08-3278f92d4a31,ce9145cd-39f2-40ee-87d5-f7000adbed42,d8c8df5a-1ff3-4ad8-acf7-f66aa381163e,37f2e259-d95e-4cc9-82fd-b5c3d98bae4c,0faa3013-2ec9-44aa-a6f0-7356ef432217,eaa0f4e1-8144-4a45-be61-a66b6f83002e,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.98|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570578,d49473a1-335c-4a29-a888-938e5dd25c96,7d029703-7fad-4acd-b599-ba8b6260922c,3ed255cb-fd3d-4f13-83a9-3b4e4bdd401d,eb21bdac-655e-44a6-ab2a-b2e893642797,983504ad-78b9-4603-8905-eba65e97ecda,7601a0ae-adbf-4c8c-a42e-03c244582bd3,48148572-8ac6-4cb5-92fa-4ee4f8838944,9fa38db2-bf54-403f-81c0-61adca7a1c16,dac13ea0-d3e8-4ab4-b1ae-8d52af6bdcf3,4f36a6bc-79a2-4d27-9537-f83afa615172,e49dd02c-fda1-414f-8697-8f7dec5cbd18,d47d20f0-4d9e-442c-a5cd-ed6bd7565f48,d71e9499-ff04-4d37-a149-74ea03a92857,56b0d2cb-d710-4728-b687-5040794ba50e,7c383af1-c568-4899-b303-83138fc36fa8,6dcdc25e-b00a-4ca1-a179-adb0b997074e,0ad533a0-b7d4-457d-b4ad-95f57f0573b9,f73ea6fe-920d-45c3-8e20-404ce0e5305e,b86423ae-5ff2-4848-9727-c18d668b3915,77072b5f-a6d4-4ad0-a137-710074df8628,20865dc5-2fe2-4f43-bc4b-e94ffec99460,57936128-be92-4a5e-b9a0-8ac6b27eccea,6765fcb1-d633-4f4f-94a9-33c6f9e2de5e,19d69d07-2d6e-497e-a582-a6fd43072e3f,6df0d3a3-e992-47c8-84ec-3ce450625e26,5ddb0cc2-fd4a-4bfa-a3d2-cbaf04ea385c,8335846d-5fa2-4f8d-93eb-45b04d1e97a7,6e98389a-5ae0-48cc-a5f6-82e0a21f0796,afa3ac0c-c3dc-4f85-9f18-0a4ab8fa1365,75601f16-268c-4012-aa3d-f51de5f33451,afe2b118-1675-4a0c-ba0c-1f018dddda55,1a193e85-7ad0-4444-9a51-03b6f50364a6,cfd7cbb8-13aa-4c19-a02f-3544e5e4f617,4f2016e7-6207-412a-aa13-dea71601bc82,5750cebb-8d9c-43ae-a00a-50f0b4be8faa,92cef666-f5c4-479a-8ce2-7e1c3b700c1c,9de4b0da-45b7-4c46-9192-b735a8ce5bd6,ed3e6081-d8bf-4620-b17a-a9df7e396699,b8c6cc2b-b36b-48a9-b81d-66405b96fce2,585b6740-4053-4cc5-b6be-ac76492e38e2,96188424-9162-4f20-b5fb-e809e81d379d,10c8ebc0-2c9a-434a-892b-6e589aa13d19,de80b01b-eb36-401d-b996-9c03e51a6de0,d3743a17-3723-41c0-a201-b813cc0e65ef,21af32d6-af9b-4d68-b8c8-52922f45bf33,cef909c7-62b7-4f26-8bc7-d86d4867a322,d8aa7195-8b8d-4632-8aa8-24d88fbd05c5,4841b004-b3d5-4e5c-91d6-ffb291a383c9,64c6a6cc-2384-4e0f-ac89-d6dabd229a99,008e1c87-e014-485e-a6d6-d87d44650d00,44f083a4-4370-4204-9b08-3278f92d4a31,ce9145cd-39f2-40ee-87d5-f7000adbed42,d8c8df5a-1ff3-4ad8-acf7-f66aa381163e,37f2e259-d95e-4cc9-82fd-b5c3d98bae4c,0faa3013-2ec9-44aa-a6f0-7356ef432217,eaa0f4e1-8144-4a45-be61-a66b6f83002e, pattern=[METRICS]
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.98|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570578,d49473a1-335c-4a29-a888-938e5dd25c96,7d029703-7fad-4acd-b599-ba8b6260922c,3ed255cb-fd3d-4f13-83a9-3b4e4bdd401d,eb21bdac-655e-44a6-ab2a-b2e893642797,983504ad-78b9-4603-8905-eba65e97ecda,7601a0ae-adbf-4c8c-a42e-03c244582bd3,48148572-8ac6-4cb5-92fa-4ee4f8838944,9fa38db2-bf54-403f-81c0-61adca7a1c16,dac13ea0-d3e8-4ab4-b1ae-8d52af6bdcf3,4f36a6bc-79a2-4d27-9537-f83afa615172,e49dd02c-fda1-414f-8697-8f7dec5cbd18,d47d20f0-4d9e-442c-a5cd-ed6bd7565f48,d71e9499-ff04-4d37-a149-74ea03a92857,56b0d2cb-d710-4728-b687-5040794ba50e,7c383af1-c568-4899-b303-83138fc36fa8,6dcdc25e-b00a-4ca1-a179-adb0b997074e,0ad533a0-b7d4-457d-b4ad-95f57f0573b9,f73ea6fe-920d-45c3-8e20-404ce0e5305e,b86423ae-5ff2-4848-9727-c18d668b3915,77072b5f-a6d4-4ad0-a137-710074df8628,20865dc5-2fe2-4f43-bc4b-e94ffec99460,57936128-be92-4a5e-b9a0-8ac6b27eccea,6765fcb1-d633-4f4f-94a9-33c6f9e2de5e,19d69d07-2d6e-497e-a582-a6fd43072e3f,6df0d3a3-e992-47c8-84ec-3ce450625e26,5ddb0cc2-fd4a-4bfa-a3d2-cbaf04ea385c,8335846d-5fa2-4f8d-93eb-45b04d1e97a7,6e98389a-5ae0-48cc-a5f6-82e0a21f0796,afa3ac0c-c3dc-4f85-9f18-0a4ab8fa1365,75601f16-268c-4012-aa3d-f51de5f33451,afe2b118-1675-4a0c-ba0c-1f018dddda55,1a193e85-7ad0-4444-9a51-03b6f50364a6,cfd7cbb8-13aa-4c19-a02f-3544e5e4f617,4f2016e7-6207-412a-aa13-dea71601bc82,5750cebb-8d9c-43ae-a00a-50f0b4be8faa,92cef666-f5c4-479a-8ce2-7e1c3b700c1c,9de4b0da-45b7-4c46-9192-b735a8ce5bd6,ed3e6081-d8bf-4620-b17a-a9df7e396699,b8c6cc2b-b36b-48a9-b81d-66405b96fce2,585b6740-4053-4cc5-b6be-ac76492e38e2,96188424-9162-4f20-b5fb-e809e81d379d,10c8ebc0-2c9a-434a-892b-6e589aa13d19,de80b01b-eb36-401d-b996-9c03e51a6de0,d3743a17-3723-41c0-a201-b813cc0e65ef,21af32d6-af9b-4d68-b8c8-52922f45bf33,cef909c7-62b7-4f26-8bc7-d86d4867a322,d8aa7195-8b8d-4632-8aa8-24d88fbd05c5,4841b004-b3d5-4e5c-91d6-ffb291a383c9,64c6a6cc-2384-4e0f-ac89-d6dabd229a99,008e1c87-e014-485e-a6d6-d87d44650d00,44f083a4-4370-4204-9b08-3278f92d4a31,ce9145cd-39f2-40ee-87d5-f7000adbed42,d8c8df5a-1ff3-4ad8-acf7-f66aa381163e,37f2e259-d95e-4cc9-82fd-b5c3d98bae4c,0faa3013-2ec9-44aa-a6f0-7356ef432217,eaa0f4e1-8144-4a45-be61-a66b6f83002e, pattern=[METRICS]
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:537.98|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:d49473a1-335c-4a29-a888-938e5dd25c96,7d029703-7fad-4acd-b599-ba8b6260922c,3ed255cb-fd3d-4f13-83a9-3b4e4bdd401d,eb21bdac-655e-44a6-ab2a-b2e893642797,983504ad-78b9-4603-8905-eba65e97ecda,7601a0ae-adbf-4c8c-a42e-03c244582bd3,48148572-8ac6-4cb5-92fa-4ee4f8838944,9fa38db2-bf54-403f-81c0-61adca7a1c16,dac13ea0-d3e8-4ab4-b1ae-8d52af6bdcf3,4f36a6bc-79a2-4d27-9537-f83afa615172,e49dd02c-fda1-414f-8697-8f7dec5cbd18,d47d20f0-4d9e-442c-a5cd-ed6bd7565f48,d71e9499-ff04-4d37-a149-74ea03a92857,56b0d2cb-d710-4728-b687-5040794ba50e,7c383af1-c568-4899-b303-83138fc36fa8,6dcdc25e-b00a-4ca1-a179-adb0b997074e,0ad533a0-b7d4-457d-b4ad-95f57f0573b9,f73ea6fe-920d-45c3-8e20-404ce0e5305e,b86423ae-5ff2-4848-9727-c18d668b3915,77072b5f-a6d4-4ad0-a137-710074df8628,20865dc5-2fe2-4f43-bc4b-e94ffec99460,57936128-be92-4a5e-b9a0-8ac6b27eccea,6765fcb1-d633-4f4f-94a9-33c6f9e2de5e,19d69d07-2d6e-497e-a582-a6fd43072e3f,6df0d3a3-e992-47c8-84ec-3ce450625e26,5ddb0cc2-fd4a-4bfa-a3d2-cbaf04ea385c,8335846d-5fa2-4f8d-93eb-45b04d1e97a7,6e98389a-5ae0-48cc-a5f6-82e0a21f0796,afa3ac0c-c3dc-4f85-9f18-0a4ab8fa1365,75601f16-268c-4012-aa3d-f51de5f33451,afe2b118-1675-4a0c-ba0c-1f018dddda55,1a193e85-7ad0-4444-9a51-03b6f50364a6,cfd7cbb8-13aa-4c19-a02f-3544e5e4f617,4f2016e7-6207-412a-aa13-dea71601bc82,5750cebb-8d9c-43ae-a00a-50f0b4be8faa,92cef666-f5c4-479a-8ce2-7e1c3b700c1c,9de4b0da-45b7-4c46-9192-b735a8ce5bd6,ed3e6081-d8bf-4620-b17a-a9df7e396699,b8c6cc2b-b36b-48a9-b81d-66405b96fce2,585b6740-4053-4cc5-b6be-ac76492e38e2,96188424-9162-4f20-b5fb-e809e81d379d,10c8ebc0-2c9a-434a-892b-6e589aa13d19,de80b01b-eb36-401d-b996-9c03e51a6de0,d3743a17-3723-41c0-a201-b813cc0e65ef,21af32d6-af9b-4d68-b8c8-52922f45bf33,cef909c7-62b7-4f26-8bc7-d86d4867a322,d8aa7195-8b8d-4632-8aa8-24d88fbd05c5,4841b004-b3d5-4e5c-91d6-ffb291a383c9,64c6a6cc-2384-4e0f-ac89-d6dabd229a99,008e1c87-e014-485e-a6d6-d87d44650d00,44f083a4-4370-4204-9b08-3278f92d4a31,ce9145cd-39f2-40ee-87d5-f7000adbed42,d8c8df5a-1ff3-4ad8-acf7-f66aa381163e,37f2e259-d95e-4cc9-82fd-b5c3d98bae4c,0faa3013-2ec9-44aa-a6f0-7356ef432217,eaa0f4e1-8144-4a45-be61-a66b6f83002e,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098665.611|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556564.468|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556564468, Backend time ns: 542440912
2023-05-08T18:29:38,605 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556564468, Backend time ns: 542440912
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098663.11|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556189.406|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556189406, Backend time ns: 542582780
2023-05-08T18:29:38,605 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556189406, Backend time ns: 542582780
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098632.289|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,605 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556021.427|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556021427, Backend time ns: 542700857
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556021427, Backend time ns: 542700857
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098710.533|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555982.665|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555982665, Backend time ns: 542815183
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555982665, Backend time ns: 542815183
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,606 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098698.722|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555846.607|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555846607, Backend time ns: 542952271
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555846607, Backend time ns: 542952271
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098434.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555451.485|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555451485, Backend time ns: 543127091
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555451485, Backend time ns: 543127091
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,606 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098487.481|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555324.078|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555324078, Backend time ns: 543296240
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555324078, Backend time ns: 543296240
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098660.341|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555332.319|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555332319, Backend time ns: 543429017
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555332319, Backend time ns: 543429017
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098626.868|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555166.379|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555166379, Backend time ns: 543551274
2023-05-08T18:29:38,606 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555166379, Backend time ns: 543551274
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,606 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,606 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098577.746|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554996.21|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554996210, Backend time ns: 543711563
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554996210, Backend time ns: 543711563
2023-05-08T18:29:38,607 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098539.883|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554788.528|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554788528, Backend time ns: 543895103
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554788528, Backend time ns: 543895103
2023-05-08T18:29:38,607 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098621.189|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554668.092|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554668092, Backend time ns: 544066973
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554668092, Backend time ns: 544066973
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098552.665|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554458.18|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554458180, Backend time ns: 544202921
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554458180, Backend time ns: 544202921
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098579.256|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554348.714|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554348714, Backend time ns: 544328488
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554348714, Backend time ns: 544328488
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,607 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098532.954|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554164.084|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554164084, Backend time ns: 544494767
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554164084, Backend time ns: 544494767
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,607 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098499.192|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553968.743|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553968743, Backend time ns: 544629614
2023-05-08T18:29:38,607 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553968743, Backend time ns: 544629614
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,607 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098474.24|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553814.054|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553814054, Backend time ns: 544764352
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553814054, Backend time ns: 544764352
2023-05-08T18:29:38,608 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098515.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553693.627|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553693627, Backend time ns: 544931651
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553693627, Backend time ns: 544931651
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,608 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098457.879|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553495.486|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553495486, Backend time ns: 545072209
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553495486, Backend time ns: 545072209
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098390.906|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553288.275|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553288275, Backend time ns: 545201726
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553288275, Backend time ns: 545201726
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098327.112|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553090.864|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553090864, Backend time ns: 545344704
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553090864, Backend time ns: 545344704
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098343.043|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552971.338|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552971338, Backend time ns: 545456839
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552971338, Backend time ns: 545456839
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098065.428|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552582.377|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552582377, Backend time ns: 545577086
2023-05-08T18:29:38,608 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552582377, Backend time ns: 545577086
2023-05-08T18:29:38,608 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,608 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,608 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098143.932|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552516.173|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552516173, Backend time ns: 545725234
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552516173, Backend time ns: 545725234
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098116.48|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552356.194|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552356194, Backend time ns: 545858382
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552356194, Backend time ns: 545858382
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098096.989|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552212.226|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552212226, Backend time ns: 545974038
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552212226, Backend time ns: 545974038
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097941.401|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551940.571|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551940571, Backend time ns: 546135917
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551940571, Backend time ns: 546135917
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,609 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097970.312|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551801.593|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551801593, Backend time ns: 546328508
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551801593, Backend time ns: 546328508
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,609 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097968.972|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551602.812|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551602812, Backend time ns: 546523039
2023-05-08T18:29:38,609 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551602812, Backend time ns: 546523039
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,609 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097906.879|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551332.447|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551332447, Backend time ns: 546709709
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551332447, Backend time ns: 546709709
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097846.795|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551088.313|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551088313, Backend time ns: 546888989
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551088313, Backend time ns: 546888989
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,610 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097908.329|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550983.928|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550983928, Backend time ns: 547100341
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550983928, Backend time ns: 547100341
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097906.889|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550775.746|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550775746, Backend time ns: 547271881
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550775746, Backend time ns: 547271881
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097856.086|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550539.923|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550539923, Backend time ns: 547469002
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550539923, Backend time ns: 547469002
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,610 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097845.945|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550331.291|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550331291, Backend time ns: 547676203
2023-05-08T18:29:38,610 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550331291, Backend time ns: 547676203
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097875.587|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550162.702|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550162702, Backend time ns: 547807350
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550162702, Backend time ns: 547807350
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097785.322|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549950.03|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549950030, Backend time ns: 547914966
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549950030, Backend time ns: 547914966
2023-05-08T18:29:38,611 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097715.538|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549762.95|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549762950, Backend time ns: 548050114
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549762950, Backend time ns: 548050114
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,611 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097553.129|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549474.804|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549474804, Backend time ns: 548236734
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549474804, Backend time ns: 548236734
2023-05-08T18:29:38,611 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097719.398|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549430.021|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549430021, Backend time ns: 548387833
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549430021, Backend time ns: 548387833
2023-05-08T18:29:38,611 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097690.097|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549243.831|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549243831, Backend time ns: 548532831
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549243831, Backend time ns: 548532831
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097320.676|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548759.724|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548759724, Backend time ns: 548652267
2023-05-08T18:29:38,611 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548759724, Backend time ns: 548652267
2023-05-08T18:29:38,611 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097462.224|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548782.945|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548782945, Backend time ns: 548775194
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548782945, Backend time ns: 548775194
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097487.356|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548685.46|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548685460, Backend time ns: 548900141
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548685460, Backend time ns: 548900141
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,612 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557633.817|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8706.674|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8706674, Backend time ns: 549060250
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8706674, Backend time ns: 549060250
2023-05-08T18:29:38,612 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557744.283|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8655.161|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8655161, Backend time ns: 549179997
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8655161, Backend time ns: 549179997
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557816.307|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8609.679|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8609679, Backend time ns: 549314214
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8609679, Backend time ns: 549314214
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,612 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557730.242|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8386.796|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8386796, Backend time ns: 549460102
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8386796, Backend time ns: 549460102
2023-05-08T18:29:38,612 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557886.811|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8367.775|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8367775, Backend time ns: 549608761
2023-05-08T18:29:38,612 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8367775, Backend time ns: 549608761
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,612 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,612 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557966.145|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8329.843|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8329843, Backend time ns: 549735248
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8329843, Backend time ns: 549735248
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,613 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557621.166|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7859.097|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7859097, Backend time ns: 549869825
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7859097, Backend time ns: 549869825
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,613 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557711.641|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7807.394|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7807394, Backend time ns: 550012093
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7807394, Backend time ns: 550012093
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557809.827|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7771.712|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7771712, Backend time ns: 550135560
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7771712, Backend time ns: 550135560
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557854.87|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7692.578|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7692578, Backend time ns: 550266927
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7692578, Backend time ns: 550266927
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557640.297|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7343.368|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7343368, Backend time ns: 550385554
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7343368, Backend time ns: 550385554
2023-05-08T18:29:38,613 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557652.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7209.421|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7209421, Backend time ns: 550532972
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7209421, Backend time ns: 550532972
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:38,613 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-05-08T18:29:38,613 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,614 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570578
2023-05-08T18:29:38,614 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570578614
2023-05-08T18:29:38,614 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570578614
2023-05-08T18:29:38,617 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570578
2023-05-08T18:29:38,617 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,617 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,617 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,617 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,617 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,617 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,618 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,619 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,620 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,621 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,622 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:38,624 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:38,625 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:38,625 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:38,626 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:38,631 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:38,668 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:38,691 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:38,698 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:38,730 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:38,734 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:38,736 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:38,768 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:38,774 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:38,774 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:38,776 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:38,806 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:38,813 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:38,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:38,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:38,845 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:38,851 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:38,855 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:38,857 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:38,883 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:38,890 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:38,895 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:38,897 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:38,922 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:38,935 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:38,937 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:38,960 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:38,976 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:38,978 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:39,016 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:39,018 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:39,060 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:39,154 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:39,154 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:536.94|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570579,6b2cedf5-e637-481f-8645-65b8968bcbe7,e522e7fd-e5a3-411e-9bd1-d81c0f249bde,23b829a8-19d7-43cc-b364-c702c7de93f8,cc6ddda8-ab67-49bd-8a77-38fe7fccba7d,6ebe25c1-fc1d-438a-b544-2384c17cdad2,2ad243ae-e3c8-4637-b7d6-aa6596ab0fe7,b71d985b-4f26-45c1-a2d2-1a3c153bd70f,30986cac-776a-4dc1-bbd7-5ff19b560448,17b390ee-80f9-4d05-938e-4e54b2269a32,70358c37-bc7c-4dea-840b-3ca08a925210,75fae75c-faf3-4580-875e-b8ab73b9c667,677b4061-1cd2-45f6-b17c-d67d68da546d,240cf943-2820-40f6-8664-a3c1de6fb4da,cacaa4e5-5aa0-4db3-8859-337fffffed56,d1bbbc77-04f7-465d-968c-fe305fe04040,1b5e3188-cee8-43bf-9e07-c575ace52a06,c73bf8bb-6bb3-47c1-ba31-32ea133bbd1c,9d2dfebd-e2e1-41cd-a4e4-6f077177bccd,857bd8bd-6493-4ec3-85d9-76fb6ad3c779,b55bd715-0205-4db8-ad21-9dcc9d5d70ea,8da3fa62-eea0-4ea4-a32a-f512cf9e4be7,9151d14d-f25c-4472-9385-efa1979c807a,7e1520cf-4f54-4845-9a1d-cc0eaf4961bb,13e084ae-339d-468d-8313-5911a2100e0e,9ea62135-15ff-4753-8570-c24038f91aeb,f7a15c78-6c5e-4d68-821f-c11c152223e0,848cc806-331b-4715-a4aa-2465a6889644,2f028911-87ac-407a-ac50-d124dce1f2dd,9e536c59-c6b8-4170-9aa4-3cab170caaef,ba78b125-0674-4043-b2dc-cc5721ff72c5,99f66abf-67bf-400f-9747-7713e56db80d,b4e698dd-3b67-482e-ab57-d8fe486aa05d,f8d8fedb-b394-4db6-a2c5-3d1cc772523a,bfb95715-7d31-4019-a567-b6ddef21c712,1d46fcb0-62bb-4a0e-b0bc-02e61f690a48,74cad049-eaeb-4f0f-be66-b8941618bf0e,b09798b1-6e6b-4329-948d-9bfa614ded66,b6f87048-b7da-4b19-9ce9-327051f5725e,6ace098a-bd2d-412a-a7f1-6122d1166a5a,d4bdb5fd-39b6-4b8f-ba4a-fd2aaf3017d9,8423f032-5044-4d6d-a90b-06a5794c00c5,f20dd434-a2d5-4aeb-a5c9-48cf42ef1896,9d37d6eb-d1ef-4a7b-bde5-18bddf84d3cb,496a9e90-a923-4c93-8c50-3ba5b9cd4fc2,103bb268-9ee6-43d2-86b8-6aa35002dbf9,e8b739d1-f5d1-4c02-90d9-0dba7810ba2b,a4cd3026-d907-4410-9cc8-6b8f33631723,46838cee-66c3-4ce0-9678-8529af5435bd,a81340ff-6461-4db0-8078-07e01653f817,118032d8-e3e7-4f22-9f46-bc0f9d1be974,1cd86901-0688-47af-b176-ead33d55c1d9,a9e01087-ee1d-4173-93a0-1d31ada047c6,ee09ad65-91d8-4f66-a718-06a89ff61877,4cd1fb70-7b90-465c-ae16-d1ded1c319f7,2db853df-b1af-4272-83e3-f6cf68a52ce8,5abe140b-8164-442c-9d64-bc5e1dcb8417, pattern=[METRICS]
2023-05-08T18:29:39,154 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:536.94|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570579,6b2cedf5-e637-481f-8645-65b8968bcbe7,e522e7fd-e5a3-411e-9bd1-d81c0f249bde,23b829a8-19d7-43cc-b364-c702c7de93f8,cc6ddda8-ab67-49bd-8a77-38fe7fccba7d,6ebe25c1-fc1d-438a-b544-2384c17cdad2,2ad243ae-e3c8-4637-b7d6-aa6596ab0fe7,b71d985b-4f26-45c1-a2d2-1a3c153bd70f,30986cac-776a-4dc1-bbd7-5ff19b560448,17b390ee-80f9-4d05-938e-4e54b2269a32,70358c37-bc7c-4dea-840b-3ca08a925210,75fae75c-faf3-4580-875e-b8ab73b9c667,677b4061-1cd2-45f6-b17c-d67d68da546d,240cf943-2820-40f6-8664-a3c1de6fb4da,cacaa4e5-5aa0-4db3-8859-337fffffed56,d1bbbc77-04f7-465d-968c-fe305fe04040,1b5e3188-cee8-43bf-9e07-c575ace52a06,c73bf8bb-6bb3-47c1-ba31-32ea133bbd1c,9d2dfebd-e2e1-41cd-a4e4-6f077177bccd,857bd8bd-6493-4ec3-85d9-76fb6ad3c779,b55bd715-0205-4db8-ad21-9dcc9d5d70ea,8da3fa62-eea0-4ea4-a32a-f512cf9e4be7,9151d14d-f25c-4472-9385-efa1979c807a,7e1520cf-4f54-4845-9a1d-cc0eaf4961bb,13e084ae-339d-468d-8313-5911a2100e0e,9ea62135-15ff-4753-8570-c24038f91aeb,f7a15c78-6c5e-4d68-821f-c11c152223e0,848cc806-331b-4715-a4aa-2465a6889644,2f028911-87ac-407a-ac50-d124dce1f2dd,9e536c59-c6b8-4170-9aa4-3cab170caaef,ba78b125-0674-4043-b2dc-cc5721ff72c5,99f66abf-67bf-400f-9747-7713e56db80d,b4e698dd-3b67-482e-ab57-d8fe486aa05d,f8d8fedb-b394-4db6-a2c5-3d1cc772523a,bfb95715-7d31-4019-a567-b6ddef21c712,1d46fcb0-62bb-4a0e-b0bc-02e61f690a48,74cad049-eaeb-4f0f-be66-b8941618bf0e,b09798b1-6e6b-4329-948d-9bfa614ded66,b6f87048-b7da-4b19-9ce9-327051f5725e,6ace098a-bd2d-412a-a7f1-6122d1166a5a,d4bdb5fd-39b6-4b8f-ba4a-fd2aaf3017d9,8423f032-5044-4d6d-a90b-06a5794c00c5,f20dd434-a2d5-4aeb-a5c9-48cf42ef1896,9d37d6eb-d1ef-4a7b-bde5-18bddf84d3cb,496a9e90-a923-4c93-8c50-3ba5b9cd4fc2,103bb268-9ee6-43d2-86b8-6aa35002dbf9,e8b739d1-f5d1-4c02-90d9-0dba7810ba2b,a4cd3026-d907-4410-9cc8-6b8f33631723,46838cee-66c3-4ce0-9678-8529af5435bd,a81340ff-6461-4db0-8078-07e01653f817,118032d8-e3e7-4f22-9f46-bc0f9d1be974,1cd86901-0688-47af-b176-ead33d55c1d9,a9e01087-ee1d-4173-93a0-1d31ada047c6,ee09ad65-91d8-4f66-a718-06a89ff61877,4cd1fb70-7b90-465c-ae16-d1ded1c319f7,2db853df-b1af-4272-83e3-f6cf68a52ce8,5abe140b-8164-442c-9d64-bc5e1dcb8417, pattern=[METRICS]
2023-05-08T18:29:39,154 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:536.94|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:6b2cedf5-e637-481f-8645-65b8968bcbe7,e522e7fd-e5a3-411e-9bd1-d81c0f249bde,23b829a8-19d7-43cc-b364-c702c7de93f8,cc6ddda8-ab67-49bd-8a77-38fe7fccba7d,6ebe25c1-fc1d-438a-b544-2384c17cdad2,2ad243ae-e3c8-4637-b7d6-aa6596ab0fe7,b71d985b-4f26-45c1-a2d2-1a3c153bd70f,30986cac-776a-4dc1-bbd7-5ff19b560448,17b390ee-80f9-4d05-938e-4e54b2269a32,70358c37-bc7c-4dea-840b-3ca08a925210,75fae75c-faf3-4580-875e-b8ab73b9c667,677b4061-1cd2-45f6-b17c-d67d68da546d,240cf943-2820-40f6-8664-a3c1de6fb4da,cacaa4e5-5aa0-4db3-8859-337fffffed56,d1bbbc77-04f7-465d-968c-fe305fe04040,1b5e3188-cee8-43bf-9e07-c575ace52a06,c73bf8bb-6bb3-47c1-ba31-32ea133bbd1c,9d2dfebd-e2e1-41cd-a4e4-6f077177bccd,857bd8bd-6493-4ec3-85d9-76fb6ad3c779,b55bd715-0205-4db8-ad21-9dcc9d5d70ea,8da3fa62-eea0-4ea4-a32a-f512cf9e4be7,9151d14d-f25c-4472-9385-efa1979c807a,7e1520cf-4f54-4845-9a1d-cc0eaf4961bb,13e084ae-339d-468d-8313-5911a2100e0e,9ea62135-15ff-4753-8570-c24038f91aeb,f7a15c78-6c5e-4d68-821f-c11c152223e0,848cc806-331b-4715-a4aa-2465a6889644,2f028911-87ac-407a-ac50-d124dce1f2dd,9e536c59-c6b8-4170-9aa4-3cab170caaef,ba78b125-0674-4043-b2dc-cc5721ff72c5,99f66abf-67bf-400f-9747-7713e56db80d,b4e698dd-3b67-482e-ab57-d8fe486aa05d,f8d8fedb-b394-4db6-a2c5-3d1cc772523a,bfb95715-7d31-4019-a567-b6ddef21c712,1d46fcb0-62bb-4a0e-b0bc-02e61f690a48,74cad049-eaeb-4f0f-be66-b8941618bf0e,b09798b1-6e6b-4329-948d-9bfa614ded66,b6f87048-b7da-4b19-9ce9-327051f5725e,6ace098a-bd2d-412a-a7f1-6122d1166a5a,d4bdb5fd-39b6-4b8f-ba4a-fd2aaf3017d9,8423f032-5044-4d6d-a90b-06a5794c00c5,f20dd434-a2d5-4aeb-a5c9-48cf42ef1896,9d37d6eb-d1ef-4a7b-bde5-18bddf84d3cb,496a9e90-a923-4c93-8c50-3ba5b9cd4fc2,103bb268-9ee6-43d2-86b8-6aa35002dbf9,e8b739d1-f5d1-4c02-90d9-0dba7810ba2b,a4cd3026-d907-4410-9cc8-6b8f33631723,46838cee-66c3-4ce0-9678-8529af5435bd,a81340ff-6461-4db0-8078-07e01653f817,118032d8-e3e7-4f22-9f46-bc0f9d1be974,1cd86901-0688-47af-b176-ead33d55c1d9,a9e01087-ee1d-4173-93a0-1d31ada047c6,ee09ad65-91d8-4f66-a718-06a89ff61877,4cd1fb70-7b90-465c-ae16-d1ded1c319f7,2db853df-b1af-4272-83e3-f6cf68a52ce8,5abe140b-8164-442c-9d64-bc5e1dcb8417,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.05|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570579,6b2cedf5-e637-481f-8645-65b8968bcbe7,e522e7fd-e5a3-411e-9bd1-d81c0f249bde,23b829a8-19d7-43cc-b364-c702c7de93f8,cc6ddda8-ab67-49bd-8a77-38fe7fccba7d,6ebe25c1-fc1d-438a-b544-2384c17cdad2,2ad243ae-e3c8-4637-b7d6-aa6596ab0fe7,b71d985b-4f26-45c1-a2d2-1a3c153bd70f,30986cac-776a-4dc1-bbd7-5ff19b560448,17b390ee-80f9-4d05-938e-4e54b2269a32,70358c37-bc7c-4dea-840b-3ca08a925210,75fae75c-faf3-4580-875e-b8ab73b9c667,677b4061-1cd2-45f6-b17c-d67d68da546d,240cf943-2820-40f6-8664-a3c1de6fb4da,cacaa4e5-5aa0-4db3-8859-337fffffed56,d1bbbc77-04f7-465d-968c-fe305fe04040,1b5e3188-cee8-43bf-9e07-c575ace52a06,c73bf8bb-6bb3-47c1-ba31-32ea133bbd1c,9d2dfebd-e2e1-41cd-a4e4-6f077177bccd,857bd8bd-6493-4ec3-85d9-76fb6ad3c779,b55bd715-0205-4db8-ad21-9dcc9d5d70ea,8da3fa62-eea0-4ea4-a32a-f512cf9e4be7,9151d14d-f25c-4472-9385-efa1979c807a,7e1520cf-4f54-4845-9a1d-cc0eaf4961bb,13e084ae-339d-468d-8313-5911a2100e0e,9ea62135-15ff-4753-8570-c24038f91aeb,f7a15c78-6c5e-4d68-821f-c11c152223e0,848cc806-331b-4715-a4aa-2465a6889644,2f028911-87ac-407a-ac50-d124dce1f2dd,9e536c59-c6b8-4170-9aa4-3cab170caaef,ba78b125-0674-4043-b2dc-cc5721ff72c5,99f66abf-67bf-400f-9747-7713e56db80d,b4e698dd-3b67-482e-ab57-d8fe486aa05d,f8d8fedb-b394-4db6-a2c5-3d1cc772523a,bfb95715-7d31-4019-a567-b6ddef21c712,1d46fcb0-62bb-4a0e-b0bc-02e61f690a48,74cad049-eaeb-4f0f-be66-b8941618bf0e,b09798b1-6e6b-4329-948d-9bfa614ded66,b6f87048-b7da-4b19-9ce9-327051f5725e,6ace098a-bd2d-412a-a7f1-6122d1166a5a,d4bdb5fd-39b6-4b8f-ba4a-fd2aaf3017d9,8423f032-5044-4d6d-a90b-06a5794c00c5,f20dd434-a2d5-4aeb-a5c9-48cf42ef1896,9d37d6eb-d1ef-4a7b-bde5-18bddf84d3cb,496a9e90-a923-4c93-8c50-3ba5b9cd4fc2,103bb268-9ee6-43d2-86b8-6aa35002dbf9,e8b739d1-f5d1-4c02-90d9-0dba7810ba2b,a4cd3026-d907-4410-9cc8-6b8f33631723,46838cee-66c3-4ce0-9678-8529af5435bd,a81340ff-6461-4db0-8078-07e01653f817,118032d8-e3e7-4f22-9f46-bc0f9d1be974,1cd86901-0688-47af-b176-ead33d55c1d9,a9e01087-ee1d-4173-93a0-1d31ada047c6,ee09ad65-91d8-4f66-a718-06a89ff61877,4cd1fb70-7b90-465c-ae16-d1ded1c319f7,2db853df-b1af-4272-83e3-f6cf68a52ce8,5abe140b-8164-442c-9d64-bc5e1dcb8417, pattern=[METRICS]
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.05|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570579,6b2cedf5-e637-481f-8645-65b8968bcbe7,e522e7fd-e5a3-411e-9bd1-d81c0f249bde,23b829a8-19d7-43cc-b364-c702c7de93f8,cc6ddda8-ab67-49bd-8a77-38fe7fccba7d,6ebe25c1-fc1d-438a-b544-2384c17cdad2,2ad243ae-e3c8-4637-b7d6-aa6596ab0fe7,b71d985b-4f26-45c1-a2d2-1a3c153bd70f,30986cac-776a-4dc1-bbd7-5ff19b560448,17b390ee-80f9-4d05-938e-4e54b2269a32,70358c37-bc7c-4dea-840b-3ca08a925210,75fae75c-faf3-4580-875e-b8ab73b9c667,677b4061-1cd2-45f6-b17c-d67d68da546d,240cf943-2820-40f6-8664-a3c1de6fb4da,cacaa4e5-5aa0-4db3-8859-337fffffed56,d1bbbc77-04f7-465d-968c-fe305fe04040,1b5e3188-cee8-43bf-9e07-c575ace52a06,c73bf8bb-6bb3-47c1-ba31-32ea133bbd1c,9d2dfebd-e2e1-41cd-a4e4-6f077177bccd,857bd8bd-6493-4ec3-85d9-76fb6ad3c779,b55bd715-0205-4db8-ad21-9dcc9d5d70ea,8da3fa62-eea0-4ea4-a32a-f512cf9e4be7,9151d14d-f25c-4472-9385-efa1979c807a,7e1520cf-4f54-4845-9a1d-cc0eaf4961bb,13e084ae-339d-468d-8313-5911a2100e0e,9ea62135-15ff-4753-8570-c24038f91aeb,f7a15c78-6c5e-4d68-821f-c11c152223e0,848cc806-331b-4715-a4aa-2465a6889644,2f028911-87ac-407a-ac50-d124dce1f2dd,9e536c59-c6b8-4170-9aa4-3cab170caaef,ba78b125-0674-4043-b2dc-cc5721ff72c5,99f66abf-67bf-400f-9747-7713e56db80d,b4e698dd-3b67-482e-ab57-d8fe486aa05d,f8d8fedb-b394-4db6-a2c5-3d1cc772523a,bfb95715-7d31-4019-a567-b6ddef21c712,1d46fcb0-62bb-4a0e-b0bc-02e61f690a48,74cad049-eaeb-4f0f-be66-b8941618bf0e,b09798b1-6e6b-4329-948d-9bfa614ded66,b6f87048-b7da-4b19-9ce9-327051f5725e,6ace098a-bd2d-412a-a7f1-6122d1166a5a,d4bdb5fd-39b6-4b8f-ba4a-fd2aaf3017d9,8423f032-5044-4d6d-a90b-06a5794c00c5,f20dd434-a2d5-4aeb-a5c9-48cf42ef1896,9d37d6eb-d1ef-4a7b-bde5-18bddf84d3cb,496a9e90-a923-4c93-8c50-3ba5b9cd4fc2,103bb268-9ee6-43d2-86b8-6aa35002dbf9,e8b739d1-f5d1-4c02-90d9-0dba7810ba2b,a4cd3026-d907-4410-9cc8-6b8f33631723,46838cee-66c3-4ce0-9678-8529af5435bd,a81340ff-6461-4db0-8078-07e01653f817,118032d8-e3e7-4f22-9f46-bc0f9d1be974,1cd86901-0688-47af-b176-ead33d55c1d9,a9e01087-ee1d-4173-93a0-1d31ada047c6,ee09ad65-91d8-4f66-a718-06a89ff61877,4cd1fb70-7b90-465c-ae16-d1ded1c319f7,2db853df-b1af-4272-83e3-f6cf68a52ce8,5abe140b-8164-442c-9d64-bc5e1dcb8417, pattern=[METRICS]
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:537.05|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:6b2cedf5-e637-481f-8645-65b8968bcbe7,e522e7fd-e5a3-411e-9bd1-d81c0f249bde,23b829a8-19d7-43cc-b364-c702c7de93f8,cc6ddda8-ab67-49bd-8a77-38fe7fccba7d,6ebe25c1-fc1d-438a-b544-2384c17cdad2,2ad243ae-e3c8-4637-b7d6-aa6596ab0fe7,b71d985b-4f26-45c1-a2d2-1a3c153bd70f,30986cac-776a-4dc1-bbd7-5ff19b560448,17b390ee-80f9-4d05-938e-4e54b2269a32,70358c37-bc7c-4dea-840b-3ca08a925210,75fae75c-faf3-4580-875e-b8ab73b9c667,677b4061-1cd2-45f6-b17c-d67d68da546d,240cf943-2820-40f6-8664-a3c1de6fb4da,cacaa4e5-5aa0-4db3-8859-337fffffed56,d1bbbc77-04f7-465d-968c-fe305fe04040,1b5e3188-cee8-43bf-9e07-c575ace52a06,c73bf8bb-6bb3-47c1-ba31-32ea133bbd1c,9d2dfebd-e2e1-41cd-a4e4-6f077177bccd,857bd8bd-6493-4ec3-85d9-76fb6ad3c779,b55bd715-0205-4db8-ad21-9dcc9d5d70ea,8da3fa62-eea0-4ea4-a32a-f512cf9e4be7,9151d14d-f25c-4472-9385-efa1979c807a,7e1520cf-4f54-4845-9a1d-cc0eaf4961bb,13e084ae-339d-468d-8313-5911a2100e0e,9ea62135-15ff-4753-8570-c24038f91aeb,f7a15c78-6c5e-4d68-821f-c11c152223e0,848cc806-331b-4715-a4aa-2465a6889644,2f028911-87ac-407a-ac50-d124dce1f2dd,9e536c59-c6b8-4170-9aa4-3cab170caaef,ba78b125-0674-4043-b2dc-cc5721ff72c5,99f66abf-67bf-400f-9747-7713e56db80d,b4e698dd-3b67-482e-ab57-d8fe486aa05d,f8d8fedb-b394-4db6-a2c5-3d1cc772523a,bfb95715-7d31-4019-a567-b6ddef21c712,1d46fcb0-62bb-4a0e-b0bc-02e61f690a48,74cad049-eaeb-4f0f-be66-b8941618bf0e,b09798b1-6e6b-4329-948d-9bfa614ded66,b6f87048-b7da-4b19-9ce9-327051f5725e,6ace098a-bd2d-412a-a7f1-6122d1166a5a,d4bdb5fd-39b6-4b8f-ba4a-fd2aaf3017d9,8423f032-5044-4d6d-a90b-06a5794c00c5,f20dd434-a2d5-4aeb-a5c9-48cf42ef1896,9d37d6eb-d1ef-4a7b-bde5-18bddf84d3cb,496a9e90-a923-4c93-8c50-3ba5b9cd4fc2,103bb268-9ee6-43d2-86b8-6aa35002dbf9,e8b739d1-f5d1-4c02-90d9-0dba7810ba2b,a4cd3026-d907-4410-9cc8-6b8f33631723,46838cee-66c3-4ce0-9678-8529af5435bd,a81340ff-6461-4db0-8078-07e01653f817,118032d8-e3e7-4f22-9f46-bc0f9d1be974,1cd86901-0688-47af-b176-ead33d55c1d9,a9e01087-ee1d-4173-93a0-1d31ada047c6,ee09ad65-91d8-4f66-a718-06a89ff61877,4cd1fb70-7b90-465c-ae16-d1ded1c319f7,2db853df-b1af-4272-83e3-f6cf68a52ce8,5abe140b-8164-442c-9d64-bc5e1dcb8417,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098715.044|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557716.832|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557716832, Backend time ns: 541343431
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557716832, Backend time ns: 541343431
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099079.585|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557695.951|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557695951, Backend time ns: 541487399
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557695951, Backend time ns: 541487399
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099051.443|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557535.992|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557535992, Backend time ns: 541609586
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557535992, Backend time ns: 541609586
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099039.853|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557404.725|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557404725, Backend time ns: 541725503
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557404725, Backend time ns: 541725503
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098990.659|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557239.065|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557239065, Backend time ns: 541840259
2023-05-08T18:29:39,155 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557239065, Backend time ns: 541840259
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:39,155 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098851.031|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556985.181|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556985181, Backend time ns: 541957895
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556985181, Backend time ns: 541957895
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098875.332|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556881.445|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556881445, Backend time ns: 542265282
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556881445, Backend time ns: 542265282
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099006.57|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556714.496|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556714496, Backend time ns: 542407550
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556714496, Backend time ns: 542407550
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099062.643|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556629.321|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556629321, Backend time ns: 542522347
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556629321, Backend time ns: 542522347
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099013.84|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556466.162|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556466162, Backend time ns: 542651754
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556466162, Backend time ns: 542651754
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098940.397|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556261.361|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556261361, Backend time ns: 542781491
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556261361, Backend time ns: 542781491
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098978.168|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556165.285|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556165285, Backend time ns: 542907708
2023-05-08T18:29:39,156 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556165285, Backend time ns: 542907708
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098905.285|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555971.825|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555971825, Backend time ns: 543139401
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555971825, Backend time ns: 543139401
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098879.773|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555691.559|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555691559, Backend time ns: 543338632
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555691559, Backend time ns: 543338632
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098926.176|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555559.602|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555559602, Backend time ns: 543484990
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555559602, Backend time ns: 543484990
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,157 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098915.825|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555398.863|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555398863, Backend time ns: 543624388
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555398863, Backend time ns: 543624388
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,157 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098810.729|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555156.289|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555156289, Backend time ns: 543752465
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555156289, Backend time ns: 543752465
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,157 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098850.132|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555072.025|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555072025, Backend time ns: 543877912
2023-05-08T18:29:39,157 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555072025, Backend time ns: 543877912
2023-05-08T18:29:39,157 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098803.129|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554894.795|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554894795, Backend time ns: 543998739
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554894795, Backend time ns: 543998739
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,158 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098626.549|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554598.768|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554598768, Backend time ns: 544130756
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554598768, Backend time ns: 544130756
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,158 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098541.144|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554383.806|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554383806, Backend time ns: 544313476
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554383806, Backend time ns: 544313476
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098655.92|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554311.062|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554311062, Backend time ns: 544437593
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554311062, Backend time ns: 544437593
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098767.407|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554303.222|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554303222, Backend time ns: 544566741
2023-05-08T18:29:39,158 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554303222, Backend time ns: 544566741
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098795.178|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554176.545|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554176545, Backend time ns: 544716379
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554176545, Backend time ns: 544716379
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:39,158 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098708.063|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553964.343|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553964343, Backend time ns: 544875858
2023-05-08T18:29:39,158 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553964343, Backend time ns: 544875858
2023-05-08T18:29:39,158 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,159 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098688.052|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553784.633|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553784633, Backend time ns: 544999675
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553784633, Backend time ns: 544999675
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098677.791|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553647.865|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553647865, Backend time ns: 545137912
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553647865, Backend time ns: 545137912
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098562.755|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553397.631|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553397631, Backend time ns: 545278870
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553397631, Backend time ns: 545278870
2023-05-08T18:29:39,159 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098532.594|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553210.201|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553210201, Backend time ns: 545422618
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553210201, Backend time ns: 545422618
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098616.938|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553168.068|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553168068, Backend time ns: 545556206
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553168068, Backend time ns: 545556206
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:39,159 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098567.915|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552982.848|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552982848, Backend time ns: 545679553
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552982848, Backend time ns: 545679553
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:39,159 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098495.222|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552781.537|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552781537, Backend time ns: 545805390
2023-05-08T18:29:39,159 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552781537, Backend time ns: 545805390
2023-05-08T18:29:39,159 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,159 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098394.976|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552564.355|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552564355, Backend time ns: 546357390
2023-05-08T18:29:39,160 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552564355, Backend time ns: 546357390
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098875.312|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552484.61|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552484610, Backend time ns: 546509369
2023-05-08T18:29:39,160 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552484610, Backend time ns: 546509369
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,160 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098918.185|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552376.514|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552376514, Backend time ns: 546666918
2023-05-08T18:29:39,160 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552376514, Backend time ns: 546666918
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098874.862|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552175.913|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552175913, Backend time ns: 546819996
2023-05-08T18:29:39,160 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552175913, Backend time ns: 546819996
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,160 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,160 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098907.105|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552058.577|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552058577, Backend time ns: 546961274
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552058577, Backend time ns: 546961274
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098952.997|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551961.681|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551961681, Backend time ns: 547086851
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551961681, Backend time ns: 547086851
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098880.933|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551767.77|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551767770, Backend time ns: 547233699
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551767770, Backend time ns: 547233699
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098667.641|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551392.41|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551392410, Backend time ns: 547388217
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551392410, Backend time ns: 547388217
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098727.394|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551277.994|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551277994, Backend time ns: 547617920
2023-05-08T18:29:39,161 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551277994, Backend time ns: 547617920
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098943.816|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551240.172|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551240172, Backend time ns: 547820151
2023-05-08T18:29:39,161 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551240172, Backend time ns: 547820151
2023-05-08T18:29:39,161 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:39,161 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098833.44|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550979.557|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550979557, Backend time ns: 547950068
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550979557, Backend time ns: 547950068
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098826.64|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550842.83|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550842830, Backend time ns: 548085876
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550842830, Backend time ns: 548085876
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556007.796|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7895.769|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7895769, Backend time ns: 548208533
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7895769, Backend time ns: 548208533
2023-05-08T18:29:39,162 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556015.327|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7728.58|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7728580, Backend time ns: 548400553
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7728580, Backend time ns: 548400553
2023-05-08T18:29:39,162 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556139.244|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7686.348|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7686348, Backend time ns: 548560772
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7686348, Backend time ns: 548560772
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,162 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556164.456|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7575.462|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7575462, Backend time ns: 548705770
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7575462, Backend time ns: 548705770
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,162 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556250.99|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7517.138|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7517138, Backend time ns: 548845238
2023-05-08T18:29:39,162 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7517138, Backend time ns: 548845238
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,162 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,163 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556010.416|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7138.677|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7138677, Backend time ns: 549018378
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7138677, Backend time ns: 549018378
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556090.841|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7045.352|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7045352, Backend time ns: 549165536
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7045352, Backend time ns: 549165536
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,163 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556121.382|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6926.895|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6926895, Backend time ns: 549295423
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6926895, Backend time ns: 549295423
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,163 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556173.286|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6845.591|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6845591, Backend time ns: 549450772
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6845591, Backend time ns: 549450772
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556276.451|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6799.308|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6799308, Backend time ns: 549583459
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6799308, Backend time ns: 549583459
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556104.962|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6494.371|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6494371, Backend time ns: 549711316
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6494371, Backend time ns: 549711316
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:556088.191|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6350.223|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6350223, Backend time ns: 549873185
2023-05-08T18:29:39,163 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6350223, Backend time ns: 549873185
2023-05-08T18:29:39,163 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,163 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,164 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:39,164 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:39,164 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 541
2023-05-08T18:29:39,164 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 541
2023-05-08T18:29:39,164 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:9.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,164 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,164 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570579164
2023-05-08T18:29:39,164 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570579164
2023-05-08T18:29:39,167 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570579
2023-05-08T18:29:39,167 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,167 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,167 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,167 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,168 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,170 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,172 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,173 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,174 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,175 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:39,176 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:39,176 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:39,181 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:39,218 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:39,243 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:39,250 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:39,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:39,285 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:39,288 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:39,320 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:39,325 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:39,326 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:39,327 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:39,358 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:39,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:39,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:39,368 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:39,397 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:39,404 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:39,406 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:39,408 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:39,436 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:39,442 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:39,446 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:39,448 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:39,474 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:39,487 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:39,488 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:39,512 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:39,527 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:39,529 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:39,567 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:39,569 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:39,611 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:39,705 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:538.11|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570579,a6b1ec89-10cd-4b26-a331-3704cd1fc717,5b2dad7d-b687-4c43-8c19-7f52088fc61a,114847ad-5ae1-4249-804f-2c8882e848e9,b16af92d-ee2c-4eb4-bf9a-0d41ca6c01c6,5f659a4d-2f03-42e1-bbc0-b3f040140adf,d0a52768-69f9-4137-9bed-c13a2ac487f9,f1b97ea6-e5e2-436e-bbc9-960f1321c6d5,1ef1bb70-6677-4f0c-bdd5-ae73d8ae306b,95bcfa2f-12ac-4960-8a7e-0ba6324ae874,f16532bb-2a70-4f20-9178-9c3d3d4d6be5,83b1f20a-0c0c-4865-9007-398959d409a6,ab796b80-017a-4fb6-b256-7ac0e058a056,ea0beebe-7a24-4a39-acab-9d844f1c93d0,75de99e3-ea5d-45da-80ec-30356065d32e,5e7bfc14-0a5b-414a-af46-7e95e9f902f3,c110c722-ccb8-4fbc-a725-a3023a99a4fc,0a71f605-dba8-4e2b-be8c-f8b85e70a742,9ab232e1-cb77-43df-b873-0aab92f5faae,5434268f-f85f-4d5d-aac0-5525807eff16,3cf5c77a-3fd4-45dd-9784-159873d4b079,b9b22f28-d625-4046-ac2b-8424f86de6bb,5f1d4b6d-4cc1-4fcf-9fd7-3fff56e844e1,a62787ae-c2e6-4886-9011-f428e440359f,66aa01e3-1ef6-4fb6-a04c-a7acf55466e4,31107dee-248c-4901-a1e1-6f943f743fb3,984779d7-fabd-4ebb-81c2-7908ddf82639,e97348cd-7902-4719-b530-f9a9b8cb443b,5ae67745-7d15-4293-8013-1d18d114175a,959594dd-003e-4d56-8ff3-e28ed30959dd,2770838e-8fe6-4b34-9957-e008e272223f,a342e43d-6723-43d9-abe0-d4de181bfd6e,50ddbc7a-2558-4650-8736-408b08d7cf8e,1bbea2ac-1d3f-4aa9-bba9-1ed926a333ca,f392ba50-0785-40b9-a353-a3ef6fbd3ecf,d9868eae-5ce7-473d-98a6-4edf61aea347,aca2a04e-2a84-4a38-b8e7-de7d505c6606,43a8ca6f-3615-4076-96f3-28fbc880d271,51d5394e-b808-4fe9-8aef-046e50755fec,9f1cee1e-80a5-4b98-9a55-8ab185872cb7,0cd2a0b4-f226-4a3b-903c-7105c016ce4c,78ac7fc4-51c9-4866-93db-1e00ced653f8,2bc3de82-27c9-445d-86ad-1574ee19ab8b,3da99180-6a16-4baf-8dc1-a33acc04bb55,74c23c29-a301-44d7-9cf0-c683475cfddc,0c2e4045-e255-45e3-b7be-4a6d9e932b99,1a2d8ce9-208e-4a82-9922-afe228ea209f,c1b1bb0e-0e6c-461f-b0c6-aeebbecb6c84,7cc3de0c-1c66-4383-a834-1073cde35329,fce585cb-4e80-44e3-8028-09c2df205ec3,aa87a529-9677-4d08-8301-5b27ccf9fb91,bc295a58-81c8-4715-87e3-1cbc6cd0824b,3565a7e9-4e14-4ca6-9845-90fc91843952,357c667a-44c2-42f2-bf9a-5ca75f018233,774c4c6f-7e6e-4bfc-9eaf-a72b6f3d87e7,a1088aaf-b6bc-4673-bfef-1380674bb476,95946f01-e438-43da-a39b-8efd3d53fd29, pattern=[METRICS]
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:538.11|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570579,a6b1ec89-10cd-4b26-a331-3704cd1fc717,5b2dad7d-b687-4c43-8c19-7f52088fc61a,114847ad-5ae1-4249-804f-2c8882e848e9,b16af92d-ee2c-4eb4-bf9a-0d41ca6c01c6,5f659a4d-2f03-42e1-bbc0-b3f040140adf,d0a52768-69f9-4137-9bed-c13a2ac487f9,f1b97ea6-e5e2-436e-bbc9-960f1321c6d5,1ef1bb70-6677-4f0c-bdd5-ae73d8ae306b,95bcfa2f-12ac-4960-8a7e-0ba6324ae874,f16532bb-2a70-4f20-9178-9c3d3d4d6be5,83b1f20a-0c0c-4865-9007-398959d409a6,ab796b80-017a-4fb6-b256-7ac0e058a056,ea0beebe-7a24-4a39-acab-9d844f1c93d0,75de99e3-ea5d-45da-80ec-30356065d32e,5e7bfc14-0a5b-414a-af46-7e95e9f902f3,c110c722-ccb8-4fbc-a725-a3023a99a4fc,0a71f605-dba8-4e2b-be8c-f8b85e70a742,9ab232e1-cb77-43df-b873-0aab92f5faae,5434268f-f85f-4d5d-aac0-5525807eff16,3cf5c77a-3fd4-45dd-9784-159873d4b079,b9b22f28-d625-4046-ac2b-8424f86de6bb,5f1d4b6d-4cc1-4fcf-9fd7-3fff56e844e1,a62787ae-c2e6-4886-9011-f428e440359f,66aa01e3-1ef6-4fb6-a04c-a7acf55466e4,31107dee-248c-4901-a1e1-6f943f743fb3,984779d7-fabd-4ebb-81c2-7908ddf82639,e97348cd-7902-4719-b530-f9a9b8cb443b,5ae67745-7d15-4293-8013-1d18d114175a,959594dd-003e-4d56-8ff3-e28ed30959dd,2770838e-8fe6-4b34-9957-e008e272223f,a342e43d-6723-43d9-abe0-d4de181bfd6e,50ddbc7a-2558-4650-8736-408b08d7cf8e,1bbea2ac-1d3f-4aa9-bba9-1ed926a333ca,f392ba50-0785-40b9-a353-a3ef6fbd3ecf,d9868eae-5ce7-473d-98a6-4edf61aea347,aca2a04e-2a84-4a38-b8e7-de7d505c6606,43a8ca6f-3615-4076-96f3-28fbc880d271,51d5394e-b808-4fe9-8aef-046e50755fec,9f1cee1e-80a5-4b98-9a55-8ab185872cb7,0cd2a0b4-f226-4a3b-903c-7105c016ce4c,78ac7fc4-51c9-4866-93db-1e00ced653f8,2bc3de82-27c9-445d-86ad-1574ee19ab8b,3da99180-6a16-4baf-8dc1-a33acc04bb55,74c23c29-a301-44d7-9cf0-c683475cfddc,0c2e4045-e255-45e3-b7be-4a6d9e932b99,1a2d8ce9-208e-4a82-9922-afe228ea209f,c1b1bb0e-0e6c-461f-b0c6-aeebbecb6c84,7cc3de0c-1c66-4383-a834-1073cde35329,fce585cb-4e80-44e3-8028-09c2df205ec3,aa87a529-9677-4d08-8301-5b27ccf9fb91,bc295a58-81c8-4715-87e3-1cbc6cd0824b,3565a7e9-4e14-4ca6-9845-90fc91843952,357c667a-44c2-42f2-bf9a-5ca75f018233,774c4c6f-7e6e-4bfc-9eaf-a72b6f3d87e7,a1088aaf-b6bc-4673-bfef-1380674bb476,95946f01-e438-43da-a39b-8efd3d53fd29, pattern=[METRICS]
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:538.11|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:a6b1ec89-10cd-4b26-a331-3704cd1fc717,5b2dad7d-b687-4c43-8c19-7f52088fc61a,114847ad-5ae1-4249-804f-2c8882e848e9,b16af92d-ee2c-4eb4-bf9a-0d41ca6c01c6,5f659a4d-2f03-42e1-bbc0-b3f040140adf,d0a52768-69f9-4137-9bed-c13a2ac487f9,f1b97ea6-e5e2-436e-bbc9-960f1321c6d5,1ef1bb70-6677-4f0c-bdd5-ae73d8ae306b,95bcfa2f-12ac-4960-8a7e-0ba6324ae874,f16532bb-2a70-4f20-9178-9c3d3d4d6be5,83b1f20a-0c0c-4865-9007-398959d409a6,ab796b80-017a-4fb6-b256-7ac0e058a056,ea0beebe-7a24-4a39-acab-9d844f1c93d0,75de99e3-ea5d-45da-80ec-30356065d32e,5e7bfc14-0a5b-414a-af46-7e95e9f902f3,c110c722-ccb8-4fbc-a725-a3023a99a4fc,0a71f605-dba8-4e2b-be8c-f8b85e70a742,9ab232e1-cb77-43df-b873-0aab92f5faae,5434268f-f85f-4d5d-aac0-5525807eff16,3cf5c77a-3fd4-45dd-9784-159873d4b079,b9b22f28-d625-4046-ac2b-8424f86de6bb,5f1d4b6d-4cc1-4fcf-9fd7-3fff56e844e1,a62787ae-c2e6-4886-9011-f428e440359f,66aa01e3-1ef6-4fb6-a04c-a7acf55466e4,31107dee-248c-4901-a1e1-6f943f743fb3,984779d7-fabd-4ebb-81c2-7908ddf82639,e97348cd-7902-4719-b530-f9a9b8cb443b,5ae67745-7d15-4293-8013-1d18d114175a,959594dd-003e-4d56-8ff3-e28ed30959dd,2770838e-8fe6-4b34-9957-e008e272223f,a342e43d-6723-43d9-abe0-d4de181bfd6e,50ddbc7a-2558-4650-8736-408b08d7cf8e,1bbea2ac-1d3f-4aa9-bba9-1ed926a333ca,f392ba50-0785-40b9-a353-a3ef6fbd3ecf,d9868eae-5ce7-473d-98a6-4edf61aea347,aca2a04e-2a84-4a38-b8e7-de7d505c6606,43a8ca6f-3615-4076-96f3-28fbc880d271,51d5394e-b808-4fe9-8aef-046e50755fec,9f1cee1e-80a5-4b98-9a55-8ab185872cb7,0cd2a0b4-f226-4a3b-903c-7105c016ce4c,78ac7fc4-51c9-4866-93db-1e00ced653f8,2bc3de82-27c9-445d-86ad-1574ee19ab8b,3da99180-6a16-4baf-8dc1-a33acc04bb55,74c23c29-a301-44d7-9cf0-c683475cfddc,0c2e4045-e255-45e3-b7be-4a6d9e932b99,1a2d8ce9-208e-4a82-9922-afe228ea209f,c1b1bb0e-0e6c-461f-b0c6-aeebbecb6c84,7cc3de0c-1c66-4383-a834-1073cde35329,fce585cb-4e80-44e3-8028-09c2df205ec3,aa87a529-9677-4d08-8301-5b27ccf9fb91,bc295a58-81c8-4715-87e3-1cbc6cd0824b,3565a7e9-4e14-4ca6-9845-90fc91843952,357c667a-44c2-42f2-bf9a-5ca75f018233,774c4c6f-7e6e-4bfc-9eaf-a72b6f3d87e7,a1088aaf-b6bc-4673-bfef-1380674bb476,95946f01-e438-43da-a39b-8efd3d53fd29,timestamp:1683570579
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:538.2|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570579,a6b1ec89-10cd-4b26-a331-3704cd1fc717,5b2dad7d-b687-4c43-8c19-7f52088fc61a,114847ad-5ae1-4249-804f-2c8882e848e9,b16af92d-ee2c-4eb4-bf9a-0d41ca6c01c6,5f659a4d-2f03-42e1-bbc0-b3f040140adf,d0a52768-69f9-4137-9bed-c13a2ac487f9,f1b97ea6-e5e2-436e-bbc9-960f1321c6d5,1ef1bb70-6677-4f0c-bdd5-ae73d8ae306b,95bcfa2f-12ac-4960-8a7e-0ba6324ae874,f16532bb-2a70-4f20-9178-9c3d3d4d6be5,83b1f20a-0c0c-4865-9007-398959d409a6,ab796b80-017a-4fb6-b256-7ac0e058a056,ea0beebe-7a24-4a39-acab-9d844f1c93d0,75de99e3-ea5d-45da-80ec-30356065d32e,5e7bfc14-0a5b-414a-af46-7e95e9f902f3,c110c722-ccb8-4fbc-a725-a3023a99a4fc,0a71f605-dba8-4e2b-be8c-f8b85e70a742,9ab232e1-cb77-43df-b873-0aab92f5faae,5434268f-f85f-4d5d-aac0-5525807eff16,3cf5c77a-3fd4-45dd-9784-159873d4b079,b9b22f28-d625-4046-ac2b-8424f86de6bb,5f1d4b6d-4cc1-4fcf-9fd7-3fff56e844e1,a62787ae-c2e6-4886-9011-f428e440359f,66aa01e3-1ef6-4fb6-a04c-a7acf55466e4,31107dee-248c-4901-a1e1-6f943f743fb3,984779d7-fabd-4ebb-81c2-7908ddf82639,e97348cd-7902-4719-b530-f9a9b8cb443b,5ae67745-7d15-4293-8013-1d18d114175a,959594dd-003e-4d56-8ff3-e28ed30959dd,2770838e-8fe6-4b34-9957-e008e272223f,a342e43d-6723-43d9-abe0-d4de181bfd6e,50ddbc7a-2558-4650-8736-408b08d7cf8e,1bbea2ac-1d3f-4aa9-bba9-1ed926a333ca,f392ba50-0785-40b9-a353-a3ef6fbd3ecf,d9868eae-5ce7-473d-98a6-4edf61aea347,aca2a04e-2a84-4a38-b8e7-de7d505c6606,43a8ca6f-3615-4076-96f3-28fbc880d271,51d5394e-b808-4fe9-8aef-046e50755fec,9f1cee1e-80a5-4b98-9a55-8ab185872cb7,0cd2a0b4-f226-4a3b-903c-7105c016ce4c,78ac7fc4-51c9-4866-93db-1e00ced653f8,2bc3de82-27c9-445d-86ad-1574ee19ab8b,3da99180-6a16-4baf-8dc1-a33acc04bb55,74c23c29-a301-44d7-9cf0-c683475cfddc,0c2e4045-e255-45e3-b7be-4a6d9e932b99,1a2d8ce9-208e-4a82-9922-afe228ea209f,c1b1bb0e-0e6c-461f-b0c6-aeebbecb6c84,7cc3de0c-1c66-4383-a834-1073cde35329,fce585cb-4e80-44e3-8028-09c2df205ec3,aa87a529-9677-4d08-8301-5b27ccf9fb91,bc295a58-81c8-4715-87e3-1cbc6cd0824b,3565a7e9-4e14-4ca6-9845-90fc91843952,357c667a-44c2-42f2-bf9a-5ca75f018233,774c4c6f-7e6e-4bfc-9eaf-a72b6f3d87e7,a1088aaf-b6bc-4673-bfef-1380674bb476,95946f01-e438-43da-a39b-8efd3d53fd29, pattern=[METRICS]
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:538.2|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570579,a6b1ec89-10cd-4b26-a331-3704cd1fc717,5b2dad7d-b687-4c43-8c19-7f52088fc61a,114847ad-5ae1-4249-804f-2c8882e848e9,b16af92d-ee2c-4eb4-bf9a-0d41ca6c01c6,5f659a4d-2f03-42e1-bbc0-b3f040140adf,d0a52768-69f9-4137-9bed-c13a2ac487f9,f1b97ea6-e5e2-436e-bbc9-960f1321c6d5,1ef1bb70-6677-4f0c-bdd5-ae73d8ae306b,95bcfa2f-12ac-4960-8a7e-0ba6324ae874,f16532bb-2a70-4f20-9178-9c3d3d4d6be5,83b1f20a-0c0c-4865-9007-398959d409a6,ab796b80-017a-4fb6-b256-7ac0e058a056,ea0beebe-7a24-4a39-acab-9d844f1c93d0,75de99e3-ea5d-45da-80ec-30356065d32e,5e7bfc14-0a5b-414a-af46-7e95e9f902f3,c110c722-ccb8-4fbc-a725-a3023a99a4fc,0a71f605-dba8-4e2b-be8c-f8b85e70a742,9ab232e1-cb77-43df-b873-0aab92f5faae,5434268f-f85f-4d5d-aac0-5525807eff16,3cf5c77a-3fd4-45dd-9784-159873d4b079,b9b22f28-d625-4046-ac2b-8424f86de6bb,5f1d4b6d-4cc1-4fcf-9fd7-3fff56e844e1,a62787ae-c2e6-4886-9011-f428e440359f,66aa01e3-1ef6-4fb6-a04c-a7acf55466e4,31107dee-248c-4901-a1e1-6f943f743fb3,984779d7-fabd-4ebb-81c2-7908ddf82639,e97348cd-7902-4719-b530-f9a9b8cb443b,5ae67745-7d15-4293-8013-1d18d114175a,959594dd-003e-4d56-8ff3-e28ed30959dd,2770838e-8fe6-4b34-9957-e008e272223f,a342e43d-6723-43d9-abe0-d4de181bfd6e,50ddbc7a-2558-4650-8736-408b08d7cf8e,1bbea2ac-1d3f-4aa9-bba9-1ed926a333ca,f392ba50-0785-40b9-a353-a3ef6fbd3ecf,d9868eae-5ce7-473d-98a6-4edf61aea347,aca2a04e-2a84-4a38-b8e7-de7d505c6606,43a8ca6f-3615-4076-96f3-28fbc880d271,51d5394e-b808-4fe9-8aef-046e50755fec,9f1cee1e-80a5-4b98-9a55-8ab185872cb7,0cd2a0b4-f226-4a3b-903c-7105c016ce4c,78ac7fc4-51c9-4866-93db-1e00ced653f8,2bc3de82-27c9-445d-86ad-1574ee19ab8b,3da99180-6a16-4baf-8dc1-a33acc04bb55,74c23c29-a301-44d7-9cf0-c683475cfddc,0c2e4045-e255-45e3-b7be-4a6d9e932b99,1a2d8ce9-208e-4a82-9922-afe228ea209f,c1b1bb0e-0e6c-461f-b0c6-aeebbecb6c84,7cc3de0c-1c66-4383-a834-1073cde35329,fce585cb-4e80-44e3-8028-09c2df205ec3,aa87a529-9677-4d08-8301-5b27ccf9fb91,bc295a58-81c8-4715-87e3-1cbc6cd0824b,3565a7e9-4e14-4ca6-9845-90fc91843952,357c667a-44c2-42f2-bf9a-5ca75f018233,774c4c6f-7e6e-4bfc-9eaf-a72b6f3d87e7,a1088aaf-b6bc-4673-bfef-1380674bb476,95946f01-e438-43da-a39b-8efd3d53fd29, pattern=[METRICS]
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:538.2|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:a6b1ec89-10cd-4b26-a331-3704cd1fc717,5b2dad7d-b687-4c43-8c19-7f52088fc61a,114847ad-5ae1-4249-804f-2c8882e848e9,b16af92d-ee2c-4eb4-bf9a-0d41ca6c01c6,5f659a4d-2f03-42e1-bbc0-b3f040140adf,d0a52768-69f9-4137-9bed-c13a2ac487f9,f1b97ea6-e5e2-436e-bbc9-960f1321c6d5,1ef1bb70-6677-4f0c-bdd5-ae73d8ae306b,95bcfa2f-12ac-4960-8a7e-0ba6324ae874,f16532bb-2a70-4f20-9178-9c3d3d4d6be5,83b1f20a-0c0c-4865-9007-398959d409a6,ab796b80-017a-4fb6-b256-7ac0e058a056,ea0beebe-7a24-4a39-acab-9d844f1c93d0,75de99e3-ea5d-45da-80ec-30356065d32e,5e7bfc14-0a5b-414a-af46-7e95e9f902f3,c110c722-ccb8-4fbc-a725-a3023a99a4fc,0a71f605-dba8-4e2b-be8c-f8b85e70a742,9ab232e1-cb77-43df-b873-0aab92f5faae,5434268f-f85f-4d5d-aac0-5525807eff16,3cf5c77a-3fd4-45dd-9784-159873d4b079,b9b22f28-d625-4046-ac2b-8424f86de6bb,5f1d4b6d-4cc1-4fcf-9fd7-3fff56e844e1,a62787ae-c2e6-4886-9011-f428e440359f,66aa01e3-1ef6-4fb6-a04c-a7acf55466e4,31107dee-248c-4901-a1e1-6f943f743fb3,984779d7-fabd-4ebb-81c2-7908ddf82639,e97348cd-7902-4719-b530-f9a9b8cb443b,5ae67745-7d15-4293-8013-1d18d114175a,959594dd-003e-4d56-8ff3-e28ed30959dd,2770838e-8fe6-4b34-9957-e008e272223f,a342e43d-6723-43d9-abe0-d4de181bfd6e,50ddbc7a-2558-4650-8736-408b08d7cf8e,1bbea2ac-1d3f-4aa9-bba9-1ed926a333ca,f392ba50-0785-40b9-a353-a3ef6fbd3ecf,d9868eae-5ce7-473d-98a6-4edf61aea347,aca2a04e-2a84-4a38-b8e7-de7d505c6606,43a8ca6f-3615-4076-96f3-28fbc880d271,51d5394e-b808-4fe9-8aef-046e50755fec,9f1cee1e-80a5-4b98-9a55-8ab185872cb7,0cd2a0b4-f226-4a3b-903c-7105c016ce4c,78ac7fc4-51c9-4866-93db-1e00ced653f8,2bc3de82-27c9-445d-86ad-1574ee19ab8b,3da99180-6a16-4baf-8dc1-a33acc04bb55,74c23c29-a301-44d7-9cf0-c683475cfddc,0c2e4045-e255-45e3-b7be-4a6d9e932b99,1a2d8ce9-208e-4a82-9922-afe228ea209f,c1b1bb0e-0e6c-461f-b0c6-aeebbecb6c84,7cc3de0c-1c66-4383-a834-1073cde35329,fce585cb-4e80-44e3-8028-09c2df205ec3,aa87a529-9677-4d08-8301-5b27ccf9fb91,bc295a58-81c8-4715-87e3-1cbc6cd0824b,3565a7e9-4e14-4ca6-9845-90fc91843952,357c667a-44c2-42f2-bf9a-5ca75f018233,774c4c6f-7e6e-4bfc-9eaf-a72b6f3d87e7,a1088aaf-b6bc-4673-bfef-1380674bb476,95946f01-e438-43da-a39b-8efd3d53fd29,timestamp:1683570579
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098592.797|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556343.635|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,706 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556343635, Backend time ns: 542698477
2023-05-08T18:29:39,706 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556343635, Backend time ns: 542698477
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,706 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099071.354|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556325.394|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556325394, Backend time ns: 542855196
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556325394, Backend time ns: 542855196
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098971.569|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556085.551|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556085551, Backend time ns: 542972023
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556085551, Backend time ns: 542972023
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099000.01|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556002.266|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556002266, Backend time ns: 543082389
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556002266, Backend time ns: 543082389
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098990.369|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555883.339|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555883339, Backend time ns: 543191785
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555883339, Backend time ns: 543191785
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098991.769|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555773.663|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555773663, Backend time ns: 543358634
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555773663, Backend time ns: 543358634
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,707 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098977.288|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555579.352|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555579352, Backend time ns: 543630689
2023-05-08T18:29:39,707 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555579352, Backend time ns: 543630689
2023-05-08T18:29:39,707 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098996.22|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,707 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555321.378|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555321378, Backend time ns: 543789488
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555321378, Backend time ns: 543789488
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099096.856|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555278.446|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555278446, Backend time ns: 543924145
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555278446, Backend time ns: 543924145
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099178.719|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555204.451|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555204451, Backend time ns: 544080164
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555204451, Backend time ns: 544080164
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,708 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099178.43|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555070.564|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555070564, Backend time ns: 544208461
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555070564, Backend time ns: 544208461
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099033.492|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554793.699|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554793699, Backend time ns: 544342239
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554793699, Backend time ns: 544342239
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,708 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099046.632|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554678.702|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554678702, Backend time ns: 544511378
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554678702, Backend time ns: 544511378
2023-05-08T18:29:39,708 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099132.607|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554585.017|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554585017, Backend time ns: 544686198
2023-05-08T18:29:39,708 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554585017, Backend time ns: 544686198
2023-05-08T18:29:39,708 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,708 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099209.271|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554469.381|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554469381, Backend time ns: 544839705
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554469381, Backend time ns: 544839705
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099255.404|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554388.157|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554388157, Backend time ns: 544972873
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554388157, Backend time ns: 544972873
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099117.756|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554118.922|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554118922, Backend time ns: 545127701
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554118922, Backend time ns: 545127701
2023-05-08T18:29:39,709 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099077.064|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553890.439|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553890439, Backend time ns: 545369135
2023-05-08T18:29:39,709 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553890439, Backend time ns: 545369135
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099161.978|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553726.64|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553726640, Backend time ns: 545540024
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553726640, Backend time ns: 545540024
2023-05-08T18:29:39,709 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099138.207|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553559.111|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553559111, Backend time ns: 545661861
2023-05-08T18:29:39,709 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553559111, Backend time ns: 545661861
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099003.39|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,709 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553313.077|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553313077, Backend time ns: 545793958
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553313077, Backend time ns: 545793958
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099067.513|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553229.402|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553229402, Backend time ns: 545976728
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553229402, Backend time ns: 545976728
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,710 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098972.078|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552951.617|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552951617, Backend time ns: 546184220
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552951617, Backend time ns: 546184220
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099092.205|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552876.423|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552876423, Backend time ns: 546307717
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552876423, Backend time ns: 546307717
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,710 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099069.913|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552733.795|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552733795, Backend time ns: 546428564
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552733795, Backend time ns: 546428564
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,710 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099074.913|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552616.218|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552616218, Backend time ns: 546587642
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552616218, Backend time ns: 546587642
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,710 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099074.754|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552459.98|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552459980, Backend time ns: 546719920
2023-05-08T18:29:39,710 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552459980, Backend time ns: 546719920
2023-05-08T18:29:39,710 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,710 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099010.71|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552263.989|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552263989, Backend time ns: 546969564
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552263989, Backend time ns: 546969564
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099149.498|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552148.172|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552148172, Backend time ns: 547086420
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552148172, Backend time ns: 547086420
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099129.337|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552016.555|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552016555, Backend time ns: 547203207
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552016555, Backend time ns: 547203207
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099136.557|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551906.899|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551906899, Backend time ns: 547335644
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551906899, Backend time ns: 547335644
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099172.439|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551811.683|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551811683, Backend time ns: 547436910
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551811683, Backend time ns: 547436910
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099051.113|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551582.751|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551582751, Backend time ns: 547551516
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551582751, Backend time ns: 547551516
2023-05-08T18:29:39,711 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099107.645|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551501.096|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551501096, Backend time ns: 547683814
2023-05-08T18:29:39,711 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551501096, Backend time ns: 547683814
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099097.325|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,711 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551388.13|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551388130, Backend time ns: 547800880
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551388130, Backend time ns: 547800880
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099041.412|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551214.74|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551214740, Backend time ns: 547910586
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551214740, Backend time ns: 547910586
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099027.331|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551087.323|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551087323, Backend time ns: 548020232
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551087323, Backend time ns: 548020232
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099004.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550955.806|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550955806, Backend time ns: 548125298
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550955806, Backend time ns: 548125298
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098959.467|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550795.267|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550795267, Backend time ns: 548373332
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550795267, Backend time ns: 548373332
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099054.023|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550647.679|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550647679, Backend time ns: 548516570
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550647679, Backend time ns: 548516570
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099076.633|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550533.262|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550533262, Backend time ns: 548621956
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550533262, Backend time ns: 548621956
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099139.867|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550460.658|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550460658, Backend time ns: 548772614
2023-05-08T18:29:39,712 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550460658, Backend time ns: 548772614
2023-05-08T18:29:39,713 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099122.176|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550301.449|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550301449, Backend time ns: 548902501
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550301449, Backend time ns: 548902501
2023-05-08T18:29:39,713 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 1100
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1099106.395|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550140.5|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550140500, Backend time ns: 549050050
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550140500, Backend time ns: 549050050
2023-05-08T18:29:39,713 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557156.87|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8063.898|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8063898, Backend time ns: 549164996
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8063898, Backend time ns: 549164996
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557197.723|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:8003.415|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8003415, Backend time ns: 549282673
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 8003415, Backend time ns: 549282673
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557277.417|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7966.813|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7966813, Backend time ns: 549417450
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7966813, Backend time ns: 549417450
2023-05-08T18:29:39,713 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557394.323|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7938.871|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7938871, Backend time ns: 549536947
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7938871, Backend time ns: 549536947
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557463.097|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7896.619|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7896619, Backend time ns: 549685295
2023-05-08T18:29:39,713 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7896619, Backend time ns: 549685295
2023-05-08T18:29:39,713 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:39,713 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557497.549|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7752.961|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7752961, Backend time ns: 549855065
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7752961, Backend time ns: 549855065
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557247.635|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7361.469|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7361469, Backend time ns: 549967191
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7361469, Backend time ns: 549967191
2023-05-08T18:29:39,714 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557350.741|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7317.777|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7317777, Backend time ns: 550115269
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7317777, Backend time ns: 550115269
2023-05-08T18:29:39,714 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 558
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557472.888|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7301.806|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7301806, Backend time ns: 550265967
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7301806, Backend time ns: 550265967
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:39,714 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557406.814|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7109.385|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7109385, Backend time ns: 550382254
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7109385, Backend time ns: 550382254
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557483.748|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7073.303|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7073303, Backend time ns: 550487270
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7073303, Backend time ns: 550487270
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 557
2023-05-08T18:29:39,714 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:557527.491|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7013.78|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7013780, Backend time ns: 550638158
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7013780, Backend time ns: 550638158
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:39,714 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,714 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-05-08T18:29:39,714 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,715 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570579
2023-05-08T18:29:39,715 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570579715
2023-05-08T18:29:39,715 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570579715
2023-05-08T18:29:39,717 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570579
2023-05-08T18:29:39,718 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,718 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,718 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,718 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,718 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,718 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,718 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,718 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,720 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,722 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,723 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:39,725 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:39,726 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:39,726 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:39,727 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:39,732 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:39,769 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:39,792 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:39,798 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:39,830 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:39,834 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:39,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:39,868 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:39,874 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:39,875 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:39,877 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:39,907 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:39,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:39,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:39,917 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:39,945 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:39,951 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:39,955 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:39,957 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:39,983 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:39,990 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:39,996 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:39,997 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:40,022 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:40,036 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:40,038 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:40,060 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:40,076 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:40,078 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:40,116 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:40,119 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:40,160 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:536.73|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570580,e7b3da1b-d47d-4f55-81f6-25678c6e8c6c,3d6e3817-fe87-422c-8529-b56e9b505732,7b4e25d1-74c7-441d-96c1-a30d3157bbe0,cb571ac0-e650-4538-89a9-ab470b926433,7c8c4e04-1667-4f7c-b2ea-7cf04095654a,afffb0d9-55a5-4080-945b-ff93215b2e2e,5af4db4a-5a23-4149-b181-85dfcf773a2d,1336ebeb-386f-4400-a0ad-22d088e7d60f,702fdbda-6b03-4d9d-818f-de04423e606a,a6438043-b518-4a54-ab16-45a257a30058,2f3b5577-7468-487b-b53d-6560943e27d3,98645806-5945-4576-93c1-6bfa37953631,e4891e8d-b537-4d7f-9d67-35d427c07d1f,d885d54e-701b-4ae7-9b00-b768bc9dd4b1,3db940e2-4cef-41a0-8ae9-6ef540353dbc,59468ad7-d33b-4da8-9a38-1764a959f872,c53cc3f5-c5e7-46eb-a4b6-edb877213422,c537b235-1670-45e0-ab37-f10bfc2a956e,28c2a613-f46c-45d6-83c8-e48948e17995,0a4e2fb1-ab04-476b-94ad-4be93517b3bc,c0f67851-ed60-45fc-8fc4-13a42d447e6e,b137d85f-6697-4207-a3e4-6df50acb4e13,c5216eeb-3cf3-444e-aafb-c2c28cb6c8d4,b0a6b80c-e551-40e1-81e2-d7799d7e55d6,18143456-829b-4de3-8aae-789dcd218968,d7db8021-c67c-4637-aec7-4427e0f06b21,8efbd0c2-3063-4673-9504-eb2c0e982b4c,ef0546f9-cea2-4536-9afd-2b97cd6cef7c,a0d45484-6473-4736-8b92-b9b8407af2db,41ebe866-6659-43d6-acc4-dcd535723670,c3f14487-3731-4daf-b1ee-811af7faf20b,8150ce8f-fb79-461a-ba89-49df24c673ed,945448fa-f68b-47de-a4f2-08d64b171342,ca07a4e6-34bb-459d-b2f2-c4e80f4bc2f3,32ed8960-abc6-4d9f-b539-1cefc8242d68,4f00b66a-f870-4323-a9f1-aa72a47f822d,b398a294-b9ac-401e-ae63-9f7a2bfa9976,c9a388fe-fff2-4814-9fa1-0b48af7c89a5,7fe60a01-713d-4b31-88c1-efaca49af6d9,6d15ed7a-a783-4b57-83dc-152a62e52e83,82822967-db58-4d68-bb26-1fbd366bbb69,f32edd80-b156-4831-b111-c92807d49b50,f6c5b318-ea95-4bbf-9a2d-249b12dcb16e,ddd180c9-623d-4e4a-9168-900c588474b5,3ce89285-07c8-4898-b861-b761048a1799,529d3687-bc06-4ea0-8fc8-da5862ab19d8,cf74888c-ada1-46d2-9c69-5d1e2bc4d86e,d0033411-67fc-443d-abc2-4c439368faf7,f490026c-01c2-4ecc-9160-ef6357fb5b9e,5468875f-8617-47e5-9e65-04db1f670f6e,701ae518-5e09-4820-aabc-9c465e148305,a973e4cd-b965-4256-98ee-7d1cd2ff3f93,77b6d06b-addd-4898-b1fa-ae7e47e507e9,e3a8d1bd-1607-4542-85c2-10a402809c72,d241a6be-d895-4160-acec-0d35aee5da36,2a36fdd8-a1bb-4185-9f48-6dfc85d9de44, pattern=[METRICS]
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:536.73|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570580,e7b3da1b-d47d-4f55-81f6-25678c6e8c6c,3d6e3817-fe87-422c-8529-b56e9b505732,7b4e25d1-74c7-441d-96c1-a30d3157bbe0,cb571ac0-e650-4538-89a9-ab470b926433,7c8c4e04-1667-4f7c-b2ea-7cf04095654a,afffb0d9-55a5-4080-945b-ff93215b2e2e,5af4db4a-5a23-4149-b181-85dfcf773a2d,1336ebeb-386f-4400-a0ad-22d088e7d60f,702fdbda-6b03-4d9d-818f-de04423e606a,a6438043-b518-4a54-ab16-45a257a30058,2f3b5577-7468-487b-b53d-6560943e27d3,98645806-5945-4576-93c1-6bfa37953631,e4891e8d-b537-4d7f-9d67-35d427c07d1f,d885d54e-701b-4ae7-9b00-b768bc9dd4b1,3db940e2-4cef-41a0-8ae9-6ef540353dbc,59468ad7-d33b-4da8-9a38-1764a959f872,c53cc3f5-c5e7-46eb-a4b6-edb877213422,c537b235-1670-45e0-ab37-f10bfc2a956e,28c2a613-f46c-45d6-83c8-e48948e17995,0a4e2fb1-ab04-476b-94ad-4be93517b3bc,c0f67851-ed60-45fc-8fc4-13a42d447e6e,b137d85f-6697-4207-a3e4-6df50acb4e13,c5216eeb-3cf3-444e-aafb-c2c28cb6c8d4,b0a6b80c-e551-40e1-81e2-d7799d7e55d6,18143456-829b-4de3-8aae-789dcd218968,d7db8021-c67c-4637-aec7-4427e0f06b21,8efbd0c2-3063-4673-9504-eb2c0e982b4c,ef0546f9-cea2-4536-9afd-2b97cd6cef7c,a0d45484-6473-4736-8b92-b9b8407af2db,41ebe866-6659-43d6-acc4-dcd535723670,c3f14487-3731-4daf-b1ee-811af7faf20b,8150ce8f-fb79-461a-ba89-49df24c673ed,945448fa-f68b-47de-a4f2-08d64b171342,ca07a4e6-34bb-459d-b2f2-c4e80f4bc2f3,32ed8960-abc6-4d9f-b539-1cefc8242d68,4f00b66a-f870-4323-a9f1-aa72a47f822d,b398a294-b9ac-401e-ae63-9f7a2bfa9976,c9a388fe-fff2-4814-9fa1-0b48af7c89a5,7fe60a01-713d-4b31-88c1-efaca49af6d9,6d15ed7a-a783-4b57-83dc-152a62e52e83,82822967-db58-4d68-bb26-1fbd366bbb69,f32edd80-b156-4831-b111-c92807d49b50,f6c5b318-ea95-4bbf-9a2d-249b12dcb16e,ddd180c9-623d-4e4a-9168-900c588474b5,3ce89285-07c8-4898-b861-b761048a1799,529d3687-bc06-4ea0-8fc8-da5862ab19d8,cf74888c-ada1-46d2-9c69-5d1e2bc4d86e,d0033411-67fc-443d-abc2-4c439368faf7,f490026c-01c2-4ecc-9160-ef6357fb5b9e,5468875f-8617-47e5-9e65-04db1f670f6e,701ae518-5e09-4820-aabc-9c465e148305,a973e4cd-b965-4256-98ee-7d1cd2ff3f93,77b6d06b-addd-4898-b1fa-ae7e47e507e9,e3a8d1bd-1607-4542-85c2-10a402809c72,d241a6be-d895-4160-acec-0d35aee5da36,2a36fdd8-a1bb-4185-9f48-6dfc85d9de44, pattern=[METRICS]
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:536.73|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:e7b3da1b-d47d-4f55-81f6-25678c6e8c6c,3d6e3817-fe87-422c-8529-b56e9b505732,7b4e25d1-74c7-441d-96c1-a30d3157bbe0,cb571ac0-e650-4538-89a9-ab470b926433,7c8c4e04-1667-4f7c-b2ea-7cf04095654a,afffb0d9-55a5-4080-945b-ff93215b2e2e,5af4db4a-5a23-4149-b181-85dfcf773a2d,1336ebeb-386f-4400-a0ad-22d088e7d60f,702fdbda-6b03-4d9d-818f-de04423e606a,a6438043-b518-4a54-ab16-45a257a30058,2f3b5577-7468-487b-b53d-6560943e27d3,98645806-5945-4576-93c1-6bfa37953631,e4891e8d-b537-4d7f-9d67-35d427c07d1f,d885d54e-701b-4ae7-9b00-b768bc9dd4b1,3db940e2-4cef-41a0-8ae9-6ef540353dbc,59468ad7-d33b-4da8-9a38-1764a959f872,c53cc3f5-c5e7-46eb-a4b6-edb877213422,c537b235-1670-45e0-ab37-f10bfc2a956e,28c2a613-f46c-45d6-83c8-e48948e17995,0a4e2fb1-ab04-476b-94ad-4be93517b3bc,c0f67851-ed60-45fc-8fc4-13a42d447e6e,b137d85f-6697-4207-a3e4-6df50acb4e13,c5216eeb-3cf3-444e-aafb-c2c28cb6c8d4,b0a6b80c-e551-40e1-81e2-d7799d7e55d6,18143456-829b-4de3-8aae-789dcd218968,d7db8021-c67c-4637-aec7-4427e0f06b21,8efbd0c2-3063-4673-9504-eb2c0e982b4c,ef0546f9-cea2-4536-9afd-2b97cd6cef7c,a0d45484-6473-4736-8b92-b9b8407af2db,41ebe866-6659-43d6-acc4-dcd535723670,c3f14487-3731-4daf-b1ee-811af7faf20b,8150ce8f-fb79-461a-ba89-49df24c673ed,945448fa-f68b-47de-a4f2-08d64b171342,ca07a4e6-34bb-459d-b2f2-c4e80f4bc2f3,32ed8960-abc6-4d9f-b539-1cefc8242d68,4f00b66a-f870-4323-a9f1-aa72a47f822d,b398a294-b9ac-401e-ae63-9f7a2bfa9976,c9a388fe-fff2-4814-9fa1-0b48af7c89a5,7fe60a01-713d-4b31-88c1-efaca49af6d9,6d15ed7a-a783-4b57-83dc-152a62e52e83,82822967-db58-4d68-bb26-1fbd366bbb69,f32edd80-b156-4831-b111-c92807d49b50,f6c5b318-ea95-4bbf-9a2d-249b12dcb16e,ddd180c9-623d-4e4a-9168-900c588474b5,3ce89285-07c8-4898-b861-b761048a1799,529d3687-bc06-4ea0-8fc8-da5862ab19d8,cf74888c-ada1-46d2-9c69-5d1e2bc4d86e,d0033411-67fc-443d-abc2-4c439368faf7,f490026c-01c2-4ecc-9160-ef6357fb5b9e,5468875f-8617-47e5-9e65-04db1f670f6e,701ae518-5e09-4820-aabc-9c465e148305,a973e4cd-b965-4256-98ee-7d1cd2ff3f93,77b6d06b-addd-4898-b1fa-ae7e47e507e9,e3a8d1bd-1607-4542-85c2-10a402809c72,d241a6be-d895-4160-acec-0d35aee5da36,2a36fdd8-a1bb-4185-9f48-6dfc85d9de44,timestamp:1683570580
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:536.82|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570580,e7b3da1b-d47d-4f55-81f6-25678c6e8c6c,3d6e3817-fe87-422c-8529-b56e9b505732,7b4e25d1-74c7-441d-96c1-a30d3157bbe0,cb571ac0-e650-4538-89a9-ab470b926433,7c8c4e04-1667-4f7c-b2ea-7cf04095654a,afffb0d9-55a5-4080-945b-ff93215b2e2e,5af4db4a-5a23-4149-b181-85dfcf773a2d,1336ebeb-386f-4400-a0ad-22d088e7d60f,702fdbda-6b03-4d9d-818f-de04423e606a,a6438043-b518-4a54-ab16-45a257a30058,2f3b5577-7468-487b-b53d-6560943e27d3,98645806-5945-4576-93c1-6bfa37953631,e4891e8d-b537-4d7f-9d67-35d427c07d1f,d885d54e-701b-4ae7-9b00-b768bc9dd4b1,3db940e2-4cef-41a0-8ae9-6ef540353dbc,59468ad7-d33b-4da8-9a38-1764a959f872,c53cc3f5-c5e7-46eb-a4b6-edb877213422,c537b235-1670-45e0-ab37-f10bfc2a956e,28c2a613-f46c-45d6-83c8-e48948e17995,0a4e2fb1-ab04-476b-94ad-4be93517b3bc,c0f67851-ed60-45fc-8fc4-13a42d447e6e,b137d85f-6697-4207-a3e4-6df50acb4e13,c5216eeb-3cf3-444e-aafb-c2c28cb6c8d4,b0a6b80c-e551-40e1-81e2-d7799d7e55d6,18143456-829b-4de3-8aae-789dcd218968,d7db8021-c67c-4637-aec7-4427e0f06b21,8efbd0c2-3063-4673-9504-eb2c0e982b4c,ef0546f9-cea2-4536-9afd-2b97cd6cef7c,a0d45484-6473-4736-8b92-b9b8407af2db,41ebe866-6659-43d6-acc4-dcd535723670,c3f14487-3731-4daf-b1ee-811af7faf20b,8150ce8f-fb79-461a-ba89-49df24c673ed,945448fa-f68b-47de-a4f2-08d64b171342,ca07a4e6-34bb-459d-b2f2-c4e80f4bc2f3,32ed8960-abc6-4d9f-b539-1cefc8242d68,4f00b66a-f870-4323-a9f1-aa72a47f822d,b398a294-b9ac-401e-ae63-9f7a2bfa9976,c9a388fe-fff2-4814-9fa1-0b48af7c89a5,7fe60a01-713d-4b31-88c1-efaca49af6d9,6d15ed7a-a783-4b57-83dc-152a62e52e83,82822967-db58-4d68-bb26-1fbd366bbb69,f32edd80-b156-4831-b111-c92807d49b50,f6c5b318-ea95-4bbf-9a2d-249b12dcb16e,ddd180c9-623d-4e4a-9168-900c588474b5,3ce89285-07c8-4898-b861-b761048a1799,529d3687-bc06-4ea0-8fc8-da5862ab19d8,cf74888c-ada1-46d2-9c69-5d1e2bc4d86e,d0033411-67fc-443d-abc2-4c439368faf7,f490026c-01c2-4ecc-9160-ef6357fb5b9e,5468875f-8617-47e5-9e65-04db1f670f6e,701ae518-5e09-4820-aabc-9c465e148305,a973e4cd-b965-4256-98ee-7d1cd2ff3f93,77b6d06b-addd-4898-b1fa-ae7e47e507e9,e3a8d1bd-1607-4542-85c2-10a402809c72,d241a6be-d895-4160-acec-0d35aee5da36,2a36fdd8-a1bb-4185-9f48-6dfc85d9de44, pattern=[METRICS]
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:536.82|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570580,e7b3da1b-d47d-4f55-81f6-25678c6e8c6c,3d6e3817-fe87-422c-8529-b56e9b505732,7b4e25d1-74c7-441d-96c1-a30d3157bbe0,cb571ac0-e650-4538-89a9-ab470b926433,7c8c4e04-1667-4f7c-b2ea-7cf04095654a,afffb0d9-55a5-4080-945b-ff93215b2e2e,5af4db4a-5a23-4149-b181-85dfcf773a2d,1336ebeb-386f-4400-a0ad-22d088e7d60f,702fdbda-6b03-4d9d-818f-de04423e606a,a6438043-b518-4a54-ab16-45a257a30058,2f3b5577-7468-487b-b53d-6560943e27d3,98645806-5945-4576-93c1-6bfa37953631,e4891e8d-b537-4d7f-9d67-35d427c07d1f,d885d54e-701b-4ae7-9b00-b768bc9dd4b1,3db940e2-4cef-41a0-8ae9-6ef540353dbc,59468ad7-d33b-4da8-9a38-1764a959f872,c53cc3f5-c5e7-46eb-a4b6-edb877213422,c537b235-1670-45e0-ab37-f10bfc2a956e,28c2a613-f46c-45d6-83c8-e48948e17995,0a4e2fb1-ab04-476b-94ad-4be93517b3bc,c0f67851-ed60-45fc-8fc4-13a42d447e6e,b137d85f-6697-4207-a3e4-6df50acb4e13,c5216eeb-3cf3-444e-aafb-c2c28cb6c8d4,b0a6b80c-e551-40e1-81e2-d7799d7e55d6,18143456-829b-4de3-8aae-789dcd218968,d7db8021-c67c-4637-aec7-4427e0f06b21,8efbd0c2-3063-4673-9504-eb2c0e982b4c,ef0546f9-cea2-4536-9afd-2b97cd6cef7c,a0d45484-6473-4736-8b92-b9b8407af2db,41ebe866-6659-43d6-acc4-dcd535723670,c3f14487-3731-4daf-b1ee-811af7faf20b,8150ce8f-fb79-461a-ba89-49df24c673ed,945448fa-f68b-47de-a4f2-08d64b171342,ca07a4e6-34bb-459d-b2f2-c4e80f4bc2f3,32ed8960-abc6-4d9f-b539-1cefc8242d68,4f00b66a-f870-4323-a9f1-aa72a47f822d,b398a294-b9ac-401e-ae63-9f7a2bfa9976,c9a388fe-fff2-4814-9fa1-0b48af7c89a5,7fe60a01-713d-4b31-88c1-efaca49af6d9,6d15ed7a-a783-4b57-83dc-152a62e52e83,82822967-db58-4d68-bb26-1fbd366bbb69,f32edd80-b156-4831-b111-c92807d49b50,f6c5b318-ea95-4bbf-9a2d-249b12dcb16e,ddd180c9-623d-4e4a-9168-900c588474b5,3ce89285-07c8-4898-b861-b761048a1799,529d3687-bc06-4ea0-8fc8-da5862ab19d8,cf74888c-ada1-46d2-9c69-5d1e2bc4d86e,d0033411-67fc-443d-abc2-4c439368faf7,f490026c-01c2-4ecc-9160-ef6357fb5b9e,5468875f-8617-47e5-9e65-04db1f670f6e,701ae518-5e09-4820-aabc-9c465e148305,a973e4cd-b965-4256-98ee-7d1cd2ff3f93,77b6d06b-addd-4898-b1fa-ae7e47e507e9,e3a8d1bd-1607-4542-85c2-10a402809c72,d241a6be-d895-4160-acec-0d35aee5da36,2a36fdd8-a1bb-4185-9f48-6dfc85d9de44, pattern=[METRICS]
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:536.82|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:e7b3da1b-d47d-4f55-81f6-25678c6e8c6c,3d6e3817-fe87-422c-8529-b56e9b505732,7b4e25d1-74c7-441d-96c1-a30d3157bbe0,cb571ac0-e650-4538-89a9-ab470b926433,7c8c4e04-1667-4f7c-b2ea-7cf04095654a,afffb0d9-55a5-4080-945b-ff93215b2e2e,5af4db4a-5a23-4149-b181-85dfcf773a2d,1336ebeb-386f-4400-a0ad-22d088e7d60f,702fdbda-6b03-4d9d-818f-de04423e606a,a6438043-b518-4a54-ab16-45a257a30058,2f3b5577-7468-487b-b53d-6560943e27d3,98645806-5945-4576-93c1-6bfa37953631,e4891e8d-b537-4d7f-9d67-35d427c07d1f,d885d54e-701b-4ae7-9b00-b768bc9dd4b1,3db940e2-4cef-41a0-8ae9-6ef540353dbc,59468ad7-d33b-4da8-9a38-1764a959f872,c53cc3f5-c5e7-46eb-a4b6-edb877213422,c537b235-1670-45e0-ab37-f10bfc2a956e,28c2a613-f46c-45d6-83c8-e48948e17995,0a4e2fb1-ab04-476b-94ad-4be93517b3bc,c0f67851-ed60-45fc-8fc4-13a42d447e6e,b137d85f-6697-4207-a3e4-6df50acb4e13,c5216eeb-3cf3-444e-aafb-c2c28cb6c8d4,b0a6b80c-e551-40e1-81e2-d7799d7e55d6,18143456-829b-4de3-8aae-789dcd218968,d7db8021-c67c-4637-aec7-4427e0f06b21,8efbd0c2-3063-4673-9504-eb2c0e982b4c,ef0546f9-cea2-4536-9afd-2b97cd6cef7c,a0d45484-6473-4736-8b92-b9b8407af2db,41ebe866-6659-43d6-acc4-dcd535723670,c3f14487-3731-4daf-b1ee-811af7faf20b,8150ce8f-fb79-461a-ba89-49df24c673ed,945448fa-f68b-47de-a4f2-08d64b171342,ca07a4e6-34bb-459d-b2f2-c4e80f4bc2f3,32ed8960-abc6-4d9f-b539-1cefc8242d68,4f00b66a-f870-4323-a9f1-aa72a47f822d,b398a294-b9ac-401e-ae63-9f7a2bfa9976,c9a388fe-fff2-4814-9fa1-0b48af7c89a5,7fe60a01-713d-4b31-88c1-efaca49af6d9,6d15ed7a-a783-4b57-83dc-152a62e52e83,82822967-db58-4d68-bb26-1fbd366bbb69,f32edd80-b156-4831-b111-c92807d49b50,f6c5b318-ea95-4bbf-9a2d-249b12dcb16e,ddd180c9-623d-4e4a-9168-900c588474b5,3ce89285-07c8-4898-b861-b761048a1799,529d3687-bc06-4ea0-8fc8-da5862ab19d8,cf74888c-ada1-46d2-9c69-5d1e2bc4d86e,d0033411-67fc-443d-abc2-4c439368faf7,f490026c-01c2-4ecc-9160-ef6357fb5b9e,5468875f-8617-47e5-9e65-04db1f670f6e,701ae518-5e09-4820-aabc-9c465e148305,a973e4cd-b965-4256-98ee-7d1cd2ff3f93,77b6d06b-addd-4898-b1fa-ae7e47e507e9,e3a8d1bd-1607-4542-85c2-10a402809c72,d241a6be-d895-4160-acec-0d35aee5da36,2a36fdd8-a1bb-4185-9f48-6dfc85d9de44,timestamp:1683570580
2023-05-08T18:29:40,255 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098426.318|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557696.7|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557696700, Backend time ns: 541044385
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557696700, Backend time ns: 541044385
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098516.202|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557419.374|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557419374, Backend time ns: 541212885
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557419374, Backend time ns: 541212885
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098529.833|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557289.177|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557289177, Backend time ns: 541352393
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557289177, Backend time ns: 541352393
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098551.655|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:557158.071|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557158071, Backend time ns: 541534272
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 557158071, Backend time ns: 541534272
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:557.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098507.882|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556931.958|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556931958, Backend time ns: 541742493
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556931958, Backend time ns: 541742493
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098677.962|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556902.857|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556902857, Backend time ns: 541865980
2023-05-08T18:29:40,256 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556902857, Backend time ns: 541865980
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,256 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098637.049|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556747.278|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556747278, Backend time ns: 541969466
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556747278, Backend time ns: 541969466
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098613.818|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556620.101|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556620101, Backend time ns: 542058151
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556620101, Backend time ns: 542058151
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098478.18|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556389.268|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556389268, Backend time ns: 542162917
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556389268, Backend time ns: 542162917
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098406.006|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556215.468|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556215468, Backend time ns: 542259712
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556215468, Backend time ns: 542259712
2023-05-08T18:29:40,257 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,257 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098465.64|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556168.556|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556168556, Backend time ns: 542448302
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556168556, Backend time ns: 542448302
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098508.132|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:556034.248|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556034248, Backend time ns: 542556058
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 556034248, Backend time ns: 542556058
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:556.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098438.949|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555859.229|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555859229, Backend time ns: 542654244
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555859229, Backend time ns: 542654244
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098423.497|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555740.482|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555740482, Backend time ns: 542762810
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555740482, Backend time ns: 542762810
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098459.53|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555663.648|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555663648, Backend time ns: 542886047
2023-05-08T18:29:40,257 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555663648, Backend time ns: 542886047
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,257 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098376.895|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555466.067|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555466067, Backend time ns: 543000303
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555466067, Backend time ns: 543000303
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098414.247|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555360.561|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555360561, Backend time ns: 543196034
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555360561, Backend time ns: 543196034
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098450.379|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555224.603|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555224603, Backend time ns: 543353123
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555224603, Backend time ns: 543353123
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 1099
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098486.421|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555106.757|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555106757, Backend time ns: 543478860
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555106757, Backend time ns: 543478860
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098481.24|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554939.927|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554939927, Backend time ns: 543615757
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554939927, Backend time ns: 543615757
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098010.195|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554369.596|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554369596, Backend time ns: 543729784
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554369596, Backend time ns: 543729784
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097987.193|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554233.448|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554233448, Backend time ns: 543842900
2023-05-08T18:29:40,258 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554233448, Backend time ns: 543842900
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,258 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,258 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097952.331|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554078.349|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554078349, Backend time ns: 543971147
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554078349, Backend time ns: 543971147
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,259 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097961.052|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553965.083|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553965083, Backend time ns: 544134856
2023-05-08T18:29:40,259 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553965083, Backend time ns: 544134856
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098012.214|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553825.185|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553825185, Backend time ns: 544278314
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553825185, Backend time ns: 544278314
2023-05-08T18:29:40,259 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098005.044|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553678.297|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553678297, Backend time ns: 544431263
2023-05-08T18:29:40,259 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553678297, Backend time ns: 544431263
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,259 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1098061.578|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553523.409|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553523409, Backend time ns: 544632664
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553523409, Backend time ns: 544632664
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097979.072|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553321.837|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553321837, Backend time ns: 544766921
2023-05-08T18:29:40,259 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553321837, Backend time ns: 544766921
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097943.231|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,259 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553131.727|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553131727, Backend time ns: 544940691
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553131727, Backend time ns: 544940691
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097966.452|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552979.858|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552979858, Backend time ns: 545147073
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552979858, Backend time ns: 545147073
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097894.458|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552720.194|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552720194, Backend time ns: 545289441
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552720194, Backend time ns: 545289441
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097851.765|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552533.913|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552533913, Backend time ns: 545391386
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552533913, Backend time ns: 545391386
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097915.739|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552494.561|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552494561, Backend time ns: 545508493
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552494561, Backend time ns: 545508493
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097862.516|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552327.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552327552, Backend time ns: 545621249
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552327552, Backend time ns: 545621249
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097837.435|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552190.764|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552190764, Backend time ns: 545772518
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552190764, Backend time ns: 545772518
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097844.345|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552028.165|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552028165, Backend time ns: 545895254
2023-05-08T18:29:40,260 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552028165, Backend time ns: 545895254
2023-05-08T18:29:40,260 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,260 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097840.415|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551889.908|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551889908, Backend time ns: 546056583
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551889908, Backend time ns: 546056583
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097831.314|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551744.709|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551744709, Backend time ns: 546168930
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551744709, Backend time ns: 546168930
2023-05-08T18:29:40,261 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097801.102|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551583.75|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551583750, Backend time ns: 546300957
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551583750, Backend time ns: 546300957
2023-05-08T18:29:40,261 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097766.061|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551431.452|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551431452, Backend time ns: 546409733
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551431452, Backend time ns: 546409733
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097730.298|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551295.434|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551295434, Backend time ns: 546519319
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551295434, Backend time ns: 546519319
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,261 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097664.295|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551113.934|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551113934, Backend time ns: 546640056
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551113934, Backend time ns: 546640056
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 1098
2023-05-08T18:29:40,261 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097721.768|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551057.261|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551057261, Backend time ns: 546730871
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551057261, Backend time ns: 546730871
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1097686.936|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550932.844|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550932844, Backend time ns: 546830146
2023-05-08T18:29:40,261 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550932844, Backend time ns: 546830146
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:40,261 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,261 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554262.209|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7406.941|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7406941, Backend time ns: 546936652
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7406941, Backend time ns: 546936652
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554348.464|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7383.71|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7383710, Backend time ns: 547095841
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7383710, Backend time ns: 547095841
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554448.85|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7326.687|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7326687, Backend time ns: 547222598
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7326687, Backend time ns: 547222598
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554533.244|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7286.174|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7286174, Backend time ns: 547349725
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7286174, Backend time ns: 547349725
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554630.339|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7244.492|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7244492, Backend time ns: 547463422
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7244492, Backend time ns: 547463422
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554693.403|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7203.82|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7203820, Backend time ns: 547590109
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7203820, Backend time ns: 547590109
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554735.065|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7117.785|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7117785, Backend time ns: 547716496
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7117785, Backend time ns: 547716496
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554470.881|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6720.723|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6720723, Backend time ns: 547830812
2023-05-08T18:29:40,262 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6720723, Backend time ns: 547830812
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,262 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554553.605|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6690.291|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6690291, Backend time ns: 547942218
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6690291, Backend time ns: 547942218
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,263 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554519.974|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6553.214|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6553214, Backend time ns: 548059775
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6553214, Backend time ns: 548059775
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,263 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554525.553|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6438.747|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6438747, Backend time ns: 548169321
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6438747, Backend time ns: 548169321
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554529.565|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6333.812|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6333812, Backend time ns: 548282197
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6333812, Backend time ns: 548282197
2023-05-08T18:29:40,263 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:40,263 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 540
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 540
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570580263
2023-05-08T18:29:40,263 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570580263
2023-05-08T18:29:40,266 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570580
2023-05-08T18:29:40,266 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,266 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,268 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,270 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,272 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,273 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,274 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,274 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,274 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,274 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,274 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:40,275 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:40,275 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:40,281 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:40,317 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:40,338 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:40,344 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:40,376 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:40,381 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:40,383 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:40,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:40,421 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:40,422 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:40,423 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:40,453 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:40,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:40,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:40,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:40,492 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:40,498 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:40,502 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:40,504 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:40,530 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:40,537 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:40,542 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:40,544 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:40,570 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:40,583 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:40,584 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:40,608 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:40,623 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:40,625 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:40,663 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:40,665 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:40,707 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:535.04|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570580,7f568e26-93b9-41c1-9ec0-1d3b2c7bf88a,9dff9570-66e3-4d04-b38d-5294f7e388cd,d2c5c118-5554-4307-8fae-563a4436e56d,6115b4c0-0b6b-4374-8e86-fe2d469b5918,7bfe065c-aaf5-4750-b669-5a607c72477b,e8d0da82-bc63-47b1-b2e0-fa8804e6ecfd,9470a5ed-3625-4954-8dcf-46cbf5dde717,21e6aa4a-9ff5-4755-8055-b3aa150a51c1,8e7f1bdc-5bc1-482a-8bda-d6bc96a63c59,617d73eb-8008-4cec-8c11-fee3d3ee0f51,8e252a56-6042-4020-a89e-fe4fc5747144,3b5708de-28f0-4eec-9751-1981b934263d,1997e701-85ce-44d9-a532-d70ff355194e,3af112ea-a272-46fa-9fd4-e87feffb6829,4eaf7369-caba-49b5-905e-126ffb86cf5d,64f3a87d-5390-4e64-b751-b92a5a1a5b19,c8090231-10a9-487e-8b3b-6a4c52b99ec6,b146437f-2d3d-4a25-ab87-0ad7bc82f925,f47211f3-8b3d-4278-abf9-2d82be8c3397,dfce9974-dccc-4ce4-b52b-aa2e2c8ecc0a,78564541-623e-43da-ada0-174ef05137c6,42d51bb5-d3e6-4736-9b92-2fc725698342,1d9b9c06-25e0-4296-ab38-7ec0aaaff120,3cc61bbb-e97c-4865-9a87-35f77f008b5c,419e64c4-7129-4f6f-8ddf-ed7ebfcdd115,e84839ed-8abb-4549-a7a8-4a6920a87a05,ba333209-fd90-4a8f-95a0-f5dc046356a0,bd78b8fb-e799-46ef-b9ac-d2ea2cad75a8,1a59e245-adb7-4492-ba96-58119ac1ef4f,f9cd1042-1a36-4e31-9d83-ae03e5ea0f4f,cc3f042d-3e61-4942-8310-4e9f287341c7,19b71da4-a23d-4583-b1e3-644251ad2589,e3470b43-1865-4c7d-aacc-95a020a9f627,e353a9e0-55e2-40ea-b0c7-ca5499cabb11,f20e3767-0265-4629-ae9f-c443a4956b33,2a68af72-e92e-446d-89c6-ce311313c4dc,71836f73-5406-402f-a888-8aebdd786893,4e98ee4f-325e-412a-9e19-25a155473432,cfb79704-168c-4515-bfc4-87f4fbb45e8c,36e0acbe-35cc-4f58-b4f9-09c024c85c4a,c64b4cc6-e3b8-47a1-8544-9af20b4991d0,a37946ee-bb88-45d2-9d12-e5fef1a518ad,2dc4f008-b840-4edc-9a52-e6aaccd868a8,ad24f290-0f5c-44dc-a541-4066304a2470,e9f50283-8deb-4fd4-b8b2-6f45cd06c2f1,396fa8cb-4668-4ebc-bd3d-d0f88c4d0680,aaeb49ef-2689-4735-93a6-cb7b38dff772,19a4ef69-0dd7-4437-a259-282ad91293a7,642c959d-b814-4e0b-b215-861843b97f64,a313b04c-e6ac-46aa-8330-759f39554ea2,c55e86c6-7998-4278-85ea-77f2389c48eb,4bc634e7-dec0-4ff7-9dc6-82baac7e3ef9,41d3a75a-323f-4838-9197-b1ef61610a35,fbc0d8da-6c2f-4183-b255-2f04b0b8cc92,8cfe507c-2cff-429f-8b7b-d78ca51b53a6,5cfa0ede-a706-42d6-a9c2-3636f46f79fa, pattern=[METRICS]
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:535.04|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570580,7f568e26-93b9-41c1-9ec0-1d3b2c7bf88a,9dff9570-66e3-4d04-b38d-5294f7e388cd,d2c5c118-5554-4307-8fae-563a4436e56d,6115b4c0-0b6b-4374-8e86-fe2d469b5918,7bfe065c-aaf5-4750-b669-5a607c72477b,e8d0da82-bc63-47b1-b2e0-fa8804e6ecfd,9470a5ed-3625-4954-8dcf-46cbf5dde717,21e6aa4a-9ff5-4755-8055-b3aa150a51c1,8e7f1bdc-5bc1-482a-8bda-d6bc96a63c59,617d73eb-8008-4cec-8c11-fee3d3ee0f51,8e252a56-6042-4020-a89e-fe4fc5747144,3b5708de-28f0-4eec-9751-1981b934263d,1997e701-85ce-44d9-a532-d70ff355194e,3af112ea-a272-46fa-9fd4-e87feffb6829,4eaf7369-caba-49b5-905e-126ffb86cf5d,64f3a87d-5390-4e64-b751-b92a5a1a5b19,c8090231-10a9-487e-8b3b-6a4c52b99ec6,b146437f-2d3d-4a25-ab87-0ad7bc82f925,f47211f3-8b3d-4278-abf9-2d82be8c3397,dfce9974-dccc-4ce4-b52b-aa2e2c8ecc0a,78564541-623e-43da-ada0-174ef05137c6,42d51bb5-d3e6-4736-9b92-2fc725698342,1d9b9c06-25e0-4296-ab38-7ec0aaaff120,3cc61bbb-e97c-4865-9a87-35f77f008b5c,419e64c4-7129-4f6f-8ddf-ed7ebfcdd115,e84839ed-8abb-4549-a7a8-4a6920a87a05,ba333209-fd90-4a8f-95a0-f5dc046356a0,bd78b8fb-e799-46ef-b9ac-d2ea2cad75a8,1a59e245-adb7-4492-ba96-58119ac1ef4f,f9cd1042-1a36-4e31-9d83-ae03e5ea0f4f,cc3f042d-3e61-4942-8310-4e9f287341c7,19b71da4-a23d-4583-b1e3-644251ad2589,e3470b43-1865-4c7d-aacc-95a020a9f627,e353a9e0-55e2-40ea-b0c7-ca5499cabb11,f20e3767-0265-4629-ae9f-c443a4956b33,2a68af72-e92e-446d-89c6-ce311313c4dc,71836f73-5406-402f-a888-8aebdd786893,4e98ee4f-325e-412a-9e19-25a155473432,cfb79704-168c-4515-bfc4-87f4fbb45e8c,36e0acbe-35cc-4f58-b4f9-09c024c85c4a,c64b4cc6-e3b8-47a1-8544-9af20b4991d0,a37946ee-bb88-45d2-9d12-e5fef1a518ad,2dc4f008-b840-4edc-9a52-e6aaccd868a8,ad24f290-0f5c-44dc-a541-4066304a2470,e9f50283-8deb-4fd4-b8b2-6f45cd06c2f1,396fa8cb-4668-4ebc-bd3d-d0f88c4d0680,aaeb49ef-2689-4735-93a6-cb7b38dff772,19a4ef69-0dd7-4437-a259-282ad91293a7,642c959d-b814-4e0b-b215-861843b97f64,a313b04c-e6ac-46aa-8330-759f39554ea2,c55e86c6-7998-4278-85ea-77f2389c48eb,4bc634e7-dec0-4ff7-9dc6-82baac7e3ef9,41d3a75a-323f-4838-9197-b1ef61610a35,fbc0d8da-6c2f-4183-b255-2f04b0b8cc92,8cfe507c-2cff-429f-8b7b-d78ca51b53a6,5cfa0ede-a706-42d6-a9c2-3636f46f79fa, pattern=[METRICS]
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:535.04|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:7f568e26-93b9-41c1-9ec0-1d3b2c7bf88a,9dff9570-66e3-4d04-b38d-5294f7e388cd,d2c5c118-5554-4307-8fae-563a4436e56d,6115b4c0-0b6b-4374-8e86-fe2d469b5918,7bfe065c-aaf5-4750-b669-5a607c72477b,e8d0da82-bc63-47b1-b2e0-fa8804e6ecfd,9470a5ed-3625-4954-8dcf-46cbf5dde717,21e6aa4a-9ff5-4755-8055-b3aa150a51c1,8e7f1bdc-5bc1-482a-8bda-d6bc96a63c59,617d73eb-8008-4cec-8c11-fee3d3ee0f51,8e252a56-6042-4020-a89e-fe4fc5747144,3b5708de-28f0-4eec-9751-1981b934263d,1997e701-85ce-44d9-a532-d70ff355194e,3af112ea-a272-46fa-9fd4-e87feffb6829,4eaf7369-caba-49b5-905e-126ffb86cf5d,64f3a87d-5390-4e64-b751-b92a5a1a5b19,c8090231-10a9-487e-8b3b-6a4c52b99ec6,b146437f-2d3d-4a25-ab87-0ad7bc82f925,f47211f3-8b3d-4278-abf9-2d82be8c3397,dfce9974-dccc-4ce4-b52b-aa2e2c8ecc0a,78564541-623e-43da-ada0-174ef05137c6,42d51bb5-d3e6-4736-9b92-2fc725698342,1d9b9c06-25e0-4296-ab38-7ec0aaaff120,3cc61bbb-e97c-4865-9a87-35f77f008b5c,419e64c4-7129-4f6f-8ddf-ed7ebfcdd115,e84839ed-8abb-4549-a7a8-4a6920a87a05,ba333209-fd90-4a8f-95a0-f5dc046356a0,bd78b8fb-e799-46ef-b9ac-d2ea2cad75a8,1a59e245-adb7-4492-ba96-58119ac1ef4f,f9cd1042-1a36-4e31-9d83-ae03e5ea0f4f,cc3f042d-3e61-4942-8310-4e9f287341c7,19b71da4-a23d-4583-b1e3-644251ad2589,e3470b43-1865-4c7d-aacc-95a020a9f627,e353a9e0-55e2-40ea-b0c7-ca5499cabb11,f20e3767-0265-4629-ae9f-c443a4956b33,2a68af72-e92e-446d-89c6-ce311313c4dc,71836f73-5406-402f-a888-8aebdd786893,4e98ee4f-325e-412a-9e19-25a155473432,cfb79704-168c-4515-bfc4-87f4fbb45e8c,36e0acbe-35cc-4f58-b4f9-09c024c85c4a,c64b4cc6-e3b8-47a1-8544-9af20b4991d0,a37946ee-bb88-45d2-9d12-e5fef1a518ad,2dc4f008-b840-4edc-9a52-e6aaccd868a8,ad24f290-0f5c-44dc-a541-4066304a2470,e9f50283-8deb-4fd4-b8b2-6f45cd06c2f1,396fa8cb-4668-4ebc-bd3d-d0f88c4d0680,aaeb49ef-2689-4735-93a6-cb7b38dff772,19a4ef69-0dd7-4437-a259-282ad91293a7,642c959d-b814-4e0b-b215-861843b97f64,a313b04c-e6ac-46aa-8330-759f39554ea2,c55e86c6-7998-4278-85ea-77f2389c48eb,4bc634e7-dec0-4ff7-9dc6-82baac7e3ef9,41d3a75a-323f-4838-9197-b1ef61610a35,fbc0d8da-6c2f-4183-b255-2f04b0b8cc92,8cfe507c-2cff-429f-8b7b-d78ca51b53a6,5cfa0ede-a706-42d6-a9c2-3636f46f79fa,timestamp:1683570580
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093574.218|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554662.561|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,802 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554662561, Backend time ns: 539184972
2023-05-08T18:29:40,802 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554662561, Backend time ns: 539184972
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:535.13|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570580,7f568e26-93b9-41c1-9ec0-1d3b2c7bf88a,9dff9570-66e3-4d04-b38d-5294f7e388cd,d2c5c118-5554-4307-8fae-563a4436e56d,6115b4c0-0b6b-4374-8e86-fe2d469b5918,7bfe065c-aaf5-4750-b669-5a607c72477b,e8d0da82-bc63-47b1-b2e0-fa8804e6ecfd,9470a5ed-3625-4954-8dcf-46cbf5dde717,21e6aa4a-9ff5-4755-8055-b3aa150a51c1,8e7f1bdc-5bc1-482a-8bda-d6bc96a63c59,617d73eb-8008-4cec-8c11-fee3d3ee0f51,8e252a56-6042-4020-a89e-fe4fc5747144,3b5708de-28f0-4eec-9751-1981b934263d,1997e701-85ce-44d9-a532-d70ff355194e,3af112ea-a272-46fa-9fd4-e87feffb6829,4eaf7369-caba-49b5-905e-126ffb86cf5d,64f3a87d-5390-4e64-b751-b92a5a1a5b19,c8090231-10a9-487e-8b3b-6a4c52b99ec6,b146437f-2d3d-4a25-ab87-0ad7bc82f925,f47211f3-8b3d-4278-abf9-2d82be8c3397,dfce9974-dccc-4ce4-b52b-aa2e2c8ecc0a,78564541-623e-43da-ada0-174ef05137c6,42d51bb5-d3e6-4736-9b92-2fc725698342,1d9b9c06-25e0-4296-ab38-7ec0aaaff120,3cc61bbb-e97c-4865-9a87-35f77f008b5c,419e64c4-7129-4f6f-8ddf-ed7ebfcdd115,e84839ed-8abb-4549-a7a8-4a6920a87a05,ba333209-fd90-4a8f-95a0-f5dc046356a0,bd78b8fb-e799-46ef-b9ac-d2ea2cad75a8,1a59e245-adb7-4492-ba96-58119ac1ef4f,f9cd1042-1a36-4e31-9d83-ae03e5ea0f4f,cc3f042d-3e61-4942-8310-4e9f287341c7,19b71da4-a23d-4583-b1e3-644251ad2589,e3470b43-1865-4c7d-aacc-95a020a9f627,e353a9e0-55e2-40ea-b0c7-ca5499cabb11,f20e3767-0265-4629-ae9f-c443a4956b33,2a68af72-e92e-446d-89c6-ce311313c4dc,71836f73-5406-402f-a888-8aebdd786893,4e98ee4f-325e-412a-9e19-25a155473432,cfb79704-168c-4515-bfc4-87f4fbb45e8c,36e0acbe-35cc-4f58-b4f9-09c024c85c4a,c64b4cc6-e3b8-47a1-8544-9af20b4991d0,a37946ee-bb88-45d2-9d12-e5fef1a518ad,2dc4f008-b840-4edc-9a52-e6aaccd868a8,ad24f290-0f5c-44dc-a541-4066304a2470,e9f50283-8deb-4fd4-b8b2-6f45cd06c2f1,396fa8cb-4668-4ebc-bd3d-d0f88c4d0680,aaeb49ef-2689-4735-93a6-cb7b38dff772,19a4ef69-0dd7-4437-a259-282ad91293a7,642c959d-b814-4e0b-b215-861843b97f64,a313b04c-e6ac-46aa-8330-759f39554ea2,c55e86c6-7998-4278-85ea-77f2389c48eb,4bc634e7-dec0-4ff7-9dc6-82baac7e3ef9,41d3a75a-323f-4838-9197-b1ef61610a35,fbc0d8da-6c2f-4183-b255-2f04b0b8cc92,8cfe507c-2cff-429f-8b7b-d78ca51b53a6,5cfa0ede-a706-42d6-a9c2-3636f46f79fa, pattern=[METRICS]
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:535.13|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570580,7f568e26-93b9-41c1-9ec0-1d3b2c7bf88a,9dff9570-66e3-4d04-b38d-5294f7e388cd,d2c5c118-5554-4307-8fae-563a4436e56d,6115b4c0-0b6b-4374-8e86-fe2d469b5918,7bfe065c-aaf5-4750-b669-5a607c72477b,e8d0da82-bc63-47b1-b2e0-fa8804e6ecfd,9470a5ed-3625-4954-8dcf-46cbf5dde717,21e6aa4a-9ff5-4755-8055-b3aa150a51c1,8e7f1bdc-5bc1-482a-8bda-d6bc96a63c59,617d73eb-8008-4cec-8c11-fee3d3ee0f51,8e252a56-6042-4020-a89e-fe4fc5747144,3b5708de-28f0-4eec-9751-1981b934263d,1997e701-85ce-44d9-a532-d70ff355194e,3af112ea-a272-46fa-9fd4-e87feffb6829,4eaf7369-caba-49b5-905e-126ffb86cf5d,64f3a87d-5390-4e64-b751-b92a5a1a5b19,c8090231-10a9-487e-8b3b-6a4c52b99ec6,b146437f-2d3d-4a25-ab87-0ad7bc82f925,f47211f3-8b3d-4278-abf9-2d82be8c3397,dfce9974-dccc-4ce4-b52b-aa2e2c8ecc0a,78564541-623e-43da-ada0-174ef05137c6,42d51bb5-d3e6-4736-9b92-2fc725698342,1d9b9c06-25e0-4296-ab38-7ec0aaaff120,3cc61bbb-e97c-4865-9a87-35f77f008b5c,419e64c4-7129-4f6f-8ddf-ed7ebfcdd115,e84839ed-8abb-4549-a7a8-4a6920a87a05,ba333209-fd90-4a8f-95a0-f5dc046356a0,bd78b8fb-e799-46ef-b9ac-d2ea2cad75a8,1a59e245-adb7-4492-ba96-58119ac1ef4f,f9cd1042-1a36-4e31-9d83-ae03e5ea0f4f,cc3f042d-3e61-4942-8310-4e9f287341c7,19b71da4-a23d-4583-b1e3-644251ad2589,e3470b43-1865-4c7d-aacc-95a020a9f627,e353a9e0-55e2-40ea-b0c7-ca5499cabb11,f20e3767-0265-4629-ae9f-c443a4956b33,2a68af72-e92e-446d-89c6-ce311313c4dc,71836f73-5406-402f-a888-8aebdd786893,4e98ee4f-325e-412a-9e19-25a155473432,cfb79704-168c-4515-bfc4-87f4fbb45e8c,36e0acbe-35cc-4f58-b4f9-09c024c85c4a,c64b4cc6-e3b8-47a1-8544-9af20b4991d0,a37946ee-bb88-45d2-9d12-e5fef1a518ad,2dc4f008-b840-4edc-9a52-e6aaccd868a8,ad24f290-0f5c-44dc-a541-4066304a2470,e9f50283-8deb-4fd4-b8b2-6f45cd06c2f1,396fa8cb-4668-4ebc-bd3d-d0f88c4d0680,aaeb49ef-2689-4735-93a6-cb7b38dff772,19a4ef69-0dd7-4437-a259-282ad91293a7,642c959d-b814-4e0b-b215-861843b97f64,a313b04c-e6ac-46aa-8330-759f39554ea2,c55e86c6-7998-4278-85ea-77f2389c48eb,4bc634e7-dec0-4ff7-9dc6-82baac7e3ef9,41d3a75a-323f-4838-9197-b1ef61610a35,fbc0d8da-6c2f-4183-b255-2f04b0b8cc92,8cfe507c-2cff-429f-8b7b-d78ca51b53a6,5cfa0ede-a706-42d6-a9c2-3636f46f79fa, pattern=[METRICS]
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093491.684|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554266.6|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,802 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554266600, Backend time ns: 539374572
2023-05-08T18:29:40,802 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554266600, Backend time ns: 539374572
2023-05-08T18:29:40,802 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:535.13|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:7f568e26-93b9-41c1-9ec0-1d3b2c7bf88a,9dff9570-66e3-4d04-b38d-5294f7e388cd,d2c5c118-5554-4307-8fae-563a4436e56d,6115b4c0-0b6b-4374-8e86-fe2d469b5918,7bfe065c-aaf5-4750-b669-5a607c72477b,e8d0da82-bc63-47b1-b2e0-fa8804e6ecfd,9470a5ed-3625-4954-8dcf-46cbf5dde717,21e6aa4a-9ff5-4755-8055-b3aa150a51c1,8e7f1bdc-5bc1-482a-8bda-d6bc96a63c59,617d73eb-8008-4cec-8c11-fee3d3ee0f51,8e252a56-6042-4020-a89e-fe4fc5747144,3b5708de-28f0-4eec-9751-1981b934263d,1997e701-85ce-44d9-a532-d70ff355194e,3af112ea-a272-46fa-9fd4-e87feffb6829,4eaf7369-caba-49b5-905e-126ffb86cf5d,64f3a87d-5390-4e64-b751-b92a5a1a5b19,c8090231-10a9-487e-8b3b-6a4c52b99ec6,b146437f-2d3d-4a25-ab87-0ad7bc82f925,f47211f3-8b3d-4278-abf9-2d82be8c3397,dfce9974-dccc-4ce4-b52b-aa2e2c8ecc0a,78564541-623e-43da-ada0-174ef05137c6,42d51bb5-d3e6-4736-9b92-2fc725698342,1d9b9c06-25e0-4296-ab38-7ec0aaaff120,3cc61bbb-e97c-4865-9a87-35f77f008b5c,419e64c4-7129-4f6f-8ddf-ed7ebfcdd115,e84839ed-8abb-4549-a7a8-4a6920a87a05,ba333209-fd90-4a8f-95a0-f5dc046356a0,bd78b8fb-e799-46ef-b9ac-d2ea2cad75a8,1a59e245-adb7-4492-ba96-58119ac1ef4f,f9cd1042-1a36-4e31-9d83-ae03e5ea0f4f,cc3f042d-3e61-4942-8310-4e9f287341c7,19b71da4-a23d-4583-b1e3-644251ad2589,e3470b43-1865-4c7d-aacc-95a020a9f627,e353a9e0-55e2-40ea-b0c7-ca5499cabb11,f20e3767-0265-4629-ae9f-c443a4956b33,2a68af72-e92e-446d-89c6-ce311313c4dc,71836f73-5406-402f-a888-8aebdd786893,4e98ee4f-325e-412a-9e19-25a155473432,cfb79704-168c-4515-bfc4-87f4fbb45e8c,36e0acbe-35cc-4f58-b4f9-09c024c85c4a,c64b4cc6-e3b8-47a1-8544-9af20b4991d0,a37946ee-bb88-45d2-9d12-e5fef1a518ad,2dc4f008-b840-4edc-9a52-e6aaccd868a8,ad24f290-0f5c-44dc-a541-4066304a2470,e9f50283-8deb-4fd4-b8b2-6f45cd06c2f1,396fa8cb-4668-4ebc-bd3d-d0f88c4d0680,aaeb49ef-2689-4735-93a6-cb7b38dff772,19a4ef69-0dd7-4437-a259-282ad91293a7,642c959d-b814-4e0b-b215-861843b97f64,a313b04c-e6ac-46aa-8330-759f39554ea2,c55e86c6-7998-4278-85ea-77f2389c48eb,4bc634e7-dec0-4ff7-9dc6-82baac7e3ef9,41d3a75a-323f-4838-9197-b1ef61610a35,fbc0d8da-6c2f-4183-b255-2f04b0b8cc92,8cfe507c-2cff-429f-8b7b-d78ca51b53a6,5cfa0ede-a706-42d6-a9c2-3636f46f79fa,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093618.691|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554214.757|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554214757, Backend time ns: 539505249
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554214757, Backend time ns: 539505249
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,803 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093683.284|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554143.773|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554143773, Backend time ns: 539645817
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554143773, Backend time ns: 539645817
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093666.274|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553994.995|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553994995, Backend time ns: 539774724
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553994995, Backend time ns: 539774724
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,803 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093637.121|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553823.675|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553823675, Backend time ns: 539971185
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553823675, Backend time ns: 539971185
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093619.25|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553608.153|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553608153, Backend time ns: 540139165
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553608153, Backend time ns: 540139165
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093698.295|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553517.408|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553517408, Backend time ns: 540260881
2023-05-08T18:29:40,803 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553517408, Backend time ns: 540260881
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,803 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,803 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093621.812|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553321.918|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553321918, Backend time ns: 540453932
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553321918, Backend time ns: 540453932
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093784.94|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553284.385|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553284385, Backend time ns: 540610501
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553284385, Backend time ns: 540610501
2023-05-08T18:29:40,804 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093669.913|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553015.28|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553015280, Backend time ns: 540755719
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553015280, Backend time ns: 540755719
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093657.863|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552870.232|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552870232, Backend time ns: 540866845
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552870232, Backend time ns: 540866845
2023-05-08T18:29:40,804 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093638.882|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552736.975|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552736975, Backend time ns: 540985122
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552736975, Backend time ns: 540985122
2023-05-08T18:29:40,804 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093606.591|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552589.107|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552589107, Backend time ns: 541091888
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552589107, Backend time ns: 541091888
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,804 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093584.859|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552465.15|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552465150, Backend time ns: 541220465
2023-05-08T18:29:40,804 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552465150, Backend time ns: 541220465
2023-05-08T18:29:40,804 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093500.524|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,804 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552220.896|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552220896, Backend time ns: 541395105
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552220896, Backend time ns: 541395105
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093511.525|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552089.119|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552089119, Backend time ns: 541499950
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552089119, Backend time ns: 541499950
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,805 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093161.666|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551637.124|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551637124, Backend time ns: 541601946
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551637124, Backend time ns: 541601946
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093158.976|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551492.366|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551492366, Backend time ns: 541777136
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551492366, Backend time ns: 541777136
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,805 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092968.314|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551161.927|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551161927, Backend time ns: 541909743
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551161927, Backend time ns: 541909743
2023-05-08T18:29:40,805 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093082.621|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551127.245|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551127245, Backend time ns: 542041901
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551127245, Backend time ns: 542041901
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093192.097|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551119.045|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551119045, Backend time ns: 542165707
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551119045, Backend time ns: 542165707
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093292.573|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551102.564|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551102564, Backend time ns: 542299575
2023-05-08T18:29:40,805 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551102564, Backend time ns: 542299575
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,805 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093392.139|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551064.042|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551064042, Backend time ns: 542409871
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551064042, Backend time ns: 542409871
2023-05-08T18:29:40,806 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093491.534|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551046.841|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551046841, Backend time ns: 542516837
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551046841, Backend time ns: 542516837
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093495.014|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550955.176|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550955176, Backend time ns: 542622213
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550955176, Backend time ns: 542622213
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,806 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093544.586|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550896.982|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550896982, Backend time ns: 542806973
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550896982, Backend time ns: 542806973
2023-05-08T18:29:40,806 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093491.654|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550621.037|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550621037, Backend time ns: 542963432
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550621037, Backend time ns: 542963432
2023-05-08T18:29:40,806 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093591.39|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550579.925|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550579925, Backend time ns: 543096769
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550579925, Backend time ns: 543096769
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093553.197|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550430.306|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550430306, Backend time ns: 543216246
2023-05-08T18:29:40,806 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550430306, Backend time ns: 543216246
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093577.029|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550308.05|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550308050, Backend time ns: 543370885
2023-05-08T18:29:40,806 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550308050, Backend time ns: 543370885
2023-05-08T18:29:40,806 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093393.988|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549997.532|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549997532, Backend time ns: 543474600
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549997532, Backend time ns: 543474600
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093481.743|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549976.891|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549976891, Backend time ns: 543589787
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549976891, Backend time ns: 543589787
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093570.759|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549947.79|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549947790, Backend time ns: 543719474
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549947790, Backend time ns: 543719474
2023-05-08T18:29:40,807 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093503.154|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549737.138|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549737138, Backend time ns: 543853561
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549737138, Backend time ns: 543853561
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093548.607|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549650.093|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549650093, Backend time ns: 543983789
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549650093, Backend time ns: 543983789
2023-05-08T18:29:40,807 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093589.329|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549539.887|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549539887, Backend time ns: 544169599
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549539887, Backend time ns: 544169599
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093564.007|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549365.907|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549365907, Backend time ns: 544276555
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549365907, Backend time ns: 544276555
2023-05-08T18:29:40,807 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093546.526|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549244.44|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549244440, Backend time ns: 544379511
2023-05-08T18:29:40,807 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549244440, Backend time ns: 544379511
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,808 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093470.272|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549059.55|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549059550, Backend time ns: 544508648
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549059550, Backend time ns: 544508648
2023-05-08T18:29:40,808 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093372.147|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548825.447|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548825447, Backend time ns: 544628454
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548825447, Backend time ns: 544628454
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,808 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093459.742|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548803.426|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548803426, Backend time ns: 544768102
2023-05-08T18:29:40,808 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548803426, Backend time ns: 544768102
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093507.664|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548687.419|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548687419, Backend time ns: 544900910
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548687419, Backend time ns: 544900910
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093483.183|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548553.002|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548553002, Backend time ns: 545027647
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548553002, Backend time ns: 545027647
2023-05-08T18:29:40,808 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:551971.562|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6900.123|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6900123, Backend time ns: 545171815
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6900123, Backend time ns: 545171815
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552092.268|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6885.852|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6885852, Backend time ns: 545292291
2023-05-08T18:29:40,808 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6885852, Backend time ns: 545292291
2023-05-08T18:29:40,808 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,808 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552181.314|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6861.981|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6861981, Backend time ns: 545402627
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6861981, Backend time ns: 545402627
2023-05-08T18:29:40,809 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552240.137|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6812.028|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6812028, Backend time ns: 545505733
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6812028, Backend time ns: 545505733
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552242.497|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6698.232|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6698232, Backend time ns: 545688893
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6698232, Backend time ns: 545688893
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:551978.193|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6261.328|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6261328, Backend time ns: 545823301
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6261328, Backend time ns: 545823301
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552092.479|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6236.046|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6236046, Backend time ns: 545940227
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6236046, Backend time ns: 545940227
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552140.702|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6172.353|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6172353, Backend time ns: 546050843
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6172353, Backend time ns: 546050843
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552232.727|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6157.332|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6157332, Backend time ns: 546188871
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6157332, Backend time ns: 546188871
2023-05-08T18:29:40,809 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552346.703|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6106.299|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6106299, Backend time ns: 546353040
2023-05-08T18:29:40,809 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6106299, Backend time ns: 546353040
2023-05-08T18:29:40,809 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:40,810 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552076.408|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5694.326|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5694326, Backend time ns: 546551971
2023-05-08T18:29:40,810 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5694326, Backend time ns: 546551971
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552288.679|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5682.355|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5682355, Backend time ns: 546695059
2023-05-08T18:29:40,810 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5682355, Backend time ns: 546695059
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:40,810 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 539
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 539
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570580
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570580810
2023-05-08T18:29:40,810 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570580810
2023-05-08T18:29:40,813 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570580
2023-05-08T18:29:40,813 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,813 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,815 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,816 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,818 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,820 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,821 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,821 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,821 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:40,821 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:40,821 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:40,822 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:40,822 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:40,827 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:40,863 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:40,884 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:40,891 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:40,923 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:40,927 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:40,929 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:40,961 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:40,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:40,967 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:40,969 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:41,000 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:41,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:41,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:41,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:41,038 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:41,045 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:41,048 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:41,050 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:41,076 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:41,082 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:41,088 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:41,090 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:41,115 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:41,128 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:41,131 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:41,153 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:41,169 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:41,171 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:41,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:41,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:41,253 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:41,347 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:41,347 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:533.77|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570581,6750e257-cd5c-4bcc-822f-236aabf865e2,148441a3-e9f0-4bff-9837-4ac12dadb591,3ed07937-8560-494e-b648-333c0cc4e35f,e626d6cb-14a2-40f0-add5-2daace13e5b7,5c2e1c6e-3b35-49a2-aad9-6171db53fdd3,bb11673a-38b0-4561-bb5f-9bb773277497,5735db22-525a-46c2-9c3d-a28aba2f0747,ea83328d-1526-439b-8877-e107b92ad7f0,6eaa6a9a-b463-4f3e-a15e-1a818849ab0d,4d4e938e-fe9b-40ab-a1f1-d21d5eae9a3f,535f25cb-7557-4be1-b9f8-fd6029e1bf35,d36274cc-9167-4842-b38e-9f8c84955d1e,e01bdb92-a856-4472-aa87-6a1611bd5086,a2e882aa-3fc3-4a4a-82eb-25340a341fdf,6a76f99a-7c35-4adc-bacc-03c9d6f7e784,856df318-f80c-4fca-a281-7bb1fa2feb0f,eab522b1-759d-4339-9ba5-2f882d8c4335,e6635764-997c-47bb-9617-fe50b4fa7587,68e7891a-0e8e-4382-a0f9-e9bcb15a5e15,0039b71a-369c-4f9d-b915-b4b20876b09e,be23f9e3-1af7-4d88-aa88-0a435b59d4e3,14fa7f84-d09b-4c1c-9945-83f0c37d10b9,ffa26dd0-fcb8-4c49-b708-68184a95b40e,3fb6f2ba-a7d9-4575-9f63-44ffb03cd610,345325aa-4dca-459b-a111-98d15fc1bf5d,eb511ba4-392d-473a-8042-d2852f2f402a,d461dfa5-860b-40bc-810b-7d06aeb01bc9,47dda793-0adb-41ae-ae76-ad2edd5175a5,3824f515-1a20-4773-b594-197545842d8d,4d334b1b-8dc5-43e7-81dd-62ab5d0d8197,9b1659b5-f931-4073-b488-3b2dd89a258d,54685dec-fb69-43bd-b5e2-4a20a60b03ca,a5cf47f5-665d-414a-914d-31dc015a6e32,745edafb-638f-491b-99aa-eeca0e6fa66e,9e8e87c0-9add-46d4-8e4f-de13d6589502,13b70f8e-26dc-4550-a110-4428f11b36f5,e36614e1-7e17-48df-93de-d517ee5a72c2,8bfa3020-9000-4ce2-b2e9-e5f252d56276,2d14e51f-ab2f-4105-a499-a843e0fb3d7b,430a1b5a-eeec-45fb-9b6b-9787f9803fe2,a5660532-a9f7-43b1-89ed-6bdee06bb209,94dd94d4-1abf-4a78-8cb8-a0dbbba7a54d,2535496c-e48c-41af-8804-20d7b622e543,17ddfb08-131c-46ff-8689-3d048f6ea660,a861f18c-3c34-4f5d-9394-dcf58c391b3c,73a92710-6943-4e82-af06-a909325da259,648f3fa9-7b51-403c-b3fd-d80a211dd75f,de90ae05-29e1-4b9d-9272-5e3ba0be8285,6ff91787-16b2-4922-a855-3df12136bd91,5be02a7f-b729-4c67-a076-05dc19c03a19,15fc1f7b-70c0-4ca7-8d18-9d6ee6cac612,fa85151f-f49b-47f4-bac8-f7f987973252,efb453d7-d16d-42c3-889c-90ae8ec59529,18877502-94e5-4b82-8a71-69ddc61904ca,c360f94d-4c40-4bd0-8e6c-73d7165109c1,e930cc38-bf12-4678-a403-4a0fb54e0995, pattern=[METRICS]
2023-05-08T18:29:41,347 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:533.77|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570581,6750e257-cd5c-4bcc-822f-236aabf865e2,148441a3-e9f0-4bff-9837-4ac12dadb591,3ed07937-8560-494e-b648-333c0cc4e35f,e626d6cb-14a2-40f0-add5-2daace13e5b7,5c2e1c6e-3b35-49a2-aad9-6171db53fdd3,bb11673a-38b0-4561-bb5f-9bb773277497,5735db22-525a-46c2-9c3d-a28aba2f0747,ea83328d-1526-439b-8877-e107b92ad7f0,6eaa6a9a-b463-4f3e-a15e-1a818849ab0d,4d4e938e-fe9b-40ab-a1f1-d21d5eae9a3f,535f25cb-7557-4be1-b9f8-fd6029e1bf35,d36274cc-9167-4842-b38e-9f8c84955d1e,e01bdb92-a856-4472-aa87-6a1611bd5086,a2e882aa-3fc3-4a4a-82eb-25340a341fdf,6a76f99a-7c35-4adc-bacc-03c9d6f7e784,856df318-f80c-4fca-a281-7bb1fa2feb0f,eab522b1-759d-4339-9ba5-2f882d8c4335,e6635764-997c-47bb-9617-fe50b4fa7587,68e7891a-0e8e-4382-a0f9-e9bcb15a5e15,0039b71a-369c-4f9d-b915-b4b20876b09e,be23f9e3-1af7-4d88-aa88-0a435b59d4e3,14fa7f84-d09b-4c1c-9945-83f0c37d10b9,ffa26dd0-fcb8-4c49-b708-68184a95b40e,3fb6f2ba-a7d9-4575-9f63-44ffb03cd610,345325aa-4dca-459b-a111-98d15fc1bf5d,eb511ba4-392d-473a-8042-d2852f2f402a,d461dfa5-860b-40bc-810b-7d06aeb01bc9,47dda793-0adb-41ae-ae76-ad2edd5175a5,3824f515-1a20-4773-b594-197545842d8d,4d334b1b-8dc5-43e7-81dd-62ab5d0d8197,9b1659b5-f931-4073-b488-3b2dd89a258d,54685dec-fb69-43bd-b5e2-4a20a60b03ca,a5cf47f5-665d-414a-914d-31dc015a6e32,745edafb-638f-491b-99aa-eeca0e6fa66e,9e8e87c0-9add-46d4-8e4f-de13d6589502,13b70f8e-26dc-4550-a110-4428f11b36f5,e36614e1-7e17-48df-93de-d517ee5a72c2,8bfa3020-9000-4ce2-b2e9-e5f252d56276,2d14e51f-ab2f-4105-a499-a843e0fb3d7b,430a1b5a-eeec-45fb-9b6b-9787f9803fe2,a5660532-a9f7-43b1-89ed-6bdee06bb209,94dd94d4-1abf-4a78-8cb8-a0dbbba7a54d,2535496c-e48c-41af-8804-20d7b622e543,17ddfb08-131c-46ff-8689-3d048f6ea660,a861f18c-3c34-4f5d-9394-dcf58c391b3c,73a92710-6943-4e82-af06-a909325da259,648f3fa9-7b51-403c-b3fd-d80a211dd75f,de90ae05-29e1-4b9d-9272-5e3ba0be8285,6ff91787-16b2-4922-a855-3df12136bd91,5be02a7f-b729-4c67-a076-05dc19c03a19,15fc1f7b-70c0-4ca7-8d18-9d6ee6cac612,fa85151f-f49b-47f4-bac8-f7f987973252,efb453d7-d16d-42c3-889c-90ae8ec59529,18877502-94e5-4b82-8a71-69ddc61904ca,c360f94d-4c40-4bd0-8e6c-73d7165109c1,e930cc38-bf12-4678-a403-4a0fb54e0995, pattern=[METRICS]
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:533.77|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:6750e257-cd5c-4bcc-822f-236aabf865e2,148441a3-e9f0-4bff-9837-4ac12dadb591,3ed07937-8560-494e-b648-333c0cc4e35f,e626d6cb-14a2-40f0-add5-2daace13e5b7,5c2e1c6e-3b35-49a2-aad9-6171db53fdd3,bb11673a-38b0-4561-bb5f-9bb773277497,5735db22-525a-46c2-9c3d-a28aba2f0747,ea83328d-1526-439b-8877-e107b92ad7f0,6eaa6a9a-b463-4f3e-a15e-1a818849ab0d,4d4e938e-fe9b-40ab-a1f1-d21d5eae9a3f,535f25cb-7557-4be1-b9f8-fd6029e1bf35,d36274cc-9167-4842-b38e-9f8c84955d1e,e01bdb92-a856-4472-aa87-6a1611bd5086,a2e882aa-3fc3-4a4a-82eb-25340a341fdf,6a76f99a-7c35-4adc-bacc-03c9d6f7e784,856df318-f80c-4fca-a281-7bb1fa2feb0f,eab522b1-759d-4339-9ba5-2f882d8c4335,e6635764-997c-47bb-9617-fe50b4fa7587,68e7891a-0e8e-4382-a0f9-e9bcb15a5e15,0039b71a-369c-4f9d-b915-b4b20876b09e,be23f9e3-1af7-4d88-aa88-0a435b59d4e3,14fa7f84-d09b-4c1c-9945-83f0c37d10b9,ffa26dd0-fcb8-4c49-b708-68184a95b40e,3fb6f2ba-a7d9-4575-9f63-44ffb03cd610,345325aa-4dca-459b-a111-98d15fc1bf5d,eb511ba4-392d-473a-8042-d2852f2f402a,d461dfa5-860b-40bc-810b-7d06aeb01bc9,47dda793-0adb-41ae-ae76-ad2edd5175a5,3824f515-1a20-4773-b594-197545842d8d,4d334b1b-8dc5-43e7-81dd-62ab5d0d8197,9b1659b5-f931-4073-b488-3b2dd89a258d,54685dec-fb69-43bd-b5e2-4a20a60b03ca,a5cf47f5-665d-414a-914d-31dc015a6e32,745edafb-638f-491b-99aa-eeca0e6fa66e,9e8e87c0-9add-46d4-8e4f-de13d6589502,13b70f8e-26dc-4550-a110-4428f11b36f5,e36614e1-7e17-48df-93de-d517ee5a72c2,8bfa3020-9000-4ce2-b2e9-e5f252d56276,2d14e51f-ab2f-4105-a499-a843e0fb3d7b,430a1b5a-eeec-45fb-9b6b-9787f9803fe2,a5660532-a9f7-43b1-89ed-6bdee06bb209,94dd94d4-1abf-4a78-8cb8-a0dbbba7a54d,2535496c-e48c-41af-8804-20d7b622e543,17ddfb08-131c-46ff-8689-3d048f6ea660,a861f18c-3c34-4f5d-9394-dcf58c391b3c,73a92710-6943-4e82-af06-a909325da259,648f3fa9-7b51-403c-b3fd-d80a211dd75f,de90ae05-29e1-4b9d-9272-5e3ba0be8285,6ff91787-16b2-4922-a855-3df12136bd91,5be02a7f-b729-4c67-a076-05dc19c03a19,15fc1f7b-70c0-4ca7-8d18-9d6ee6cac612,fa85151f-f49b-47f4-bac8-f7f987973252,efb453d7-d16d-42c3-889c-90ae8ec59529,18877502-94e5-4b82-8a71-69ddc61904ca,c360f94d-4c40-4bd0-8e6c-73d7165109c1,e930cc38-bf12-4678-a403-4a0fb54e0995,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 1091
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:533.87|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570581,6750e257-cd5c-4bcc-822f-236aabf865e2,148441a3-e9f0-4bff-9837-4ac12dadb591,3ed07937-8560-494e-b648-333c0cc4e35f,e626d6cb-14a2-40f0-add5-2daace13e5b7,5c2e1c6e-3b35-49a2-aad9-6171db53fdd3,bb11673a-38b0-4561-bb5f-9bb773277497,5735db22-525a-46c2-9c3d-a28aba2f0747,ea83328d-1526-439b-8877-e107b92ad7f0,6eaa6a9a-b463-4f3e-a15e-1a818849ab0d,4d4e938e-fe9b-40ab-a1f1-d21d5eae9a3f,535f25cb-7557-4be1-b9f8-fd6029e1bf35,d36274cc-9167-4842-b38e-9f8c84955d1e,e01bdb92-a856-4472-aa87-6a1611bd5086,a2e882aa-3fc3-4a4a-82eb-25340a341fdf,6a76f99a-7c35-4adc-bacc-03c9d6f7e784,856df318-f80c-4fca-a281-7bb1fa2feb0f,eab522b1-759d-4339-9ba5-2f882d8c4335,e6635764-997c-47bb-9617-fe50b4fa7587,68e7891a-0e8e-4382-a0f9-e9bcb15a5e15,0039b71a-369c-4f9d-b915-b4b20876b09e,be23f9e3-1af7-4d88-aa88-0a435b59d4e3,14fa7f84-d09b-4c1c-9945-83f0c37d10b9,ffa26dd0-fcb8-4c49-b708-68184a95b40e,3fb6f2ba-a7d9-4575-9f63-44ffb03cd610,345325aa-4dca-459b-a111-98d15fc1bf5d,eb511ba4-392d-473a-8042-d2852f2f402a,d461dfa5-860b-40bc-810b-7d06aeb01bc9,47dda793-0adb-41ae-ae76-ad2edd5175a5,3824f515-1a20-4773-b594-197545842d8d,4d334b1b-8dc5-43e7-81dd-62ab5d0d8197,9b1659b5-f931-4073-b488-3b2dd89a258d,54685dec-fb69-43bd-b5e2-4a20a60b03ca,a5cf47f5-665d-414a-914d-31dc015a6e32,745edafb-638f-491b-99aa-eeca0e6fa66e,9e8e87c0-9add-46d4-8e4f-de13d6589502,13b70f8e-26dc-4550-a110-4428f11b36f5,e36614e1-7e17-48df-93de-d517ee5a72c2,8bfa3020-9000-4ce2-b2e9-e5f252d56276,2d14e51f-ab2f-4105-a499-a843e0fb3d7b,430a1b5a-eeec-45fb-9b6b-9787f9803fe2,a5660532-a9f7-43b1-89ed-6bdee06bb209,94dd94d4-1abf-4a78-8cb8-a0dbbba7a54d,2535496c-e48c-41af-8804-20d7b622e543,17ddfb08-131c-46ff-8689-3d048f6ea660,a861f18c-3c34-4f5d-9394-dcf58c391b3c,73a92710-6943-4e82-af06-a909325da259,648f3fa9-7b51-403c-b3fd-d80a211dd75f,de90ae05-29e1-4b9d-9272-5e3ba0be8285,6ff91787-16b2-4922-a855-3df12136bd91,5be02a7f-b729-4c67-a076-05dc19c03a19,15fc1f7b-70c0-4ca7-8d18-9d6ee6cac612,fa85151f-f49b-47f4-bac8-f7f987973252,efb453d7-d16d-42c3-889c-90ae8ec59529,18877502-94e5-4b82-8a71-69ddc61904ca,c360f94d-4c40-4bd0-8e6c-73d7165109c1,e930cc38-bf12-4678-a403-4a0fb54e0995, pattern=[METRICS]
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:533.87|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570581,6750e257-cd5c-4bcc-822f-236aabf865e2,148441a3-e9f0-4bff-9837-4ac12dadb591,3ed07937-8560-494e-b648-333c0cc4e35f,e626d6cb-14a2-40f0-add5-2daace13e5b7,5c2e1c6e-3b35-49a2-aad9-6171db53fdd3,bb11673a-38b0-4561-bb5f-9bb773277497,5735db22-525a-46c2-9c3d-a28aba2f0747,ea83328d-1526-439b-8877-e107b92ad7f0,6eaa6a9a-b463-4f3e-a15e-1a818849ab0d,4d4e938e-fe9b-40ab-a1f1-d21d5eae9a3f,535f25cb-7557-4be1-b9f8-fd6029e1bf35,d36274cc-9167-4842-b38e-9f8c84955d1e,e01bdb92-a856-4472-aa87-6a1611bd5086,a2e882aa-3fc3-4a4a-82eb-25340a341fdf,6a76f99a-7c35-4adc-bacc-03c9d6f7e784,856df318-f80c-4fca-a281-7bb1fa2feb0f,eab522b1-759d-4339-9ba5-2f882d8c4335,e6635764-997c-47bb-9617-fe50b4fa7587,68e7891a-0e8e-4382-a0f9-e9bcb15a5e15,0039b71a-369c-4f9d-b915-b4b20876b09e,be23f9e3-1af7-4d88-aa88-0a435b59d4e3,14fa7f84-d09b-4c1c-9945-83f0c37d10b9,ffa26dd0-fcb8-4c49-b708-68184a95b40e,3fb6f2ba-a7d9-4575-9f63-44ffb03cd610,345325aa-4dca-459b-a111-98d15fc1bf5d,eb511ba4-392d-473a-8042-d2852f2f402a,d461dfa5-860b-40bc-810b-7d06aeb01bc9,47dda793-0adb-41ae-ae76-ad2edd5175a5,3824f515-1a20-4773-b594-197545842d8d,4d334b1b-8dc5-43e7-81dd-62ab5d0d8197,9b1659b5-f931-4073-b488-3b2dd89a258d,54685dec-fb69-43bd-b5e2-4a20a60b03ca,a5cf47f5-665d-414a-914d-31dc015a6e32,745edafb-638f-491b-99aa-eeca0e6fa66e,9e8e87c0-9add-46d4-8e4f-de13d6589502,13b70f8e-26dc-4550-a110-4428f11b36f5,e36614e1-7e17-48df-93de-d517ee5a72c2,8bfa3020-9000-4ce2-b2e9-e5f252d56276,2d14e51f-ab2f-4105-a499-a843e0fb3d7b,430a1b5a-eeec-45fb-9b6b-9787f9803fe2,a5660532-a9f7-43b1-89ed-6bdee06bb209,94dd94d4-1abf-4a78-8cb8-a0dbbba7a54d,2535496c-e48c-41af-8804-20d7b622e543,17ddfb08-131c-46ff-8689-3d048f6ea660,a861f18c-3c34-4f5d-9394-dcf58c391b3c,73a92710-6943-4e82-af06-a909325da259,648f3fa9-7b51-403c-b3fd-d80a211dd75f,de90ae05-29e1-4b9d-9272-5e3ba0be8285,6ff91787-16b2-4922-a855-3df12136bd91,5be02a7f-b729-4c67-a076-05dc19c03a19,15fc1f7b-70c0-4ca7-8d18-9d6ee6cac612,fa85151f-f49b-47f4-bac8-f7f987973252,efb453d7-d16d-42c3-889c-90ae8ec59529,18877502-94e5-4b82-8a71-69ddc61904ca,c360f94d-4c40-4bd0-8e6c-73d7165109c1,e930cc38-bf12-4678-a403-4a0fb54e0995, pattern=[METRICS]
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090019.06|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552393.125|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552393125, Backend time ns: 537856288
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552393125, Backend time ns: 537856288
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:533.87|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:6750e257-cd5c-4bcc-822f-236aabf865e2,148441a3-e9f0-4bff-9837-4ac12dadb591,3ed07937-8560-494e-b648-333c0cc4e35f,e626d6cb-14a2-40f0-add5-2daace13e5b7,5c2e1c6e-3b35-49a2-aad9-6171db53fdd3,bb11673a-38b0-4561-bb5f-9bb773277497,5735db22-525a-46c2-9c3d-a28aba2f0747,ea83328d-1526-439b-8877-e107b92ad7f0,6eaa6a9a-b463-4f3e-a15e-1a818849ab0d,4d4e938e-fe9b-40ab-a1f1-d21d5eae9a3f,535f25cb-7557-4be1-b9f8-fd6029e1bf35,d36274cc-9167-4842-b38e-9f8c84955d1e,e01bdb92-a856-4472-aa87-6a1611bd5086,a2e882aa-3fc3-4a4a-82eb-25340a341fdf,6a76f99a-7c35-4adc-bacc-03c9d6f7e784,856df318-f80c-4fca-a281-7bb1fa2feb0f,eab522b1-759d-4339-9ba5-2f882d8c4335,e6635764-997c-47bb-9617-fe50b4fa7587,68e7891a-0e8e-4382-a0f9-e9bcb15a5e15,0039b71a-369c-4f9d-b915-b4b20876b09e,be23f9e3-1af7-4d88-aa88-0a435b59d4e3,14fa7f84-d09b-4c1c-9945-83f0c37d10b9,ffa26dd0-fcb8-4c49-b708-68184a95b40e,3fb6f2ba-a7d9-4575-9f63-44ffb03cd610,345325aa-4dca-459b-a111-98d15fc1bf5d,eb511ba4-392d-473a-8042-d2852f2f402a,d461dfa5-860b-40bc-810b-7d06aeb01bc9,47dda793-0adb-41ae-ae76-ad2edd5175a5,3824f515-1a20-4773-b594-197545842d8d,4d334b1b-8dc5-43e7-81dd-62ab5d0d8197,9b1659b5-f931-4073-b488-3b2dd89a258d,54685dec-fb69-43bd-b5e2-4a20a60b03ca,a5cf47f5-665d-414a-914d-31dc015a6e32,745edafb-638f-491b-99aa-eeca0e6fa66e,9e8e87c0-9add-46d4-8e4f-de13d6589502,13b70f8e-26dc-4550-a110-4428f11b36f5,e36614e1-7e17-48df-93de-d517ee5a72c2,8bfa3020-9000-4ce2-b2e9-e5f252d56276,2d14e51f-ab2f-4105-a499-a843e0fb3d7b,430a1b5a-eeec-45fb-9b6b-9787f9803fe2,a5660532-a9f7-43b1-89ed-6bdee06bb209,94dd94d4-1abf-4a78-8cb8-a0dbbba7a54d,2535496c-e48c-41af-8804-20d7b622e543,17ddfb08-131c-46ff-8689-3d048f6ea660,a861f18c-3c34-4f5d-9394-dcf58c391b3c,73a92710-6943-4e82-af06-a909325da259,648f3fa9-7b51-403c-b3fd-d80a211dd75f,de90ae05-29e1-4b9d-9272-5e3ba0be8285,6ff91787-16b2-4922-a855-3df12136bd91,5be02a7f-b729-4c67-a076-05dc19c03a19,15fc1f7b-70c0-4ca7-8d18-9d6ee6cac612,fa85151f-f49b-47f4-bac8-f7f987973252,efb453d7-d16d-42c3-889c-90ae8ec59529,18877502-94e5-4b82-8a71-69ddc61904ca,c360f94d-4c40-4bd0-8e6c-73d7165109c1,e930cc38-bf12-4678-a403-4a0fb54e0995,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090267.594|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552373.084|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552373084, Backend time ns: 537973915
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552373084, Backend time ns: 537973915
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 1091
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090346.299|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552349.243|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552349243, Backend time ns: 538066550
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552349243, Backend time ns: 538066550
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090365.62|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552274.509|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552274509, Backend time ns: 538168226
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552274509, Backend time ns: 538168226
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090308.027|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552115.11|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552115110, Backend time ns: 538280882
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552115110, Backend time ns: 538280882
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,348 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090215.951|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551908.508|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551908508, Backend time ns: 538433530
2023-05-08T18:29:41,348 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551908508, Backend time ns: 538433530
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,348 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090221.812|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551764.49|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551764490, Backend time ns: 538528336
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551764490, Backend time ns: 538528336
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 1091
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090200.831|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551648.234|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551648234, Backend time ns: 538633462
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551648234, Backend time ns: 538633462
2023-05-08T18:29:41,349 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 1091
2023-05-08T18:29:41,349 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090215.592|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551521.497|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551521497, Backend time ns: 538782440
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551521497, Backend time ns: 538782440
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,349 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090198.27|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551388.259|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551388259, Backend time ns: 538979871
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551388259, Backend time ns: 538979871
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090288.936|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551277.803|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551277803, Backend time ns: 539092077
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551277803, Backend time ns: 539092077
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,349 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090249.194|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551122.935|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551122935, Backend time ns: 539229635
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551122935, Backend time ns: 539229635
2023-05-08T18:29:41,349 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090273.785|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550987.517|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550987517, Backend time ns: 539360882
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550987517, Backend time ns: 539360882
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090245.633|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550860.95|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550860950, Backend time ns: 539474018
2023-05-08T18:29:41,349 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550860950, Backend time ns: 539474018
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 1091
2023-05-08T18:29:41,350 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089984.529|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550481.429|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550481429, Backend time ns: 539640408
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550481429, Backend time ns: 539640408
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090004.15|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550338.221|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550338221, Backend time ns: 539741333
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550338221, Backend time ns: 539741333
2023-05-08T18:29:41,350 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090098.536|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550297.569|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550297569, Backend time ns: 539895742
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550297569, Backend time ns: 539895742
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090100.535|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550177.512|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550177512, Backend time ns: 540011878
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550177512, Backend time ns: 540011878
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090019.771|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549982.991|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549982991, Backend time ns: 540122784
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549982991, Backend time ns: 540122784
2023-05-08T18:29:41,350 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,350 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090018.701|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549847.164|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549847164, Backend time ns: 540303085
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549847164, Backend time ns: 540303085
2023-05-08T18:29:41,350 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090073.104|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549733.267|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549733267, Backend time ns: 540413191
2023-05-08T18:29:41,350 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549733267, Backend time ns: 540413191
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,350 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090081.055|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549634.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549634552, Backend time ns: 540536318
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549634552, Backend time ns: 540536318
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 1091
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090059.503|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549499.104|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549499104, Backend time ns: 540638853
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549499104, Backend time ns: 540638853
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090052.663|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549390.128|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549390128, Backend time ns: 540745369
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549390128, Backend time ns: 540745369
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090003.47|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549231.73|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549231730, Backend time ns: 540862205
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549231730, Backend time ns: 540862205
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090010.331|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549114.424|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549114424, Backend time ns: 540993782
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549114424, Backend time ns: 540993782
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089971.298|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548941.434|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548941434, Backend time ns: 541108648
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548941434, Backend time ns: 541108648
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089991.63|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548858.64|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548858640, Backend time ns: 541213654
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548858640, Backend time ns: 541213654
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089987.319|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548749.993|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548749993, Backend time ns: 541322100
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548749993, Backend time ns: 541322100
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089906.415|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548555.633|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548555633, Backend time ns: 541430446
2023-05-08T18:29:41,351 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548555633, Backend time ns: 541430446
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 1089
2023-05-08T18:29:41,351 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089900.124|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548444.636|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548444636, Backend time ns: 541528292
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548444636, Backend time ns: 541528292
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,352 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089916.345|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548364.882|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548364882, Backend time ns: 541630297
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548364882, Backend time ns: 541630297
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090025.961|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548370.472|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548370472, Backend time ns: 541740134
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548370472, Backend time ns: 541740134
2023-05-08T18:29:41,352 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090013.2|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548228.304|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548228304, Backend time ns: 541889142
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548228304, Backend time ns: 541889142
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089999.64|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548060.985|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548060985, Backend time ns: 542014839
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548060985, Backend time ns: 542014839
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,352 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1089980.838|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547923.617|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547923617, Backend time ns: 542233031
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547923617, Backend time ns: 542233031
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090058.443|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547799.08|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547799080, Backend time ns: 542344807
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547799080, Backend time ns: 542344807
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090069.894|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547701.075|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547701075, Backend time ns: 542448073
2023-05-08T18:29:41,352 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547701075, Backend time ns: 542448073
2023-05-08T18:29:41,352 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,352 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 1091
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090055.383|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547558.547|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547558547, Backend time ns: 542588611
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547558547, Backend time ns: 542588611
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090044.942|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547429.58|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547429580, Backend time ns: 542694087
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547429580, Backend time ns: 542694087
2023-05-08T18:29:41,353 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090054.932|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547330.854|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547330854, Backend time ns: 542795402
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547330854, Backend time ns: 542795402
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090049.262|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547222.758|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547222758, Backend time ns: 542911339
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547222758, Backend time ns: 542911339
2023-05-08T18:29:41,353 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090072.444|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547105.162|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547105162, Backend time ns: 543065177
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547105162, Backend time ns: 543065177
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 1090
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1090076.724|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546985.925|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546985925, Backend time ns: 543197255
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546985925, Backend time ns: 543197255
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550560.373|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7337.417|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7337417, Backend time ns: 543306681
2023-05-08T18:29:41,353 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7337417, Backend time ns: 543306681
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550536.492|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7175.848|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7175848, Backend time ns: 543459619
2023-05-08T18:29:41,353 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7175848, Backend time ns: 543459619
2023-05-08T18:29:41,353 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550524.572|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:7036.871|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7036871, Backend time ns: 543557715
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 7036871, Backend time ns: 543557715
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550408.156|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6818.329|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6818329, Backend time ns: 543706453
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6818329, Backend time ns: 543706453
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550518.832|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6787.167|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6787167, Backend time ns: 543823060
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6787167, Backend time ns: 543823060
2023-05-08T18:29:41,354 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550469.298|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6596.636|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6596636, Backend time ns: 543937926
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6596636, Backend time ns: 543937926
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550507.911|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6543.453|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6543453, Backend time ns: 544046672
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6543453, Backend time ns: 544046672
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:41,354 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550352.002|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6275.438|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6275438, Backend time ns: 544152228
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6275438, Backend time ns: 544152228
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:41,354 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550416.485|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6238.786|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6238786, Backend time ns: 544297006
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6238786, Backend time ns: 544297006
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550530.232|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6204.574|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6204574, Backend time ns: 544392271
2023-05-08T18:29:41,354 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6204574, Backend time ns: 544392271
2023-05-08T18:29:41,354 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:41,354 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550459.818|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6027.004|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6027004, Backend time ns: 544545870
2023-05-08T18:29:41,355 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6027004, Backend time ns: 544545870
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550485.859|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5913.508|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5913508, Backend time ns: 544683428
2023-05-08T18:29:41,355 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5913508, Backend time ns: 544683428
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:41,355 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 538
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 538
2023-05-08T18:29:41,355 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570581355
2023-05-08T18:29:41,355 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570581355
2023-05-08T18:29:41,358 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570581
2023-05-08T18:29:41,358 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,358 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,358 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,358 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,359 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,362 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,364 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,365 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,366 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,366 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,366 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:41,367 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:41,367 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:41,373 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:41,410 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:41,434 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:41,441 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:41,473 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:41,477 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:41,479 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:41,511 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:41,517 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:41,518 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:41,519 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:41,549 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:41,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:41,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:41,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:41,588 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:41,595 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:41,598 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:41,600 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:41,627 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:41,633 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:41,638 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:41,640 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:41,665 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:41,678 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:41,681 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:41,703 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:41,719 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:41,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:41,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:41,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:41,803 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:539.41|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570581,db2062e0-1f1e-4e9d-833a-1ddf698881a5,3400db33-d836-4ba5-b7e2-89887f7526d3,f2f168d1-a14b-4dc0-b8b1-7be6997275b2,25a7456d-0dca-4071-86a5-2312ebf0c5be,20153368-942e-4fb3-a561-be6c2e3b894b,3967bfc2-2e68-41a6-ae40-7ab3819043b4,35f00767-7f27-4e41-a14c-69bf0262b069,aa6f8f43-8747-4c48-ab70-b91bef54f4ea,6002d905-3487-4367-b67f-1a43f82996a0,7f7c708a-45ec-4aef-ab3e-6182abfd69ae,2ab29cc0-5748-45f2-9432-357b95bebb08,114c4336-ed44-4f53-a9dd-f4ec15229320,b02b24b0-c2bb-4c43-9cbd-368461cdfd65,a97b5f71-bc45-458e-956e-21d91e7312a9,dfda09ed-2fdd-4584-a2bc-6c2dcbeb97b1,73c5ffdd-61a6-49b9-b068-3ca1db83072e,a5f4574c-ec18-4f82-85bb-31dfe7628cf4,f5c49092-7d90-4fd3-b23f-861a70d17390,961a9cf6-626e-477e-b095-6fe40e793c70,62c97990-7432-4b6d-9b1a-649d41ca0ffa,87c7d782-7eb2-4c73-91e9-b9db2d386da7,15b8e1d4-6b86-44b2-b242-d571c0d8f725,5fb30868-e1d3-4e4a-b1fe-153835ad03c6,e988613f-86f7-4acb-a858-174bfb9e2bcf,cea0164a-e444-48ef-bcd6-bd19b85ef4f4,87481064-5b11-4fd3-bf66-4621e4a9cb34,9878b605-1d56-4d8f-847a-5ea4b63ad745,90a7c2ae-feed-4649-9c23-3f4b15ae0003,e1bf6a52-2357-4b57-92df-9eddbb651533,45b5112c-a0d9-4c5c-b310-63ab0891f157,d3572b31-a31f-46e4-ae7f-f0fc3581cd1f,85e1bfb7-8a91-4f02-9555-08ec2d76469c,c442d6a1-c9ea-47c6-ab18-4ec104e6f2db,f8ee4010-c8e2-409d-a165-c010aa7cf93e,507c00f2-f490-4a37-b5f6-10d0342dcf78,041d55d9-4f7c-478f-bd65-d8aba906efae,db78b724-fd97-4e81-aaae-d6d758c95fb2,e18264ef-1c46-4bb5-9393-31fd326aec6b,ee6274e3-96f9-4e5f-a60d-44366c1a43b8,3f7c6c0a-567b-4162-9776-258959e1d54c,4dd96ac4-1259-493c-9795-d274fb4f9db2,1de726ca-5264-4367-b6c8-3a82ef94045c,bd8ea2e2-10d3-41ad-8373-e4649c44806a,a53b5914-2ea0-485c-bada-21f0d97f503c,030e6694-adad-42cc-a1ed-1e57e24830f5,c3ba01a0-4cff-4578-8928-31f4fb5a6542,6eca24c1-ae6b-44d6-a5dd-6e2f3bb726bd,45d82ca9-4ba2-4683-80ba-4d048fbc96ef,6f3b9450-1cf5-4f8c-a1c3-eabd41bd0128,e2da82c3-fad3-4a55-bbd7-d0229066f196,31f7a578-6ebe-4f0b-b74b-0a73b91a762a,25f05ffb-986a-4f33-b3dc-890d42b6aab7,f93c0c20-f0da-4fe6-8c87-dc9596439b48,5f9c8e2b-1ec0-4629-91c1-e4173d80c30e,224ad770-a507-4640-b963-8b7505a20508,0e9ddef9-b498-4075-8e85-0df3c990d534, pattern=[METRICS]
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:539.41|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570581,db2062e0-1f1e-4e9d-833a-1ddf698881a5,3400db33-d836-4ba5-b7e2-89887f7526d3,f2f168d1-a14b-4dc0-b8b1-7be6997275b2,25a7456d-0dca-4071-86a5-2312ebf0c5be,20153368-942e-4fb3-a561-be6c2e3b894b,3967bfc2-2e68-41a6-ae40-7ab3819043b4,35f00767-7f27-4e41-a14c-69bf0262b069,aa6f8f43-8747-4c48-ab70-b91bef54f4ea,6002d905-3487-4367-b67f-1a43f82996a0,7f7c708a-45ec-4aef-ab3e-6182abfd69ae,2ab29cc0-5748-45f2-9432-357b95bebb08,114c4336-ed44-4f53-a9dd-f4ec15229320,b02b24b0-c2bb-4c43-9cbd-368461cdfd65,a97b5f71-bc45-458e-956e-21d91e7312a9,dfda09ed-2fdd-4584-a2bc-6c2dcbeb97b1,73c5ffdd-61a6-49b9-b068-3ca1db83072e,a5f4574c-ec18-4f82-85bb-31dfe7628cf4,f5c49092-7d90-4fd3-b23f-861a70d17390,961a9cf6-626e-477e-b095-6fe40e793c70,62c97990-7432-4b6d-9b1a-649d41ca0ffa,87c7d782-7eb2-4c73-91e9-b9db2d386da7,15b8e1d4-6b86-44b2-b242-d571c0d8f725,5fb30868-e1d3-4e4a-b1fe-153835ad03c6,e988613f-86f7-4acb-a858-174bfb9e2bcf,cea0164a-e444-48ef-bcd6-bd19b85ef4f4,87481064-5b11-4fd3-bf66-4621e4a9cb34,9878b605-1d56-4d8f-847a-5ea4b63ad745,90a7c2ae-feed-4649-9c23-3f4b15ae0003,e1bf6a52-2357-4b57-92df-9eddbb651533,45b5112c-a0d9-4c5c-b310-63ab0891f157,d3572b31-a31f-46e4-ae7f-f0fc3581cd1f,85e1bfb7-8a91-4f02-9555-08ec2d76469c,c442d6a1-c9ea-47c6-ab18-4ec104e6f2db,f8ee4010-c8e2-409d-a165-c010aa7cf93e,507c00f2-f490-4a37-b5f6-10d0342dcf78,041d55d9-4f7c-478f-bd65-d8aba906efae,db78b724-fd97-4e81-aaae-d6d758c95fb2,e18264ef-1c46-4bb5-9393-31fd326aec6b,ee6274e3-96f9-4e5f-a60d-44366c1a43b8,3f7c6c0a-567b-4162-9776-258959e1d54c,4dd96ac4-1259-493c-9795-d274fb4f9db2,1de726ca-5264-4367-b6c8-3a82ef94045c,bd8ea2e2-10d3-41ad-8373-e4649c44806a,a53b5914-2ea0-485c-bada-21f0d97f503c,030e6694-adad-42cc-a1ed-1e57e24830f5,c3ba01a0-4cff-4578-8928-31f4fb5a6542,6eca24c1-ae6b-44d6-a5dd-6e2f3bb726bd,45d82ca9-4ba2-4683-80ba-4d048fbc96ef,6f3b9450-1cf5-4f8c-a1c3-eabd41bd0128,e2da82c3-fad3-4a55-bbd7-d0229066f196,31f7a578-6ebe-4f0b-b74b-0a73b91a762a,25f05ffb-986a-4f33-b3dc-890d42b6aab7,f93c0c20-f0da-4fe6-8c87-dc9596439b48,5f9c8e2b-1ec0-4629-91c1-e4173d80c30e,224ad770-a507-4640-b963-8b7505a20508,0e9ddef9-b498-4075-8e85-0df3c990d534, pattern=[METRICS]
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093938.758|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550620.027|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,898 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550620027, Backend time ns: 543525222
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:539.41|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:db2062e0-1f1e-4e9d-833a-1ddf698881a5,3400db33-d836-4ba5-b7e2-89887f7526d3,f2f168d1-a14b-4dc0-b8b1-7be6997275b2,25a7456d-0dca-4071-86a5-2312ebf0c5be,20153368-942e-4fb3-a561-be6c2e3b894b,3967bfc2-2e68-41a6-ae40-7ab3819043b4,35f00767-7f27-4e41-a14c-69bf0262b069,aa6f8f43-8747-4c48-ab70-b91bef54f4ea,6002d905-3487-4367-b67f-1a43f82996a0,7f7c708a-45ec-4aef-ab3e-6182abfd69ae,2ab29cc0-5748-45f2-9432-357b95bebb08,114c4336-ed44-4f53-a9dd-f4ec15229320,b02b24b0-c2bb-4c43-9cbd-368461cdfd65,a97b5f71-bc45-458e-956e-21d91e7312a9,dfda09ed-2fdd-4584-a2bc-6c2dcbeb97b1,73c5ffdd-61a6-49b9-b068-3ca1db83072e,a5f4574c-ec18-4f82-85bb-31dfe7628cf4,f5c49092-7d90-4fd3-b23f-861a70d17390,961a9cf6-626e-477e-b095-6fe40e793c70,62c97990-7432-4b6d-9b1a-649d41ca0ffa,87c7d782-7eb2-4c73-91e9-b9db2d386da7,15b8e1d4-6b86-44b2-b242-d571c0d8f725,5fb30868-e1d3-4e4a-b1fe-153835ad03c6,e988613f-86f7-4acb-a858-174bfb9e2bcf,cea0164a-e444-48ef-bcd6-bd19b85ef4f4,87481064-5b11-4fd3-bf66-4621e4a9cb34,9878b605-1d56-4d8f-847a-5ea4b63ad745,90a7c2ae-feed-4649-9c23-3f4b15ae0003,e1bf6a52-2357-4b57-92df-9eddbb651533,45b5112c-a0d9-4c5c-b310-63ab0891f157,d3572b31-a31f-46e4-ae7f-f0fc3581cd1f,85e1bfb7-8a91-4f02-9555-08ec2d76469c,c442d6a1-c9ea-47c6-ab18-4ec104e6f2db,f8ee4010-c8e2-409d-a165-c010aa7cf93e,507c00f2-f490-4a37-b5f6-10d0342dcf78,041d55d9-4f7c-478f-bd65-d8aba906efae,db78b724-fd97-4e81-aaae-d6d758c95fb2,e18264ef-1c46-4bb5-9393-31fd326aec6b,ee6274e3-96f9-4e5f-a60d-44366c1a43b8,3f7c6c0a-567b-4162-9776-258959e1d54c,4dd96ac4-1259-493c-9795-d274fb4f9db2,1de726ca-5264-4367-b6c8-3a82ef94045c,bd8ea2e2-10d3-41ad-8373-e4649c44806a,a53b5914-2ea0-485c-bada-21f0d97f503c,030e6694-adad-42cc-a1ed-1e57e24830f5,c3ba01a0-4cff-4578-8928-31f4fb5a6542,6eca24c1-ae6b-44d6-a5dd-6e2f3bb726bd,45d82ca9-4ba2-4683-80ba-4d048fbc96ef,6f3b9450-1cf5-4f8c-a1c3-eabd41bd0128,e2da82c3-fad3-4a55-bbd7-d0229066f196,31f7a578-6ebe-4f0b-b74b-0a73b91a762a,25f05ffb-986a-4f33-b3dc-890d42b6aab7,f93c0c20-f0da-4fe6-8c87-dc9596439b48,5f9c8e2b-1ec0-4629-91c1-e4173d80c30e,224ad770-a507-4640-b963-8b7505a20508,0e9ddef9-b498-4075-8e85-0df3c990d534,timestamp:1683570581
2023-05-08T18:29:41,898 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550620027, Backend time ns: 543525222
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,898 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094115.898|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550514.812|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550514812, Backend time ns: 543678241
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550514812, Backend time ns: 543678241
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094106.057|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:539.49|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570581,db2062e0-1f1e-4e9d-833a-1ddf698881a5,3400db33-d836-4ba5-b7e2-89887f7526d3,f2f168d1-a14b-4dc0-b8b1-7be6997275b2,25a7456d-0dca-4071-86a5-2312ebf0c5be,20153368-942e-4fb3-a561-be6c2e3b894b,3967bfc2-2e68-41a6-ae40-7ab3819043b4,35f00767-7f27-4e41-a14c-69bf0262b069,aa6f8f43-8747-4c48-ab70-b91bef54f4ea,6002d905-3487-4367-b67f-1a43f82996a0,7f7c708a-45ec-4aef-ab3e-6182abfd69ae,2ab29cc0-5748-45f2-9432-357b95bebb08,114c4336-ed44-4f53-a9dd-f4ec15229320,b02b24b0-c2bb-4c43-9cbd-368461cdfd65,a97b5f71-bc45-458e-956e-21d91e7312a9,dfda09ed-2fdd-4584-a2bc-6c2dcbeb97b1,73c5ffdd-61a6-49b9-b068-3ca1db83072e,a5f4574c-ec18-4f82-85bb-31dfe7628cf4,f5c49092-7d90-4fd3-b23f-861a70d17390,961a9cf6-626e-477e-b095-6fe40e793c70,62c97990-7432-4b6d-9b1a-649d41ca0ffa,87c7d782-7eb2-4c73-91e9-b9db2d386da7,15b8e1d4-6b86-44b2-b242-d571c0d8f725,5fb30868-e1d3-4e4a-b1fe-153835ad03c6,e988613f-86f7-4acb-a858-174bfb9e2bcf,cea0164a-e444-48ef-bcd6-bd19b85ef4f4,87481064-5b11-4fd3-bf66-4621e4a9cb34,9878b605-1d56-4d8f-847a-5ea4b63ad745,90a7c2ae-feed-4649-9c23-3f4b15ae0003,e1bf6a52-2357-4b57-92df-9eddbb651533,45b5112c-a0d9-4c5c-b310-63ab0891f157,d3572b31-a31f-46e4-ae7f-f0fc3581cd1f,85e1bfb7-8a91-4f02-9555-08ec2d76469c,c442d6a1-c9ea-47c6-ab18-4ec104e6f2db,f8ee4010-c8e2-409d-a165-c010aa7cf93e,507c00f2-f490-4a37-b5f6-10d0342dcf78,041d55d9-4f7c-478f-bd65-d8aba906efae,db78b724-fd97-4e81-aaae-d6d758c95fb2,e18264ef-1c46-4bb5-9393-31fd326aec6b,ee6274e3-96f9-4e5f-a60d-44366c1a43b8,3f7c6c0a-567b-4162-9776-258959e1d54c,4dd96ac4-1259-493c-9795-d274fb4f9db2,1de726ca-5264-4367-b6c8-3a82ef94045c,bd8ea2e2-10d3-41ad-8373-e4649c44806a,a53b5914-2ea0-485c-bada-21f0d97f503c,030e6694-adad-42cc-a1ed-1e57e24830f5,c3ba01a0-4cff-4578-8928-31f4fb5a6542,6eca24c1-ae6b-44d6-a5dd-6e2f3bb726bd,45d82ca9-4ba2-4683-80ba-4d048fbc96ef,6f3b9450-1cf5-4f8c-a1c3-eabd41bd0128,e2da82c3-fad3-4a55-bbd7-d0229066f196,31f7a578-6ebe-4f0b-b74b-0a73b91a762a,25f05ffb-986a-4f33-b3dc-890d42b6aab7,f93c0c20-f0da-4fe6-8c87-dc9596439b48,5f9c8e2b-1ec0-4629-91c1-e4173d80c30e,224ad770-a507-4640-b963-8b7505a20508,0e9ddef9-b498-4075-8e85-0df3c990d534, pattern=[METRICS]
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550405.955|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550405955, Backend time ns: 543786977
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:539.49|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570581,db2062e0-1f1e-4e9d-833a-1ddf698881a5,3400db33-d836-4ba5-b7e2-89887f7526d3,f2f168d1-a14b-4dc0-b8b1-7be6997275b2,25a7456d-0dca-4071-86a5-2312ebf0c5be,20153368-942e-4fb3-a561-be6c2e3b894b,3967bfc2-2e68-41a6-ae40-7ab3819043b4,35f00767-7f27-4e41-a14c-69bf0262b069,aa6f8f43-8747-4c48-ab70-b91bef54f4ea,6002d905-3487-4367-b67f-1a43f82996a0,7f7c708a-45ec-4aef-ab3e-6182abfd69ae,2ab29cc0-5748-45f2-9432-357b95bebb08,114c4336-ed44-4f53-a9dd-f4ec15229320,b02b24b0-c2bb-4c43-9cbd-368461cdfd65,a97b5f71-bc45-458e-956e-21d91e7312a9,dfda09ed-2fdd-4584-a2bc-6c2dcbeb97b1,73c5ffdd-61a6-49b9-b068-3ca1db83072e,a5f4574c-ec18-4f82-85bb-31dfe7628cf4,f5c49092-7d90-4fd3-b23f-861a70d17390,961a9cf6-626e-477e-b095-6fe40e793c70,62c97990-7432-4b6d-9b1a-649d41ca0ffa,87c7d782-7eb2-4c73-91e9-b9db2d386da7,15b8e1d4-6b86-44b2-b242-d571c0d8f725,5fb30868-e1d3-4e4a-b1fe-153835ad03c6,e988613f-86f7-4acb-a858-174bfb9e2bcf,cea0164a-e444-48ef-bcd6-bd19b85ef4f4,87481064-5b11-4fd3-bf66-4621e4a9cb34,9878b605-1d56-4d8f-847a-5ea4b63ad745,90a7c2ae-feed-4649-9c23-3f4b15ae0003,e1bf6a52-2357-4b57-92df-9eddbb651533,45b5112c-a0d9-4c5c-b310-63ab0891f157,d3572b31-a31f-46e4-ae7f-f0fc3581cd1f,85e1bfb7-8a91-4f02-9555-08ec2d76469c,c442d6a1-c9ea-47c6-ab18-4ec104e6f2db,f8ee4010-c8e2-409d-a165-c010aa7cf93e,507c00f2-f490-4a37-b5f6-10d0342dcf78,041d55d9-4f7c-478f-bd65-d8aba906efae,db78b724-fd97-4e81-aaae-d6d758c95fb2,e18264ef-1c46-4bb5-9393-31fd326aec6b,ee6274e3-96f9-4e5f-a60d-44366c1a43b8,3f7c6c0a-567b-4162-9776-258959e1d54c,4dd96ac4-1259-493c-9795-d274fb4f9db2,1de726ca-5264-4367-b6c8-3a82ef94045c,bd8ea2e2-10d3-41ad-8373-e4649c44806a,a53b5914-2ea0-485c-bada-21f0d97f503c,030e6694-adad-42cc-a1ed-1e57e24830f5,c3ba01a0-4cff-4578-8928-31f4fb5a6542,6eca24c1-ae6b-44d6-a5dd-6e2f3bb726bd,45d82ca9-4ba2-4683-80ba-4d048fbc96ef,6f3b9450-1cf5-4f8c-a1c3-eabd41bd0128,e2da82c3-fad3-4a55-bbd7-d0229066f196,31f7a578-6ebe-4f0b-b74b-0a73b91a762a,25f05ffb-986a-4f33-b3dc-890d42b6aab7,f93c0c20-f0da-4fe6-8c87-dc9596439b48,5f9c8e2b-1ec0-4629-91c1-e4173d80c30e,224ad770-a507-4640-b963-8b7505a20508,0e9ddef9-b498-4075-8e85-0df3c990d534, pattern=[METRICS]
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550405955, Backend time ns: 543786977
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:539.49|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:db2062e0-1f1e-4e9d-833a-1ddf698881a5,3400db33-d836-4ba5-b7e2-89887f7526d3,f2f168d1-a14b-4dc0-b8b1-7be6997275b2,25a7456d-0dca-4071-86a5-2312ebf0c5be,20153368-942e-4fb3-a561-be6c2e3b894b,3967bfc2-2e68-41a6-ae40-7ab3819043b4,35f00767-7f27-4e41-a14c-69bf0262b069,aa6f8f43-8747-4c48-ab70-b91bef54f4ea,6002d905-3487-4367-b67f-1a43f82996a0,7f7c708a-45ec-4aef-ab3e-6182abfd69ae,2ab29cc0-5748-45f2-9432-357b95bebb08,114c4336-ed44-4f53-a9dd-f4ec15229320,b02b24b0-c2bb-4c43-9cbd-368461cdfd65,a97b5f71-bc45-458e-956e-21d91e7312a9,dfda09ed-2fdd-4584-a2bc-6c2dcbeb97b1,73c5ffdd-61a6-49b9-b068-3ca1db83072e,a5f4574c-ec18-4f82-85bb-31dfe7628cf4,f5c49092-7d90-4fd3-b23f-861a70d17390,961a9cf6-626e-477e-b095-6fe40e793c70,62c97990-7432-4b6d-9b1a-649d41ca0ffa,87c7d782-7eb2-4c73-91e9-b9db2d386da7,15b8e1d4-6b86-44b2-b242-d571c0d8f725,5fb30868-e1d3-4e4a-b1fe-153835ad03c6,e988613f-86f7-4acb-a858-174bfb9e2bcf,cea0164a-e444-48ef-bcd6-bd19b85ef4f4,87481064-5b11-4fd3-bf66-4621e4a9cb34,9878b605-1d56-4d8f-847a-5ea4b63ad745,90a7c2ae-feed-4649-9c23-3f4b15ae0003,e1bf6a52-2357-4b57-92df-9eddbb651533,45b5112c-a0d9-4c5c-b310-63ab0891f157,d3572b31-a31f-46e4-ae7f-f0fc3581cd1f,85e1bfb7-8a91-4f02-9555-08ec2d76469c,c442d6a1-c9ea-47c6-ab18-4ec104e6f2db,f8ee4010-c8e2-409d-a165-c010aa7cf93e,507c00f2-f490-4a37-b5f6-10d0342dcf78,041d55d9-4f7c-478f-bd65-d8aba906efae,db78b724-fd97-4e81-aaae-d6d758c95fb2,e18264ef-1c46-4bb5-9393-31fd326aec6b,ee6274e3-96f9-4e5f-a60d-44366c1a43b8,3f7c6c0a-567b-4162-9776-258959e1d54c,4dd96ac4-1259-493c-9795-d274fb4f9db2,1de726ca-5264-4367-b6c8-3a82ef94045c,bd8ea2e2-10d3-41ad-8373-e4649c44806a,a53b5914-2ea0-485c-bada-21f0d97f503c,030e6694-adad-42cc-a1ed-1e57e24830f5,c3ba01a0-4cff-4578-8928-31f4fb5a6542,6eca24c1-ae6b-44d6-a5dd-6e2f3bb726bd,45d82ca9-4ba2-4683-80ba-4d048fbc96ef,6f3b9450-1cf5-4f8c-a1c3-eabd41bd0128,e2da82c3-fad3-4a55-bbd7-d0229066f196,31f7a578-6ebe-4f0b-b74b-0a73b91a762a,25f05ffb-986a-4f33-b3dc-890d42b6aab7,f93c0c20-f0da-4fe6-8c87-dc9596439b48,5f9c8e2b-1ec0-4629-91c1-e4173d80c30e,224ad770-a507-4640-b963-8b7505a20508,0e9ddef9-b498-4075-8e85-0df3c990d534,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094062.105|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550233.516|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550233516, Backend time ns: 543995708
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550233516, Backend time ns: 543995708
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094050.934|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550027.124|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550027124, Backend time ns: 544116935
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550027124, Backend time ns: 544116935
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094072.395|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549933.809|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549933809, Backend time ns: 544205990
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549933809, Backend time ns: 544205990
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094072.116|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549839.114|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549839114, Backend time ns: 544304796
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549839114, Backend time ns: 544304796
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094017.422|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549687.805|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549687805, Backend time ns: 544416642
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549687805, Backend time ns: 544416642
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,899 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093936.558|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549494.295|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549494295, Backend time ns: 544557710
2023-05-08T18:29:41,899 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549494295, Backend time ns: 544557710
2023-05-08T18:29:41,899 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,899 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094062.455|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549441.812|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549441812, Backend time ns: 544721699
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549441812, Backend time ns: 544721699
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094092.116|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549346.326|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549346326, Backend time ns: 544819654
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549346326, Backend time ns: 544819654
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093924.797|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549084.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549084552, Backend time ns: 544951222
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549084552, Backend time ns: 544951222
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093939.449|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548936.334|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548936334, Backend time ns: 545110090
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548936334, Backend time ns: 545110090
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094060.365|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548923.983|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548923983, Backend time ns: 545213886
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548923983, Backend time ns: 545213886
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094018.383|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548781.185|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548781185, Backend time ns: 545302371
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548781185, Backend time ns: 545302371
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093872.674|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548548.122|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548548122, Backend time ns: 545408757
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548548122, Backend time ns: 545408757
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093899.346|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548460.197|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548460197, Backend time ns: 545537954
2023-05-08T18:29:41,900 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548460197, Backend time ns: 545537954
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,900 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093986.631|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548421.655|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548421655, Backend time ns: 545643980
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548421655, Backend time ns: 545643980
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093930.108|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548261.536|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548261536, Backend time ns: 545731815
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548261536, Backend time ns: 545731815
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093892.945|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548140.329|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548140329, Backend time ns: 545842641
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548140329, Backend time ns: 545842641
2023-05-08T18:29:41,901 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093909.906|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548030.743|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548030743, Backend time ns: 545987239
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548030743, Backend time ns: 545987239
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093885.685|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547869.424|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547869424, Backend time ns: 546084645
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547869424, Backend time ns: 546084645
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,901 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093857.064|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547750.358|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547750358, Backend time ns: 546209732
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547750358, Backend time ns: 546209732
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093854.094|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547621.851|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547621851, Backend time ns: 546338209
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547621851, Backend time ns: 546338209
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093847.453|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547487.853|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547487853, Backend time ns: 546430064
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547487853, Backend time ns: 546430064
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093797.601|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547342.155|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547342155, Backend time ns: 546531700
2023-05-08T18:29:41,901 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547342155, Backend time ns: 546531700
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,901 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093796.9|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547243.259|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547243259, Backend time ns: 546631225
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547243259, Backend time ns: 546631225
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093745.088|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547082.901|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547082901, Backend time ns: 546782964
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547082901, Backend time ns: 546782964
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093803.491|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546997.946|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546997946, Backend time ns: 546872789
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546997946, Backend time ns: 546872789
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093734.427|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546827.716|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546827716, Backend time ns: 546971944
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546827716, Backend time ns: 546971944
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093742.508|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546724.071|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546724071, Backend time ns: 547154374
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546724071, Backend time ns: 547154374
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093794.031|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546617.455|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546617455, Backend time ns: 547244739
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546617455, Backend time ns: 547244739
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093742.088|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546475.497|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546475497, Backend time ns: 547344895
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546475497, Backend time ns: 547344895
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093733.308|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546362.681|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546362681, Backend time ns: 547468462
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546362681, Backend time ns: 547468462
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093710.026|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546212.632|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546212632, Backend time ns: 547583788
2023-05-08T18:29:41,902 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546212632, Backend time ns: 547583788
2023-05-08T18:29:41,902 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,902 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093717.677|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546111.467|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546111467, Backend time ns: 547673003
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546111467, Backend time ns: 547673003
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093666.584|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:545969.749|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545969749, Backend time ns: 547811141
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545969749, Backend time ns: 547811141
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093685.205|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:545847.942|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545847942, Backend time ns: 547950739
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545847942, Backend time ns: 547950739
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093648.982|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:545675.642|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545675642, Backend time ns: 548060015
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545675642, Backend time ns: 548060015
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093651.893|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:545552.066|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545552066, Backend time ns: 548170741
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545552066, Backend time ns: 548170741
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093628.661|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:545436.679|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545436679, Backend time ns: 548261146
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545436679, Backend time ns: 548261146
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093596.53|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:545305.272|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545305272, Backend time ns: 548359322
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545305272, Backend time ns: 548359322
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:41,903 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093507.645|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:545123.612|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545123612, Backend time ns: 548560193
2023-05-08T18:29:41,903 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 545123612, Backend time ns: 548560193
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,903 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093543.027|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:544961.473|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 544961473, Backend time ns: 548657398
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 544961473, Backend time ns: 548657398
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:544.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555255.985|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6554.744|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6554744, Backend time ns: 548795016
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6554744, Backend time ns: 548795016
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555348.35|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6521.922|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6521922, Backend time ns: 548895202
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6521922, Backend time ns: 548895202
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555421.044|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6503.051|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6503051, Backend time ns: 549031099
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6503051, Backend time ns: 549031099
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555538.16|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6485.071|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6485071, Backend time ns: 549123333
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6485071, Backend time ns: 549123333
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555355.201|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6208.696|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6208696, Backend time ns: 549258451
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6208696, Backend time ns: 549258451
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555471.216|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6169.643|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6169643, Backend time ns: 549368137
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6169643, Backend time ns: 549368137
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555395.572|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6008.274|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6008274, Backend time ns: 549456622
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6008274, Backend time ns: 549456622
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555433.384|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5954.311|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5954311, Backend time ns: 549561938
2023-05-08T18:29:41,904 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5954311, Backend time ns: 549561938
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,904 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555546.22|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5937.89|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5937890, Backend time ns: 549693055
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5937890, Backend time ns: 549693055
2023-05-08T18:29:41,905 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555442.665|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5717.178|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5717178, Backend time ns: 549801051
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5717178, Backend time ns: 549801051
2023-05-08T18:29:41,905 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555451.566|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5621.743|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5621743, Backend time ns: 549903917
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5621743, Backend time ns: 549903917
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 556
2023-05-08T18:29:41,905 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:555389.133|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5455.174|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5455174, Backend time ns: 550043715
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5455174, Backend time ns: 550043715
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:41,905 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 543
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 543
2023-05-08T18:29:41,905 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570581
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570581905
2023-05-08T18:29:41,905 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570581905
2023-05-08T18:29:41,908 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570581
2023-05-08T18:29:41,908 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,908 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,910 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,911 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,915 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,916 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,916 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,916 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,916 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,916 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:41,916 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:41,916 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:41,917 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:41,917 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:41,923 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:41,960 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:41,982 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:41,989 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:42,020 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:42,025 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:42,027 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:42,059 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:42,065 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:42,065 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:42,068 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:42,097 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:42,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:42,106 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:42,108 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:42,136 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:42,143 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:42,146 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:42,148 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:42,175 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:42,182 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:42,186 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:42,188 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:42,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:42,226 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:42,228 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:42,252 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:42,267 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:42,269 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:42,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:42,309 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:42,351 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:537.03|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570582,8c2e3641-053c-452f-ae1c-9a9043eda239,79475c2d-64e4-4eae-a2ae-8f8fe16f7469,8048d7fc-5ef9-4ee8-a99d-3edb9a602c07,aa4e70c3-dea2-4b02-af6c-1be8bc40c9cf,f51eeb19-ca25-41db-babd-0da54f37306b,fa6fad2f-b805-427d-964e-a5de18b52edd,6ea870d3-4c19-4766-9f2d-4c56b3e39987,5d95a424-08cc-43b2-9e76-ffec9e231d40,eaadb200-6760-46dd-9ced-98378f6a876f,80440073-ff3c-4eca-ab31-4a6516cc6e8b,9028972a-f87e-45da-aab5-5d2ef61882ae,ae7b0a3e-48e5-4583-9eca-5e7f27fba2d8,be427109-6882-4dab-95e9-52877ed4995f,3c5588f2-4ffc-411a-bed3-c187c1e8f593,22ad49a3-3509-45b3-aa1e-a9c5a3a6b76f,e76f30ef-ea4b-4a19-8c81-166c878b20fe,62509e6c-cdea-4f79-bfa7-b3e9c0c4bbdd,70ba91f9-e781-4d1e-95bd-2605de82aa54,5556b1af-892a-43f9-a8d1-1f10980b2818,99e165e9-948b-4d71-ae59-8219bafd0242,96e2b2bf-04a2-479c-930f-0ccca48d693d,4d0b5780-f9d2-4358-874f-bdd608a81227,69baa664-e024-44a8-9855-dc595ace519a,79d1d240-1405-4ec6-8c2b-bee07842bda2,9b311501-d727-421c-a12c-936e0094e9f9,17ee85dd-82d5-45a1-a5c9-f31eb3f1b7ab,fe08dd7e-be65-4962-a133-f8936bc26a4a,16f7dbf6-8786-412d-8e94-4f3b1806190e,e604d71c-010e-4e62-aeb2-848aaf95f2e7,9928ecfa-77e6-474e-8029-2d3f3afe37d6,4a08d73e-d51b-42f8-bc5c-07fab99b3194,0c302c5b-6a3c-4058-a6ea-3becece4caee,6d742168-0cf4-4dff-b5a5-52d176ef5baf,8244cf15-babc-4011-b4f3-f8fe761b4ca7,693d5c9e-8a2e-4ecc-a53b-e80af9eea478,99a80fb5-c1d9-4c46-a95b-dae2dcb0299d,0a505643-67d0-48b1-8aa4-42f48d7f2516,b03d3ca1-8479-474b-a282-e4c4b2bd55a8,659109fb-7a53-4da7-8408-fd4b0cf246f0,8e561df9-16dd-4b3c-80d3-5d786c4df91e,d7c25456-b995-4ff8-b7aa-e058736b0f7e,6768a7f5-063b-4545-8d9f-2ad1b7d6429d,c7d4178c-510f-4015-96f4-5142d6393c72,2f41a1d8-b8ed-4c52-a03b-5894fe252998,d2eccff3-3435-4bd0-b0e7-59407d905716,4c550a6a-3377-4289-a7de-52c59f0d3c43,1e0a5e51-a668-4d8a-ae62-0d9db69f3ef7,7100964a-7708-424f-b627-363fa800ca38,70ddc0e1-832d-48a1-a21f-4f4acc79cc5c,53be38df-0c95-463f-8be4-cef84172dfa6,b5dc6d89-81a5-4fe8-a53d-cb469379b0b4,e48a15c8-9a66-4e44-b50b-47a06fa90738,460522af-a1b4-4039-857b-c7cc47cedd0f,c757d40e-e762-40aa-9c7e-f4ffbad2cbc5,049ce6d5-6bc0-4dc5-b855-f0721e3ce710,744e4170-7c9d-4497-a89c-eee65dd9513e, pattern=[METRICS]
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:537.03|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570582,8c2e3641-053c-452f-ae1c-9a9043eda239,79475c2d-64e4-4eae-a2ae-8f8fe16f7469,8048d7fc-5ef9-4ee8-a99d-3edb9a602c07,aa4e70c3-dea2-4b02-af6c-1be8bc40c9cf,f51eeb19-ca25-41db-babd-0da54f37306b,fa6fad2f-b805-427d-964e-a5de18b52edd,6ea870d3-4c19-4766-9f2d-4c56b3e39987,5d95a424-08cc-43b2-9e76-ffec9e231d40,eaadb200-6760-46dd-9ced-98378f6a876f,80440073-ff3c-4eca-ab31-4a6516cc6e8b,9028972a-f87e-45da-aab5-5d2ef61882ae,ae7b0a3e-48e5-4583-9eca-5e7f27fba2d8,be427109-6882-4dab-95e9-52877ed4995f,3c5588f2-4ffc-411a-bed3-c187c1e8f593,22ad49a3-3509-45b3-aa1e-a9c5a3a6b76f,e76f30ef-ea4b-4a19-8c81-166c878b20fe,62509e6c-cdea-4f79-bfa7-b3e9c0c4bbdd,70ba91f9-e781-4d1e-95bd-2605de82aa54,5556b1af-892a-43f9-a8d1-1f10980b2818,99e165e9-948b-4d71-ae59-8219bafd0242,96e2b2bf-04a2-479c-930f-0ccca48d693d,4d0b5780-f9d2-4358-874f-bdd608a81227,69baa664-e024-44a8-9855-dc595ace519a,79d1d240-1405-4ec6-8c2b-bee07842bda2,9b311501-d727-421c-a12c-936e0094e9f9,17ee85dd-82d5-45a1-a5c9-f31eb3f1b7ab,fe08dd7e-be65-4962-a133-f8936bc26a4a,16f7dbf6-8786-412d-8e94-4f3b1806190e,e604d71c-010e-4e62-aeb2-848aaf95f2e7,9928ecfa-77e6-474e-8029-2d3f3afe37d6,4a08d73e-d51b-42f8-bc5c-07fab99b3194,0c302c5b-6a3c-4058-a6ea-3becece4caee,6d742168-0cf4-4dff-b5a5-52d176ef5baf,8244cf15-babc-4011-b4f3-f8fe761b4ca7,693d5c9e-8a2e-4ecc-a53b-e80af9eea478,99a80fb5-c1d9-4c46-a95b-dae2dcb0299d,0a505643-67d0-48b1-8aa4-42f48d7f2516,b03d3ca1-8479-474b-a282-e4c4b2bd55a8,659109fb-7a53-4da7-8408-fd4b0cf246f0,8e561df9-16dd-4b3c-80d3-5d786c4df91e,d7c25456-b995-4ff8-b7aa-e058736b0f7e,6768a7f5-063b-4545-8d9f-2ad1b7d6429d,c7d4178c-510f-4015-96f4-5142d6393c72,2f41a1d8-b8ed-4c52-a03b-5894fe252998,d2eccff3-3435-4bd0-b0e7-59407d905716,4c550a6a-3377-4289-a7de-52c59f0d3c43,1e0a5e51-a668-4d8a-ae62-0d9db69f3ef7,7100964a-7708-424f-b627-363fa800ca38,70ddc0e1-832d-48a1-a21f-4f4acc79cc5c,53be38df-0c95-463f-8be4-cef84172dfa6,b5dc6d89-81a5-4fe8-a53d-cb469379b0b4,e48a15c8-9a66-4e44-b50b-47a06fa90738,460522af-a1b4-4039-857b-c7cc47cedd0f,c757d40e-e762-40aa-9c7e-f4ffbad2cbc5,049ce6d5-6bc0-4dc5-b855-f0721e3ce710,744e4170-7c9d-4497-a89c-eee65dd9513e, pattern=[METRICS]
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:537.03|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:8c2e3641-053c-452f-ae1c-9a9043eda239,79475c2d-64e4-4eae-a2ae-8f8fe16f7469,8048d7fc-5ef9-4ee8-a99d-3edb9a602c07,aa4e70c3-dea2-4b02-af6c-1be8bc40c9cf,f51eeb19-ca25-41db-babd-0da54f37306b,fa6fad2f-b805-427d-964e-a5de18b52edd,6ea870d3-4c19-4766-9f2d-4c56b3e39987,5d95a424-08cc-43b2-9e76-ffec9e231d40,eaadb200-6760-46dd-9ced-98378f6a876f,80440073-ff3c-4eca-ab31-4a6516cc6e8b,9028972a-f87e-45da-aab5-5d2ef61882ae,ae7b0a3e-48e5-4583-9eca-5e7f27fba2d8,be427109-6882-4dab-95e9-52877ed4995f,3c5588f2-4ffc-411a-bed3-c187c1e8f593,22ad49a3-3509-45b3-aa1e-a9c5a3a6b76f,e76f30ef-ea4b-4a19-8c81-166c878b20fe,62509e6c-cdea-4f79-bfa7-b3e9c0c4bbdd,70ba91f9-e781-4d1e-95bd-2605de82aa54,5556b1af-892a-43f9-a8d1-1f10980b2818,99e165e9-948b-4d71-ae59-8219bafd0242,96e2b2bf-04a2-479c-930f-0ccca48d693d,4d0b5780-f9d2-4358-874f-bdd608a81227,69baa664-e024-44a8-9855-dc595ace519a,79d1d240-1405-4ec6-8c2b-bee07842bda2,9b311501-d727-421c-a12c-936e0094e9f9,17ee85dd-82d5-45a1-a5c9-f31eb3f1b7ab,fe08dd7e-be65-4962-a133-f8936bc26a4a,16f7dbf6-8786-412d-8e94-4f3b1806190e,e604d71c-010e-4e62-aeb2-848aaf95f2e7,9928ecfa-77e6-474e-8029-2d3f3afe37d6,4a08d73e-d51b-42f8-bc5c-07fab99b3194,0c302c5b-6a3c-4058-a6ea-3becece4caee,6d742168-0cf4-4dff-b5a5-52d176ef5baf,8244cf15-babc-4011-b4f3-f8fe761b4ca7,693d5c9e-8a2e-4ecc-a53b-e80af9eea478,99a80fb5-c1d9-4c46-a95b-dae2dcb0299d,0a505643-67d0-48b1-8aa4-42f48d7f2516,b03d3ca1-8479-474b-a282-e4c4b2bd55a8,659109fb-7a53-4da7-8408-fd4b0cf246f0,8e561df9-16dd-4b3c-80d3-5d786c4df91e,d7c25456-b995-4ff8-b7aa-e058736b0f7e,6768a7f5-063b-4545-8d9f-2ad1b7d6429d,c7d4178c-510f-4015-96f4-5142d6393c72,2f41a1d8-b8ed-4c52-a03b-5894fe252998,d2eccff3-3435-4bd0-b0e7-59407d905716,4c550a6a-3377-4289-a7de-52c59f0d3c43,1e0a5e51-a668-4d8a-ae62-0d9db69f3ef7,7100964a-7708-424f-b627-363fa800ca38,70ddc0e1-832d-48a1-a21f-4f4acc79cc5c,53be38df-0c95-463f-8be4-cef84172dfa6,b5dc6d89-81a5-4fe8-a53d-cb469379b0b4,e48a15c8-9a66-4e44-b50b-47a06fa90738,460522af-a1b4-4039-857b-c7cc47cedd0f,c757d40e-e762-40aa-9c7e-f4ffbad2cbc5,049ce6d5-6bc0-4dc5-b855-f0721e3ce710,744e4170-7c9d-4497-a89c-eee65dd9513e,timestamp:1683570582
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096568.104|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555590.673|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,446 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555590673, Backend time ns: 541239466
2023-05-08T18:29:42,446 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555590673, Backend time ns: 541239466
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.12|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570582,8c2e3641-053c-452f-ae1c-9a9043eda239,79475c2d-64e4-4eae-a2ae-8f8fe16f7469,8048d7fc-5ef9-4ee8-a99d-3edb9a602c07,aa4e70c3-dea2-4b02-af6c-1be8bc40c9cf,f51eeb19-ca25-41db-babd-0da54f37306b,fa6fad2f-b805-427d-964e-a5de18b52edd,6ea870d3-4c19-4766-9f2d-4c56b3e39987,5d95a424-08cc-43b2-9e76-ffec9e231d40,eaadb200-6760-46dd-9ced-98378f6a876f,80440073-ff3c-4eca-ab31-4a6516cc6e8b,9028972a-f87e-45da-aab5-5d2ef61882ae,ae7b0a3e-48e5-4583-9eca-5e7f27fba2d8,be427109-6882-4dab-95e9-52877ed4995f,3c5588f2-4ffc-411a-bed3-c187c1e8f593,22ad49a3-3509-45b3-aa1e-a9c5a3a6b76f,e76f30ef-ea4b-4a19-8c81-166c878b20fe,62509e6c-cdea-4f79-bfa7-b3e9c0c4bbdd,70ba91f9-e781-4d1e-95bd-2605de82aa54,5556b1af-892a-43f9-a8d1-1f10980b2818,99e165e9-948b-4d71-ae59-8219bafd0242,96e2b2bf-04a2-479c-930f-0ccca48d693d,4d0b5780-f9d2-4358-874f-bdd608a81227,69baa664-e024-44a8-9855-dc595ace519a,79d1d240-1405-4ec6-8c2b-bee07842bda2,9b311501-d727-421c-a12c-936e0094e9f9,17ee85dd-82d5-45a1-a5c9-f31eb3f1b7ab,fe08dd7e-be65-4962-a133-f8936bc26a4a,16f7dbf6-8786-412d-8e94-4f3b1806190e,e604d71c-010e-4e62-aeb2-848aaf95f2e7,9928ecfa-77e6-474e-8029-2d3f3afe37d6,4a08d73e-d51b-42f8-bc5c-07fab99b3194,0c302c5b-6a3c-4058-a6ea-3becece4caee,6d742168-0cf4-4dff-b5a5-52d176ef5baf,8244cf15-babc-4011-b4f3-f8fe761b4ca7,693d5c9e-8a2e-4ecc-a53b-e80af9eea478,99a80fb5-c1d9-4c46-a95b-dae2dcb0299d,0a505643-67d0-48b1-8aa4-42f48d7f2516,b03d3ca1-8479-474b-a282-e4c4b2bd55a8,659109fb-7a53-4da7-8408-fd4b0cf246f0,8e561df9-16dd-4b3c-80d3-5d786c4df91e,d7c25456-b995-4ff8-b7aa-e058736b0f7e,6768a7f5-063b-4545-8d9f-2ad1b7d6429d,c7d4178c-510f-4015-96f4-5142d6393c72,2f41a1d8-b8ed-4c52-a03b-5894fe252998,d2eccff3-3435-4bd0-b0e7-59407d905716,4c550a6a-3377-4289-a7de-52c59f0d3c43,1e0a5e51-a668-4d8a-ae62-0d9db69f3ef7,7100964a-7708-424f-b627-363fa800ca38,70ddc0e1-832d-48a1-a21f-4f4acc79cc5c,53be38df-0c95-463f-8be4-cef84172dfa6,b5dc6d89-81a5-4fe8-a53d-cb469379b0b4,e48a15c8-9a66-4e44-b50b-47a06fa90738,460522af-a1b4-4039-857b-c7cc47cedd0f,c757d40e-e762-40aa-9c7e-f4ffbad2cbc5,049ce6d5-6bc0-4dc5-b855-f0721e3ce710,744e4170-7c9d-4497-a89c-eee65dd9513e, pattern=[METRICS]
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:537.12|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570582,8c2e3641-053c-452f-ae1c-9a9043eda239,79475c2d-64e4-4eae-a2ae-8f8fe16f7469,8048d7fc-5ef9-4ee8-a99d-3edb9a602c07,aa4e70c3-dea2-4b02-af6c-1be8bc40c9cf,f51eeb19-ca25-41db-babd-0da54f37306b,fa6fad2f-b805-427d-964e-a5de18b52edd,6ea870d3-4c19-4766-9f2d-4c56b3e39987,5d95a424-08cc-43b2-9e76-ffec9e231d40,eaadb200-6760-46dd-9ced-98378f6a876f,80440073-ff3c-4eca-ab31-4a6516cc6e8b,9028972a-f87e-45da-aab5-5d2ef61882ae,ae7b0a3e-48e5-4583-9eca-5e7f27fba2d8,be427109-6882-4dab-95e9-52877ed4995f,3c5588f2-4ffc-411a-bed3-c187c1e8f593,22ad49a3-3509-45b3-aa1e-a9c5a3a6b76f,e76f30ef-ea4b-4a19-8c81-166c878b20fe,62509e6c-cdea-4f79-bfa7-b3e9c0c4bbdd,70ba91f9-e781-4d1e-95bd-2605de82aa54,5556b1af-892a-43f9-a8d1-1f10980b2818,99e165e9-948b-4d71-ae59-8219bafd0242,96e2b2bf-04a2-479c-930f-0ccca48d693d,4d0b5780-f9d2-4358-874f-bdd608a81227,69baa664-e024-44a8-9855-dc595ace519a,79d1d240-1405-4ec6-8c2b-bee07842bda2,9b311501-d727-421c-a12c-936e0094e9f9,17ee85dd-82d5-45a1-a5c9-f31eb3f1b7ab,fe08dd7e-be65-4962-a133-f8936bc26a4a,16f7dbf6-8786-412d-8e94-4f3b1806190e,e604d71c-010e-4e62-aeb2-848aaf95f2e7,9928ecfa-77e6-474e-8029-2d3f3afe37d6,4a08d73e-d51b-42f8-bc5c-07fab99b3194,0c302c5b-6a3c-4058-a6ea-3becece4caee,6d742168-0cf4-4dff-b5a5-52d176ef5baf,8244cf15-babc-4011-b4f3-f8fe761b4ca7,693d5c9e-8a2e-4ecc-a53b-e80af9eea478,99a80fb5-c1d9-4c46-a95b-dae2dcb0299d,0a505643-67d0-48b1-8aa4-42f48d7f2516,b03d3ca1-8479-474b-a282-e4c4b2bd55a8,659109fb-7a53-4da7-8408-fd4b0cf246f0,8e561df9-16dd-4b3c-80d3-5d786c4df91e,d7c25456-b995-4ff8-b7aa-e058736b0f7e,6768a7f5-063b-4545-8d9f-2ad1b7d6429d,c7d4178c-510f-4015-96f4-5142d6393c72,2f41a1d8-b8ed-4c52-a03b-5894fe252998,d2eccff3-3435-4bd0-b0e7-59407d905716,4c550a6a-3377-4289-a7de-52c59f0d3c43,1e0a5e51-a668-4d8a-ae62-0d9db69f3ef7,7100964a-7708-424f-b627-363fa800ca38,70ddc0e1-832d-48a1-a21f-4f4acc79cc5c,53be38df-0c95-463f-8be4-cef84172dfa6,b5dc6d89-81a5-4fe8-a53d-cb469379b0b4,e48a15c8-9a66-4e44-b50b-47a06fa90738,460522af-a1b4-4039-857b-c7cc47cedd0f,c757d40e-e762-40aa-9c7e-f4ffbad2cbc5,049ce6d5-6bc0-4dc5-b855-f0721e3ce710,744e4170-7c9d-4497-a89c-eee65dd9513e, pattern=[METRICS]
2023-05-08T18:29:42,446 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096780.156|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555510.209|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555510209, Backend time ns: 541392414
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555510209, Backend time ns: 541392414
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:537.12|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:8c2e3641-053c-452f-ae1c-9a9043eda239,79475c2d-64e4-4eae-a2ae-8f8fe16f7469,8048d7fc-5ef9-4ee8-a99d-3edb9a602c07,aa4e70c3-dea2-4b02-af6c-1be8bc40c9cf,f51eeb19-ca25-41db-babd-0da54f37306b,fa6fad2f-b805-427d-964e-a5de18b52edd,6ea870d3-4c19-4766-9f2d-4c56b3e39987,5d95a424-08cc-43b2-9e76-ffec9e231d40,eaadb200-6760-46dd-9ced-98378f6a876f,80440073-ff3c-4eca-ab31-4a6516cc6e8b,9028972a-f87e-45da-aab5-5d2ef61882ae,ae7b0a3e-48e5-4583-9eca-5e7f27fba2d8,be427109-6882-4dab-95e9-52877ed4995f,3c5588f2-4ffc-411a-bed3-c187c1e8f593,22ad49a3-3509-45b3-aa1e-a9c5a3a6b76f,e76f30ef-ea4b-4a19-8c81-166c878b20fe,62509e6c-cdea-4f79-bfa7-b3e9c0c4bbdd,70ba91f9-e781-4d1e-95bd-2605de82aa54,5556b1af-892a-43f9-a8d1-1f10980b2818,99e165e9-948b-4d71-ae59-8219bafd0242,96e2b2bf-04a2-479c-930f-0ccca48d693d,4d0b5780-f9d2-4358-874f-bdd608a81227,69baa664-e024-44a8-9855-dc595ace519a,79d1d240-1405-4ec6-8c2b-bee07842bda2,9b311501-d727-421c-a12c-936e0094e9f9,17ee85dd-82d5-45a1-a5c9-f31eb3f1b7ab,fe08dd7e-be65-4962-a133-f8936bc26a4a,16f7dbf6-8786-412d-8e94-4f3b1806190e,e604d71c-010e-4e62-aeb2-848aaf95f2e7,9928ecfa-77e6-474e-8029-2d3f3afe37d6,4a08d73e-d51b-42f8-bc5c-07fab99b3194,0c302c5b-6a3c-4058-a6ea-3becece4caee,6d742168-0cf4-4dff-b5a5-52d176ef5baf,8244cf15-babc-4011-b4f3-f8fe761b4ca7,693d5c9e-8a2e-4ecc-a53b-e80af9eea478,99a80fb5-c1d9-4c46-a95b-dae2dcb0299d,0a505643-67d0-48b1-8aa4-42f48d7f2516,b03d3ca1-8479-474b-a282-e4c4b2bd55a8,659109fb-7a53-4da7-8408-fd4b0cf246f0,8e561df9-16dd-4b3c-80d3-5d786c4df91e,d7c25456-b995-4ff8-b7aa-e058736b0f7e,6768a7f5-063b-4545-8d9f-2ad1b7d6429d,c7d4178c-510f-4015-96f4-5142d6393c72,2f41a1d8-b8ed-4c52-a03b-5894fe252998,d2eccff3-3435-4bd0-b0e7-59407d905716,4c550a6a-3377-4289-a7de-52c59f0d3c43,1e0a5e51-a668-4d8a-ae62-0d9db69f3ef7,7100964a-7708-424f-b627-363fa800ca38,70ddc0e1-832d-48a1-a21f-4f4acc79cc5c,53be38df-0c95-463f-8be4-cef84172dfa6,b5dc6d89-81a5-4fe8-a53d-cb469379b0b4,e48a15c8-9a66-4e44-b50b-47a06fa90738,460522af-a1b4-4039-857b-c7cc47cedd0f,c757d40e-e762-40aa-9c7e-f4ffbad2cbc5,049ce6d5-6bc0-4dc5-b855-f0721e3ce710,744e4170-7c9d-4497-a89c-eee65dd9513e,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096781.937|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:555362.461|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555362461, Backend time ns: 541494370
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 555362461, Backend time ns: 541494370
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:555.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096502.901|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554985.38|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554985380, Backend time ns: 541609366
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554985380, Backend time ns: 541609366
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096566.494|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554935.057|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554935057, Backend time ns: 541704491
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554935057, Backend time ns: 541704491
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,447 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096610.666|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554874.623|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554874623, Backend time ns: 541875361
2023-05-08T18:29:42,447 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554874623, Backend time ns: 541875361
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,447 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096732.903|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554818.91|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554818910, Backend time ns: 542013109
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554818910, Backend time ns: 542013109
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096713.842|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554679.202|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554679202, Backend time ns: 542103114
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554679202, Backend time ns: 542103114
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096701.092|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554572.427|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554572427, Backend time ns: 542193759
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554572427, Backend time ns: 542193759
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096632.118|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554417.408|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554417408, Backend time ns: 542321616
2023-05-08T18:29:42,447 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554417408, Backend time ns: 542321616
2023-05-08T18:29:42,447 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096696.071|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554352.774|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554352774, Backend time ns: 542457673
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554352774, Backend time ns: 542457673
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096732.073|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554219.917|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554219917, Backend time ns: 542596611
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554219917, Backend time ns: 542596611
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096722.633|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554102.15|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554102150, Backend time ns: 542691726
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554102150, Backend time ns: 542691726
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096695.012|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553981.724|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553981724, Backend time ns: 542811393
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553981724, Backend time ns: 542811393
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096679.56|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553845.226|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553845226, Backend time ns: 542911889
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553845226, Backend time ns: 542911889
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096681.62|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553744.81|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553744810, Backend time ns: 543024215
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553744810, Backend time ns: 543024215
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096720.952|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553672.596|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553672596, Backend time ns: 543115490
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553672596, Backend time ns: 543115490
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096706.212|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553568.771|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553568771, Backend time ns: 543241567
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553568771, Backend time ns: 543241567
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096686.211|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553423.983|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553423983, Backend time ns: 543324012
2023-05-08T18:29:42,448 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553423983, Backend time ns: 543324012
2023-05-08T18:29:42,448 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096714.542|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553370.169|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553370169, Backend time ns: 543413627
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553370169, Backend time ns: 543413627
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096508.101|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553071.723|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553071723, Backend time ns: 543500602
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553071723, Backend time ns: 543500602
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096515.902|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552993.049|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552993049, Backend time ns: 543624408
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552993049, Backend time ns: 543624408
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096596.466|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552950.126|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552950126, Backend time ns: 543725184
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552950126, Backend time ns: 543725184
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096553.293|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552803.918|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552803918, Backend time ns: 543813569
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552803918, Backend time ns: 543813569
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096496.1|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552660.04|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552660040, Backend time ns: 543907444
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552660040, Backend time ns: 543907444
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096490.48|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552560.424|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552560424, Backend time ns: 544036711
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552560424, Backend time ns: 544036711
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096511.891|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552426.787|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552426787, Backend time ns: 544182780
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552426787, Backend time ns: 544182780
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096502.411|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552297.571|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552297571, Backend time ns: 544273024
2023-05-08T18:29:42,449 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552297571, Backend time ns: 544273024
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,449 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096485.48|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552187.065|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552187065, Backend time ns: 544393460
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552187065, Backend time ns: 544393460
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096520.481|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552088.739|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552088739, Backend time ns: 544499466
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552088739, Backend time ns: 544499466
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096478.729|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551958.242|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551958242, Backend time ns: 544598742
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551958242, Backend time ns: 544598742
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096432.127|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551810.674|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551810674, Backend time ns: 544694727
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551810674, Backend time ns: 544694727
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096441.417|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551705.748|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551705748, Backend time ns: 544816234
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551705748, Backend time ns: 544816234
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096429.377|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551528.538|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551528538, Backend time ns: 544971453
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551528538, Backend time ns: 544971453
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096445.767|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551444.093|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551444093, Backend time ns: 545065978
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551444093, Backend time ns: 545065978
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096387.654|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551297.145|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551297145, Backend time ns: 545185804
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551297145, Backend time ns: 545185804
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096373.783|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551162.067|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551162067, Backend time ns: 545306741
2023-05-08T18:29:42,450 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,450 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551162067, Backend time ns: 545306741
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096402.315|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551038.911|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551038911, Backend time ns: 545428058
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551038911, Backend time ns: 545428058
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096363.003|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550912.004|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550912004, Backend time ns: 545547585
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550912004, Backend time ns: 545547585
2023-05-08T18:29:42,451 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096447.427|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550851.96|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550851960, Backend time ns: 545665121
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550851960, Backend time ns: 545665121
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 1097
2023-05-08T18:29:42,451 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096409.135|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550721.173|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550721173, Backend time ns: 545772177
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550721173, Backend time ns: 545772177
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,451 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096405.585|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550611.997|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550611997, Backend time ns: 545897834
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550611997, Backend time ns: 545897834
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,451 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096415.056|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550492.76|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550492760, Backend time ns: 546010290
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550492760, Backend time ns: 546010290
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 1096
2023-05-08T18:29:42,451 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096409.645|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550372.513|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550372513, Backend time ns: 546136037
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550372513, Backend time ns: 546136037
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552519.933|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6361.194|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6361194, Backend time ns: 546256184
2023-05-08T18:29:42,451 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6361194, Backend time ns: 546256184
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,451 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552609.288|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6326.592|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6326592, Backend time ns: 546350209
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6326592, Backend time ns: 546350209
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552665.861|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6293.65|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6293650, Backend time ns: 546446985
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6293650, Backend time ns: 546446985
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552647.62|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6179.184|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6179184, Backend time ns: 546540890
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6179184, Backend time ns: 546540890
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552448.358|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5884.477|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5884477, Backend time ns: 546631125
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5884477, Backend time ns: 546631125
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552421.727|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5769.731|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5769731, Backend time ns: 546727650
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5769731, Backend time ns: 546727650
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552424.567|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5671.705|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5671705, Backend time ns: 546833886
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5671705, Backend time ns: 546833886
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552471.33|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5580.42|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5580420, Backend time ns: 546970034
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5580420, Backend time ns: 546970034
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552415.607|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5422.722|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5422722, Backend time ns: 547068669
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5422722, Backend time ns: 547068669
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552435.188|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5331.137|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5331137, Backend time ns: 547185966
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5331137, Backend time ns: 547185966
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:42,452 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552495.341|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5287.694|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5287694, Backend time ns: 547281901
2023-05-08T18:29:42,452 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5287694, Backend time ns: 547281901
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 552
2023-05-08T18:29:42,452 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,453 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,453 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552488.301|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,453 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5182.988|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,453 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5182988, Backend time ns: 547383957
2023-05-08T18:29:42,453 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5182988, Backend time ns: 547383957
2023-05-08T18:29:42,453 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,453 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,453 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:42,453 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:42,453 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 541
2023-05-08T18:29:42,453 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 541
2023-05-08T18:29:42,453 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,453 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,453 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570582453
2023-05-08T18:29:42,453 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570582453
2023-05-08T18:29:42,456 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570582
2023-05-08T18:29:42,456 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,456 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,456 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,456 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,456 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,456 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,458 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,459 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,460 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,461 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:42,463 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:42,464 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:42,464 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:42,465 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:42,471 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:42,507 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:42,525 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:42,531 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:42,564 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:42,568 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:42,570 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:42,602 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:42,608 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:42,609 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:42,610 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:42,641 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:42,647 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:42,649 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:42,650 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:42,679 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:42,685 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:42,689 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:42,691 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:42,717 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:42,724 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:42,729 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:42,731 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:42,756 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:42,769 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:42,771 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:42,794 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:42,810 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:42,811 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:42,850 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:42,852 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:42,894 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:42,992 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:42,992 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:535.83|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570582,45d7e770-a38a-411f-903e-8844ce4ce030,0309e585-57c0-4560-9e08-b9677437edee,6334f31b-e687-4519-8430-72c2e354d5d6,fd5369dd-387a-41e1-85ee-d96fb3ae9801,1847bf8c-80f5-4743-a6dc-ed356652309b,77d0dd80-0517-42cd-b43e-a9ee197e11be,d1b141fb-0164-490f-8518-271808d60cf9,6a6fa790-f71e-46bf-bafd-4148435ebc15,a9f5f776-20c0-4396-89f2-16926a795b46,c0991a2e-160a-47e0-a221-0339fe2da879,5e5c11c9-7548-42bd-bb7c-f856c8982dfa,3a0bb06a-7abc-4583-b7ed-ba426cb0f19e,0b6b62f0-5aa3-401a-94c6-2666c881b54e,e456b7f0-e6b3-43f3-9747-20050ef6693e,ab707a66-074b-4a6d-ac0f-c7b57f71eff2,0e061a6a-94fb-4b3a-8536-d26a39cc70aa,5470d20f-e0de-4df1-a2d2-f1ccbfc46187,8e1f8425-089a-4675-a358-11b6158d5128,0e8604ca-814f-4261-acfc-caaeac4e89c1,d9771d9a-47ca-460c-baf2-ba2bb0f8d331,2b5822a0-55af-40f4-a563-0c97aa46f2c5,7fef2cb7-ef23-4231-b8bb-547d594207a3,596258d8-e362-4666-826d-bd7938aafd0d,8c8f140f-4a1e-41c4-9086-537e2593a661,fa1cf40e-4f62-4e65-b533-a9439ab8c673,7c2e68b7-a007-455a-a62e-f7f8122410d0,fb899142-d818-497b-940b-08cdd8a8af49,7f5fa10e-0082-4754-b494-8dd03161e9b1,a8a552a2-e4b9-45d5-9629-01135ff9f69a,47d6f792-cbb4-4cb9-8915-0cb8841dfbf3,577599d4-75db-497f-9492-bc0cebd781f2,9e1721f3-290e-437e-a35b-9e80b0ad5100,93f915f0-552a-4e38-bf1d-2c1f131e9a27,9e2bfb14-a3bc-42f2-8aa2-d817c24841ab,2d88e3aa-f96e-49a2-93bb-e731f589e052,059d44bf-cf34-40c2-b467-3f2f5aa5f8ff,84441c88-dd01-41e4-bf99-f418bec899a5,2a8a238c-a97f-4f05-b50b-c1abd65c9930,2b6b32a5-e24f-431c-a074-ce623ebef36f,5d0c7deb-9e24-4a0e-a6a0-529b7f383d0d,b4d34229-d574-4eb5-b9e0-782cf0aea382,140fe5eb-7638-4789-8e77-3086d5f76f37,dcf409f2-44d4-4a2a-a016-a17569d1e3a6,3818def0-fa57-41f3-a4a4-05fe415a45b7,d0e736ff-d606-46d8-806a-fdc133ef69b5,59affa01-9b43-429b-a95b-5de210191822,6d9e66a2-330f-4a53-a1b6-0773857cb3ec,37d16b2b-daf9-4e7c-8d61-8c1261af7e0e,ef0e4878-f1fe-4600-8563-54ede1c6c2bd,8dbe77b2-50e2-42fa-bb18-7b3a20632200,9cafd6ad-7fac-49b0-ab2e-275ab5a90b10,d7af1702-6c3d-4c7e-ac19-cb53e162311a,cb752890-d43e-4df8-b916-d5d63b2ec69f,744f17c7-893a-41c3-b1b9-ab4bac68115f,810de1e6-222b-46ae-9511-a3feddd9d7a3,2c6b6f1a-0dfb-4f27-96f2-982d6531f299, pattern=[METRICS]
2023-05-08T18:29:42,992 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:535.83|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570582,45d7e770-a38a-411f-903e-8844ce4ce030,0309e585-57c0-4560-9e08-b9677437edee,6334f31b-e687-4519-8430-72c2e354d5d6,fd5369dd-387a-41e1-85ee-d96fb3ae9801,1847bf8c-80f5-4743-a6dc-ed356652309b,77d0dd80-0517-42cd-b43e-a9ee197e11be,d1b141fb-0164-490f-8518-271808d60cf9,6a6fa790-f71e-46bf-bafd-4148435ebc15,a9f5f776-20c0-4396-89f2-16926a795b46,c0991a2e-160a-47e0-a221-0339fe2da879,5e5c11c9-7548-42bd-bb7c-f856c8982dfa,3a0bb06a-7abc-4583-b7ed-ba426cb0f19e,0b6b62f0-5aa3-401a-94c6-2666c881b54e,e456b7f0-e6b3-43f3-9747-20050ef6693e,ab707a66-074b-4a6d-ac0f-c7b57f71eff2,0e061a6a-94fb-4b3a-8536-d26a39cc70aa,5470d20f-e0de-4df1-a2d2-f1ccbfc46187,8e1f8425-089a-4675-a358-11b6158d5128,0e8604ca-814f-4261-acfc-caaeac4e89c1,d9771d9a-47ca-460c-baf2-ba2bb0f8d331,2b5822a0-55af-40f4-a563-0c97aa46f2c5,7fef2cb7-ef23-4231-b8bb-547d594207a3,596258d8-e362-4666-826d-bd7938aafd0d,8c8f140f-4a1e-41c4-9086-537e2593a661,fa1cf40e-4f62-4e65-b533-a9439ab8c673,7c2e68b7-a007-455a-a62e-f7f8122410d0,fb899142-d818-497b-940b-08cdd8a8af49,7f5fa10e-0082-4754-b494-8dd03161e9b1,a8a552a2-e4b9-45d5-9629-01135ff9f69a,47d6f792-cbb4-4cb9-8915-0cb8841dfbf3,577599d4-75db-497f-9492-bc0cebd781f2,9e1721f3-290e-437e-a35b-9e80b0ad5100,93f915f0-552a-4e38-bf1d-2c1f131e9a27,9e2bfb14-a3bc-42f2-8aa2-d817c24841ab,2d88e3aa-f96e-49a2-93bb-e731f589e052,059d44bf-cf34-40c2-b467-3f2f5aa5f8ff,84441c88-dd01-41e4-bf99-f418bec899a5,2a8a238c-a97f-4f05-b50b-c1abd65c9930,2b6b32a5-e24f-431c-a074-ce623ebef36f,5d0c7deb-9e24-4a0e-a6a0-529b7f383d0d,b4d34229-d574-4eb5-b9e0-782cf0aea382,140fe5eb-7638-4789-8e77-3086d5f76f37,dcf409f2-44d4-4a2a-a016-a17569d1e3a6,3818def0-fa57-41f3-a4a4-05fe415a45b7,d0e736ff-d606-46d8-806a-fdc133ef69b5,59affa01-9b43-429b-a95b-5de210191822,6d9e66a2-330f-4a53-a1b6-0773857cb3ec,37d16b2b-daf9-4e7c-8d61-8c1261af7e0e,ef0e4878-f1fe-4600-8563-54ede1c6c2bd,8dbe77b2-50e2-42fa-bb18-7b3a20632200,9cafd6ad-7fac-49b0-ab2e-275ab5a90b10,d7af1702-6c3d-4c7e-ac19-cb53e162311a,cb752890-d43e-4df8-b916-d5d63b2ec69f,744f17c7-893a-41c3-b1b9-ab4bac68115f,810de1e6-222b-46ae-9511-a3feddd9d7a3,2c6b6f1a-0dfb-4f27-96f2-982d6531f299, pattern=[METRICS]
2023-05-08T18:29:42,992 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:535.83|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:45d7e770-a38a-411f-903e-8844ce4ce030,0309e585-57c0-4560-9e08-b9677437edee,6334f31b-e687-4519-8430-72c2e354d5d6,fd5369dd-387a-41e1-85ee-d96fb3ae9801,1847bf8c-80f5-4743-a6dc-ed356652309b,77d0dd80-0517-42cd-b43e-a9ee197e11be,d1b141fb-0164-490f-8518-271808d60cf9,6a6fa790-f71e-46bf-bafd-4148435ebc15,a9f5f776-20c0-4396-89f2-16926a795b46,c0991a2e-160a-47e0-a221-0339fe2da879,5e5c11c9-7548-42bd-bb7c-f856c8982dfa,3a0bb06a-7abc-4583-b7ed-ba426cb0f19e,0b6b62f0-5aa3-401a-94c6-2666c881b54e,e456b7f0-e6b3-43f3-9747-20050ef6693e,ab707a66-074b-4a6d-ac0f-c7b57f71eff2,0e061a6a-94fb-4b3a-8536-d26a39cc70aa,5470d20f-e0de-4df1-a2d2-f1ccbfc46187,8e1f8425-089a-4675-a358-11b6158d5128,0e8604ca-814f-4261-acfc-caaeac4e89c1,d9771d9a-47ca-460c-baf2-ba2bb0f8d331,2b5822a0-55af-40f4-a563-0c97aa46f2c5,7fef2cb7-ef23-4231-b8bb-547d594207a3,596258d8-e362-4666-826d-bd7938aafd0d,8c8f140f-4a1e-41c4-9086-537e2593a661,fa1cf40e-4f62-4e65-b533-a9439ab8c673,7c2e68b7-a007-455a-a62e-f7f8122410d0,fb899142-d818-497b-940b-08cdd8a8af49,7f5fa10e-0082-4754-b494-8dd03161e9b1,a8a552a2-e4b9-45d5-9629-01135ff9f69a,47d6f792-cbb4-4cb9-8915-0cb8841dfbf3,577599d4-75db-497f-9492-bc0cebd781f2,9e1721f3-290e-437e-a35b-9e80b0ad5100,93f915f0-552a-4e38-bf1d-2c1f131e9a27,9e2bfb14-a3bc-42f2-8aa2-d817c24841ab,2d88e3aa-f96e-49a2-93bb-e731f589e052,059d44bf-cf34-40c2-b467-3f2f5aa5f8ff,84441c88-dd01-41e4-bf99-f418bec899a5,2a8a238c-a97f-4f05-b50b-c1abd65c9930,2b6b32a5-e24f-431c-a074-ce623ebef36f,5d0c7deb-9e24-4a0e-a6a0-529b7f383d0d,b4d34229-d574-4eb5-b9e0-782cf0aea382,140fe5eb-7638-4789-8e77-3086d5f76f37,dcf409f2-44d4-4a2a-a016-a17569d1e3a6,3818def0-fa57-41f3-a4a4-05fe415a45b7,d0e736ff-d606-46d8-806a-fdc133ef69b5,59affa01-9b43-429b-a95b-5de210191822,6d9e66a2-330f-4a53-a1b6-0773857cb3ec,37d16b2b-daf9-4e7c-8d61-8c1261af7e0e,ef0e4878-f1fe-4600-8563-54ede1c6c2bd,8dbe77b2-50e2-42fa-bb18-7b3a20632200,9cafd6ad-7fac-49b0-ab2e-275ab5a90b10,d7af1702-6c3d-4c7e-ac19-cb53e162311a,cb752890-d43e-4df8-b916-d5d63b2ec69f,744f17c7-893a-41c3-b1b9-ab4bac68115f,810de1e6-222b-46ae-9511-a3feddd9d7a3,2c6b6f1a-0dfb-4f27-96f2-982d6531f299,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:535.92|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570582,45d7e770-a38a-411f-903e-8844ce4ce030,0309e585-57c0-4560-9e08-b9677437edee,6334f31b-e687-4519-8430-72c2e354d5d6,fd5369dd-387a-41e1-85ee-d96fb3ae9801,1847bf8c-80f5-4743-a6dc-ed356652309b,77d0dd80-0517-42cd-b43e-a9ee197e11be,d1b141fb-0164-490f-8518-271808d60cf9,6a6fa790-f71e-46bf-bafd-4148435ebc15,a9f5f776-20c0-4396-89f2-16926a795b46,c0991a2e-160a-47e0-a221-0339fe2da879,5e5c11c9-7548-42bd-bb7c-f856c8982dfa,3a0bb06a-7abc-4583-b7ed-ba426cb0f19e,0b6b62f0-5aa3-401a-94c6-2666c881b54e,e456b7f0-e6b3-43f3-9747-20050ef6693e,ab707a66-074b-4a6d-ac0f-c7b57f71eff2,0e061a6a-94fb-4b3a-8536-d26a39cc70aa,5470d20f-e0de-4df1-a2d2-f1ccbfc46187,8e1f8425-089a-4675-a358-11b6158d5128,0e8604ca-814f-4261-acfc-caaeac4e89c1,d9771d9a-47ca-460c-baf2-ba2bb0f8d331,2b5822a0-55af-40f4-a563-0c97aa46f2c5,7fef2cb7-ef23-4231-b8bb-547d594207a3,596258d8-e362-4666-826d-bd7938aafd0d,8c8f140f-4a1e-41c4-9086-537e2593a661,fa1cf40e-4f62-4e65-b533-a9439ab8c673,7c2e68b7-a007-455a-a62e-f7f8122410d0,fb899142-d818-497b-940b-08cdd8a8af49,7f5fa10e-0082-4754-b494-8dd03161e9b1,a8a552a2-e4b9-45d5-9629-01135ff9f69a,47d6f792-cbb4-4cb9-8915-0cb8841dfbf3,577599d4-75db-497f-9492-bc0cebd781f2,9e1721f3-290e-437e-a35b-9e80b0ad5100,93f915f0-552a-4e38-bf1d-2c1f131e9a27,9e2bfb14-a3bc-42f2-8aa2-d817c24841ab,2d88e3aa-f96e-49a2-93bb-e731f589e052,059d44bf-cf34-40c2-b467-3f2f5aa5f8ff,84441c88-dd01-41e4-bf99-f418bec899a5,2a8a238c-a97f-4f05-b50b-c1abd65c9930,2b6b32a5-e24f-431c-a074-ce623ebef36f,5d0c7deb-9e24-4a0e-a6a0-529b7f383d0d,b4d34229-d574-4eb5-b9e0-782cf0aea382,140fe5eb-7638-4789-8e77-3086d5f76f37,dcf409f2-44d4-4a2a-a016-a17569d1e3a6,3818def0-fa57-41f3-a4a4-05fe415a45b7,d0e736ff-d606-46d8-806a-fdc133ef69b5,59affa01-9b43-429b-a95b-5de210191822,6d9e66a2-330f-4a53-a1b6-0773857cb3ec,37d16b2b-daf9-4e7c-8d61-8c1261af7e0e,ef0e4878-f1fe-4600-8563-54ede1c6c2bd,8dbe77b2-50e2-42fa-bb18-7b3a20632200,9cafd6ad-7fac-49b0-ab2e-275ab5a90b10,d7af1702-6c3d-4c7e-ac19-cb53e162311a,cb752890-d43e-4df8-b916-d5d63b2ec69f,744f17c7-893a-41c3-b1b9-ab4bac68115f,810de1e6-222b-46ae-9511-a3feddd9d7a3,2c6b6f1a-0dfb-4f27-96f2-982d6531f299, pattern=[METRICS]
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:535.92|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570582,45d7e770-a38a-411f-903e-8844ce4ce030,0309e585-57c0-4560-9e08-b9677437edee,6334f31b-e687-4519-8430-72c2e354d5d6,fd5369dd-387a-41e1-85ee-d96fb3ae9801,1847bf8c-80f5-4743-a6dc-ed356652309b,77d0dd80-0517-42cd-b43e-a9ee197e11be,d1b141fb-0164-490f-8518-271808d60cf9,6a6fa790-f71e-46bf-bafd-4148435ebc15,a9f5f776-20c0-4396-89f2-16926a795b46,c0991a2e-160a-47e0-a221-0339fe2da879,5e5c11c9-7548-42bd-bb7c-f856c8982dfa,3a0bb06a-7abc-4583-b7ed-ba426cb0f19e,0b6b62f0-5aa3-401a-94c6-2666c881b54e,e456b7f0-e6b3-43f3-9747-20050ef6693e,ab707a66-074b-4a6d-ac0f-c7b57f71eff2,0e061a6a-94fb-4b3a-8536-d26a39cc70aa,5470d20f-e0de-4df1-a2d2-f1ccbfc46187,8e1f8425-089a-4675-a358-11b6158d5128,0e8604ca-814f-4261-acfc-caaeac4e89c1,d9771d9a-47ca-460c-baf2-ba2bb0f8d331,2b5822a0-55af-40f4-a563-0c97aa46f2c5,7fef2cb7-ef23-4231-b8bb-547d594207a3,596258d8-e362-4666-826d-bd7938aafd0d,8c8f140f-4a1e-41c4-9086-537e2593a661,fa1cf40e-4f62-4e65-b533-a9439ab8c673,7c2e68b7-a007-455a-a62e-f7f8122410d0,fb899142-d818-497b-940b-08cdd8a8af49,7f5fa10e-0082-4754-b494-8dd03161e9b1,a8a552a2-e4b9-45d5-9629-01135ff9f69a,47d6f792-cbb4-4cb9-8915-0cb8841dfbf3,577599d4-75db-497f-9492-bc0cebd781f2,9e1721f3-290e-437e-a35b-9e80b0ad5100,93f915f0-552a-4e38-bf1d-2c1f131e9a27,9e2bfb14-a3bc-42f2-8aa2-d817c24841ab,2d88e3aa-f96e-49a2-93bb-e731f589e052,059d44bf-cf34-40c2-b467-3f2f5aa5f8ff,84441c88-dd01-41e4-bf99-f418bec899a5,2a8a238c-a97f-4f05-b50b-c1abd65c9930,2b6b32a5-e24f-431c-a074-ce623ebef36f,5d0c7deb-9e24-4a0e-a6a0-529b7f383d0d,b4d34229-d574-4eb5-b9e0-782cf0aea382,140fe5eb-7638-4789-8e77-3086d5f76f37,dcf409f2-44d4-4a2a-a016-a17569d1e3a6,3818def0-fa57-41f3-a4a4-05fe415a45b7,d0e736ff-d606-46d8-806a-fdc133ef69b5,59affa01-9b43-429b-a95b-5de210191822,6d9e66a2-330f-4a53-a1b6-0773857cb3ec,37d16b2b-daf9-4e7c-8d61-8c1261af7e0e,ef0e4878-f1fe-4600-8563-54ede1c6c2bd,8dbe77b2-50e2-42fa-bb18-7b3a20632200,9cafd6ad-7fac-49b0-ab2e-275ab5a90b10,d7af1702-6c3d-4c7e-ac19-cb53e162311a,cb752890-d43e-4df8-b916-d5d63b2ec69f,744f17c7-893a-41c3-b1b9-ab4bac68115f,810de1e6-222b-46ae-9511-a3feddd9d7a3,2c6b6f1a-0dfb-4f27-96f2-982d6531f299, pattern=[METRICS]
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:535.92|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:45d7e770-a38a-411f-903e-8844ce4ce030,0309e585-57c0-4560-9e08-b9677437edee,6334f31b-e687-4519-8430-72c2e354d5d6,fd5369dd-387a-41e1-85ee-d96fb3ae9801,1847bf8c-80f5-4743-a6dc-ed356652309b,77d0dd80-0517-42cd-b43e-a9ee197e11be,d1b141fb-0164-490f-8518-271808d60cf9,6a6fa790-f71e-46bf-bafd-4148435ebc15,a9f5f776-20c0-4396-89f2-16926a795b46,c0991a2e-160a-47e0-a221-0339fe2da879,5e5c11c9-7548-42bd-bb7c-f856c8982dfa,3a0bb06a-7abc-4583-b7ed-ba426cb0f19e,0b6b62f0-5aa3-401a-94c6-2666c881b54e,e456b7f0-e6b3-43f3-9747-20050ef6693e,ab707a66-074b-4a6d-ac0f-c7b57f71eff2,0e061a6a-94fb-4b3a-8536-d26a39cc70aa,5470d20f-e0de-4df1-a2d2-f1ccbfc46187,8e1f8425-089a-4675-a358-11b6158d5128,0e8604ca-814f-4261-acfc-caaeac4e89c1,d9771d9a-47ca-460c-baf2-ba2bb0f8d331,2b5822a0-55af-40f4-a563-0c97aa46f2c5,7fef2cb7-ef23-4231-b8bb-547d594207a3,596258d8-e362-4666-826d-bd7938aafd0d,8c8f140f-4a1e-41c4-9086-537e2593a661,fa1cf40e-4f62-4e65-b533-a9439ab8c673,7c2e68b7-a007-455a-a62e-f7f8122410d0,fb899142-d818-497b-940b-08cdd8a8af49,7f5fa10e-0082-4754-b494-8dd03161e9b1,a8a552a2-e4b9-45d5-9629-01135ff9f69a,47d6f792-cbb4-4cb9-8915-0cb8841dfbf3,577599d4-75db-497f-9492-bc0cebd781f2,9e1721f3-290e-437e-a35b-9e80b0ad5100,93f915f0-552a-4e38-bf1d-2c1f131e9a27,9e2bfb14-a3bc-42f2-8aa2-d817c24841ab,2d88e3aa-f96e-49a2-93bb-e731f589e052,059d44bf-cf34-40c2-b467-3f2f5aa5f8ff,84441c88-dd01-41e4-bf99-f418bec899a5,2a8a238c-a97f-4f05-b50b-c1abd65c9930,2b6b32a5-e24f-431c-a074-ce623ebef36f,5d0c7deb-9e24-4a0e-a6a0-529b7f383d0d,b4d34229-d574-4eb5-b9e0-782cf0aea382,140fe5eb-7638-4789-8e77-3086d5f76f37,dcf409f2-44d4-4a2a-a016-a17569d1e3a6,3818def0-fa57-41f3-a4a4-05fe415a45b7,d0e736ff-d606-46d8-806a-fdc133ef69b5,59affa01-9b43-429b-a95b-5de210191822,6d9e66a2-330f-4a53-a1b6-0773857cb3ec,37d16b2b-daf9-4e7c-8d61-8c1261af7e0e,ef0e4878-f1fe-4600-8563-54ede1c6c2bd,8dbe77b2-50e2-42fa-bb18-7b3a20632200,9cafd6ad-7fac-49b0-ab2e-275ab5a90b10,d7af1702-6c3d-4c7e-ac19-cb53e162311a,cb752890-d43e-4df8-b916-d5d63b2ec69f,744f17c7-893a-41c3-b1b9-ab4bac68115f,810de1e6-222b-46ae-9511-a3feddd9d7a3,2c6b6f1a-0dfb-4f27-96f2-982d6531f299,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092219.473|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552455.299|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552455299, Backend time ns: 540062590
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552455299, Backend time ns: 540062590
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092478.437|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552386.275|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552386275, Backend time ns: 540166026
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552386275, Backend time ns: 540166026
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092550.901|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552364.354|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552364354, Backend time ns: 540255001
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552364354, Backend time ns: 540255001
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092533.71|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552258.638|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552258638, Backend time ns: 540348836
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552258638, Backend time ns: 540348836
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092500.248|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552130.521|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552130521, Backend time ns: 540462883
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552130521, Backend time ns: 540462883
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,993 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092516.229|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552025.115|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552025115, Backend time ns: 540585069
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552025115, Backend time ns: 540585069
2023-05-08T18:29:42,993 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092626.335|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551971.402|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551971402, Backend time ns: 540750398
2023-05-08T18:29:42,993 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551971402, Backend time ns: 540750398
2023-05-08T18:29:42,993 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092636.226|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551864.496|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551864496, Backend time ns: 540848434
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551864496, Backend time ns: 540848434
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092568.802|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551695.377|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551695377, Backend time ns: 540962570
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551695377, Backend time ns: 540962570
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,994 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092562.512|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551576.57|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551576570, Backend time ns: 541120969
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551576570, Backend time ns: 541120969
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092496.338|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551337.917|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551337917, Backend time ns: 541229475
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551337917, Backend time ns: 541229475
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,994 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092534.26|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551281.984|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551281984, Backend time ns: 541339861
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551281984, Backend time ns: 541339861
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092549.33|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551188.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551188548, Backend time ns: 541451928
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551188548, Backend time ns: 541451928
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092558.881|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551082.902|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551082902, Backend time ns: 541548803
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551082902, Backend time ns: 541548803
2023-05-08T18:29:42,994 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092677.448|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551074.172|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551074172, Backend time ns: 541673910
2023-05-08T18:29:42,994 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551074172, Backend time ns: 541673910
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092637.356|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,994 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550942.405|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550942405, Backend time ns: 541767135
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550942405, Backend time ns: 541767135
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092544.06|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550755.774|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550755774, Backend time ns: 541876661
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550755774, Backend time ns: 541876661
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092608.715|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550709.562|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550709562, Backend time ns: 542021809
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550709562, Backend time ns: 542021809
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092499.698|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550422.916|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550422916, Backend time ns: 542147876
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550422916, Backend time ns: 542147876
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092574.043|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550387.604|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550387604, Backend time ns: 542264073
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550387604, Backend time ns: 542264073
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092598.043|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550312.759|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550312759, Backend time ns: 542358958
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550312759, Backend time ns: 542358958
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092626.615|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550246.026|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550246026, Backend time ns: 542482225
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550246026, Backend time ns: 542482225
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092569.102|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550040.274|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550040274, Backend time ns: 542593561
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550040274, Backend time ns: 542593561
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092570.082|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549955.271|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549955271, Backend time ns: 542677835
2023-05-08T18:29:42,995 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549955271, Backend time ns: 542677835
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092600.484|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,995 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549901.718|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549901718, Backend time ns: 542814023
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549901718, Backend time ns: 542814023
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092656.386|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549789.671|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549789671, Backend time ns: 542955920
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549789671, Backend time ns: 542955920
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092365.511|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549386.099|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549386099, Backend time ns: 543039545
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549386099, Backend time ns: 543039545
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092411.793|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549352.067|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549352067, Backend time ns: 543133620
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549352067, Backend time ns: 543133620
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092484.138|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549328.886|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549328886, Backend time ns: 543226186
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549328886, Backend time ns: 543226186
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092549.811|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549302.004|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549302004, Backend time ns: 543336242
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549302004, Backend time ns: 543336242
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092562.492|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549156.026|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549156026, Backend time ns: 543501591
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549156026, Backend time ns: 543501591
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092550.531|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549028.199|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549028199, Backend time ns: 543594146
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549028199, Backend time ns: 543594146
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092500.668|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548877.16|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548877160, Backend time ns: 543689201
2023-05-08T18:29:42,996 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548877160, Backend time ns: 543689201
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,996 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,996 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092527.32|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548816.707|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548816707, Backend time ns: 543796687
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548816707, Backend time ns: 543796687
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092512.879|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548669.089|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548669089, Backend time ns: 543911914
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548669089, Backend time ns: 543911914
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092520.55|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548555.703|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548555703, Backend time ns: 544033701
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548555703, Backend time ns: 544033701
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092381.442|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548309.019|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548309019, Backend time ns: 544137126
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548309019, Backend time ns: 544137126
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092421.544|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548254.466|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548254466, Backend time ns: 544244332
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548254466, Backend time ns: 544244332
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092529.5|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548242.645|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548242645, Backend time ns: 544367059
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548242645, Backend time ns: 544367059
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092546.26|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548123.238|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548123238, Backend time ns: 544516117
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548123238, Backend time ns: 544516117
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092558.822|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548021.713|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548021713, Backend time ns: 544599742
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548021713, Backend time ns: 544599742
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092472.336|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547852.573|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547852573, Backend time ns: 544684597
2023-05-08T18:29:42,997 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547852573, Backend time ns: 544684597
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:42,997 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,997 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092392.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547683.004|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547683004, Backend time ns: 544783232
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547683004, Backend time ns: 544783232
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092471.307|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547659.313|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547659313, Backend time ns: 544899429
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547659313, Backend time ns: 544899429
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550711.932|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5791.112|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5791112, Backend time ns: 545000394
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5791112, Backend time ns: 545000394
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550776.646|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5754.94|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5754940, Backend time ns: 545088439
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5754940, Backend time ns: 545088439
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550816.898|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5704.047|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5704047, Backend time ns: 545205946
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5704047, Backend time ns: 545205946
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550879.751|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5652.024|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5652024, Backend time ns: 545307972
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5652024, Backend time ns: 545307972
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550958.616|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5629.943|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5629943, Backend time ns: 545393516
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5629943, Backend time ns: 545393516
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550708.372|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5288.364|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5288364, Backend time ns: 545487912
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5288364, Backend time ns: 545487912
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550748.944|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5217.89|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5217890, Backend time ns: 545613229
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5217890, Backend time ns: 545613229
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,998 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550795.567|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5161.257|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5161257, Backend time ns: 545705684
2023-05-08T18:29:42,998 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5161257, Backend time ns: 545705684
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:42,998 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550842.029|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5115.794|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5115794, Backend time ns: 545796719
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5115794, Backend time ns: 545796719
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550907.323|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5086.873|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5086873, Backend time ns: 545887464
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5086873, Backend time ns: 545887464
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550908.993|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5000.878|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5000878, Backend time ns: 545987559
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5000878, Backend time ns: 545987559
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550811.908|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4803.137|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4803137, Backend time ns: 546084775
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4803137, Backend time ns: 546084775
2023-05-08T18:29:42,999 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:42,999 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 539
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 539
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570582
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570582999
2023-05-08T18:29:42,999 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570582999
2023-05-08T18:29:43,002 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570583
2023-05-08T18:29:43,002 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,002 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,003 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,004 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,005 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,006 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,007 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,008 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,009 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,010 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:43,011 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:43,011 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:43,017 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:43,055 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:43,079 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:43,085 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:43,117 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:43,121 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:43,124 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:43,156 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:43,161 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:43,162 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:43,164 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:43,194 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:43,200 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:43,202 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:43,204 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:43,232 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:43,238 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:43,242 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:43,244 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:43,271 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:43,277 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:43,282 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:43,284 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:43,309 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:43,323 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:43,325 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:43,347 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:43,363 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:43,366 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:43,403 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:43,405 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:43,447 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:43,542 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:43,542 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:539.06|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570583,ef966a40-b38f-4402-aec9-e58eb5278bda,c5eea5d0-3064-42b1-b95f-0dd12ef24be0,9c3b1a3d-0502-4877-a86e-505f8147c2c2,831e98d3-f510-4676-aa1e-83030ce723f6,9d4418a6-61d5-4048-9d9e-65005043176b,ab04ccb9-cc9e-4840-a529-b6fc75aba5f3,5d6df3fc-030d-4d6f-a0fc-a25fc2601925,541f5def-1e9a-4b88-be4f-14abc6d4b6b4,20e91feb-7fb7-4685-9222-9d9cf078d135,6843bca6-84bc-43df-ae07-e2d59379df11,a416a85e-7e84-4e5b-81ea-540a483b3b42,3d9b038e-c00c-4123-8497-7815799dfc7e,9f19a879-30ab-4f0e-9607-ef31a3f2094b,dd411988-e6c5-41e7-ac97-477a7e6a6f02,f201884c-3f9d-4b5f-af14-d56a064dbc30,eb45ea88-b01d-4804-902e-4f6502100de5,e14e4a5e-51c9-4b27-ad00-d813d6016738,e60a4ac1-423e-494e-bc96-4627b3e6c93b,c4c77a5a-af76-49c1-a384-0645daa9268a,a4b567ff-c2ae-4980-bc67-6c47b578736c,01347835-6dc6-426c-98d8-8eaf456e3e33,c1603c13-2968-48c4-b63b-c36d0febb756,90796281-edfb-4219-81cf-7e175535b4f6,6b2b42ff-eb2b-4db8-b5a8-bb061bfbce8b,ce9c11fc-7326-40c4-a6db-0f944094e9a9,88dc35af-b436-412b-9281-f2537175f038,dfa42905-4203-447e-8165-d9b5a0cd7a29,eb21b0a9-7427-468f-923f-fa1341646550,d32c6ebf-7b31-40cb-b01d-562d60f0036e,4bd08a96-8d16-4816-b6fc-34b16646859c,a3e4117a-127a-484c-a93a-70f4ad6eced8,03286de7-bca2-496a-992e-c5714bacd2a4,54d59cd8-a90a-48e8-adc9-91b5e0694f1e,70c9a8a1-64be-4fb3-afec-3cdeeb7140dc,75f07387-8500-4535-993a-69cd81b654cc,22a24006-54a8-423a-aa14-9331061548b5,6a09568b-e216-4393-a3dd-55e6a7af567d,f7207d1b-cfd5-4cec-925d-9e76a09b929f,10f06533-d858-4613-b811-171023cdf398,8587004c-71a6-44b4-8342-37e92ff5898f,b0c46f59-287b-466e-aa36-e0df542f8db9,0be8dd5d-2271-4378-b8ce-5ca20d335431,fc82d023-3ed4-4d0d-91e2-dd618b89c69a,d5f3efe9-9462-4834-a8df-d049a22430f0,49a10234-030a-4a2f-b750-579b842068dc,88de0084-4bd7-499e-add4-52fa0b874aa3,b0c2293f-ff56-42ea-928d-28224f0a4cae,1e4269b6-787a-416a-a1c1-ceae611c1449,74bcc696-244e-498d-8200-8c201819a685,35bdf550-25d5-4660-9e56-49eecefc877e,e1cd023c-7411-4928-b33a-dbd309294503,14a0fb6a-e272-4f35-bced-bbe7d4f905ca,fdf78dc5-3cc9-44ce-8423-f3e289aebe92,7dbe78d9-ec7d-4a73-9f38-0ddde9265345,07e95ad8-bf33-463c-8eac-31d92854176b,d899ae7b-eb76-4e02-9831-ab7978d09393, pattern=[METRICS]
2023-05-08T18:29:43,542 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:539.06|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570583,ef966a40-b38f-4402-aec9-e58eb5278bda,c5eea5d0-3064-42b1-b95f-0dd12ef24be0,9c3b1a3d-0502-4877-a86e-505f8147c2c2,831e98d3-f510-4676-aa1e-83030ce723f6,9d4418a6-61d5-4048-9d9e-65005043176b,ab04ccb9-cc9e-4840-a529-b6fc75aba5f3,5d6df3fc-030d-4d6f-a0fc-a25fc2601925,541f5def-1e9a-4b88-be4f-14abc6d4b6b4,20e91feb-7fb7-4685-9222-9d9cf078d135,6843bca6-84bc-43df-ae07-e2d59379df11,a416a85e-7e84-4e5b-81ea-540a483b3b42,3d9b038e-c00c-4123-8497-7815799dfc7e,9f19a879-30ab-4f0e-9607-ef31a3f2094b,dd411988-e6c5-41e7-ac97-477a7e6a6f02,f201884c-3f9d-4b5f-af14-d56a064dbc30,eb45ea88-b01d-4804-902e-4f6502100de5,e14e4a5e-51c9-4b27-ad00-d813d6016738,e60a4ac1-423e-494e-bc96-4627b3e6c93b,c4c77a5a-af76-49c1-a384-0645daa9268a,a4b567ff-c2ae-4980-bc67-6c47b578736c,01347835-6dc6-426c-98d8-8eaf456e3e33,c1603c13-2968-48c4-b63b-c36d0febb756,90796281-edfb-4219-81cf-7e175535b4f6,6b2b42ff-eb2b-4db8-b5a8-bb061bfbce8b,ce9c11fc-7326-40c4-a6db-0f944094e9a9,88dc35af-b436-412b-9281-f2537175f038,dfa42905-4203-447e-8165-d9b5a0cd7a29,eb21b0a9-7427-468f-923f-fa1341646550,d32c6ebf-7b31-40cb-b01d-562d60f0036e,4bd08a96-8d16-4816-b6fc-34b16646859c,a3e4117a-127a-484c-a93a-70f4ad6eced8,03286de7-bca2-496a-992e-c5714bacd2a4,54d59cd8-a90a-48e8-adc9-91b5e0694f1e,70c9a8a1-64be-4fb3-afec-3cdeeb7140dc,75f07387-8500-4535-993a-69cd81b654cc,22a24006-54a8-423a-aa14-9331061548b5,6a09568b-e216-4393-a3dd-55e6a7af567d,f7207d1b-cfd5-4cec-925d-9e76a09b929f,10f06533-d858-4613-b811-171023cdf398,8587004c-71a6-44b4-8342-37e92ff5898f,b0c46f59-287b-466e-aa36-e0df542f8db9,0be8dd5d-2271-4378-b8ce-5ca20d335431,fc82d023-3ed4-4d0d-91e2-dd618b89c69a,d5f3efe9-9462-4834-a8df-d049a22430f0,49a10234-030a-4a2f-b750-579b842068dc,88de0084-4bd7-499e-add4-52fa0b874aa3,b0c2293f-ff56-42ea-928d-28224f0a4cae,1e4269b6-787a-416a-a1c1-ceae611c1449,74bcc696-244e-498d-8200-8c201819a685,35bdf550-25d5-4660-9e56-49eecefc877e,e1cd023c-7411-4928-b33a-dbd309294503,14a0fb6a-e272-4f35-bced-bbe7d4f905ca,fdf78dc5-3cc9-44ce-8423-f3e289aebe92,7dbe78d9-ec7d-4a73-9f38-0ddde9265345,07e95ad8-bf33-463c-8eac-31d92854176b,d899ae7b-eb76-4e02-9831-ab7978d09393, pattern=[METRICS]
2023-05-08T18:29:43,542 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:539.06|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:ef966a40-b38f-4402-aec9-e58eb5278bda,c5eea5d0-3064-42b1-b95f-0dd12ef24be0,9c3b1a3d-0502-4877-a86e-505f8147c2c2,831e98d3-f510-4676-aa1e-83030ce723f6,9d4418a6-61d5-4048-9d9e-65005043176b,ab04ccb9-cc9e-4840-a529-b6fc75aba5f3,5d6df3fc-030d-4d6f-a0fc-a25fc2601925,541f5def-1e9a-4b88-be4f-14abc6d4b6b4,20e91feb-7fb7-4685-9222-9d9cf078d135,6843bca6-84bc-43df-ae07-e2d59379df11,a416a85e-7e84-4e5b-81ea-540a483b3b42,3d9b038e-c00c-4123-8497-7815799dfc7e,9f19a879-30ab-4f0e-9607-ef31a3f2094b,dd411988-e6c5-41e7-ac97-477a7e6a6f02,f201884c-3f9d-4b5f-af14-d56a064dbc30,eb45ea88-b01d-4804-902e-4f6502100de5,e14e4a5e-51c9-4b27-ad00-d813d6016738,e60a4ac1-423e-494e-bc96-4627b3e6c93b,c4c77a5a-af76-49c1-a384-0645daa9268a,a4b567ff-c2ae-4980-bc67-6c47b578736c,01347835-6dc6-426c-98d8-8eaf456e3e33,c1603c13-2968-48c4-b63b-c36d0febb756,90796281-edfb-4219-81cf-7e175535b4f6,6b2b42ff-eb2b-4db8-b5a8-bb061bfbce8b,ce9c11fc-7326-40c4-a6db-0f944094e9a9,88dc35af-b436-412b-9281-f2537175f038,dfa42905-4203-447e-8165-d9b5a0cd7a29,eb21b0a9-7427-468f-923f-fa1341646550,d32c6ebf-7b31-40cb-b01d-562d60f0036e,4bd08a96-8d16-4816-b6fc-34b16646859c,a3e4117a-127a-484c-a93a-70f4ad6eced8,03286de7-bca2-496a-992e-c5714bacd2a4,54d59cd8-a90a-48e8-adc9-91b5e0694f1e,70c9a8a1-64be-4fb3-afec-3cdeeb7140dc,75f07387-8500-4535-993a-69cd81b654cc,22a24006-54a8-423a-aa14-9331061548b5,6a09568b-e216-4393-a3dd-55e6a7af567d,f7207d1b-cfd5-4cec-925d-9e76a09b929f,10f06533-d858-4613-b811-171023cdf398,8587004c-71a6-44b4-8342-37e92ff5898f,b0c46f59-287b-466e-aa36-e0df542f8db9,0be8dd5d-2271-4378-b8ce-5ca20d335431,fc82d023-3ed4-4d0d-91e2-dd618b89c69a,d5f3efe9-9462-4834-a8df-d049a22430f0,49a10234-030a-4a2f-b750-579b842068dc,88de0084-4bd7-499e-add4-52fa0b874aa3,b0c2293f-ff56-42ea-928d-28224f0a4cae,1e4269b6-787a-416a-a1c1-ceae611c1449,74bcc696-244e-498d-8200-8c201819a685,35bdf550-25d5-4660-9e56-49eecefc877e,e1cd023c-7411-4928-b33a-dbd309294503,14a0fb6a-e272-4f35-bced-bbe7d4f905ca,fdf78dc5-3cc9-44ce-8423-f3e289aebe92,7dbe78d9-ec7d-4a73-9f38-0ddde9265345,07e95ad8-bf33-463c-8eac-31d92854176b,d899ae7b-eb76-4e02-9831-ab7978d09393,timestamp:1683570583
2023-05-08T18:29:43,542 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:539.14|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570583,ef966a40-b38f-4402-aec9-e58eb5278bda,c5eea5d0-3064-42b1-b95f-0dd12ef24be0,9c3b1a3d-0502-4877-a86e-505f8147c2c2,831e98d3-f510-4676-aa1e-83030ce723f6,9d4418a6-61d5-4048-9d9e-65005043176b,ab04ccb9-cc9e-4840-a529-b6fc75aba5f3,5d6df3fc-030d-4d6f-a0fc-a25fc2601925,541f5def-1e9a-4b88-be4f-14abc6d4b6b4,20e91feb-7fb7-4685-9222-9d9cf078d135,6843bca6-84bc-43df-ae07-e2d59379df11,a416a85e-7e84-4e5b-81ea-540a483b3b42,3d9b038e-c00c-4123-8497-7815799dfc7e,9f19a879-30ab-4f0e-9607-ef31a3f2094b,dd411988-e6c5-41e7-ac97-477a7e6a6f02,f201884c-3f9d-4b5f-af14-d56a064dbc30,eb45ea88-b01d-4804-902e-4f6502100de5,e14e4a5e-51c9-4b27-ad00-d813d6016738,e60a4ac1-423e-494e-bc96-4627b3e6c93b,c4c77a5a-af76-49c1-a384-0645daa9268a,a4b567ff-c2ae-4980-bc67-6c47b578736c,01347835-6dc6-426c-98d8-8eaf456e3e33,c1603c13-2968-48c4-b63b-c36d0febb756,90796281-edfb-4219-81cf-7e175535b4f6,6b2b42ff-eb2b-4db8-b5a8-bb061bfbce8b,ce9c11fc-7326-40c4-a6db-0f944094e9a9,88dc35af-b436-412b-9281-f2537175f038,dfa42905-4203-447e-8165-d9b5a0cd7a29,eb21b0a9-7427-468f-923f-fa1341646550,d32c6ebf-7b31-40cb-b01d-562d60f0036e,4bd08a96-8d16-4816-b6fc-34b16646859c,a3e4117a-127a-484c-a93a-70f4ad6eced8,03286de7-bca2-496a-992e-c5714bacd2a4,54d59cd8-a90a-48e8-adc9-91b5e0694f1e,70c9a8a1-64be-4fb3-afec-3cdeeb7140dc,75f07387-8500-4535-993a-69cd81b654cc,22a24006-54a8-423a-aa14-9331061548b5,6a09568b-e216-4393-a3dd-55e6a7af567d,f7207d1b-cfd5-4cec-925d-9e76a09b929f,10f06533-d858-4613-b811-171023cdf398,8587004c-71a6-44b4-8342-37e92ff5898f,b0c46f59-287b-466e-aa36-e0df542f8db9,0be8dd5d-2271-4378-b8ce-5ca20d335431,fc82d023-3ed4-4d0d-91e2-dd618b89c69a,d5f3efe9-9462-4834-a8df-d049a22430f0,49a10234-030a-4a2f-b750-579b842068dc,88de0084-4bd7-499e-add4-52fa0b874aa3,b0c2293f-ff56-42ea-928d-28224f0a4cae,1e4269b6-787a-416a-a1c1-ceae611c1449,74bcc696-244e-498d-8200-8c201819a685,35bdf550-25d5-4660-9e56-49eecefc877e,e1cd023c-7411-4928-b33a-dbd309294503,14a0fb6a-e272-4f35-bced-bbe7d4f905ca,fdf78dc5-3cc9-44ce-8423-f3e289aebe92,7dbe78d9-ec7d-4a73-9f38-0ddde9265345,07e95ad8-bf33-463c-8eac-31d92854176b,d899ae7b-eb76-4e02-9831-ab7978d09393, pattern=[METRICS]
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:539.14|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570583,ef966a40-b38f-4402-aec9-e58eb5278bda,c5eea5d0-3064-42b1-b95f-0dd12ef24be0,9c3b1a3d-0502-4877-a86e-505f8147c2c2,831e98d3-f510-4676-aa1e-83030ce723f6,9d4418a6-61d5-4048-9d9e-65005043176b,ab04ccb9-cc9e-4840-a529-b6fc75aba5f3,5d6df3fc-030d-4d6f-a0fc-a25fc2601925,541f5def-1e9a-4b88-be4f-14abc6d4b6b4,20e91feb-7fb7-4685-9222-9d9cf078d135,6843bca6-84bc-43df-ae07-e2d59379df11,a416a85e-7e84-4e5b-81ea-540a483b3b42,3d9b038e-c00c-4123-8497-7815799dfc7e,9f19a879-30ab-4f0e-9607-ef31a3f2094b,dd411988-e6c5-41e7-ac97-477a7e6a6f02,f201884c-3f9d-4b5f-af14-d56a064dbc30,eb45ea88-b01d-4804-902e-4f6502100de5,e14e4a5e-51c9-4b27-ad00-d813d6016738,e60a4ac1-423e-494e-bc96-4627b3e6c93b,c4c77a5a-af76-49c1-a384-0645daa9268a,a4b567ff-c2ae-4980-bc67-6c47b578736c,01347835-6dc6-426c-98d8-8eaf456e3e33,c1603c13-2968-48c4-b63b-c36d0febb756,90796281-edfb-4219-81cf-7e175535b4f6,6b2b42ff-eb2b-4db8-b5a8-bb061bfbce8b,ce9c11fc-7326-40c4-a6db-0f944094e9a9,88dc35af-b436-412b-9281-f2537175f038,dfa42905-4203-447e-8165-d9b5a0cd7a29,eb21b0a9-7427-468f-923f-fa1341646550,d32c6ebf-7b31-40cb-b01d-562d60f0036e,4bd08a96-8d16-4816-b6fc-34b16646859c,a3e4117a-127a-484c-a93a-70f4ad6eced8,03286de7-bca2-496a-992e-c5714bacd2a4,54d59cd8-a90a-48e8-adc9-91b5e0694f1e,70c9a8a1-64be-4fb3-afec-3cdeeb7140dc,75f07387-8500-4535-993a-69cd81b654cc,22a24006-54a8-423a-aa14-9331061548b5,6a09568b-e216-4393-a3dd-55e6a7af567d,f7207d1b-cfd5-4cec-925d-9e76a09b929f,10f06533-d858-4613-b811-171023cdf398,8587004c-71a6-44b4-8342-37e92ff5898f,b0c46f59-287b-466e-aa36-e0df542f8db9,0be8dd5d-2271-4378-b8ce-5ca20d335431,fc82d023-3ed4-4d0d-91e2-dd618b89c69a,d5f3efe9-9462-4834-a8df-d049a22430f0,49a10234-030a-4a2f-b750-579b842068dc,88de0084-4bd7-499e-add4-52fa0b874aa3,b0c2293f-ff56-42ea-928d-28224f0a4cae,1e4269b6-787a-416a-a1c1-ceae611c1449,74bcc696-244e-498d-8200-8c201819a685,35bdf550-25d5-4660-9e56-49eecefc877e,e1cd023c-7411-4928-b33a-dbd309294503,14a0fb6a-e272-4f35-bced-bbe7d4f905ca,fdf78dc5-3cc9-44ce-8423-f3e289aebe92,7dbe78d9-ec7d-4a73-9f38-0ddde9265345,07e95ad8-bf33-463c-8eac-31d92854176b,d899ae7b-eb76-4e02-9831-ab7978d09393, pattern=[METRICS]
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094363.682|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551010.319|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551010319, Backend time ns: 543595146
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551010319, Backend time ns: 543595146
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:539.14|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:ef966a40-b38f-4402-aec9-e58eb5278bda,c5eea5d0-3064-42b1-b95f-0dd12ef24be0,9c3b1a3d-0502-4877-a86e-505f8147c2c2,831e98d3-f510-4676-aa1e-83030ce723f6,9d4418a6-61d5-4048-9d9e-65005043176b,ab04ccb9-cc9e-4840-a529-b6fc75aba5f3,5d6df3fc-030d-4d6f-a0fc-a25fc2601925,541f5def-1e9a-4b88-be4f-14abc6d4b6b4,20e91feb-7fb7-4685-9222-9d9cf078d135,6843bca6-84bc-43df-ae07-e2d59379df11,a416a85e-7e84-4e5b-81ea-540a483b3b42,3d9b038e-c00c-4123-8497-7815799dfc7e,9f19a879-30ab-4f0e-9607-ef31a3f2094b,dd411988-e6c5-41e7-ac97-477a7e6a6f02,f201884c-3f9d-4b5f-af14-d56a064dbc30,eb45ea88-b01d-4804-902e-4f6502100de5,e14e4a5e-51c9-4b27-ad00-d813d6016738,e60a4ac1-423e-494e-bc96-4627b3e6c93b,c4c77a5a-af76-49c1-a384-0645daa9268a,a4b567ff-c2ae-4980-bc67-6c47b578736c,01347835-6dc6-426c-98d8-8eaf456e3e33,c1603c13-2968-48c4-b63b-c36d0febb756,90796281-edfb-4219-81cf-7e175535b4f6,6b2b42ff-eb2b-4db8-b5a8-bb061bfbce8b,ce9c11fc-7326-40c4-a6db-0f944094e9a9,88dc35af-b436-412b-9281-f2537175f038,dfa42905-4203-447e-8165-d9b5a0cd7a29,eb21b0a9-7427-468f-923f-fa1341646550,d32c6ebf-7b31-40cb-b01d-562d60f0036e,4bd08a96-8d16-4816-b6fc-34b16646859c,a3e4117a-127a-484c-a93a-70f4ad6eced8,03286de7-bca2-496a-992e-c5714bacd2a4,54d59cd8-a90a-48e8-adc9-91b5e0694f1e,70c9a8a1-64be-4fb3-afec-3cdeeb7140dc,75f07387-8500-4535-993a-69cd81b654cc,22a24006-54a8-423a-aa14-9331061548b5,6a09568b-e216-4393-a3dd-55e6a7af567d,f7207d1b-cfd5-4cec-925d-9e76a09b929f,10f06533-d858-4613-b811-171023cdf398,8587004c-71a6-44b4-8342-37e92ff5898f,b0c46f59-287b-466e-aa36-e0df542f8db9,0be8dd5d-2271-4378-b8ce-5ca20d335431,fc82d023-3ed4-4d0d-91e2-dd618b89c69a,d5f3efe9-9462-4834-a8df-d049a22430f0,49a10234-030a-4a2f-b750-579b842068dc,88de0084-4bd7-499e-add4-52fa0b874aa3,b0c2293f-ff56-42ea-928d-28224f0a4cae,1e4269b6-787a-416a-a1c1-ceae611c1449,74bcc696-244e-498d-8200-8c201819a685,35bdf550-25d5-4660-9e56-49eecefc877e,e1cd023c-7411-4928-b33a-dbd309294503,14a0fb6a-e272-4f35-bced-bbe7d4f905ca,fdf78dc5-3cc9-44ce-8423-f3e289aebe92,7dbe78d9-ec7d-4a73-9f38-0ddde9265345,07e95ad8-bf33-463c-8eac-31d92854176b,d899ae7b-eb76-4e02-9831-ab7978d09393,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094546.992|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550919.314|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550919314, Backend time ns: 543707753
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550919314, Backend time ns: 543707753
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094545.822|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550807.718|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550807718, Backend time ns: 543800428
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550807718, Backend time ns: 543800428
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094508.83|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550688.331|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550688331, Backend time ns: 543887423
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550688331, Backend time ns: 543887423
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094476.518|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550569.054|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550569054, Backend time ns: 543984088
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550569054, Backend time ns: 543984088
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094495.869|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550487.97|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550487970, Backend time ns: 544130486
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550487970, Backend time ns: 544130486
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094475.158|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550314.45|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550314450, Backend time ns: 544374200
2023-05-08T18:29:43,543 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550314450, Backend time ns: 544374200
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094693.57|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,543 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550296.009|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550296009, Backend time ns: 544465145
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550296009, Backend time ns: 544465145
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094692.32|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550200.714|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550200714, Backend time ns: 544557570
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550200714, Backend time ns: 544557570
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094568.393|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549985.572|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549985572, Backend time ns: 544694728
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549985572, Backend time ns: 544694728
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094604.665|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549866.795|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549866795, Backend time ns: 544804364
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549866795, Backend time ns: 544804364
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094683.359|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549847.484|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549847484, Backend time ns: 544918500
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549847484, Backend time ns: 544918500
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094739.312|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549799.621|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549799621, Backend time ns: 545007575
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549799621, Backend time ns: 545007575
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094725.412|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549696.326|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549696326, Backend time ns: 545198906
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549696326, Backend time ns: 545198906
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094800.305|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549550.587|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549550587, Backend time ns: 545314152
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549550587, Backend time ns: 545314152
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094785.725|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549448.822|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549448822, Backend time ns: 545397457
2023-05-08T18:29:43,544 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549448822, Backend time ns: 545397457
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,544 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,544 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094754.014|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549335.986|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549335986, Backend time ns: 545515403
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549335986, Backend time ns: 545515403
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,545 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094771.355|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549230.88|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549230880, Backend time ns: 545607068
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549230880, Backend time ns: 545607068
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094706.741|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549079.521|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549079521, Backend time ns: 545680092
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549079521, Backend time ns: 545680092
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094688.37|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548986.296|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548986296, Backend time ns: 545769697
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548986296, Backend time ns: 545769697
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094670.379|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548879.44|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548879440, Backend time ns: 545865313
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548879440, Backend time ns: 545865313
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,545 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094583.074|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548695.16|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548695160, Backend time ns: 545998740
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548695160, Backend time ns: 545998740
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094659.848|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548639.527|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548639527, Backend time ns: 546091425
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548639527, Backend time ns: 546091425
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,545 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094653.418|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548540.441|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548540441, Backend time ns: 546216422
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548540441, Backend time ns: 546216422
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094636.407|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548398.623|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548398623, Backend time ns: 546323728
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548398623, Backend time ns: 546323728
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094634.586|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548290.187|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548290187, Backend time ns: 546407223
2023-05-08T18:29:43,545 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548290187, Backend time ns: 546407223
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,545 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094577.803|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548149.469|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548149469, Backend time ns: 546498388
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548149469, Backend time ns: 546498388
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094549.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548030.233|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548030233, Backend time ns: 546603324
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548030233, Backend time ns: 546603324
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094539.471|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547912.986|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547912986, Backend time ns: 546704180
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547912986, Backend time ns: 546704180
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094521.751|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547794.59|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547794590, Backend time ns: 546881769
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547794590, Backend time ns: 546881769
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094556.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547642.241|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547642241, Backend time ns: 546993356
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547642241, Backend time ns: 546993356
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094592.735|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547578.978|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547578978, Backend time ns: 547075350
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547578978, Backend time ns: 547075350
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094565.442|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547467.391|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547467391, Backend time ns: 547178426
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547467391, Backend time ns: 547178426
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094555.162|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547355.375|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547355375, Backend time ns: 547280682
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547355375, Backend time ns: 547280682
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094599.555|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547291.922|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547291922, Backend time ns: 547378467
2023-05-08T18:29:43,546 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547291922, Backend time ns: 547378467
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,546 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094570.723|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547171.085|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547171085, Backend time ns: 547481703
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547171085, Backend time ns: 547481703
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094609.225|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547099.021|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547099021, Backend time ns: 547604360
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547099021, Backend time ns: 547604360
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094626.926|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547001.195|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547001195, Backend time ns: 547691135
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547001195, Backend time ns: 547691135
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094621.296|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546909.33|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546909330, Backend time ns: 547802601
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546909330, Backend time ns: 547802601
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094624.636|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546778.943|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546778943, Backend time ns: 547938858
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546778943, Backend time ns: 547938858
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094602.195|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546638.805|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546638805, Backend time ns: 548031003
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546638805, Backend time ns: 548031003
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094570.483|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546517.648|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546517648, Backend time ns: 548128919
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546517648, Backend time ns: 548128919
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094601.405|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546451.775|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546451775, Backend time ns: 548242645
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546451775, Backend time ns: 548242645
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094627.266|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546346.149|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546346149, Backend time ns: 548348051
2023-05-08T18:29:43,547 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546346149, Backend time ns: 548348051
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,547 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554155.943|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5785.971|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5785971, Backend time ns: 548467828
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5785971, Backend time ns: 548467828
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554187.296|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5686.796|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5686796, Backend time ns: 548572244
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5686796, Backend time ns: 548572244
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554274.23|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5663.865|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5663865, Backend time ns: 548676108
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5663865, Backend time ns: 548676108
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554360.015|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5636.804|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5636804, Backend time ns: 548791195
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5636804, Backend time ns: 548791195
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554447.59|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5617.343|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5617343, Backend time ns: 548896311
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5617343, Backend time ns: 548896311
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554280.281|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5363.389|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5363389, Backend time ns: 548988596
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5363389, Backend time ns: 548988596
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554289.661|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5280.954|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5280954, Backend time ns: 549069600
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5280954, Backend time ns: 549069600
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554321.123|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5219.391|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5219391, Backend time ns: 549184537
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5219391, Backend time ns: 549184537
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554412.428|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5207.18|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5207180, Backend time ns: 549307034
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5207180, Backend time ns: 549307034
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554355.785|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5020.58|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5020580, Backend time ns: 549421940
2023-05-08T18:29:43,548 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5020580, Backend time ns: 549421940
2023-05-08T18:29:43,548 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554326.463|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4875.231|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4875231, Backend time ns: 549520775
2023-05-08T18:29:43,549 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4875231, Backend time ns: 549520775
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 555
2023-05-08T18:29:43,549 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:554362.295|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4819.968|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4819968, Backend time ns: 549614211
2023-05-08T18:29:43,549 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4819968, Backend time ns: 549614211
2023-05-08T18:29:43,549 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:43,549 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 543
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 543
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570583
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570583549
2023-05-08T18:29:43,549 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570583549
2023-05-08T18:29:43,552 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570583
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,553 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,554 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,555 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,556 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,557 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,558 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,559 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:43,560 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:43,561 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:43,561 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:43,567 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:43,603 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:43,625 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:43,631 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:43,663 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:43,667 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:43,670 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:43,701 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:43,707 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:43,708 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:43,710 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:43,740 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:43,746 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:43,748 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:43,750 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:43,778 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:43,786 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:43,789 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:43,790 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:43,817 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:43,826 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:43,828 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:43,831 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:43,856 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:43,869 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:43,871 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:43,894 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:43,909 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:43,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:43,949 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:43,952 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:43,994 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:44,088 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:44,088 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:535.22|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570584,d5df2317-0f38-4e40-a06f-27c5f7542b8c,2e4c407d-fe56-45c3-8ade-ee6a38b80738,26ef32ed-e062-4382-9f23-cad779045be6,b9e288aa-d9f7-41f8-8029-76dbbcd99265,fdb43096-de0c-4587-bfaf-0de99cb9c472,59e66e45-b5d7-4c5e-b93f-10803b7d013a,e886d4fc-ff5e-42c1-be24-5a111fa5ed02,eff47cde-a2ce-456b-a384-d2efd83ad954,7c41a87a-7bfd-416d-b854-6237ec948550,c40f693d-b462-42e0-bb13-8418069684a6,11f60616-9e0f-405a-a9d7-918f316cfcf3,69a71e47-52d4-4f8b-bceb-79c31f3a2668,34ceca93-7eb2-432e-8112-4c0732bf8860,35ab8654-4c2b-44b4-b35e-01f51cf5f336,47437b2c-905a-4c7d-ba9c-f2d311558f98,ab2b8337-9795-4a19-b075-5006163c9d73,e35cd9cd-2645-4722-aa94-0e937b5b1152,166f1bef-98ed-4c31-a255-d442f6552d94,c02fea66-4536-469d-ba21-c4b5c19743d0,dcc902f0-bf5e-4b2f-8b82-b4529434bd5f,77909553-9d60-4114-a718-6dfd36a706c6,bfe24f3f-74fd-487c-addf-11f3eb5ed815,dafb7687-317c-4a80-b14b-635508ef40fb,1ab0e64a-42b0-466c-ad8c-948e4cc204a8,3dad4dde-a96c-4c3c-8576-a9687cd941ea,7c02194a-be51-421c-a031-7676982432a8,421b23e2-da21-42fe-affd-8a9025ada946,57e49114-41d7-49ea-b47a-b3e2f0a24fbc,3f532cf8-5b69-4b9a-9e9d-cd888a62860f,b8a2683e-2053-4e51-b5b7-d89b5dcf057e,4e09d94b-8d2a-427e-a1d2-5cd84b6fe3d6,efec91b4-4813-4c7d-b947-d7a51dd1817b,0c6073cb-0f3b-4ed6-bc1f-51a95d52a0b3,9e0817fa-838f-4edb-981b-89eedd6b5b38,460c169b-4241-4874-b9a8-79ee2f19c93b,aa035c90-e79c-46bb-89f5-3a21a1178c49,fa253967-4422-4cd5-8b34-a89f19d39b38,a730274d-93fe-42e5-a4ce-7fd9b9f780ae,10a013fe-c6e2-4ada-bd2e-20b43415305e,1571268f-4220-4fcc-903c-01dee11dc8fe,add226c3-9cd3-443e-a038-362c10048622,b6ac5af8-f08a-44e0-a329-85cbc10fbbca,18d1ec9d-02b2-426a-90c7-6a08fed45614,b3584dba-fe9e-4847-9f15-835895dfcc66,09dfeea3-7216-4b45-9ec9-345b9fbb370c,182c5525-7fcb-4262-9269-27fd50a913e4,942faa82-29c2-44e6-ba39-7b3bfd92368b,ca84a034-c27b-4e59-bc0c-7ad6c5bbcfe7,c7aa3099-3afc-4877-bbac-4495e09a8094,3adcb2d4-c60f-4c69-8d78-a41be6469668,9dab0daf-a99f-4cd5-882e-637333d532d2,4762a605-0383-4e49-a1f9-d248a46cfc95,f1a9faf7-fe32-47f7-84c3-ca94b17e766b,c891109b-277e-4acc-911e-e08c0b88930d,d6269926-5d78-41cd-949b-fe8adc283cfe,5eba540b-63f9-4741-a2e6-6d355d6ed4e8, pattern=[METRICS]
2023-05-08T18:29:44,088 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:535.22|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570584,d5df2317-0f38-4e40-a06f-27c5f7542b8c,2e4c407d-fe56-45c3-8ade-ee6a38b80738,26ef32ed-e062-4382-9f23-cad779045be6,b9e288aa-d9f7-41f8-8029-76dbbcd99265,fdb43096-de0c-4587-bfaf-0de99cb9c472,59e66e45-b5d7-4c5e-b93f-10803b7d013a,e886d4fc-ff5e-42c1-be24-5a111fa5ed02,eff47cde-a2ce-456b-a384-d2efd83ad954,7c41a87a-7bfd-416d-b854-6237ec948550,c40f693d-b462-42e0-bb13-8418069684a6,11f60616-9e0f-405a-a9d7-918f316cfcf3,69a71e47-52d4-4f8b-bceb-79c31f3a2668,34ceca93-7eb2-432e-8112-4c0732bf8860,35ab8654-4c2b-44b4-b35e-01f51cf5f336,47437b2c-905a-4c7d-ba9c-f2d311558f98,ab2b8337-9795-4a19-b075-5006163c9d73,e35cd9cd-2645-4722-aa94-0e937b5b1152,166f1bef-98ed-4c31-a255-d442f6552d94,c02fea66-4536-469d-ba21-c4b5c19743d0,dcc902f0-bf5e-4b2f-8b82-b4529434bd5f,77909553-9d60-4114-a718-6dfd36a706c6,bfe24f3f-74fd-487c-addf-11f3eb5ed815,dafb7687-317c-4a80-b14b-635508ef40fb,1ab0e64a-42b0-466c-ad8c-948e4cc204a8,3dad4dde-a96c-4c3c-8576-a9687cd941ea,7c02194a-be51-421c-a031-7676982432a8,421b23e2-da21-42fe-affd-8a9025ada946,57e49114-41d7-49ea-b47a-b3e2f0a24fbc,3f532cf8-5b69-4b9a-9e9d-cd888a62860f,b8a2683e-2053-4e51-b5b7-d89b5dcf057e,4e09d94b-8d2a-427e-a1d2-5cd84b6fe3d6,efec91b4-4813-4c7d-b947-d7a51dd1817b,0c6073cb-0f3b-4ed6-bc1f-51a95d52a0b3,9e0817fa-838f-4edb-981b-89eedd6b5b38,460c169b-4241-4874-b9a8-79ee2f19c93b,aa035c90-e79c-46bb-89f5-3a21a1178c49,fa253967-4422-4cd5-8b34-a89f19d39b38,a730274d-93fe-42e5-a4ce-7fd9b9f780ae,10a013fe-c6e2-4ada-bd2e-20b43415305e,1571268f-4220-4fcc-903c-01dee11dc8fe,add226c3-9cd3-443e-a038-362c10048622,b6ac5af8-f08a-44e0-a329-85cbc10fbbca,18d1ec9d-02b2-426a-90c7-6a08fed45614,b3584dba-fe9e-4847-9f15-835895dfcc66,09dfeea3-7216-4b45-9ec9-345b9fbb370c,182c5525-7fcb-4262-9269-27fd50a913e4,942faa82-29c2-44e6-ba39-7b3bfd92368b,ca84a034-c27b-4e59-bc0c-7ad6c5bbcfe7,c7aa3099-3afc-4877-bbac-4495e09a8094,3adcb2d4-c60f-4c69-8d78-a41be6469668,9dab0daf-a99f-4cd5-882e-637333d532d2,4762a605-0383-4e49-a1f9-d248a46cfc95,f1a9faf7-fe32-47f7-84c3-ca94b17e766b,c891109b-277e-4acc-911e-e08c0b88930d,d6269926-5d78-41cd-949b-fe8adc283cfe,5eba540b-63f9-4741-a2e6-6d355d6ed4e8, pattern=[METRICS]
2023-05-08T18:29:44,088 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:535.22|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:d5df2317-0f38-4e40-a06f-27c5f7542b8c,2e4c407d-fe56-45c3-8ade-ee6a38b80738,26ef32ed-e062-4382-9f23-cad779045be6,b9e288aa-d9f7-41f8-8029-76dbbcd99265,fdb43096-de0c-4587-bfaf-0de99cb9c472,59e66e45-b5d7-4c5e-b93f-10803b7d013a,e886d4fc-ff5e-42c1-be24-5a111fa5ed02,eff47cde-a2ce-456b-a384-d2efd83ad954,7c41a87a-7bfd-416d-b854-6237ec948550,c40f693d-b462-42e0-bb13-8418069684a6,11f60616-9e0f-405a-a9d7-918f316cfcf3,69a71e47-52d4-4f8b-bceb-79c31f3a2668,34ceca93-7eb2-432e-8112-4c0732bf8860,35ab8654-4c2b-44b4-b35e-01f51cf5f336,47437b2c-905a-4c7d-ba9c-f2d311558f98,ab2b8337-9795-4a19-b075-5006163c9d73,e35cd9cd-2645-4722-aa94-0e937b5b1152,166f1bef-98ed-4c31-a255-d442f6552d94,c02fea66-4536-469d-ba21-c4b5c19743d0,dcc902f0-bf5e-4b2f-8b82-b4529434bd5f,77909553-9d60-4114-a718-6dfd36a706c6,bfe24f3f-74fd-487c-addf-11f3eb5ed815,dafb7687-317c-4a80-b14b-635508ef40fb,1ab0e64a-42b0-466c-ad8c-948e4cc204a8,3dad4dde-a96c-4c3c-8576-a9687cd941ea,7c02194a-be51-421c-a031-7676982432a8,421b23e2-da21-42fe-affd-8a9025ada946,57e49114-41d7-49ea-b47a-b3e2f0a24fbc,3f532cf8-5b69-4b9a-9e9d-cd888a62860f,b8a2683e-2053-4e51-b5b7-d89b5dcf057e,4e09d94b-8d2a-427e-a1d2-5cd84b6fe3d6,efec91b4-4813-4c7d-b947-d7a51dd1817b,0c6073cb-0f3b-4ed6-bc1f-51a95d52a0b3,9e0817fa-838f-4edb-981b-89eedd6b5b38,460c169b-4241-4874-b9a8-79ee2f19c93b,aa035c90-e79c-46bb-89f5-3a21a1178c49,fa253967-4422-4cd5-8b34-a89f19d39b38,a730274d-93fe-42e5-a4ce-7fd9b9f780ae,10a013fe-c6e2-4ada-bd2e-20b43415305e,1571268f-4220-4fcc-903c-01dee11dc8fe,add226c3-9cd3-443e-a038-362c10048622,b6ac5af8-f08a-44e0-a329-85cbc10fbbca,18d1ec9d-02b2-426a-90c7-6a08fed45614,b3584dba-fe9e-4847-9f15-835895dfcc66,09dfeea3-7216-4b45-9ec9-345b9fbb370c,182c5525-7fcb-4262-9269-27fd50a913e4,942faa82-29c2-44e6-ba39-7b3bfd92368b,ca84a034-c27b-4e59-bc0c-7ad6c5bbcfe7,c7aa3099-3afc-4877-bbac-4495e09a8094,3adcb2d4-c60f-4c69-8d78-a41be6469668,9dab0daf-a99f-4cd5-882e-637333d532d2,4762a605-0383-4e49-a1f9-d248a46cfc95,f1a9faf7-fe32-47f7-84c3-ca94b17e766b,c891109b-277e-4acc-911e-e08c0b88930d,d6269926-5d78-41cd-949b-fe8adc283cfe,5eba540b-63f9-4741-a2e6-6d355d6ed4e8,timestamp:1683570584
2023-05-08T18:29:44,088 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,088 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:535.31|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570584,d5df2317-0f38-4e40-a06f-27c5f7542b8c,2e4c407d-fe56-45c3-8ade-ee6a38b80738,26ef32ed-e062-4382-9f23-cad779045be6,b9e288aa-d9f7-41f8-8029-76dbbcd99265,fdb43096-de0c-4587-bfaf-0de99cb9c472,59e66e45-b5d7-4c5e-b93f-10803b7d013a,e886d4fc-ff5e-42c1-be24-5a111fa5ed02,eff47cde-a2ce-456b-a384-d2efd83ad954,7c41a87a-7bfd-416d-b854-6237ec948550,c40f693d-b462-42e0-bb13-8418069684a6,11f60616-9e0f-405a-a9d7-918f316cfcf3,69a71e47-52d4-4f8b-bceb-79c31f3a2668,34ceca93-7eb2-432e-8112-4c0732bf8860,35ab8654-4c2b-44b4-b35e-01f51cf5f336,47437b2c-905a-4c7d-ba9c-f2d311558f98,ab2b8337-9795-4a19-b075-5006163c9d73,e35cd9cd-2645-4722-aa94-0e937b5b1152,166f1bef-98ed-4c31-a255-d442f6552d94,c02fea66-4536-469d-ba21-c4b5c19743d0,dcc902f0-bf5e-4b2f-8b82-b4529434bd5f,77909553-9d60-4114-a718-6dfd36a706c6,bfe24f3f-74fd-487c-addf-11f3eb5ed815,dafb7687-317c-4a80-b14b-635508ef40fb,1ab0e64a-42b0-466c-ad8c-948e4cc204a8,3dad4dde-a96c-4c3c-8576-a9687cd941ea,7c02194a-be51-421c-a031-7676982432a8,421b23e2-da21-42fe-affd-8a9025ada946,57e49114-41d7-49ea-b47a-b3e2f0a24fbc,3f532cf8-5b69-4b9a-9e9d-cd888a62860f,b8a2683e-2053-4e51-b5b7-d89b5dcf057e,4e09d94b-8d2a-427e-a1d2-5cd84b6fe3d6,efec91b4-4813-4c7d-b947-d7a51dd1817b,0c6073cb-0f3b-4ed6-bc1f-51a95d52a0b3,9e0817fa-838f-4edb-981b-89eedd6b5b38,460c169b-4241-4874-b9a8-79ee2f19c93b,aa035c90-e79c-46bb-89f5-3a21a1178c49,fa253967-4422-4cd5-8b34-a89f19d39b38,a730274d-93fe-42e5-a4ce-7fd9b9f780ae,10a013fe-c6e2-4ada-bd2e-20b43415305e,1571268f-4220-4fcc-903c-01dee11dc8fe,add226c3-9cd3-443e-a038-362c10048622,b6ac5af8-f08a-44e0-a329-85cbc10fbbca,18d1ec9d-02b2-426a-90c7-6a08fed45614,b3584dba-fe9e-4847-9f15-835895dfcc66,09dfeea3-7216-4b45-9ec9-345b9fbb370c,182c5525-7fcb-4262-9269-27fd50a913e4,942faa82-29c2-44e6-ba39-7b3bfd92368b,ca84a034-c27b-4e59-bc0c-7ad6c5bbcfe7,c7aa3099-3afc-4877-bbac-4495e09a8094,3adcb2d4-c60f-4c69-8d78-a41be6469668,9dab0daf-a99f-4cd5-882e-637333d532d2,4762a605-0383-4e49-a1f9-d248a46cfc95,f1a9faf7-fe32-47f7-84c3-ca94b17e766b,c891109b-277e-4acc-911e-e08c0b88930d,d6269926-5d78-41cd-949b-fe8adc283cfe,5eba540b-63f9-4741-a2e6-6d355d6ed4e8, pattern=[METRICS]
2023-05-08T18:29:44,088 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:535.31|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570584,d5df2317-0f38-4e40-a06f-27c5f7542b8c,2e4c407d-fe56-45c3-8ade-ee6a38b80738,26ef32ed-e062-4382-9f23-cad779045be6,b9e288aa-d9f7-41f8-8029-76dbbcd99265,fdb43096-de0c-4587-bfaf-0de99cb9c472,59e66e45-b5d7-4c5e-b93f-10803b7d013a,e886d4fc-ff5e-42c1-be24-5a111fa5ed02,eff47cde-a2ce-456b-a384-d2efd83ad954,7c41a87a-7bfd-416d-b854-6237ec948550,c40f693d-b462-42e0-bb13-8418069684a6,11f60616-9e0f-405a-a9d7-918f316cfcf3,69a71e47-52d4-4f8b-bceb-79c31f3a2668,34ceca93-7eb2-432e-8112-4c0732bf8860,35ab8654-4c2b-44b4-b35e-01f51cf5f336,47437b2c-905a-4c7d-ba9c-f2d311558f98,ab2b8337-9795-4a19-b075-5006163c9d73,e35cd9cd-2645-4722-aa94-0e937b5b1152,166f1bef-98ed-4c31-a255-d442f6552d94,c02fea66-4536-469d-ba21-c4b5c19743d0,dcc902f0-bf5e-4b2f-8b82-b4529434bd5f,77909553-9d60-4114-a718-6dfd36a706c6,bfe24f3f-74fd-487c-addf-11f3eb5ed815,dafb7687-317c-4a80-b14b-635508ef40fb,1ab0e64a-42b0-466c-ad8c-948e4cc204a8,3dad4dde-a96c-4c3c-8576-a9687cd941ea,7c02194a-be51-421c-a031-7676982432a8,421b23e2-da21-42fe-affd-8a9025ada946,57e49114-41d7-49ea-b47a-b3e2f0a24fbc,3f532cf8-5b69-4b9a-9e9d-cd888a62860f,b8a2683e-2053-4e51-b5b7-d89b5dcf057e,4e09d94b-8d2a-427e-a1d2-5cd84b6fe3d6,efec91b4-4813-4c7d-b947-d7a51dd1817b,0c6073cb-0f3b-4ed6-bc1f-51a95d52a0b3,9e0817fa-838f-4edb-981b-89eedd6b5b38,460c169b-4241-4874-b9a8-79ee2f19c93b,aa035c90-e79c-46bb-89f5-3a21a1178c49,fa253967-4422-4cd5-8b34-a89f19d39b38,a730274d-93fe-42e5-a4ce-7fd9b9f780ae,10a013fe-c6e2-4ada-bd2e-20b43415305e,1571268f-4220-4fcc-903c-01dee11dc8fe,add226c3-9cd3-443e-a038-362c10048622,b6ac5af8-f08a-44e0-a329-85cbc10fbbca,18d1ec9d-02b2-426a-90c7-6a08fed45614,b3584dba-fe9e-4847-9f15-835895dfcc66,09dfeea3-7216-4b45-9ec9-345b9fbb370c,182c5525-7fcb-4262-9269-27fd50a913e4,942faa82-29c2-44e6-ba39-7b3bfd92368b,ca84a034-c27b-4e59-bc0c-7ad6c5bbcfe7,c7aa3099-3afc-4877-bbac-4495e09a8094,3adcb2d4-c60f-4c69-8d78-a41be6469668,9dab0daf-a99f-4cd5-882e-637333d532d2,4762a605-0383-4e49-a1f9-d248a46cfc95,f1a9faf7-fe32-47f7-84c3-ca94b17e766b,c891109b-277e-4acc-911e-e08c0b88930d,d6269926-5d78-41cd-949b-fe8adc283cfe,5eba540b-63f9-4741-a2e6-6d355d6ed4e8, pattern=[METRICS]
2023-05-08T18:29:44,088 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094030.644|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:535.31|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:d5df2317-0f38-4e40-a06f-27c5f7542b8c,2e4c407d-fe56-45c3-8ade-ee6a38b80738,26ef32ed-e062-4382-9f23-cad779045be6,b9e288aa-d9f7-41f8-8029-76dbbcd99265,fdb43096-de0c-4587-bfaf-0de99cb9c472,59e66e45-b5d7-4c5e-b93f-10803b7d013a,e886d4fc-ff5e-42c1-be24-5a111fa5ed02,eff47cde-a2ce-456b-a384-d2efd83ad954,7c41a87a-7bfd-416d-b854-6237ec948550,c40f693d-b462-42e0-bb13-8418069684a6,11f60616-9e0f-405a-a9d7-918f316cfcf3,69a71e47-52d4-4f8b-bceb-79c31f3a2668,34ceca93-7eb2-432e-8112-4c0732bf8860,35ab8654-4c2b-44b4-b35e-01f51cf5f336,47437b2c-905a-4c7d-ba9c-f2d311558f98,ab2b8337-9795-4a19-b075-5006163c9d73,e35cd9cd-2645-4722-aa94-0e937b5b1152,166f1bef-98ed-4c31-a255-d442f6552d94,c02fea66-4536-469d-ba21-c4b5c19743d0,dcc902f0-bf5e-4b2f-8b82-b4529434bd5f,77909553-9d60-4114-a718-6dfd36a706c6,bfe24f3f-74fd-487c-addf-11f3eb5ed815,dafb7687-317c-4a80-b14b-635508ef40fb,1ab0e64a-42b0-466c-ad8c-948e4cc204a8,3dad4dde-a96c-4c3c-8576-a9687cd941ea,7c02194a-be51-421c-a031-7676982432a8,421b23e2-da21-42fe-affd-8a9025ada946,57e49114-41d7-49ea-b47a-b3e2f0a24fbc,3f532cf8-5b69-4b9a-9e9d-cd888a62860f,b8a2683e-2053-4e51-b5b7-d89b5dcf057e,4e09d94b-8d2a-427e-a1d2-5cd84b6fe3d6,efec91b4-4813-4c7d-b947-d7a51dd1817b,0c6073cb-0f3b-4ed6-bc1f-51a95d52a0b3,9e0817fa-838f-4edb-981b-89eedd6b5b38,460c169b-4241-4874-b9a8-79ee2f19c93b,aa035c90-e79c-46bb-89f5-3a21a1178c49,fa253967-4422-4cd5-8b34-a89f19d39b38,a730274d-93fe-42e5-a4ce-7fd9b9f780ae,10a013fe-c6e2-4ada-bd2e-20b43415305e,1571268f-4220-4fcc-903c-01dee11dc8fe,add226c3-9cd3-443e-a038-362c10048622,b6ac5af8-f08a-44e0-a329-85cbc10fbbca,18d1ec9d-02b2-426a-90c7-6a08fed45614,b3584dba-fe9e-4847-9f15-835895dfcc66,09dfeea3-7216-4b45-9ec9-345b9fbb370c,182c5525-7fcb-4262-9269-27fd50a913e4,942faa82-29c2-44e6-ba39-7b3bfd92368b,ca84a034-c27b-4e59-bc0c-7ad6c5bbcfe7,c7aa3099-3afc-4877-bbac-4495e09a8094,3adcb2d4-c60f-4c69-8d78-a41be6469668,9dab0daf-a99f-4cd5-882e-637333d532d2,4762a605-0383-4e49-a1f9-d248a46cfc95,f1a9faf7-fe32-47f7-84c3-ca94b17e766b,c891109b-277e-4acc-911e-e08c0b88930d,d6269926-5d78-41cd-949b-fe8adc283cfe,5eba540b-63f9-4741-a2e6-6d355d6ed4e8,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554513.553|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554513553, Backend time ns: 539763165
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554513553, Backend time ns: 539763165
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094070.336|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554276.871|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554276871, Backend time ns: 539860469
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554276871, Backend time ns: 539860469
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094074.217|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554183.876|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554183876, Backend time ns: 539982546
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554183876, Backend time ns: 539982546
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094129.849|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554125.232|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554125232, Backend time ns: 540077661
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554125232, Backend time ns: 540077661
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094137.17|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:554032.047|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554032047, Backend time ns: 540183887
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 554032047, Backend time ns: 540183887
2023-05-08T18:29:44,089 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:554.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094156.181|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553920.441|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553920441, Backend time ns: 540381578
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553920441, Backend time ns: 540381578
2023-05-08T18:29:44,089 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094196.263|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553787.503|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553787503, Backend time ns: 540515396
2023-05-08T18:29:44,089 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553787503, Backend time ns: 540515396
2023-05-08T18:29:44,089 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094232.995|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,089 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553675.537|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553675537, Backend time ns: 540659314
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553675537, Backend time ns: 540659314
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094261.137|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553578.612|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553578612, Backend time ns: 540756659
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553578612, Backend time ns: 540756659
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094251.276|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553473.666|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553473666, Backend time ns: 540844434
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553473666, Backend time ns: 540844434
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,090 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094169.411|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553296.956|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553296956, Backend time ns: 540949060
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553296956, Backend time ns: 540949060
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,090 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094214.424|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553242.643|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553242643, Backend time ns: 541098818
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553242643, Backend time ns: 541098818
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094311.809|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553189.47|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553189470, Backend time ns: 541192313
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553189470, Backend time ns: 541192313
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094239.725|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553015.75|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553015750, Backend time ns: 541332041
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553015750, Backend time ns: 541332041
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094136.519|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552782.507|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552782507, Backend time ns: 541415536
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552782507, Backend time ns: 541415536
2023-05-08T18:29:44,090 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094188.592|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552722.444|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552722444, Backend time ns: 541538672
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552722444, Backend time ns: 541538672
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094259.487|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552698.663|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552698663, Backend time ns: 541627697
2023-05-08T18:29:44,090 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552698663, Backend time ns: 541627697
2023-05-08T18:29:44,090 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094271.947|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552621.808|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552621808, Backend time ns: 541746254
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552621808, Backend time ns: 541746254
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094286.068|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552485.851|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552485851, Backend time ns: 541873241
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552485851, Backend time ns: 541873241
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094243.006|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552325.872|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552325872, Backend time ns: 541984947
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552325872, Backend time ns: 541984947
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094280.298|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552267.769|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552267769, Backend time ns: 542095643
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552267769, Backend time ns: 542095643
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094260.617|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552142.512|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552142512, Backend time ns: 542212490
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552142512, Backend time ns: 542212490
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094277.837|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552038.376|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552038376, Backend time ns: 542326756
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552038376, Backend time ns: 542326756
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094257.286|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551909.899|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551909899, Backend time ns: 542451543
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551909899, Backend time ns: 542451543
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094296.349|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551820.474|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551820474, Backend time ns: 542553219
2023-05-08T18:29:44,091 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551820474, Backend time ns: 542553219
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,091 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094340.461|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551693.047|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551693047, Backend time ns: 542742839
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551693047, Backend time ns: 542742839
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094370.823|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551607.142|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551607142, Backend time ns: 542826334
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551607142, Backend time ns: 542826334
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094319.649|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551470.184|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551470184, Backend time ns: 542915749
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551470184, Backend time ns: 542915749
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094302.918|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551362.468|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551362468, Backend time ns: 543016815
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551362468, Backend time ns: 543016815
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094289.178|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551251.312|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551251312, Backend time ns: 543114880
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551251312, Backend time ns: 543114880
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094259.776|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551106.394|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551106394, Backend time ns: 543223276
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551106394, Backend time ns: 543223276
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094282.288|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550997.128|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550997128, Backend time ns: 543352053
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550997128, Backend time ns: 543352053
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094301.848|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550909.033|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550909033, Backend time ns: 543462399
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550909033, Backend time ns: 543462399
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094336.46|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550837.479|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550837479, Backend time ns: 543554114
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550837479, Backend time ns: 543554114
2023-05-08T18:29:44,092 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094262.536|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550683.98|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550683980, Backend time ns: 543644979
2023-05-08T18:29:44,092 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550683980, Backend time ns: 543644979
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094245.626|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550579.465|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550579465, Backend time ns: 543739305
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550579465, Backend time ns: 543739305
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094315.269|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550551.583|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550551583, Backend time ns: 543838210
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550551583, Backend time ns: 543838210
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094307.419|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550442.997|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550442997, Backend time ns: 543974828
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550442997, Backend time ns: 543974828
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 1095
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094324.07|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550328.411|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550328411, Backend time ns: 544050472
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550328411, Backend time ns: 544050472
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094302.348|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550230.765|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550230765, Backend time ns: 544147647
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550230765, Backend time ns: 544147647
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094286.048|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550116.249|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550116249, Backend time ns: 544235292
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550116249, Backend time ns: 544235292
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094295.768|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550037.804|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550037804, Backend time ns: 544355989
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550037804, Backend time ns: 544355989
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094394.663|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549996.842|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549996842, Backend time ns: 544452884
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549996842, Backend time ns: 544452884
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1094320.15|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549842.654|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549842654, Backend time ns: 544569241
2023-05-08T18:29:44,093 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549842654, Backend time ns: 544569241
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550281.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,093 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5690.476|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5690476, Backend time ns: 544649475
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5690476, Backend time ns: 544649475
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550302.009|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5606.661|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5606661, Backend time ns: 544769652
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5606661, Backend time ns: 544769652
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550343.481|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5553.178|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5553178, Backend time ns: 544855217
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5553178, Backend time ns: 544855217
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550412.015|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5532.157|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5532157, Backend time ns: 544941712
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5532157, Backend time ns: 544941712
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550470.019|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5502.826|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5502826, Backend time ns: 545059958
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5502826, Backend time ns: 545059958
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550531.932|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5449.963|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5449963, Backend time ns: 545161774
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5449963, Backend time ns: 545161774
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550363.333|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5178.308|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5178308, Backend time ns: 545280660
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5178308, Backend time ns: 545280660
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550458.928|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5155.116|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5155116, Backend time ns: 545368715
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5155116, Backend time ns: 545368715
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550489.3|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5091.443|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5091443, Backend time ns: 545461301
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5091443, Backend time ns: 545461301
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550443.458|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4961.746|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4961746, Backend time ns: 545577067
2023-05-08T18:29:44,094 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4961746, Backend time ns: 545577067
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,094 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550312.52|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4712.362|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4712362, Backend time ns: 545661752
2023-05-08T18:29:44,095 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4712362, Backend time ns: 545661752
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 551
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:550338.361|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4655.478|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4655478, Backend time ns: 545762057
2023-05-08T18:29:44,095 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4655478, Backend time ns: 545762057
2023-05-08T18:29:44,095 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:44,095 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 539
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 539
2023-05-08T18:29:44,095 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570584095
2023-05-08T18:29:44,095 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570584095
2023-05-08T18:29:44,098 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570584
2023-05-08T18:29:44,098 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,098 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,098 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,098 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,098 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,098 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,099 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,100 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,101 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,103 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,104 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,105 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,106 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:44,106 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:44,106 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:44,107 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:44,107 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:44,113 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:44,150 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:44,181 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:44,317 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:44,323 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:44,325 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:44,361 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:44,401 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:44,439 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:44,462 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:44,472 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:44,480 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:44,481 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:44,603 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:44,612 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:44,663 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:44,776 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:44,788 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:44,796 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:44,805 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:44,814 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:44,816 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:566.0454025268555|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:403.27823638916016|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:41.6|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:57.36494702101789|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:13210.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:53.46534653465346|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:12312.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:53.447976376585025|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:12308.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:59.62306756991489|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:13730.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:0|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:87.0|#Level:Host,DeviceId:1|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:2|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0.0|#Level:Host,DeviceId:3|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:364801.53125|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:14027.66796875|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,817 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:4.7|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570584
2023-05-08T18:29:44,819 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:44,824 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:44,862 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:44,862 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:44,902 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:44,902 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:44,942 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:44,980 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:45,020 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:45,060 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:45,102 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:45,197 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\n and', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\n.', 'Hey, are you conscious? Can you talk to me?\n.', 'Hey, are you conscious? Can you talk to me?\n.', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\n\n', 'Hey, are you conscious? Can you talk to me?\n\n', 'Hey, are you conscious? Can you talk to me?\n\n', 'Hey, are you conscious? Can you talk to me?\n\n', 'Hey, are you conscious? Can you talk to me?\n\n', 'Hey, are you conscious? Can you talk to me?\n\n', 'Hey, are you conscious? Can you talk to me?\n\n']
2023-05-08T18:29:45,197 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1098.64|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570585,df69971e-b30c-4864-99df-698d9af9d3ae,f34163ff-2da0-4316-b772-c39058eb62e4,a6d71e91-e634-4545-8535-613f0b8be8aa,caf18cf2-0cb1-4ab8-93cf-482d607907a6,4618c9f7-7111-4a7b-8ccb-009751d8d1a5,556e32c9-7273-4ad5-b3be-8f697bc61701,74946f62-7c22-4a85-b1ff-7083e2ad8ed4,d87b03a2-b7c3-4e7a-b55b-cac2038ed2dd,f80594b1-c6e5-4b32-9f43-7de1c51a5ad9,5f922c3f-32d0-4d06-b7a8-578c27d2dc15,48700a84-c338-4aec-ad3e-e11c17c5c226,c55c9cd3-aa6e-4820-8f7d-75a1b823279f,ddb581c4-6dd7-434e-a915-ae3b04452dc1,4b8cdaa4-4e9a-44be-86a5-498c438e5b90,3599744b-04a6-4959-b927-714f72ea546c,dd95599f-123e-45e6-a14d-a0266aad8911,25ceb850-f7e3-4262-9fa0-d5dbccf60bba,17c82c1e-76bd-4c9f-b30e-22e66bee73ab,640b48cd-23c4-4c61-acfa-9f9003dfc9ff,ddab77bc-ec47-4cfe-aba1-dbd6ead8009a,a5a08778-52e3-4ab5-aae8-dc7e45163cfa,af3bc56f-06c7-456c-b5bb-feca0ae73fb2,1a1de287-cdb3-4044-9e3b-32badda2d80d,83328145-73b1-4db4-bdd4-cfd7023fc415,43695932-4b08-4750-bdf2-08d4170faf64,0f03bd5e-5730-4aeb-bf83-d0111b70184c,4df3b482-b665-4379-bf8b-3b85384308c0,0ac7ad62-9cea-4435-bed8-43f348bf8b52,689a7d20-082f-469d-8dd1-d450ca2f524d,ab39ed28-43ba-4160-8e33-a91d53059d7a,827acfb3-c020-4022-a124-057f9fe46d7f,2b19024c-fa03-4583-856c-605cbe270088,ca5f0c2f-591a-4faa-89ac-93fbc4e3ad44,3855d3ef-be6f-42d6-b4be-a4e975d9c092,d660fe37-ab6e-4e68-a07b-8cf0295f1f45,92d15459-fd92-49fe-8aa9-2a4e999fb4f3,26227325-7f70-4725-a550-c5c55de43ae6,cf8ca05f-319f-4f79-abf2-e00022758918,0ed0c9e3-bb30-4389-9796-c4fff3f7a4be,0272f282-7040-4a42-98b7-844c49568ce0,22afe071-bf2d-4759-bd7e-dcc6eacd7380,3d5bf33d-8409-4db5-82f6-1e470ac9ad8c,83b49463-878b-4e07-aabb-5c2480cff3d5,f1bfd2c1-beea-462b-b06f-2fc70eca2aec,4e8aa852-0d72-42a0-aa0e-bc9c368144f8,b8535597-49a9-4677-93ec-f1095bd1994e,460c09a8-a039-4b2b-ae4f-31c1eed53d1f,1a0cfccd-5f5b-4958-8a45-9d0fb880cdc0,135ba99c-f308-4d17-bb85-ebde94e4d3ea,01e0730f-a5f1-46ce-be14-75a443f12673,f03b3ca1-ae62-4cc5-9997-8f319e5d72bb,2a26b7fa-64a4-4047-9b5e-fc17a30cf25d,e65a47cb-0223-4692-95af-fe3cd023b334,8b46a567-a22b-4c46-a6d4-bf3525cd5b50,87810ab1-1875-4288-8ebf-bcfeada8a319,f0d18982-f301-4f6e-ae01-2d9fd99d2e0f, pattern=[METRICS]
2023-05-08T18:29:45,197 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1098.64|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570585,df69971e-b30c-4864-99df-698d9af9d3ae,f34163ff-2da0-4316-b772-c39058eb62e4,a6d71e91-e634-4545-8535-613f0b8be8aa,caf18cf2-0cb1-4ab8-93cf-482d607907a6,4618c9f7-7111-4a7b-8ccb-009751d8d1a5,556e32c9-7273-4ad5-b3be-8f697bc61701,74946f62-7c22-4a85-b1ff-7083e2ad8ed4,d87b03a2-b7c3-4e7a-b55b-cac2038ed2dd,f80594b1-c6e5-4b32-9f43-7de1c51a5ad9,5f922c3f-32d0-4d06-b7a8-578c27d2dc15,48700a84-c338-4aec-ad3e-e11c17c5c226,c55c9cd3-aa6e-4820-8f7d-75a1b823279f,ddb581c4-6dd7-434e-a915-ae3b04452dc1,4b8cdaa4-4e9a-44be-86a5-498c438e5b90,3599744b-04a6-4959-b927-714f72ea546c,dd95599f-123e-45e6-a14d-a0266aad8911,25ceb850-f7e3-4262-9fa0-d5dbccf60bba,17c82c1e-76bd-4c9f-b30e-22e66bee73ab,640b48cd-23c4-4c61-acfa-9f9003dfc9ff,ddab77bc-ec47-4cfe-aba1-dbd6ead8009a,a5a08778-52e3-4ab5-aae8-dc7e45163cfa,af3bc56f-06c7-456c-b5bb-feca0ae73fb2,1a1de287-cdb3-4044-9e3b-32badda2d80d,83328145-73b1-4db4-bdd4-cfd7023fc415,43695932-4b08-4750-bdf2-08d4170faf64,0f03bd5e-5730-4aeb-bf83-d0111b70184c,4df3b482-b665-4379-bf8b-3b85384308c0,0ac7ad62-9cea-4435-bed8-43f348bf8b52,689a7d20-082f-469d-8dd1-d450ca2f524d,ab39ed28-43ba-4160-8e33-a91d53059d7a,827acfb3-c020-4022-a124-057f9fe46d7f,2b19024c-fa03-4583-856c-605cbe270088,ca5f0c2f-591a-4faa-89ac-93fbc4e3ad44,3855d3ef-be6f-42d6-b4be-a4e975d9c092,d660fe37-ab6e-4e68-a07b-8cf0295f1f45,92d15459-fd92-49fe-8aa9-2a4e999fb4f3,26227325-7f70-4725-a550-c5c55de43ae6,cf8ca05f-319f-4f79-abf2-e00022758918,0ed0c9e3-bb30-4389-9796-c4fff3f7a4be,0272f282-7040-4a42-98b7-844c49568ce0,22afe071-bf2d-4759-bd7e-dcc6eacd7380,3d5bf33d-8409-4db5-82f6-1e470ac9ad8c,83b49463-878b-4e07-aabb-5c2480cff3d5,f1bfd2c1-beea-462b-b06f-2fc70eca2aec,4e8aa852-0d72-42a0-aa0e-bc9c368144f8,b8535597-49a9-4677-93ec-f1095bd1994e,460c09a8-a039-4b2b-ae4f-31c1eed53d1f,1a0cfccd-5f5b-4958-8a45-9d0fb880cdc0,135ba99c-f308-4d17-bb85-ebde94e4d3ea,01e0730f-a5f1-46ce-be14-75a443f12673,f03b3ca1-ae62-4cc5-9997-8f319e5d72bb,2a26b7fa-64a4-4047-9b5e-fc17a30cf25d,e65a47cb-0223-4692-95af-fe3cd023b334,8b46a567-a22b-4c46-a6d4-bf3525cd5b50,87810ab1-1875-4288-8ebf-bcfeada8a319,f0d18982-f301-4f6e-ae01-2d9fd99d2e0f, pattern=[METRICS]
2023-05-08T18:29:45,197 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:1098.64|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:df69971e-b30c-4864-99df-698d9af9d3ae,f34163ff-2da0-4316-b772-c39058eb62e4,a6d71e91-e634-4545-8535-613f0b8be8aa,caf18cf2-0cb1-4ab8-93cf-482d607907a6,4618c9f7-7111-4a7b-8ccb-009751d8d1a5,556e32c9-7273-4ad5-b3be-8f697bc61701,74946f62-7c22-4a85-b1ff-7083e2ad8ed4,d87b03a2-b7c3-4e7a-b55b-cac2038ed2dd,f80594b1-c6e5-4b32-9f43-7de1c51a5ad9,5f922c3f-32d0-4d06-b7a8-578c27d2dc15,48700a84-c338-4aec-ad3e-e11c17c5c226,c55c9cd3-aa6e-4820-8f7d-75a1b823279f,ddb581c4-6dd7-434e-a915-ae3b04452dc1,4b8cdaa4-4e9a-44be-86a5-498c438e5b90,3599744b-04a6-4959-b927-714f72ea546c,dd95599f-123e-45e6-a14d-a0266aad8911,25ceb850-f7e3-4262-9fa0-d5dbccf60bba,17c82c1e-76bd-4c9f-b30e-22e66bee73ab,640b48cd-23c4-4c61-acfa-9f9003dfc9ff,ddab77bc-ec47-4cfe-aba1-dbd6ead8009a,a5a08778-52e3-4ab5-aae8-dc7e45163cfa,af3bc56f-06c7-456c-b5bb-feca0ae73fb2,1a1de287-cdb3-4044-9e3b-32badda2d80d,83328145-73b1-4db4-bdd4-cfd7023fc415,43695932-4b08-4750-bdf2-08d4170faf64,0f03bd5e-5730-4aeb-bf83-d0111b70184c,4df3b482-b665-4379-bf8b-3b85384308c0,0ac7ad62-9cea-4435-bed8-43f348bf8b52,689a7d20-082f-469d-8dd1-d450ca2f524d,ab39ed28-43ba-4160-8e33-a91d53059d7a,827acfb3-c020-4022-a124-057f9fe46d7f,2b19024c-fa03-4583-856c-605cbe270088,ca5f0c2f-591a-4faa-89ac-93fbc4e3ad44,3855d3ef-be6f-42d6-b4be-a4e975d9c092,d660fe37-ab6e-4e68-a07b-8cf0295f1f45,92d15459-fd92-49fe-8aa9-2a4e999fb4f3,26227325-7f70-4725-a550-c5c55de43ae6,cf8ca05f-319f-4f79-abf2-e00022758918,0ed0c9e3-bb30-4389-9796-c4fff3f7a4be,0272f282-7040-4a42-98b7-844c49568ce0,22afe071-bf2d-4759-bd7e-dcc6eacd7380,3d5bf33d-8409-4db5-82f6-1e470ac9ad8c,83b49463-878b-4e07-aabb-5c2480cff3d5,f1bfd2c1-beea-462b-b06f-2fc70eca2aec,4e8aa852-0d72-42a0-aa0e-bc9c368144f8,b8535597-49a9-4677-93ec-f1095bd1994e,460c09a8-a039-4b2b-ae4f-31c1eed53d1f,1a0cfccd-5f5b-4958-8a45-9d0fb880cdc0,135ba99c-f308-4d17-bb85-ebde94e4d3ea,01e0730f-a5f1-46ce-be14-75a443f12673,f03b3ca1-ae62-4cc5-9997-8f319e5d72bb,2a26b7fa-64a4-4047-9b5e-fc17a30cf25d,e65a47cb-0223-4692-95af-fe3cd023b334,8b46a567-a22b-4c46-a6d4-bf3525cd5b50,87810ab1-1875-4288-8ebf-bcfeada8a319,f0d18982-f301-4f6e-ae01-2d9fd99d2e0f,timestamp:1683570585
2023-05-08T18:29:45,197 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1098.72|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570585,df69971e-b30c-4864-99df-698d9af9d3ae,f34163ff-2da0-4316-b772-c39058eb62e4,a6d71e91-e634-4545-8535-613f0b8be8aa,caf18cf2-0cb1-4ab8-93cf-482d607907a6,4618c9f7-7111-4a7b-8ccb-009751d8d1a5,556e32c9-7273-4ad5-b3be-8f697bc61701,74946f62-7c22-4a85-b1ff-7083e2ad8ed4,d87b03a2-b7c3-4e7a-b55b-cac2038ed2dd,f80594b1-c6e5-4b32-9f43-7de1c51a5ad9,5f922c3f-32d0-4d06-b7a8-578c27d2dc15,48700a84-c338-4aec-ad3e-e11c17c5c226,c55c9cd3-aa6e-4820-8f7d-75a1b823279f,ddb581c4-6dd7-434e-a915-ae3b04452dc1,4b8cdaa4-4e9a-44be-86a5-498c438e5b90,3599744b-04a6-4959-b927-714f72ea546c,dd95599f-123e-45e6-a14d-a0266aad8911,25ceb850-f7e3-4262-9fa0-d5dbccf60bba,17c82c1e-76bd-4c9f-b30e-22e66bee73ab,640b48cd-23c4-4c61-acfa-9f9003dfc9ff,ddab77bc-ec47-4cfe-aba1-dbd6ead8009a,a5a08778-52e3-4ab5-aae8-dc7e45163cfa,af3bc56f-06c7-456c-b5bb-feca0ae73fb2,1a1de287-cdb3-4044-9e3b-32badda2d80d,83328145-73b1-4db4-bdd4-cfd7023fc415,43695932-4b08-4750-bdf2-08d4170faf64,0f03bd5e-5730-4aeb-bf83-d0111b70184c,4df3b482-b665-4379-bf8b-3b85384308c0,0ac7ad62-9cea-4435-bed8-43f348bf8b52,689a7d20-082f-469d-8dd1-d450ca2f524d,ab39ed28-43ba-4160-8e33-a91d53059d7a,827acfb3-c020-4022-a124-057f9fe46d7f,2b19024c-fa03-4583-856c-605cbe270088,ca5f0c2f-591a-4faa-89ac-93fbc4e3ad44,3855d3ef-be6f-42d6-b4be-a4e975d9c092,d660fe37-ab6e-4e68-a07b-8cf0295f1f45,92d15459-fd92-49fe-8aa9-2a4e999fb4f3,26227325-7f70-4725-a550-c5c55de43ae6,cf8ca05f-319f-4f79-abf2-e00022758918,0ed0c9e3-bb30-4389-9796-c4fff3f7a4be,0272f282-7040-4a42-98b7-844c49568ce0,22afe071-bf2d-4759-bd7e-dcc6eacd7380,3d5bf33d-8409-4db5-82f6-1e470ac9ad8c,83b49463-878b-4e07-aabb-5c2480cff3d5,f1bfd2c1-beea-462b-b06f-2fc70eca2aec,4e8aa852-0d72-42a0-aa0e-bc9c368144f8,b8535597-49a9-4677-93ec-f1095bd1994e,460c09a8-a039-4b2b-ae4f-31c1eed53d1f,1a0cfccd-5f5b-4958-8a45-9d0fb880cdc0,135ba99c-f308-4d17-bb85-ebde94e4d3ea,01e0730f-a5f1-46ce-be14-75a443f12673,f03b3ca1-ae62-4cc5-9997-8f319e5d72bb,2a26b7fa-64a4-4047-9b5e-fc17a30cf25d,e65a47cb-0223-4692-95af-fe3cd023b334,8b46a567-a22b-4c46-a6d4-bf3525cd5b50,87810ab1-1875-4288-8ebf-bcfeada8a319,f0d18982-f301-4f6e-ae01-2d9fd99d2e0f, pattern=[METRICS]
2023-05-08T18:29:45,197 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1098.72|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570585,df69971e-b30c-4864-99df-698d9af9d3ae,f34163ff-2da0-4316-b772-c39058eb62e4,a6d71e91-e634-4545-8535-613f0b8be8aa,caf18cf2-0cb1-4ab8-93cf-482d607907a6,4618c9f7-7111-4a7b-8ccb-009751d8d1a5,556e32c9-7273-4ad5-b3be-8f697bc61701,74946f62-7c22-4a85-b1ff-7083e2ad8ed4,d87b03a2-b7c3-4e7a-b55b-cac2038ed2dd,f80594b1-c6e5-4b32-9f43-7de1c51a5ad9,5f922c3f-32d0-4d06-b7a8-578c27d2dc15,48700a84-c338-4aec-ad3e-e11c17c5c226,c55c9cd3-aa6e-4820-8f7d-75a1b823279f,ddb581c4-6dd7-434e-a915-ae3b04452dc1,4b8cdaa4-4e9a-44be-86a5-498c438e5b90,3599744b-04a6-4959-b927-714f72ea546c,dd95599f-123e-45e6-a14d-a0266aad8911,25ceb850-f7e3-4262-9fa0-d5dbccf60bba,17c82c1e-76bd-4c9f-b30e-22e66bee73ab,640b48cd-23c4-4c61-acfa-9f9003dfc9ff,ddab77bc-ec47-4cfe-aba1-dbd6ead8009a,a5a08778-52e3-4ab5-aae8-dc7e45163cfa,af3bc56f-06c7-456c-b5bb-feca0ae73fb2,1a1de287-cdb3-4044-9e3b-32badda2d80d,83328145-73b1-4db4-bdd4-cfd7023fc415,43695932-4b08-4750-bdf2-08d4170faf64,0f03bd5e-5730-4aeb-bf83-d0111b70184c,4df3b482-b665-4379-bf8b-3b85384308c0,0ac7ad62-9cea-4435-bed8-43f348bf8b52,689a7d20-082f-469d-8dd1-d450ca2f524d,ab39ed28-43ba-4160-8e33-a91d53059d7a,827acfb3-c020-4022-a124-057f9fe46d7f,2b19024c-fa03-4583-856c-605cbe270088,ca5f0c2f-591a-4faa-89ac-93fbc4e3ad44,3855d3ef-be6f-42d6-b4be-a4e975d9c092,d660fe37-ab6e-4e68-a07b-8cf0295f1f45,92d15459-fd92-49fe-8aa9-2a4e999fb4f3,26227325-7f70-4725-a550-c5c55de43ae6,cf8ca05f-319f-4f79-abf2-e00022758918,0ed0c9e3-bb30-4389-9796-c4fff3f7a4be,0272f282-7040-4a42-98b7-844c49568ce0,22afe071-bf2d-4759-bd7e-dcc6eacd7380,3d5bf33d-8409-4db5-82f6-1e470ac9ad8c,83b49463-878b-4e07-aabb-5c2480cff3d5,f1bfd2c1-beea-462b-b06f-2fc70eca2aec,4e8aa852-0d72-42a0-aa0e-bc9c368144f8,b8535597-49a9-4677-93ec-f1095bd1994e,460c09a8-a039-4b2b-ae4f-31c1eed53d1f,1a0cfccd-5f5b-4958-8a45-9d0fb880cdc0,135ba99c-f308-4d17-bb85-ebde94e4d3ea,01e0730f-a5f1-46ce-be14-75a443f12673,f03b3ca1-ae62-4cc5-9997-8f319e5d72bb,2a26b7fa-64a4-4047-9b5e-fc17a30cf25d,e65a47cb-0223-4692-95af-fe3cd023b334,8b46a567-a22b-4c46-a6d4-bf3525cd5b50,87810ab1-1875-4288-8ebf-bcfeada8a319,f0d18982-f301-4f6e-ae01-2d9fd99d2e0f, pattern=[METRICS]
2023-05-08T18:29:45,197 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:1098.72|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:df69971e-b30c-4864-99df-698d9af9d3ae,f34163ff-2da0-4316-b772-c39058eb62e4,a6d71e91-e634-4545-8535-613f0b8be8aa,caf18cf2-0cb1-4ab8-93cf-482d607907a6,4618c9f7-7111-4a7b-8ccb-009751d8d1a5,556e32c9-7273-4ad5-b3be-8f697bc61701,74946f62-7c22-4a85-b1ff-7083e2ad8ed4,d87b03a2-b7c3-4e7a-b55b-cac2038ed2dd,f80594b1-c6e5-4b32-9f43-7de1c51a5ad9,5f922c3f-32d0-4d06-b7a8-578c27d2dc15,48700a84-c338-4aec-ad3e-e11c17c5c226,c55c9cd3-aa6e-4820-8f7d-75a1b823279f,ddb581c4-6dd7-434e-a915-ae3b04452dc1,4b8cdaa4-4e9a-44be-86a5-498c438e5b90,3599744b-04a6-4959-b927-714f72ea546c,dd95599f-123e-45e6-a14d-a0266aad8911,25ceb850-f7e3-4262-9fa0-d5dbccf60bba,17c82c1e-76bd-4c9f-b30e-22e66bee73ab,640b48cd-23c4-4c61-acfa-9f9003dfc9ff,ddab77bc-ec47-4cfe-aba1-dbd6ead8009a,a5a08778-52e3-4ab5-aae8-dc7e45163cfa,af3bc56f-06c7-456c-b5bb-feca0ae73fb2,1a1de287-cdb3-4044-9e3b-32badda2d80d,83328145-73b1-4db4-bdd4-cfd7023fc415,43695932-4b08-4750-bdf2-08d4170faf64,0f03bd5e-5730-4aeb-bf83-d0111b70184c,4df3b482-b665-4379-bf8b-3b85384308c0,0ac7ad62-9cea-4435-bed8-43f348bf8b52,689a7d20-082f-469d-8dd1-d450ca2f524d,ab39ed28-43ba-4160-8e33-a91d53059d7a,827acfb3-c020-4022-a124-057f9fe46d7f,2b19024c-fa03-4583-856c-605cbe270088,ca5f0c2f-591a-4faa-89ac-93fbc4e3ad44,3855d3ef-be6f-42d6-b4be-a4e975d9c092,d660fe37-ab6e-4e68-a07b-8cf0295f1f45,92d15459-fd92-49fe-8aa9-2a4e999fb4f3,26227325-7f70-4725-a550-c5c55de43ae6,cf8ca05f-319f-4f79-abf2-e00022758918,0ed0c9e3-bb30-4389-9796-c4fff3f7a4be,0272f282-7040-4a42-98b7-844c49568ce0,22afe071-bf2d-4759-bd7e-dcc6eacd7380,3d5bf33d-8409-4db5-82f6-1e470ac9ad8c,83b49463-878b-4e07-aabb-5c2480cff3d5,f1bfd2c1-beea-462b-b06f-2fc70eca2aec,4e8aa852-0d72-42a0-aa0e-bc9c368144f8,b8535597-49a9-4677-93ec-f1095bd1994e,460c09a8-a039-4b2b-ae4f-31c1eed53d1f,1a0cfccd-5f5b-4958-8a45-9d0fb880cdc0,135ba99c-f308-4d17-bb85-ebde94e4d3ea,01e0730f-a5f1-46ce-be14-75a443f12673,f03b3ca1-ae62-4cc5-9997-8f319e5d72bb,2a26b7fa-64a4-4047-9b5e-fc17a30cf25d,e65a47cb-0223-4692-95af-fe3cd023b334,8b46a567-a22b-4c46-a6d4-bf3525cd5b50,87810ab1-1875-4288-8ebf-bcfeada8a319,f0d18982-f301-4f6e-ae01-2d9fd99d2e0f,timestamp:1683570585
2023-05-08T18:29:45,197 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 1653
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653189.205|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550583.955|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550583955, Backend time ns: 1102897867
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550583955, Backend time ns: 1102897867
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653507.063|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550557.804|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550557804, Backend time ns: 1103109197
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550557804, Backend time ns: 1103109197
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653489.562|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550337.572|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550337572, Backend time ns: 1103278267
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550337572, Backend time ns: 1103278267
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 1653
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653563.155|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550238.946|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550238946, Backend time ns: 1103410434
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550238946, Backend time ns: 1103410434
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 1653
2023-05-08T18:29:45,198 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653566.526|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550132.78|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550132780, Backend time ns: 1103608795
2023-05-08T18:29:45,198 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,198 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550132780, Backend time ns: 1103608795
2023-05-08T18:29:45,198 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653718.385|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550050.606|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550050606, Backend time ns: 1103749333
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550050606, Backend time ns: 1103749333
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653661.041|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549881.266|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549881266, Backend time ns: 1103851809
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549881266, Backend time ns: 1103851809
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653682.222|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549807.842|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549807842, Backend time ns: 1103944424
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549807842, Backend time ns: 1103944424
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653616.298|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549650.033|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549650033, Backend time ns: 1104045220
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549650033, Backend time ns: 1104045220
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,199 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653679.282|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549608.391|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549608391, Backend time ns: 1104233480
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549608391, Backend time ns: 1104233480
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653794.578|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549535.767|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549535767, Backend time ns: 1104360397
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549535767, Backend time ns: 1104360397
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,199 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653690.933|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549303.894|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549303894, Backend time ns: 1104508055
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549303894, Backend time ns: 1104508055
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 1653
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653749.886|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549216.129|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549216129, Backend time ns: 1104605421
2023-05-08T18:29:45,199 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549216129, Backend time ns: 1104605421
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 1653
2023-05-08T18:29:45,199 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,199 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653740.656|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549113.944|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549113944, Backend time ns: 1104694076
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549113944, Backend time ns: 1104694076
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653774.047|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549058.39|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549058390, Backend time ns: 1104798142
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549058390, Backend time ns: 1104798142
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653744.286|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548922.493|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548922493, Backend time ns: 1104932869
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548922493, Backend time ns: 1104932869
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653848.881|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548894.381|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548894381, Backend time ns: 1105025344
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548894381, Backend time ns: 1105025344
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653887.283|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548840.878|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548840878, Backend time ns: 1105112849
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548840878, Backend time ns: 1105112849
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653774.987|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548641.157|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548641157, Backend time ns: 1105208344
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548641157, Backend time ns: 1105208344
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653815.82|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548580.404|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548580404, Backend time ns: 1105332131
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548580404, Backend time ns: 1105332131
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653882.503|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548467.197|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548467197, Backend time ns: 1105494530
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548467197, Backend time ns: 1105494530
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653885.764|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548344.111|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548344111, Backend time ns: 1105615897
2023-05-08T18:29:45,200 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548344111, Backend time ns: 1105615897
2023-05-08T18:29:45,200 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,200 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 1653
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653892.094|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548244.955|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548244955, Backend time ns: 1105714033
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548244955, Backend time ns: 1105714033
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653919.276|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548181.662|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548181662, Backend time ns: 1105834279
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548181662, Backend time ns: 1105834279
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653909.965|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548053.654|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548053654, Backend time ns: 1105928895
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548053654, Backend time ns: 1105928895
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653914.495|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547964.669|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547964669, Backend time ns: 1106024690
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547964669, Backend time ns: 1106024690
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653959.478|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547880.265|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547880265, Backend time ns: 1106181759
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547880265, Backend time ns: 1106181759
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653931.696|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547726.026|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547726026, Backend time ns: 1106310596
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547726026, Backend time ns: 1106310596
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653941.727|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547609.13|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547609130, Backend time ns: 1106399001
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547609130, Backend time ns: 1106399001
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653978.679|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547529.405|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547529405, Backend time ns: 1106524348
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547529405, Backend time ns: 1106524348
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653946.347|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547400.128|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547400128, Backend time ns: 1106626103
2023-05-08T18:29:45,201 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547400128, Backend time ns: 1106626103
2023-05-08T18:29:45,201 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 1655
2023-05-08T18:29:45,201 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653957.488|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547306.993|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547306993, Backend time ns: 1106739880
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547306993, Backend time ns: 1106739880
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653995.78|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547199.297|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547199297, Backend time ns: 1106876557
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547199297, Backend time ns: 1106876557
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653986.02|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:547087.911|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547087911, Backend time ns: 1106994834
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 547087911, Backend time ns: 1106994834
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653998.32|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546947.673|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546947673, Backend time ns: 1107142202
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546947673, Backend time ns: 1107142202
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1654027.691|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546863.788|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546863788, Backend time ns: 1107232317
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546863788, Backend time ns: 1107232317
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1654000.239|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546744.831|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546744831, Backend time ns: 1107335153
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546744831, Backend time ns: 1107335153
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1654022.391|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546666.467|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546666467, Backend time ns: 1107435809
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546666467, Backend time ns: 1107435809
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1653966.658|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546509.518|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546509518, Backend time ns: 1107526404
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546509518, Backend time ns: 1107526404
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1654023.541|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546474.956|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546474956, Backend time ns: 1107636590
2023-05-08T18:29:45,202 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546474956, Backend time ns: 1107636590
2023-05-08T18:29:45,202 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 1655
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1654068.584|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546398.892|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546398892, Backend time ns: 1107738745
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546398892, Backend time ns: 1107738745
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1654003.68|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546232.833|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546232833, Backend time ns: 1107838721
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546232833, Backend time ns: 1107838721
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1654036.372|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546158.969|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546158969, Backend time ns: 1107957878
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546158969, Backend time ns: 1107957878
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 1654
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1654057.343|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:546045.442|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546045442, Backend time ns: 1108092045
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 546045442, Backend time ns: 1108092045
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1113894.997|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5781.441|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5781441, Backend time ns: 1108193491
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5781441, Backend time ns: 1108193491
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1113926.609|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5692.176|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5692176, Backend time ns: 1108310187
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5692176, Backend time ns: 1108310187
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1113986.872|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5622.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5622552, Backend time ns: 1108432404
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5622552, Backend time ns: 1108432404
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1114062.706|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5608.161|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5608161, Backend time ns: 1108519789
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5608161, Backend time ns: 1108519789
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1114046.426|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5498.655|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5498655, Backend time ns: 1108627445
2023-05-08T18:29:45,203 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5498655, Backend time ns: 1108627445
2023-05-08T18:29:45,203 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 1115
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1114128.989|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5457.652|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5457652, Backend time ns: 1108743801
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5457652, Backend time ns: 1108743801
2023-05-08T18:29:45,204 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 1115
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1114125.93|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5359.957|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5359957, Backend time ns: 1108829586
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5359957, Backend time ns: 1108829586
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1113952.9|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5100.893|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5100893, Backend time ns: 1108931852
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5100893, Backend time ns: 1108931852
2023-05-08T18:29:45,204 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1113973.281|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4995.337|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4995337, Backend time ns: 1109073750
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4995337, Backend time ns: 1109073750
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1114030.564|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4933.663|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4933663, Backend time ns: 1109160955
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4933663, Backend time ns: 1109160955
2023-05-08T18:29:45,204 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1113957.131|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4761.254|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4761254, Backend time ns: 1109266741
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4761254, Backend time ns: 1109266741
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 1114
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1114038.915|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4744.903|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4744903, Backend time ns: 1109369406
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4744903, Backend time ns: 1109369406
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:45,204 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1102
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1102
2023-05-08T18:29:45,204 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570585204
2023-05-08T18:29:45,204 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570585204
2023-05-08T18:29:45,207 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570585
2023-05-08T18:29:45,208 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,208 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,208 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,208 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,208 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,208 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,208 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,209 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,210 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,211 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,212 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,213 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,214 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,215 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,216 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,216 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,216 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:45,217 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:45,217 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:45,222 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:45,259 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:45,283 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:45,289 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:45,321 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:45,326 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:45,328 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:45,360 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:45,366 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:45,366 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:45,368 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:45,398 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:45,404 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:45,406 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:45,408 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:45,436 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:45,443 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:45,446 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:45,448 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:45,475 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:45,482 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:45,487 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:45,489 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:45,514 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:45,527 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:45,529 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:45,552 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:45,567 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:45,569 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:45,607 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:45,610 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:45,652 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:45,746 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\n ', 'Hey, are you conscious? Can you talk to me?\n ', 'Hey, are you conscious? Can you talk to me?\n.', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\n.', 'Hey, are you conscious? Can you talk to me?\n.', 'Hey, are you conscious? Can you talk to me?\n.']
2023-05-08T18:29:45,746 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:537.92|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570585,8654a04e-dda9-44f7-a1b4-9291b79a3c7c,90e1b970-9238-4bf9-848d-61028c17417d,328584dc-755a-479f-990a-90e784da3ba7,b537a86f-4f4e-4246-b54c-9df02899f511,a3067899-c1db-4c58-ab0d-510065ee43b0,11e5aab0-608f-460a-844e-9ef4b39267f1,c036b615-b726-4378-9797-904a8b4100f6,fb46d6d4-2ee0-4c02-b605-6af63ebd870d,734b472c-d0a8-4722-bf60-20b3c35114d2,31e9e3f3-a820-41c7-a49f-013b7726edbd,57a401ee-12ca-4062-ba75-7df5c7bda8e9,43c1cf11-e33e-4eaa-86a6-6d320e14fcc1,8b51d6d7-4c07-4efd-b18f-8d18dcdb35d1,5200c7fd-5298-4140-8bd6-8a07829215b2,d1cdecf1-a0c7-46f5-a73f-fe390967c434,7a39d93c-6d52-40ff-9d7e-0fa06994b2d3,7546b647-a758-4913-be13-3a5e3733c4f3,af31966a-2d80-43d1-bf49-ed0cbd1bc046,b5647e89-7c8d-46fe-bce0-c0d14a58dce4,072b061e-f7f5-41f4-92d1-ea644fe00339,9f821416-9224-4c0f-8bbf-b67e22d22c59,c77d0aa4-fe34-44b5-bf60-f2fb542cd64f,b9bbeb26-b8be-4c3d-8e70-b9508e09b0d4,56f2647b-f7d0-4c86-adfc-9a1ddc6b02a7,e8c1e822-d193-4e9c-9f23-6ccc8ab252c4,738365e2-24d9-40c7-8de0-ccf4f85a559b,e993f6af-3556-4db9-94d3-54961628e677,de811f6f-2391-4e60-aec4-760c4e174d79,caeeb5cc-252f-4a90-b42e-b46f1e80110c,929b9f8d-c03c-43d8-9416-7c7b91ec264b,06bb9aef-3b84-4779-a437-2d92f7a00647,e9f8052a-347f-4019-bbe0-ce1cd572e215,db816c7b-d943-484b-abf8-79984e3f9c13,5b7a0bd9-7782-4753-8906-aff0f50c1245,8db2ced3-e297-4c24-b099-72b8561b0e2a,f61f9289-3fdf-4cb0-909e-a61841bb248a,87340ebb-2f9b-44eb-833f-80335e8feb39,6c20c468-a4e5-4bef-847b-cbcfa45f55e6,3bc748d3-989c-43af-909a-a65997223177,fc489a61-c68b-4b7d-9ffe-35705e1a374e,1ae0ffbf-9fd5-4451-b78f-a6c609736c2b,455a6b50-9ec1-4e75-8c56-2e88d9745cca,01965ded-9efd-4f76-a450-913647764687,5e7a023d-179a-430a-aabc-19d0ad36067d,61025185-c2e9-43c9-9ea2-3e3c65a5c7ee,482b8437-d4da-402a-811d-1da1cd70c9e1,dde02509-336d-4222-9892-cf4d6edfd990,c91caece-d91b-49c6-b8bd-1ee4d9a22525,52eb7c60-a9df-47f8-9ba5-a113f58bb21c,b3f895b1-1c1c-478e-9418-a66cf2385603,21be4d56-aa53-4de1-bf5e-5e9fc321b02e,3ecb9b59-2ca0-4c41-9e81-7d156b41c85b,93a24b8e-8971-4013-b52a-42b3ad85eea2,5aa0914c-251d-4802-98ca-b64538d64c1b,8a996d03-d905-4af1-b2e8-b61956e75e48,9041688a-66c5-4bd0-8e93-b7d125bacd0f, pattern=[METRICS]
2023-05-08T18:29:45,746 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:537.92|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570585,8654a04e-dda9-44f7-a1b4-9291b79a3c7c,90e1b970-9238-4bf9-848d-61028c17417d,328584dc-755a-479f-990a-90e784da3ba7,b537a86f-4f4e-4246-b54c-9df02899f511,a3067899-c1db-4c58-ab0d-510065ee43b0,11e5aab0-608f-460a-844e-9ef4b39267f1,c036b615-b726-4378-9797-904a8b4100f6,fb46d6d4-2ee0-4c02-b605-6af63ebd870d,734b472c-d0a8-4722-bf60-20b3c35114d2,31e9e3f3-a820-41c7-a49f-013b7726edbd,57a401ee-12ca-4062-ba75-7df5c7bda8e9,43c1cf11-e33e-4eaa-86a6-6d320e14fcc1,8b51d6d7-4c07-4efd-b18f-8d18dcdb35d1,5200c7fd-5298-4140-8bd6-8a07829215b2,d1cdecf1-a0c7-46f5-a73f-fe390967c434,7a39d93c-6d52-40ff-9d7e-0fa06994b2d3,7546b647-a758-4913-be13-3a5e3733c4f3,af31966a-2d80-43d1-bf49-ed0cbd1bc046,b5647e89-7c8d-46fe-bce0-c0d14a58dce4,072b061e-f7f5-41f4-92d1-ea644fe00339,9f821416-9224-4c0f-8bbf-b67e22d22c59,c77d0aa4-fe34-44b5-bf60-f2fb542cd64f,b9bbeb26-b8be-4c3d-8e70-b9508e09b0d4,56f2647b-f7d0-4c86-adfc-9a1ddc6b02a7,e8c1e822-d193-4e9c-9f23-6ccc8ab252c4,738365e2-24d9-40c7-8de0-ccf4f85a559b,e993f6af-3556-4db9-94d3-54961628e677,de811f6f-2391-4e60-aec4-760c4e174d79,caeeb5cc-252f-4a90-b42e-b46f1e80110c,929b9f8d-c03c-43d8-9416-7c7b91ec264b,06bb9aef-3b84-4779-a437-2d92f7a00647,e9f8052a-347f-4019-bbe0-ce1cd572e215,db816c7b-d943-484b-abf8-79984e3f9c13,5b7a0bd9-7782-4753-8906-aff0f50c1245,8db2ced3-e297-4c24-b099-72b8561b0e2a,f61f9289-3fdf-4cb0-909e-a61841bb248a,87340ebb-2f9b-44eb-833f-80335e8feb39,6c20c468-a4e5-4bef-847b-cbcfa45f55e6,3bc748d3-989c-43af-909a-a65997223177,fc489a61-c68b-4b7d-9ffe-35705e1a374e,1ae0ffbf-9fd5-4451-b78f-a6c609736c2b,455a6b50-9ec1-4e75-8c56-2e88d9745cca,01965ded-9efd-4f76-a450-913647764687,5e7a023d-179a-430a-aabc-19d0ad36067d,61025185-c2e9-43c9-9ea2-3e3c65a5c7ee,482b8437-d4da-402a-811d-1da1cd70c9e1,dde02509-336d-4222-9892-cf4d6edfd990,c91caece-d91b-49c6-b8bd-1ee4d9a22525,52eb7c60-a9df-47f8-9ba5-a113f58bb21c,b3f895b1-1c1c-478e-9418-a66cf2385603,21be4d56-aa53-4de1-bf5e-5e9fc321b02e,3ecb9b59-2ca0-4c41-9e81-7d156b41c85b,93a24b8e-8971-4013-b52a-42b3ad85eea2,5aa0914c-251d-4802-98ca-b64538d64c1b,8a996d03-d905-4af1-b2e8-b61956e75e48,9041688a-66c5-4bd0-8e93-b7d125bacd0f, pattern=[METRICS]
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:537.92|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:8654a04e-dda9-44f7-a1b4-9291b79a3c7c,90e1b970-9238-4bf9-848d-61028c17417d,328584dc-755a-479f-990a-90e784da3ba7,b537a86f-4f4e-4246-b54c-9df02899f511,a3067899-c1db-4c58-ab0d-510065ee43b0,11e5aab0-608f-460a-844e-9ef4b39267f1,c036b615-b726-4378-9797-904a8b4100f6,fb46d6d4-2ee0-4c02-b605-6af63ebd870d,734b472c-d0a8-4722-bf60-20b3c35114d2,31e9e3f3-a820-41c7-a49f-013b7726edbd,57a401ee-12ca-4062-ba75-7df5c7bda8e9,43c1cf11-e33e-4eaa-86a6-6d320e14fcc1,8b51d6d7-4c07-4efd-b18f-8d18dcdb35d1,5200c7fd-5298-4140-8bd6-8a07829215b2,d1cdecf1-a0c7-46f5-a73f-fe390967c434,7a39d93c-6d52-40ff-9d7e-0fa06994b2d3,7546b647-a758-4913-be13-3a5e3733c4f3,af31966a-2d80-43d1-bf49-ed0cbd1bc046,b5647e89-7c8d-46fe-bce0-c0d14a58dce4,072b061e-f7f5-41f4-92d1-ea644fe00339,9f821416-9224-4c0f-8bbf-b67e22d22c59,c77d0aa4-fe34-44b5-bf60-f2fb542cd64f,b9bbeb26-b8be-4c3d-8e70-b9508e09b0d4,56f2647b-f7d0-4c86-adfc-9a1ddc6b02a7,e8c1e822-d193-4e9c-9f23-6ccc8ab252c4,738365e2-24d9-40c7-8de0-ccf4f85a559b,e993f6af-3556-4db9-94d3-54961628e677,de811f6f-2391-4e60-aec4-760c4e174d79,caeeb5cc-252f-4a90-b42e-b46f1e80110c,929b9f8d-c03c-43d8-9416-7c7b91ec264b,06bb9aef-3b84-4779-a437-2d92f7a00647,e9f8052a-347f-4019-bbe0-ce1cd572e215,db816c7b-d943-484b-abf8-79984e3f9c13,5b7a0bd9-7782-4753-8906-aff0f50c1245,8db2ced3-e297-4c24-b099-72b8561b0e2a,f61f9289-3fdf-4cb0-909e-a61841bb248a,87340ebb-2f9b-44eb-833f-80335e8feb39,6c20c468-a4e5-4bef-847b-cbcfa45f55e6,3bc748d3-989c-43af-909a-a65997223177,fc489a61-c68b-4b7d-9ffe-35705e1a374e,1ae0ffbf-9fd5-4451-b78f-a6c609736c2b,455a6b50-9ec1-4e75-8c56-2e88d9745cca,01965ded-9efd-4f76-a450-913647764687,5e7a023d-179a-430a-aabc-19d0ad36067d,61025185-c2e9-43c9-9ea2-3e3c65a5c7ee,482b8437-d4da-402a-811d-1da1cd70c9e1,dde02509-336d-4222-9892-cf4d6edfd990,c91caece-d91b-49c6-b8bd-1ee4d9a22525,52eb7c60-a9df-47f8-9ba5-a113f58bb21c,b3f895b1-1c1c-478e-9418-a66cf2385603,21be4d56-aa53-4de1-bf5e-5e9fc321b02e,3ecb9b59-2ca0-4c41-9e81-7d156b41c85b,93a24b8e-8971-4013-b52a-42b3ad85eea2,5aa0914c-251d-4802-98ca-b64538d64c1b,8a996d03-d905-4af1-b2e8-b61956e75e48,9041688a-66c5-4bd0-8e93-b7d125bacd0f,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656358.531|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1114232.525|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1114232525, Backend time ns: 542306596
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1114232525, Backend time ns: 542306596
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1114.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656442.055|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1114107.829|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1114107829, Backend time ns: 542396130
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1114107829, Backend time ns: 542396130
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1114.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:538.01|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570585,8654a04e-dda9-44f7-a1b4-9291b79a3c7c,90e1b970-9238-4bf9-848d-61028c17417d,328584dc-755a-479f-990a-90e784da3ba7,b537a86f-4f4e-4246-b54c-9df02899f511,a3067899-c1db-4c58-ab0d-510065ee43b0,11e5aab0-608f-460a-844e-9ef4b39267f1,c036b615-b726-4378-9797-904a8b4100f6,fb46d6d4-2ee0-4c02-b605-6af63ebd870d,734b472c-d0a8-4722-bf60-20b3c35114d2,31e9e3f3-a820-41c7-a49f-013b7726edbd,57a401ee-12ca-4062-ba75-7df5c7bda8e9,43c1cf11-e33e-4eaa-86a6-6d320e14fcc1,8b51d6d7-4c07-4efd-b18f-8d18dcdb35d1,5200c7fd-5298-4140-8bd6-8a07829215b2,d1cdecf1-a0c7-46f5-a73f-fe390967c434,7a39d93c-6d52-40ff-9d7e-0fa06994b2d3,7546b647-a758-4913-be13-3a5e3733c4f3,af31966a-2d80-43d1-bf49-ed0cbd1bc046,b5647e89-7c8d-46fe-bce0-c0d14a58dce4,072b061e-f7f5-41f4-92d1-ea644fe00339,9f821416-9224-4c0f-8bbf-b67e22d22c59,c77d0aa4-fe34-44b5-bf60-f2fb542cd64f,b9bbeb26-b8be-4c3d-8e70-b9508e09b0d4,56f2647b-f7d0-4c86-adfc-9a1ddc6b02a7,e8c1e822-d193-4e9c-9f23-6ccc8ab252c4,738365e2-24d9-40c7-8de0-ccf4f85a559b,e993f6af-3556-4db9-94d3-54961628e677,de811f6f-2391-4e60-aec4-760c4e174d79,caeeb5cc-252f-4a90-b42e-b46f1e80110c,929b9f8d-c03c-43d8-9416-7c7b91ec264b,06bb9aef-3b84-4779-a437-2d92f7a00647,e9f8052a-347f-4019-bbe0-ce1cd572e215,db816c7b-d943-484b-abf8-79984e3f9c13,5b7a0bd9-7782-4753-8906-aff0f50c1245,8db2ced3-e297-4c24-b099-72b8561b0e2a,f61f9289-3fdf-4cb0-909e-a61841bb248a,87340ebb-2f9b-44eb-833f-80335e8feb39,6c20c468-a4e5-4bef-847b-cbcfa45f55e6,3bc748d3-989c-43af-909a-a65997223177,fc489a61-c68b-4b7d-9ffe-35705e1a374e,1ae0ffbf-9fd5-4451-b78f-a6c609736c2b,455a6b50-9ec1-4e75-8c56-2e88d9745cca,01965ded-9efd-4f76-a450-913647764687,5e7a023d-179a-430a-aabc-19d0ad36067d,61025185-c2e9-43c9-9ea2-3e3c65a5c7ee,482b8437-d4da-402a-811d-1da1cd70c9e1,dde02509-336d-4222-9892-cf4d6edfd990,c91caece-d91b-49c6-b8bd-1ee4d9a22525,52eb7c60-a9df-47f8-9ba5-a113f58bb21c,b3f895b1-1c1c-478e-9418-a66cf2385603,21be4d56-aa53-4de1-bf5e-5e9fc321b02e,3ecb9b59-2ca0-4c41-9e81-7d156b41c85b,93a24b8e-8971-4013-b52a-42b3ad85eea2,5aa0914c-251d-4802-98ca-b64538d64c1b,8a996d03-d905-4af1-b2e8-b61956e75e48,9041688a-66c5-4bd0-8e93-b7d125bacd0f, pattern=[METRICS]
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656242.454|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:538.01|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570585,8654a04e-dda9-44f7-a1b4-9291b79a3c7c,90e1b970-9238-4bf9-848d-61028c17417d,328584dc-755a-479f-990a-90e784da3ba7,b537a86f-4f4e-4246-b54c-9df02899f511,a3067899-c1db-4c58-ab0d-510065ee43b0,11e5aab0-608f-460a-844e-9ef4b39267f1,c036b615-b726-4378-9797-904a8b4100f6,fb46d6d4-2ee0-4c02-b605-6af63ebd870d,734b472c-d0a8-4722-bf60-20b3c35114d2,31e9e3f3-a820-41c7-a49f-013b7726edbd,57a401ee-12ca-4062-ba75-7df5c7bda8e9,43c1cf11-e33e-4eaa-86a6-6d320e14fcc1,8b51d6d7-4c07-4efd-b18f-8d18dcdb35d1,5200c7fd-5298-4140-8bd6-8a07829215b2,d1cdecf1-a0c7-46f5-a73f-fe390967c434,7a39d93c-6d52-40ff-9d7e-0fa06994b2d3,7546b647-a758-4913-be13-3a5e3733c4f3,af31966a-2d80-43d1-bf49-ed0cbd1bc046,b5647e89-7c8d-46fe-bce0-c0d14a58dce4,072b061e-f7f5-41f4-92d1-ea644fe00339,9f821416-9224-4c0f-8bbf-b67e22d22c59,c77d0aa4-fe34-44b5-bf60-f2fb542cd64f,b9bbeb26-b8be-4c3d-8e70-b9508e09b0d4,56f2647b-f7d0-4c86-adfc-9a1ddc6b02a7,e8c1e822-d193-4e9c-9f23-6ccc8ab252c4,738365e2-24d9-40c7-8de0-ccf4f85a559b,e993f6af-3556-4db9-94d3-54961628e677,de811f6f-2391-4e60-aec4-760c4e174d79,caeeb5cc-252f-4a90-b42e-b46f1e80110c,929b9f8d-c03c-43d8-9416-7c7b91ec264b,06bb9aef-3b84-4779-a437-2d92f7a00647,e9f8052a-347f-4019-bbe0-ce1cd572e215,db816c7b-d943-484b-abf8-79984e3f9c13,5b7a0bd9-7782-4753-8906-aff0f50c1245,8db2ced3-e297-4c24-b099-72b8561b0e2a,f61f9289-3fdf-4cb0-909e-a61841bb248a,87340ebb-2f9b-44eb-833f-80335e8feb39,6c20c468-a4e5-4bef-847b-cbcfa45f55e6,3bc748d3-989c-43af-909a-a65997223177,fc489a61-c68b-4b7d-9ffe-35705e1a374e,1ae0ffbf-9fd5-4451-b78f-a6c609736c2b,455a6b50-9ec1-4e75-8c56-2e88d9745cca,01965ded-9efd-4f76-a450-913647764687,5e7a023d-179a-430a-aabc-19d0ad36067d,61025185-c2e9-43c9-9ea2-3e3c65a5c7ee,482b8437-d4da-402a-811d-1da1cd70c9e1,dde02509-336d-4222-9892-cf4d6edfd990,c91caece-d91b-49c6-b8bd-1ee4d9a22525,52eb7c60-a9df-47f8-9ba5-a113f58bb21c,b3f895b1-1c1c-478e-9418-a66cf2385603,21be4d56-aa53-4de1-bf5e-5e9fc321b02e,3ecb9b59-2ca0-4c41-9e81-7d156b41c85b,93a24b8e-8971-4013-b52a-42b3ad85eea2,5aa0914c-251d-4802-98ca-b64538d64c1b,8a996d03-d905-4af1-b2e8-b61956e75e48,9041688a-66c5-4bd0-8e93-b7d125bacd0f, pattern=[METRICS]
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1113823.753|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113823753, Backend time ns: 542503886
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113823753, Backend time ns: 542503886
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1113.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656297.987|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:538.01|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:8654a04e-dda9-44f7-a1b4-9291b79a3c7c,90e1b970-9238-4bf9-848d-61028c17417d,328584dc-755a-479f-990a-90e784da3ba7,b537a86f-4f4e-4246-b54c-9df02899f511,a3067899-c1db-4c58-ab0d-510065ee43b0,11e5aab0-608f-460a-844e-9ef4b39267f1,c036b615-b726-4378-9797-904a8b4100f6,fb46d6d4-2ee0-4c02-b605-6af63ebd870d,734b472c-d0a8-4722-bf60-20b3c35114d2,31e9e3f3-a820-41c7-a49f-013b7726edbd,57a401ee-12ca-4062-ba75-7df5c7bda8e9,43c1cf11-e33e-4eaa-86a6-6d320e14fcc1,8b51d6d7-4c07-4efd-b18f-8d18dcdb35d1,5200c7fd-5298-4140-8bd6-8a07829215b2,d1cdecf1-a0c7-46f5-a73f-fe390967c434,7a39d93c-6d52-40ff-9d7e-0fa06994b2d3,7546b647-a758-4913-be13-3a5e3733c4f3,af31966a-2d80-43d1-bf49-ed0cbd1bc046,b5647e89-7c8d-46fe-bce0-c0d14a58dce4,072b061e-f7f5-41f4-92d1-ea644fe00339,9f821416-9224-4c0f-8bbf-b67e22d22c59,c77d0aa4-fe34-44b5-bf60-f2fb542cd64f,b9bbeb26-b8be-4c3d-8e70-b9508e09b0d4,56f2647b-f7d0-4c86-adfc-9a1ddc6b02a7,e8c1e822-d193-4e9c-9f23-6ccc8ab252c4,738365e2-24d9-40c7-8de0-ccf4f85a559b,e993f6af-3556-4db9-94d3-54961628e677,de811f6f-2391-4e60-aec4-760c4e174d79,caeeb5cc-252f-4a90-b42e-b46f1e80110c,929b9f8d-c03c-43d8-9416-7c7b91ec264b,06bb9aef-3b84-4779-a437-2d92f7a00647,e9f8052a-347f-4019-bbe0-ce1cd572e215,db816c7b-d943-484b-abf8-79984e3f9c13,5b7a0bd9-7782-4753-8906-aff0f50c1245,8db2ced3-e297-4c24-b099-72b8561b0e2a,f61f9289-3fdf-4cb0-909e-a61841bb248a,87340ebb-2f9b-44eb-833f-80335e8feb39,6c20c468-a4e5-4bef-847b-cbcfa45f55e6,3bc748d3-989c-43af-909a-a65997223177,fc489a61-c68b-4b7d-9ffe-35705e1a374e,1ae0ffbf-9fd5-4451-b78f-a6c609736c2b,455a6b50-9ec1-4e75-8c56-2e88d9745cca,01965ded-9efd-4f76-a450-913647764687,5e7a023d-179a-430a-aabc-19d0ad36067d,61025185-c2e9-43c9-9ea2-3e3c65a5c7ee,482b8437-d4da-402a-811d-1da1cd70c9e1,dde02509-336d-4222-9892-cf4d6edfd990,c91caece-d91b-49c6-b8bd-1ee4d9a22525,52eb7c60-a9df-47f8-9ba5-a113f58bb21c,b3f895b1-1c1c-478e-9418-a66cf2385603,21be4d56-aa53-4de1-bf5e-5e9fc321b02e,3ecb9b59-2ca0-4c41-9e81-7d156b41c85b,93a24b8e-8971-4013-b52a-42b3ad85eea2,5aa0914c-251d-4802-98ca-b64538d64c1b,8a996d03-d905-4af1-b2e8-b61956e75e48,9041688a-66c5-4bd0-8e93-b7d125bacd0f,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1113768.2|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113768200, Backend time ns: 542648784
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113768200, Backend time ns: 542648784
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1113.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656436.185|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1113759.79|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113759790, Backend time ns: 542749409
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113759790, Backend time ns: 542749409
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1113.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,747 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656427.255|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1113652.514|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113652514, Backend time ns: 542905758
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113652514, Backend time ns: 542905758
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1113.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656459.366|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1113531.127|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113531127, Backend time ns: 542996013
2023-05-08T18:29:45,747 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113531127, Backend time ns: 542996013
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1113.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,747 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656394.212|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1113374.358|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113374358, Backend time ns: 543107169
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113374358, Backend time ns: 543107169
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1113.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656411.813|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1113284.223|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113284223, Backend time ns: 543191184
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113284223, Backend time ns: 543191184
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1113.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656327.199|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1113114.314|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113114314, Backend time ns: 543282689
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1113114314, Backend time ns: 543282689
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1113.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656235.014|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112932.084|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112932084, Backend time ns: 543383015
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112932084, Backend time ns: 543383015
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656341.89|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112922.403|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112922403, Backend time ns: 543485510
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112922403, Backend time ns: 543485510
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656371.112|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112865.01|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112865010, Backend time ns: 543574245
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112865010, Backend time ns: 543574245
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656317.009|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112719.622|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112719622, Backend time ns: 543723834
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112719622, Backend time ns: 543723834
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656354.58|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112600.325|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112600325, Backend time ns: 543819269
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112600325, Backend time ns: 543819269
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656333.959|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112491.059|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112491059, Backend time ns: 543906814
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112491059, Backend time ns: 543906814
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656346.89|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112419.845|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112419845, Backend time ns: 544002919
2023-05-08T18:29:45,748 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112419845, Backend time ns: 544002919
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,748 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656315.698|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,748 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112290.318|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112290318, Backend time ns: 544093224
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112290318, Backend time ns: 544093224
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656289.067|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112175.202|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112175202, Backend time ns: 544186929
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112175202, Backend time ns: 544186929
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656299.718|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1112088.927|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112088927, Backend time ns: 544292275
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1112088927, Backend time ns: 544292275
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1112.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656313.919|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111992.672|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111992672, Backend time ns: 544413592
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111992672, Backend time ns: 544413592
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656329.729|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111872.655|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111872655, Backend time ns: 544521778
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111872655, Backend time ns: 544521778
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656306.918|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111764.209|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111764209, Backend time ns: 544606573
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111764209, Backend time ns: 544606573
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656294.757|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111664.103|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111664103, Backend time ns: 544699528
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111664103, Backend time ns: 544699528
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656353.701|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111632.222|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111632222, Backend time ns: 544803254
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111632222, Backend time ns: 544803254
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656285.767|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111461.262|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111461262, Backend time ns: 544898849
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111461262, Backend time ns: 544898849
2023-05-08T18:29:45,749 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656301.138|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111370.757|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111370757, Backend time ns: 544998874
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111370757, Backend time ns: 544998874
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656292.978|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111273.912|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111273912, Backend time ns: 545081799
2023-05-08T18:29:45,749 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111273912, Backend time ns: 545081799
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656272.816|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111168.576|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111168576, Backend time ns: 545178654
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111168576, Backend time ns: 545178654
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656218.074|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111018.508|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111018508, Backend time ns: 545348144
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111018508, Backend time ns: 545348144
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656379.502|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1111010.217|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111010217, Backend time ns: 545483141
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1111010217, Backend time ns: 545483141
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1111.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656382.942|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110873.239|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110873239, Backend time ns: 545598758
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110873239, Backend time ns: 545598758
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656437.695|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110811.126|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110811126, Backend time ns: 545693403
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110811126, Backend time ns: 545693403
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656393.663|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110670.388|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110670388, Backend time ns: 545793509
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110670388, Backend time ns: 545793509
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656397.273|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110581.073|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110581073, Backend time ns: 545888904
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110581073, Backend time ns: 545888904
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-19 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656342.23|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110428.925|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110428925, Backend time ns: 545982459
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110428925, Backend time ns: 545982459
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-17 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656362.621|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110358.971|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110358971, Backend time ns: 546074374
2023-05-08T18:29:45,750 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110358971, Backend time ns: 546074374
2023-05-08T18:29:45,750 [INFO ] epollEventLoopGroup-3-22 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656397.703|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110287.937|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110287937, Backend time ns: 546178760
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110287937, Backend time ns: 546178760
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] epollEventLoopGroup-3-18 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656379.292|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110172.27|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110172270, Backend time ns: 546307327
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110172270, Backend time ns: 546307327
2023-05-08T18:29:45,751 [INFO ] epollEventLoopGroup-3-20 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656373.812|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110045.103|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110045103, Backend time ns: 546390672
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110045103, Backend time ns: 546390672
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 1657
2023-05-08T18:29:45,751 [INFO ] epollEventLoopGroup-3-21 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656413.184|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1110002.131|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110002131, Backend time ns: 546482727
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1110002131, Backend time ns: 546482727
2023-05-08T18:29:45,751 [INFO ] epollEventLoopGroup-3-23 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1110.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656380.502|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1109858.053|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1109858053, Backend time ns: 546600444
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1109858053, Backend time ns: 546600444
2023-05-08T18:29:45,751 [INFO ] epollEventLoopGroup-3-24 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1109.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656387.753|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1109765.978|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1109765978, Backend time ns: 546683028
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1109765978, Backend time ns: 546683028
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1109.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 1656
2023-05-08T18:29:45,751 [INFO ] epollEventLoopGroup-3-26 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1656386.762|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1109683.093|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1109683093, Backend time ns: 546779204
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1109683093, Backend time ns: 546779204
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:1109.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,751 [INFO ] epollEventLoopGroup-3-25 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] epollEventLoopGroup-3-27 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552880.093|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6079.748|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6079748, Backend time ns: 546942983
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6079748, Backend time ns: 546942983
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553017.3|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:6050.906|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6050906, Backend time ns: 547027617
2023-05-08T18:29:45,751 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 6050906, Backend time ns: 547027617
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:6.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,751 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553026.521|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5979.332|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5979332, Backend time ns: 547106662
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5979332, Backend time ns: 547106662
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 554
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-29 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553072.313|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5944.61|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5944610, Backend time ns: 547202967
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5944610, Backend time ns: 547202967
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-31 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-28 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:553066.873|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5834.924|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5834924, Backend time ns: 547349975
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5834924, Backend time ns: 547349975
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552824.19|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5453.863|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5453863, Backend time ns: 547435830
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5453863, Backend time ns: 547435830
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-30 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552828.429|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5371.708|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5371708, Backend time ns: 547522635
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5371708, Backend time ns: 547522635
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-32 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552911.014|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5367.678|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5367678, Backend time ns: 547619160
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5367678, Backend time ns: 547619160
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552868.492|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5229.31|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5229310, Backend time ns: 547725586
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5229310, Backend time ns: 547725586
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552904.804|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5133.445|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5133445, Backend time ns: 547853083
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5133445, Backend time ns: 547853083
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552983.299|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5109.694|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5109694, Backend time ns: 547937378
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5109694, Backend time ns: 547937378
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 553
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:552904.494|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4932.044|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4932044, Backend time ns: 548035384
2023-05-08T18:29:45,752 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4932044, Backend time ns: 548035384
2023-05-08T18:29:45,752 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,752 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,753 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:45,753 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:45,753 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-05-08T18:29:45,753 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 542
2023-05-08T18:29:45,753 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,753 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570585
2023-05-08T18:29:45,753 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570585753
2023-05-08T18:29:45,753 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570585753
2023-05-08T18:29:45,755 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570585
2023-05-08T18:29:45,756 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,756 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,756 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,756 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,756 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,756 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,757 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,758 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,759 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,760 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,761 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,762 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,763 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,764 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:45,764 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:45,764 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([56, 50])
2023-05-08T18:29:45,765 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:45,765 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:45,770 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:45,807 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:45,829 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:45,836 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:45,867 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:45,872 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:45,874 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:45,906 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:45,912 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:45,913 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:45,914 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:45,944 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:45,951 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:45,952 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:45,954 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:45,982 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:45,989 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:45,993 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:45,995 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:46,021 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:46,027 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:46,033 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:46,035 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:46,060 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:46,073 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:46,075 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:46,098 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:46,113 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:46,116 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:46,154 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:46,156 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:46,198 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:46,292 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:46,292 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:536.07|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570586,17b7b61e-09f8-4a7d-8c6e-ff7541a8ec82,465b81c6-0d54-46f6-8eb1-23271357d200,3666d26c-5034-4140-9d74-8f88c1b8e23d,06d8c592-bb9f-4503-a4b1-5a5b2e9e2d62,8ca0fbc1-f478-4e9b-a70f-87cfabcc3d27,1a2decca-cea8-47fd-9107-8545957ba4d6,857360ff-877d-432d-bb3e-3922312e8c2a,8bc977c2-bf21-477c-8124-f0e2da063cd9,4c39b1ac-6c06-44f5-a770-9de492fbaaf2,d93697ea-3e6b-43f5-bd86-820ffeb59abc,af03174f-deff-4a50-866e-ea8703bfd1e0,155bd13d-1412-4162-a39a-1e000a851577,49a65363-617f-4dd7-bb69-692a52a92e2f,9a82d5c2-3ffc-4609-bf1f-cbcb4bc7be1b,718d6b14-ad24-4086-9dc3-94c57d924143,6fe4533d-b790-46dd-9152-2ea0b72ce084,8ef0ad1f-1d74-41a9-823b-fd419d6fd307,28c6e535-2325-4550-be33-7de83797df3e,8292d9fb-3c2a-4aad-981c-8b57a452ec0d,399105ee-35af-4429-9b13-59e877830171,4d705949-b5f9-489a-b4fd-1d0bbe6f9c77,ea586142-ee03-4c84-943c-52ddb963560b,cb53da71-326b-4bee-a85a-2c128cadeb44,3b80be78-355b-49cb-bfa1-1f5b3daacc3e,66e20540-aff3-41bd-96ea-e4423c947d44,753aa443-a071-4173-9747-f7edfbbd6a83,b799ec3a-f61a-4640-8359-2c257018aca6,f7dc6233-9dd9-46dd-900b-5a9b91c29520,38669ac4-7fb0-4fc1-8a82-89cfba747d8b,1d593ba9-9b37-4699-a98f-09b8c5d01c45,9219b9e5-7ebf-46cd-9c3b-dbcbf246b75f,c60efc4f-1827-4455-908a-3e65503d81df,37ee9247-05e7-4178-84bd-fd16013fb73c,d967a31e-b27a-4862-8c53-3208bf530306,f7d3dd5a-1461-40ce-aa76-046fc9b00b1c,2fe31914-f10c-41e1-8729-f3338544bbca,75acb594-f442-49ab-a902-1d3b1e8a808b,a747204d-f45c-44c0-81ac-cd817ded15be,6bd91c91-afc8-4874-91d3-52cd900cb0e3,8bd66ee3-2bf8-42a8-ad9f-d9b915c0f8c6,59e36e7e-37a7-4bab-b030-42b24896c411,a73623d6-9649-4b2e-9f0e-4a415009580a,7ac961c9-6b82-49e6-9b42-0473fe1dec36,e0466b0d-ddd5-45ca-beb2-badc0cf1c70a,6e2f2b0c-7ed8-4dd7-b764-76691ce1b36d,5a75a4cd-8c9d-45bc-a6e0-ab148b1496ac,f96a0347-da4b-42fe-98c1-2c95381f96c5,7f3bc4dc-7f0d-4e07-a7f4-bc5d6ddeb91f,d4a131f4-3e45-4935-9ddb-7c87f0249213,e5978788-65af-461e-b1da-fbce6c6e7987,9c7517f6-1cf5-4c2e-a5d4-8c767de00996,324b1ac8-2ede-44ce-b199-1c34fe300a36,4739a3bf-98c5-46f4-9e44-18566ae01f2d,01b8a961-9991-4b5e-b1d4-c55e1be4da0a,b3ef3150-5116-42e7-893b-34735d8cb578,923250a5-9400-4dda-8f94-a7391530c12f, pattern=[METRICS]
2023-05-08T18:29:46,292 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:536.07|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570586,17b7b61e-09f8-4a7d-8c6e-ff7541a8ec82,465b81c6-0d54-46f6-8eb1-23271357d200,3666d26c-5034-4140-9d74-8f88c1b8e23d,06d8c592-bb9f-4503-a4b1-5a5b2e9e2d62,8ca0fbc1-f478-4e9b-a70f-87cfabcc3d27,1a2decca-cea8-47fd-9107-8545957ba4d6,857360ff-877d-432d-bb3e-3922312e8c2a,8bc977c2-bf21-477c-8124-f0e2da063cd9,4c39b1ac-6c06-44f5-a770-9de492fbaaf2,d93697ea-3e6b-43f5-bd86-820ffeb59abc,af03174f-deff-4a50-866e-ea8703bfd1e0,155bd13d-1412-4162-a39a-1e000a851577,49a65363-617f-4dd7-bb69-692a52a92e2f,9a82d5c2-3ffc-4609-bf1f-cbcb4bc7be1b,718d6b14-ad24-4086-9dc3-94c57d924143,6fe4533d-b790-46dd-9152-2ea0b72ce084,8ef0ad1f-1d74-41a9-823b-fd419d6fd307,28c6e535-2325-4550-be33-7de83797df3e,8292d9fb-3c2a-4aad-981c-8b57a452ec0d,399105ee-35af-4429-9b13-59e877830171,4d705949-b5f9-489a-b4fd-1d0bbe6f9c77,ea586142-ee03-4c84-943c-52ddb963560b,cb53da71-326b-4bee-a85a-2c128cadeb44,3b80be78-355b-49cb-bfa1-1f5b3daacc3e,66e20540-aff3-41bd-96ea-e4423c947d44,753aa443-a071-4173-9747-f7edfbbd6a83,b799ec3a-f61a-4640-8359-2c257018aca6,f7dc6233-9dd9-46dd-900b-5a9b91c29520,38669ac4-7fb0-4fc1-8a82-89cfba747d8b,1d593ba9-9b37-4699-a98f-09b8c5d01c45,9219b9e5-7ebf-46cd-9c3b-dbcbf246b75f,c60efc4f-1827-4455-908a-3e65503d81df,37ee9247-05e7-4178-84bd-fd16013fb73c,d967a31e-b27a-4862-8c53-3208bf530306,f7d3dd5a-1461-40ce-aa76-046fc9b00b1c,2fe31914-f10c-41e1-8729-f3338544bbca,75acb594-f442-49ab-a902-1d3b1e8a808b,a747204d-f45c-44c0-81ac-cd817ded15be,6bd91c91-afc8-4874-91d3-52cd900cb0e3,8bd66ee3-2bf8-42a8-ad9f-d9b915c0f8c6,59e36e7e-37a7-4bab-b030-42b24896c411,a73623d6-9649-4b2e-9f0e-4a415009580a,7ac961c9-6b82-49e6-9b42-0473fe1dec36,e0466b0d-ddd5-45ca-beb2-badc0cf1c70a,6e2f2b0c-7ed8-4dd7-b764-76691ce1b36d,5a75a4cd-8c9d-45bc-a6e0-ab148b1496ac,f96a0347-da4b-42fe-98c1-2c95381f96c5,7f3bc4dc-7f0d-4e07-a7f4-bc5d6ddeb91f,d4a131f4-3e45-4935-9ddb-7c87f0249213,e5978788-65af-461e-b1da-fbce6c6e7987,9c7517f6-1cf5-4c2e-a5d4-8c767de00996,324b1ac8-2ede-44ce-b199-1c34fe300a36,4739a3bf-98c5-46f4-9e44-18566ae01f2d,01b8a961-9991-4b5e-b1d4-c55e1be4da0a,b3ef3150-5116-42e7-893b-34735d8cb578,923250a5-9400-4dda-8f94-a7391530c12f, pattern=[METRICS]
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:536.07|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:17b7b61e-09f8-4a7d-8c6e-ff7541a8ec82,465b81c6-0d54-46f6-8eb1-23271357d200,3666d26c-5034-4140-9d74-8f88c1b8e23d,06d8c592-bb9f-4503-a4b1-5a5b2e9e2d62,8ca0fbc1-f478-4e9b-a70f-87cfabcc3d27,1a2decca-cea8-47fd-9107-8545957ba4d6,857360ff-877d-432d-bb3e-3922312e8c2a,8bc977c2-bf21-477c-8124-f0e2da063cd9,4c39b1ac-6c06-44f5-a770-9de492fbaaf2,d93697ea-3e6b-43f5-bd86-820ffeb59abc,af03174f-deff-4a50-866e-ea8703bfd1e0,155bd13d-1412-4162-a39a-1e000a851577,49a65363-617f-4dd7-bb69-692a52a92e2f,9a82d5c2-3ffc-4609-bf1f-cbcb4bc7be1b,718d6b14-ad24-4086-9dc3-94c57d924143,6fe4533d-b790-46dd-9152-2ea0b72ce084,8ef0ad1f-1d74-41a9-823b-fd419d6fd307,28c6e535-2325-4550-be33-7de83797df3e,8292d9fb-3c2a-4aad-981c-8b57a452ec0d,399105ee-35af-4429-9b13-59e877830171,4d705949-b5f9-489a-b4fd-1d0bbe6f9c77,ea586142-ee03-4c84-943c-52ddb963560b,cb53da71-326b-4bee-a85a-2c128cadeb44,3b80be78-355b-49cb-bfa1-1f5b3daacc3e,66e20540-aff3-41bd-96ea-e4423c947d44,753aa443-a071-4173-9747-f7edfbbd6a83,b799ec3a-f61a-4640-8359-2c257018aca6,f7dc6233-9dd9-46dd-900b-5a9b91c29520,38669ac4-7fb0-4fc1-8a82-89cfba747d8b,1d593ba9-9b37-4699-a98f-09b8c5d01c45,9219b9e5-7ebf-46cd-9c3b-dbcbf246b75f,c60efc4f-1827-4455-908a-3e65503d81df,37ee9247-05e7-4178-84bd-fd16013fb73c,d967a31e-b27a-4862-8c53-3208bf530306,f7d3dd5a-1461-40ce-aa76-046fc9b00b1c,2fe31914-f10c-41e1-8729-f3338544bbca,75acb594-f442-49ab-a902-1d3b1e8a808b,a747204d-f45c-44c0-81ac-cd817ded15be,6bd91c91-afc8-4874-91d3-52cd900cb0e3,8bd66ee3-2bf8-42a8-ad9f-d9b915c0f8c6,59e36e7e-37a7-4bab-b030-42b24896c411,a73623d6-9649-4b2e-9f0e-4a415009580a,7ac961c9-6b82-49e6-9b42-0473fe1dec36,e0466b0d-ddd5-45ca-beb2-badc0cf1c70a,6e2f2b0c-7ed8-4dd7-b764-76691ce1b36d,5a75a4cd-8c9d-45bc-a6e0-ab148b1496ac,f96a0347-da4b-42fe-98c1-2c95381f96c5,7f3bc4dc-7f0d-4e07-a7f4-bc5d6ddeb91f,d4a131f4-3e45-4935-9ddb-7c87f0249213,e5978788-65af-461e-b1da-fbce6c6e7987,9c7517f6-1cf5-4c2e-a5d4-8c767de00996,324b1ac8-2ede-44ce-b199-1c34fe300a36,4739a3bf-98c5-46f4-9e44-18566ae01f2d,01b8a961-9991-4b5e-b1d4-c55e1be4da0a,b3ef3150-5116-42e7-893b-34735d8cb578,923250a5-9400-4dda-8f94-a7391530c12f,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:536.16|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570586,17b7b61e-09f8-4a7d-8c6e-ff7541a8ec82,465b81c6-0d54-46f6-8eb1-23271357d200,3666d26c-5034-4140-9d74-8f88c1b8e23d,06d8c592-bb9f-4503-a4b1-5a5b2e9e2d62,8ca0fbc1-f478-4e9b-a70f-87cfabcc3d27,1a2decca-cea8-47fd-9107-8545957ba4d6,857360ff-877d-432d-bb3e-3922312e8c2a,8bc977c2-bf21-477c-8124-f0e2da063cd9,4c39b1ac-6c06-44f5-a770-9de492fbaaf2,d93697ea-3e6b-43f5-bd86-820ffeb59abc,af03174f-deff-4a50-866e-ea8703bfd1e0,155bd13d-1412-4162-a39a-1e000a851577,49a65363-617f-4dd7-bb69-692a52a92e2f,9a82d5c2-3ffc-4609-bf1f-cbcb4bc7be1b,718d6b14-ad24-4086-9dc3-94c57d924143,6fe4533d-b790-46dd-9152-2ea0b72ce084,8ef0ad1f-1d74-41a9-823b-fd419d6fd307,28c6e535-2325-4550-be33-7de83797df3e,8292d9fb-3c2a-4aad-981c-8b57a452ec0d,399105ee-35af-4429-9b13-59e877830171,4d705949-b5f9-489a-b4fd-1d0bbe6f9c77,ea586142-ee03-4c84-943c-52ddb963560b,cb53da71-326b-4bee-a85a-2c128cadeb44,3b80be78-355b-49cb-bfa1-1f5b3daacc3e,66e20540-aff3-41bd-96ea-e4423c947d44,753aa443-a071-4173-9747-f7edfbbd6a83,b799ec3a-f61a-4640-8359-2c257018aca6,f7dc6233-9dd9-46dd-900b-5a9b91c29520,38669ac4-7fb0-4fc1-8a82-89cfba747d8b,1d593ba9-9b37-4699-a98f-09b8c5d01c45,9219b9e5-7ebf-46cd-9c3b-dbcbf246b75f,c60efc4f-1827-4455-908a-3e65503d81df,37ee9247-05e7-4178-84bd-fd16013fb73c,d967a31e-b27a-4862-8c53-3208bf530306,f7d3dd5a-1461-40ce-aa76-046fc9b00b1c,2fe31914-f10c-41e1-8729-f3338544bbca,75acb594-f442-49ab-a902-1d3b1e8a808b,a747204d-f45c-44c0-81ac-cd817ded15be,6bd91c91-afc8-4874-91d3-52cd900cb0e3,8bd66ee3-2bf8-42a8-ad9f-d9b915c0f8c6,59e36e7e-37a7-4bab-b030-42b24896c411,a73623d6-9649-4b2e-9f0e-4a415009580a,7ac961c9-6b82-49e6-9b42-0473fe1dec36,e0466b0d-ddd5-45ca-beb2-badc0cf1c70a,6e2f2b0c-7ed8-4dd7-b764-76691ce1b36d,5a75a4cd-8c9d-45bc-a6e0-ab148b1496ac,f96a0347-da4b-42fe-98c1-2c95381f96c5,7f3bc4dc-7f0d-4e07-a7f4-bc5d6ddeb91f,d4a131f4-3e45-4935-9ddb-7c87f0249213,e5978788-65af-461e-b1da-fbce6c6e7987,9c7517f6-1cf5-4c2e-a5d4-8c767de00996,324b1ac8-2ede-44ce-b199-1c34fe300a36,4739a3bf-98c5-46f4-9e44-18566ae01f2d,01b8a961-9991-4b5e-b1d4-c55e1be4da0a,b3ef3150-5116-42e7-893b-34735d8cb578,923250a5-9400-4dda-8f94-a7391530c12f, pattern=[METRICS]
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093112.552|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:536.16|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570586,17b7b61e-09f8-4a7d-8c6e-ff7541a8ec82,465b81c6-0d54-46f6-8eb1-23271357d200,3666d26c-5034-4140-9d74-8f88c1b8e23d,06d8c592-bb9f-4503-a4b1-5a5b2e9e2d62,8ca0fbc1-f478-4e9b-a70f-87cfabcc3d27,1a2decca-cea8-47fd-9107-8545957ba4d6,857360ff-877d-432d-bb3e-3922312e8c2a,8bc977c2-bf21-477c-8124-f0e2da063cd9,4c39b1ac-6c06-44f5-a770-9de492fbaaf2,d93697ea-3e6b-43f5-bd86-820ffeb59abc,af03174f-deff-4a50-866e-ea8703bfd1e0,155bd13d-1412-4162-a39a-1e000a851577,49a65363-617f-4dd7-bb69-692a52a92e2f,9a82d5c2-3ffc-4609-bf1f-cbcb4bc7be1b,718d6b14-ad24-4086-9dc3-94c57d924143,6fe4533d-b790-46dd-9152-2ea0b72ce084,8ef0ad1f-1d74-41a9-823b-fd419d6fd307,28c6e535-2325-4550-be33-7de83797df3e,8292d9fb-3c2a-4aad-981c-8b57a452ec0d,399105ee-35af-4429-9b13-59e877830171,4d705949-b5f9-489a-b4fd-1d0bbe6f9c77,ea586142-ee03-4c84-943c-52ddb963560b,cb53da71-326b-4bee-a85a-2c128cadeb44,3b80be78-355b-49cb-bfa1-1f5b3daacc3e,66e20540-aff3-41bd-96ea-e4423c947d44,753aa443-a071-4173-9747-f7edfbbd6a83,b799ec3a-f61a-4640-8359-2c257018aca6,f7dc6233-9dd9-46dd-900b-5a9b91c29520,38669ac4-7fb0-4fc1-8a82-89cfba747d8b,1d593ba9-9b37-4699-a98f-09b8c5d01c45,9219b9e5-7ebf-46cd-9c3b-dbcbf246b75f,c60efc4f-1827-4455-908a-3e65503d81df,37ee9247-05e7-4178-84bd-fd16013fb73c,d967a31e-b27a-4862-8c53-3208bf530306,f7d3dd5a-1461-40ce-aa76-046fc9b00b1c,2fe31914-f10c-41e1-8729-f3338544bbca,75acb594-f442-49ab-a902-1d3b1e8a808b,a747204d-f45c-44c0-81ac-cd817ded15be,6bd91c91-afc8-4874-91d3-52cd900cb0e3,8bd66ee3-2bf8-42a8-ad9f-d9b915c0f8c6,59e36e7e-37a7-4bab-b030-42b24896c411,a73623d6-9649-4b2e-9f0e-4a415009580a,7ac961c9-6b82-49e6-9b42-0473fe1dec36,e0466b0d-ddd5-45ca-beb2-badc0cf1c70a,6e2f2b0c-7ed8-4dd7-b764-76691ce1b36d,5a75a4cd-8c9d-45bc-a6e0-ab148b1496ac,f96a0347-da4b-42fe-98c1-2c95381f96c5,7f3bc4dc-7f0d-4e07-a7f4-bc5d6ddeb91f,d4a131f4-3e45-4935-9ddb-7c87f0249213,e5978788-65af-461e-b1da-fbce6c6e7987,9c7517f6-1cf5-4c2e-a5d4-8c767de00996,324b1ac8-2ede-44ce-b199-1c34fe300a36,4739a3bf-98c5-46f4-9e44-18566ae01f2d,01b8a961-9991-4b5e-b1d4-c55e1be4da0a,b3ef3150-5116-42e7-893b-34735d8cb578,923250a5-9400-4dda-8f94-a7391530c12f, pattern=[METRICS]
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:553048.672|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553048672, Backend time ns: 540274272
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 553048672, Backend time ns: 540274272
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:553.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:536.16|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:17b7b61e-09f8-4a7d-8c6e-ff7541a8ec82,465b81c6-0d54-46f6-8eb1-23271357d200,3666d26c-5034-4140-9d74-8f88c1b8e23d,06d8c592-bb9f-4503-a4b1-5a5b2e9e2d62,8ca0fbc1-f478-4e9b-a70f-87cfabcc3d27,1a2decca-cea8-47fd-9107-8545957ba4d6,857360ff-877d-432d-bb3e-3922312e8c2a,8bc977c2-bf21-477c-8124-f0e2da063cd9,4c39b1ac-6c06-44f5-a770-9de492fbaaf2,d93697ea-3e6b-43f5-bd86-820ffeb59abc,af03174f-deff-4a50-866e-ea8703bfd1e0,155bd13d-1412-4162-a39a-1e000a851577,49a65363-617f-4dd7-bb69-692a52a92e2f,9a82d5c2-3ffc-4609-bf1f-cbcb4bc7be1b,718d6b14-ad24-4086-9dc3-94c57d924143,6fe4533d-b790-46dd-9152-2ea0b72ce084,8ef0ad1f-1d74-41a9-823b-fd419d6fd307,28c6e535-2325-4550-be33-7de83797df3e,8292d9fb-3c2a-4aad-981c-8b57a452ec0d,399105ee-35af-4429-9b13-59e877830171,4d705949-b5f9-489a-b4fd-1d0bbe6f9c77,ea586142-ee03-4c84-943c-52ddb963560b,cb53da71-326b-4bee-a85a-2c128cadeb44,3b80be78-355b-49cb-bfa1-1f5b3daacc3e,66e20540-aff3-41bd-96ea-e4423c947d44,753aa443-a071-4173-9747-f7edfbbd6a83,b799ec3a-f61a-4640-8359-2c257018aca6,f7dc6233-9dd9-46dd-900b-5a9b91c29520,38669ac4-7fb0-4fc1-8a82-89cfba747d8b,1d593ba9-9b37-4699-a98f-09b8c5d01c45,9219b9e5-7ebf-46cd-9c3b-dbcbf246b75f,c60efc4f-1827-4455-908a-3e65503d81df,37ee9247-05e7-4178-84bd-fd16013fb73c,d967a31e-b27a-4862-8c53-3208bf530306,f7d3dd5a-1461-40ce-aa76-046fc9b00b1c,2fe31914-f10c-41e1-8729-f3338544bbca,75acb594-f442-49ab-a902-1d3b1e8a808b,a747204d-f45c-44c0-81ac-cd817ded15be,6bd91c91-afc8-4874-91d3-52cd900cb0e3,8bd66ee3-2bf8-42a8-ad9f-d9b915c0f8c6,59e36e7e-37a7-4bab-b030-42b24896c411,a73623d6-9649-4b2e-9f0e-4a415009580a,7ac961c9-6b82-49e6-9b42-0473fe1dec36,e0466b0d-ddd5-45ca-beb2-badc0cf1c70a,6e2f2b0c-7ed8-4dd7-b764-76691ce1b36d,5a75a4cd-8c9d-45bc-a6e0-ab148b1496ac,f96a0347-da4b-42fe-98c1-2c95381f96c5,7f3bc4dc-7f0d-4e07-a7f4-bc5d6ddeb91f,d4a131f4-3e45-4935-9ddb-7c87f0249213,e5978788-65af-461e-b1da-fbce6c6e7987,9c7517f6-1cf5-4c2e-a5d4-8c767de00996,324b1ac8-2ede-44ce-b199-1c34fe300a36,4739a3bf-98c5-46f4-9e44-18566ae01f2d,01b8a961-9991-4b5e-b1d4-c55e1be4da0a,b3ef3150-5116-42e7-893b-34735d8cb578,923250a5-9400-4dda-8f94-a7391530c12f,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093248.461|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552944.437|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552944437, Backend time ns: 540376198
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552944437, Backend time ns: 540376198
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093286.912|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552888.633|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552888633, Backend time ns: 540462153
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552888633, Backend time ns: 540462153
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49010 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092981.616|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552498.692|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552498692, Backend time ns: 540552718
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552498692, Backend time ns: 540552718
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48076 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093045.069|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552471.74|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552471740, Backend time ns: 540625712
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552471740, Backend time ns: 540625712
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48082 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093095.352|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] epollEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] epollEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552448.599|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552448599, Backend time ns: 540764789
2023-05-08T18:29:46,293 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552448599, Backend time ns: 540764789
2023-05-08T18:29:46,293 [INFO ] epollEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48960 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,293 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093203.137|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552402.726|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552402726, Backend time ns: 540870755
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552402726, Backend time ns: 540870755
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48098 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093172.847|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552280.08|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552280080, Backend time ns: 540954110
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552280080, Backend time ns: 540954110
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48110 "POST /predictions/benchmark HTTP/1.0" 200 1094
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093146.074|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552171.563|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552171563, Backend time ns: 541040315
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552171563, Backend time ns: 541040315
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48134 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093092.232|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:552031.576|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552031576, Backend time ns: 541124090
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 552031576, Backend time ns: 541124090
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:552.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48122 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093113.673|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551965.092|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551965092, Backend time ns: 541230655
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551965092, Backend time ns: 541230655
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48176 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093069.23|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551812.083|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551812083, Backend time ns: 541321771
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551812083, Backend time ns: 541321771
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48148 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093092.222|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551750.65|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551750650, Backend time ns: 541401615
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551750650, Backend time ns: 541401615
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48160 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093072.84|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551651.404|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551651404, Backend time ns: 541486750
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551651404, Backend time ns: 541486750
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48252 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1093029.768|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551522.477|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551522477, Backend time ns: 541575835
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551522477, Backend time ns: 541575835
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48220 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092974.265|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551371.979|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551371979, Backend time ns: 541662210
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551371979, Backend time ns: 541662210
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48192 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092957.895|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551275.224|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551275224, Backend time ns: 541747724
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551275224, Backend time ns: 541747724
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48132 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092900.531|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551132.496|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551132496, Backend time ns: 541832659
2023-05-08T18:29:46,294 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551132496, Backend time ns: 541832659
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48266 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092886.46|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:551032.85|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551032850, Backend time ns: 541921134
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 551032850, Backend time ns: 541921134
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:551.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48206 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092935.253|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550970.707|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550970707, Backend time ns: 542026570
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550970707, Backend time ns: 542026570
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48334 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092792.965|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550745.104|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550745104, Backend time ns: 542107924
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550745104, Backend time ns: 542107924
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48240 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092836.728|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550705.932|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550705932, Backend time ns: 542194609
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550705932, Backend time ns: 542194609
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48158 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092711.96|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550496.77|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550496770, Backend time ns: 542280164
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550496770, Backend time ns: 542280164
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48314 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092739.492|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550440.047|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550440047, Backend time ns: 542375489
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550440047, Backend time ns: 542375489
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48226 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092729.702|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550331.401|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550331401, Backend time ns: 542461454
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550331401, Backend time ns: 542461454
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48436 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092714.26|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550232.285|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550232285, Backend time ns: 542540078
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550232285, Backend time ns: 542540078
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48328 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092722.391|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550158.731|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550158731, Backend time ns: 542630033
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550158731, Backend time ns: 542630033
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48468 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092703.33|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:550048.825|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550048825, Backend time ns: 542715688
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 550048825, Backend time ns: 542715688
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48278 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092683.639|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549941.959|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549941959, Backend time ns: 542800503
2023-05-08T18:29:46,295 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549941959, Backend time ns: 542800503
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,295 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48254 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092637.526|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549816.622|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549816622, Backend time ns: 542883468
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549816622, Backend time ns: 542883468
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48464 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092651.557|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549747.998|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549747998, Backend time ns: 542968182
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549747998, Backend time ns: 542968182
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48446 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092576.563|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549588.199|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549588199, Backend time ns: 543051137
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549588199, Backend time ns: 543051137
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48490 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092572.712|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549478.493|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549478493, Backend time ns: 543152733
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549478493, Backend time ns: 543152733
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48460 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092536.581|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549363.927|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549363927, Backend time ns: 543236687
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549363927, Backend time ns: 543236687
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48504 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092509.079|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549255.151|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549255151, Backend time ns: 543316452
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549255151, Backend time ns: 543316452
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48404 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092493.258|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549155.955|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549155955, Backend time ns: 543400047
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549155955, Backend time ns: 543400047
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48520 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092480.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:549058.99|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549058990, Backend time ns: 543480191
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 549058990, Backend time ns: 543480191
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48344 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092353.36|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548852.368|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548852368, Backend time ns: 543562636
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548852368, Backend time ns: 543562636
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48294 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092414.044|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548831.887|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548831887, Backend time ns: 543643950
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548831887, Backend time ns: 543643950
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48396 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092425.535|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548754.983|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548754983, Backend time ns: 543734495
2023-05-08T18:29:46,296 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548754983, Backend time ns: 543734495
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48528 "POST /predictions/benchmark HTTP/1.0" 200 1092
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092385.162|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,296 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548630.346|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548630346, Backend time ns: 543831981
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548630346, Backend time ns: 543831981
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48420 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092362.071|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548506.589|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548506589, Backend time ns: 543917685
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548506589, Backend time ns: 543917685
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48380 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092294.268|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548356.341|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548356341, Backend time ns: 544005170
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548356341, Backend time ns: 544005170
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48540 "POST /predictions/benchmark HTTP/1.0" 200 1093
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1092338.14|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:548310.048|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548310048, Backend time ns: 544091975
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 548310048, Backend time ns: 544091975
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48304 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549765.199|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5652.583|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5652583, Backend time ns: 544172220
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5652583, Backend time ns: 544172220
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48560 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549812.792|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5618.551|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5618551, Backend time ns: 544251664
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5618551, Backend time ns: 544251664
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48372 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549745.989|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5466.934|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5466934, Backend time ns: 544340518
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5466934, Backend time ns: 544340518
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48376 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549744.548|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5380.369|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5380369, Backend time ns: 544425713
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5380369, Backend time ns: 544425713
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48322 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549810.972|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5361.958|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5361958, Backend time ns: 544509347
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5361958, Backend time ns: 544509347
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48360 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549704.427|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5175.238|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5175238, Backend time ns: 544599382
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5175238, Backend time ns: 544599382
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48582 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549657.644|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:5038.32|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5038320, Backend time ns: 544678467
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 5038320, Backend time ns: 544678467
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48586 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549606.091|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4906.333|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4906333, Backend time ns: 544760581
2023-05-08T18:29:46,297 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4906333, Backend time ns: 544760581
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48568 "POST /predictions/benchmark HTTP/1.0" 200 549
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,297 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549630.503|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4850.65|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4850650, Backend time ns: 544842536
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4850650, Backend time ns: 544842536
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48478 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549685.995|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4821.388|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4821388, Backend time ns: 544933201
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4821388, Backend time ns: 544933201
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549574.239|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4621.197|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4621197, Backend time ns: 545012626
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4621197, Backend time ns: 545012626
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48590 "POST /predictions/benchmark HTTP/1.0" 200 550
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:549589.31|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:4553.573|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4553573, Backend time ns: 545099400
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 4553573, Backend time ns: 545099400
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:4.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:46,298 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 540
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 540
2023-05-08T18:29:46,298 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570586
2023-05-08T18:29:48,298 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570588298
2023-05-08T18:29:48,298 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1683570588298
2023-05-08T18:29:48,301 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Backend received inference at: 1683570588
2023-05-08T18:29:48,301 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,301 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,302 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,303 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,304 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,305 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,306 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,307 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,308 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,308 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,308 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Received text: 'Hey, are you conscious? Can you talk to me?
2023-05-08T18:29:48,308 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - '
2023-05-08T18:29:48,308 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - *********** input ids size  torch.Size([47, 50])
2023-05-08T18:29:48,309 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Input length of input_ids is 50, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
2023-05-08T18:29:48,309 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [root] Running pipeline with 8 micro-batches
2023-05-08T18:29:48,315 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 0
2023-05-08T18:29:48,352 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 1
2023-05-08T18:29:48,374 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 0
2023-05-08T18:29:48,380 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 2
2023-05-08T18:29:48,411 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 1
2023-05-08T18:29:48,415 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 0
2023-05-08T18:29:48,419 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 3
2023-05-08T18:29:48,449 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 2
2023-05-08T18:29:48,455 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 1
2023-05-08T18:29:48,456 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 4
2023-05-08T18:29:48,457 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 0
2023-05-08T18:29:48,487 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 3
2023-05-08T18:29:48,494 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 5
2023-05-08T18:29:48,494 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 2
2023-05-08T18:29:48,497 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 1
2023-05-08T18:29:48,526 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 4
2023-05-08T18:29:48,532 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 6
2023-05-08T18:29:48,534 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 3
2023-05-08T18:29:48,536 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 2
2023-05-08T18:29:48,563 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 5
2023-05-08T18:29:48,570 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [0] Running forward module for microbatch 7
2023-05-08T18:29:48,574 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 4
2023-05-08T18:29:48,576 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 3
2023-05-08T18:29:48,602 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 6
2023-05-08T18:29:48,614 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 5
2023-05-08T18:29:48,616 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 4
2023-05-08T18:29:48,627 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [1] Running forward module for microbatch 7
2023-05-08T18:29:48,653 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 6
2023-05-08T18:29:48,655 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 5
2023-05-08T18:29:48,679 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [2] Running forward module for microbatch 7
2023-05-08T18:29:48,695 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 6
2023-05-08T18:29:48,721 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - [3] Running forward module for microbatch 7
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Generated text: ['Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI', 'Hey, are you conscious? Can you talk to me?\nI']
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:510.24|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570588,2b36ee81-486d-4ed5-89d2-6e7a0f0b985e,3c9e8aec-8b52-477b-bd31-5ebee8c187e8,fdc7492c-39d6-4989-9091-0441da7a7b97,69482893-ed55-40c0-abdd-f7b1f3a83600,566d050f-62f9-4f0e-8cce-903bcc42cc79,8b955f97-77e3-4bc5-ab9f-991204b9cb73,ba064e0b-1b42-4431-8063-c130889b87e4,aed2fe70-7a50-4aee-9a8d-97df4400dbd2,b8db7b58-2920-4d8c-b23c-37e1b93748e8,babcff60-ecaf-42f9-adcc-d5c64afde5b5,23311009-8db1-489b-b5fb-8ca8e7f7213a,fe484843-ae5f-46c8-bb30-87b6f722b94e,9fa28901-8708-4366-9ea5-6fd315ac2169,254e186d-e548-440c-9963-696c01f632a9,aa910d36-74c0-4f27-a2f8-6ae33228bda2,86280252-bd0f-4554-8886-186fc606858a,782a43a4-4d1f-4663-b4ee-5ba07079c2af,6f4f6d6f-5063-4f8e-a6be-936909691912,3db902ce-75d3-43b0-ab53-409873173bc2,4929a447-e822-4058-b670-d63bf6e3e8fa,4664dc8a-d0ea-47c4-9373-22d37c3eece8,e2545ba5-4c3d-4987-9ef5-ece030065361,77549ae1-7fe2-46bd-a6ef-79c712874e2e,5014089a-5a6b-42a8-9624-d8a92f479aea,c46afdce-7615-46f1-a28d-d2ab8abd6774,da0cc37a-4029-4486-b7a8-9356e1e96b5f,b61280c4-ae59-442e-a6a5-6a0228514034,c604dc86-c471-438a-af33-86ad59cd0e99,64af1ac0-4a60-46bf-ba44-42ab9dd650fb,9fe8f87f-f320-47bd-94d3-e507a402b1af,731ddf90-a3db-463b-8255-56027f531125,af8c4c0b-0f33-468d-9c23-5cbd17be7d21,e8badec7-76a1-4f3d-90a9-463948603252,14d76d0f-1b81-4539-8ebb-31513f587b67,ee599d83-17c6-4ac8-8f74-f8a982f6f158,d2a456fd-eff9-4ac4-bd9e-1866ff84b313,474f8e01-1b82-43c8-aa60-d6e6b9ed1662,b25d9522-4c9a-4fc3-a935-83e3f1815710,027f9e2a-ff63-476e-9ba9-f40d3940f9aa,f32dae9a-a33c-4efb-9fbb-7a6dab4438d0,ee7d1b43-53f9-4d8f-8576-6daf6d160452,7ed22ef4-d677-4302-8571-2f8913f41be1,072075d7-2ee0-4015-b36b-0d7bea13fac1,5606d81d-7f7a-46ce-87b6-dfc7c39792e2,3b66e767-998b-49b4-97aa-e3558546e2ad,8e3103bf-b0d1-4469-bc93-9e7ed9ec53c2,44581f93-8310-4cbf-bd9d-f9cd080f763e, pattern=[METRICS]
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:510.24|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570588,2b36ee81-486d-4ed5-89d2-6e7a0f0b985e,3c9e8aec-8b52-477b-bd31-5ebee8c187e8,fdc7492c-39d6-4989-9091-0441da7a7b97,69482893-ed55-40c0-abdd-f7b1f3a83600,566d050f-62f9-4f0e-8cce-903bcc42cc79,8b955f97-77e3-4bc5-ab9f-991204b9cb73,ba064e0b-1b42-4431-8063-c130889b87e4,aed2fe70-7a50-4aee-9a8d-97df4400dbd2,b8db7b58-2920-4d8c-b23c-37e1b93748e8,babcff60-ecaf-42f9-adcc-d5c64afde5b5,23311009-8db1-489b-b5fb-8ca8e7f7213a,fe484843-ae5f-46c8-bb30-87b6f722b94e,9fa28901-8708-4366-9ea5-6fd315ac2169,254e186d-e548-440c-9963-696c01f632a9,aa910d36-74c0-4f27-a2f8-6ae33228bda2,86280252-bd0f-4554-8886-186fc606858a,782a43a4-4d1f-4663-b4ee-5ba07079c2af,6f4f6d6f-5063-4f8e-a6be-936909691912,3db902ce-75d3-43b0-ab53-409873173bc2,4929a447-e822-4058-b670-d63bf6e3e8fa,4664dc8a-d0ea-47c4-9373-22d37c3eece8,e2545ba5-4c3d-4987-9ef5-ece030065361,77549ae1-7fe2-46bd-a6ef-79c712874e2e,5014089a-5a6b-42a8-9624-d8a92f479aea,c46afdce-7615-46f1-a28d-d2ab8abd6774,da0cc37a-4029-4486-b7a8-9356e1e96b5f,b61280c4-ae59-442e-a6a5-6a0228514034,c604dc86-c471-438a-af33-86ad59cd0e99,64af1ac0-4a60-46bf-ba44-42ab9dd650fb,9fe8f87f-f320-47bd-94d3-e507a402b1af,731ddf90-a3db-463b-8255-56027f531125,af8c4c0b-0f33-468d-9c23-5cbd17be7d21,e8badec7-76a1-4f3d-90a9-463948603252,14d76d0f-1b81-4539-8ebb-31513f587b67,ee599d83-17c6-4ac8-8f74-f8a982f6f158,d2a456fd-eff9-4ac4-bd9e-1866ff84b313,474f8e01-1b82-43c8-aa60-d6e6b9ed1662,b25d9522-4c9a-4fc3-a935-83e3f1815710,027f9e2a-ff63-476e-9ba9-f40d3940f9aa,f32dae9a-a33c-4efb-9fbb-7a6dab4438d0,ee7d1b43-53f9-4d8f-8576-6daf6d160452,7ed22ef4-d677-4302-8571-2f8913f41be1,072075d7-2ee0-4015-b36b-0d7bea13fac1,5606d81d-7f7a-46ce-87b6-dfc7c39792e2,3b66e767-998b-49b4-97aa-e3558546e2ad,8e3103bf-b0d1-4469-bc93-9e7ed9ec53c2,44581f93-8310-4cbf-bd9d-f9cd080f763e, pattern=[METRICS]
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - HandlerTime.ms:510.24|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:2b36ee81-486d-4ed5-89d2-6e7a0f0b985e,3c9e8aec-8b52-477b-bd31-5ebee8c187e8,fdc7492c-39d6-4989-9091-0441da7a7b97,69482893-ed55-40c0-abdd-f7b1f3a83600,566d050f-62f9-4f0e-8cce-903bcc42cc79,8b955f97-77e3-4bc5-ab9f-991204b9cb73,ba064e0b-1b42-4431-8063-c130889b87e4,aed2fe70-7a50-4aee-9a8d-97df4400dbd2,b8db7b58-2920-4d8c-b23c-37e1b93748e8,babcff60-ecaf-42f9-adcc-d5c64afde5b5,23311009-8db1-489b-b5fb-8ca8e7f7213a,fe484843-ae5f-46c8-bb30-87b6f722b94e,9fa28901-8708-4366-9ea5-6fd315ac2169,254e186d-e548-440c-9963-696c01f632a9,aa910d36-74c0-4f27-a2f8-6ae33228bda2,86280252-bd0f-4554-8886-186fc606858a,782a43a4-4d1f-4663-b4ee-5ba07079c2af,6f4f6d6f-5063-4f8e-a6be-936909691912,3db902ce-75d3-43b0-ab53-409873173bc2,4929a447-e822-4058-b670-d63bf6e3e8fa,4664dc8a-d0ea-47c4-9373-22d37c3eece8,e2545ba5-4c3d-4987-9ef5-ece030065361,77549ae1-7fe2-46bd-a6ef-79c712874e2e,5014089a-5a6b-42a8-9624-d8a92f479aea,c46afdce-7615-46f1-a28d-d2ab8abd6774,da0cc37a-4029-4486-b7a8-9356e1e96b5f,b61280c4-ae59-442e-a6a5-6a0228514034,c604dc86-c471-438a-af33-86ad59cd0e99,64af1ac0-4a60-46bf-ba44-42ab9dd650fb,9fe8f87f-f320-47bd-94d3-e507a402b1af,731ddf90-a3db-463b-8255-56027f531125,af8c4c0b-0f33-468d-9c23-5cbd17be7d21,e8badec7-76a1-4f3d-90a9-463948603252,14d76d0f-1b81-4539-8ebb-31513f587b67,ee599d83-17c6-4ac8-8f74-f8a982f6f158,d2a456fd-eff9-4ac4-bd9e-1866ff84b313,474f8e01-1b82-43c8-aa60-d6e6b9ed1662,b25d9522-4c9a-4fc3-a935-83e3f1815710,027f9e2a-ff63-476e-9ba9-f40d3940f9aa,f32dae9a-a33c-4efb-9fbb-7a6dab4438d0,ee7d1b43-53f9-4d8f-8576-6daf6d160452,7ed22ef4-d677-4302-8571-2f8913f41be1,072075d7-2ee0-4015-b36b-0d7bea13fac1,5606d81d-7f7a-46ce-87b6-dfc7c39792e2,3b66e767-998b-49b4-97aa-e3558546e2ad,8e3103bf-b0d1-4469-bc93-9e7ed9ec53c2,44581f93-8310-4cbf-bd9d-f9cd080f763e,timestamp:1683570588
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:510.32|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570588,2b36ee81-486d-4ed5-89d2-6e7a0f0b985e,3c9e8aec-8b52-477b-bd31-5ebee8c187e8,fdc7492c-39d6-4989-9091-0441da7a7b97,69482893-ed55-40c0-abdd-f7b1f3a83600,566d050f-62f9-4f0e-8cce-903bcc42cc79,8b955f97-77e3-4bc5-ab9f-991204b9cb73,ba064e0b-1b42-4431-8063-c130889b87e4,aed2fe70-7a50-4aee-9a8d-97df4400dbd2,b8db7b58-2920-4d8c-b23c-37e1b93748e8,babcff60-ecaf-42f9-adcc-d5c64afde5b5,23311009-8db1-489b-b5fb-8ca8e7f7213a,fe484843-ae5f-46c8-bb30-87b6f722b94e,9fa28901-8708-4366-9ea5-6fd315ac2169,254e186d-e548-440c-9963-696c01f632a9,aa910d36-74c0-4f27-a2f8-6ae33228bda2,86280252-bd0f-4554-8886-186fc606858a,782a43a4-4d1f-4663-b4ee-5ba07079c2af,6f4f6d6f-5063-4f8e-a6be-936909691912,3db902ce-75d3-43b0-ab53-409873173bc2,4929a447-e822-4058-b670-d63bf6e3e8fa,4664dc8a-d0ea-47c4-9373-22d37c3eece8,e2545ba5-4c3d-4987-9ef5-ece030065361,77549ae1-7fe2-46bd-a6ef-79c712874e2e,5014089a-5a6b-42a8-9624-d8a92f479aea,c46afdce-7615-46f1-a28d-d2ab8abd6774,da0cc37a-4029-4486-b7a8-9356e1e96b5f,b61280c4-ae59-442e-a6a5-6a0228514034,c604dc86-c471-438a-af33-86ad59cd0e99,64af1ac0-4a60-46bf-ba44-42ab9dd650fb,9fe8f87f-f320-47bd-94d3-e507a402b1af,731ddf90-a3db-463b-8255-56027f531125,af8c4c0b-0f33-468d-9c23-5cbd17be7d21,e8badec7-76a1-4f3d-90a9-463948603252,14d76d0f-1b81-4539-8ebb-31513f587b67,ee599d83-17c6-4ac8-8f74-f8a982f6f158,d2a456fd-eff9-4ac4-bd9e-1866ff84b313,474f8e01-1b82-43c8-aa60-d6e6b9ed1662,b25d9522-4c9a-4fc3-a935-83e3f1815710,027f9e2a-ff63-476e-9ba9-f40d3940f9aa,f32dae9a-a33c-4efb-9fbb-7a6dab4438d0,ee7d1b43-53f9-4d8f-8576-6daf6d160452,7ed22ef4-d677-4302-8571-2f8913f41be1,072075d7-2ee0-4015-b36b-0d7bea13fac1,5606d81d-7f7a-46ce-87b6-dfc7c39792e2,3b66e767-998b-49b4-97aa-e3558546e2ad,8e3103bf-b0d1-4469-bc93-9e7ed9ec53c2,44581f93-8310-4cbf-bd9d-f9cd080f763e, pattern=[METRICS]
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:510.32|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,1683570588,2b36ee81-486d-4ed5-89d2-6e7a0f0b985e,3c9e8aec-8b52-477b-bd31-5ebee8c187e8,fdc7492c-39d6-4989-9091-0441da7a7b97,69482893-ed55-40c0-abdd-f7b1f3a83600,566d050f-62f9-4f0e-8cce-903bcc42cc79,8b955f97-77e3-4bc5-ab9f-991204b9cb73,ba064e0b-1b42-4431-8063-c130889b87e4,aed2fe70-7a50-4aee-9a8d-97df4400dbd2,b8db7b58-2920-4d8c-b23c-37e1b93748e8,babcff60-ecaf-42f9-adcc-d5c64afde5b5,23311009-8db1-489b-b5fb-8ca8e7f7213a,fe484843-ae5f-46c8-bb30-87b6f722b94e,9fa28901-8708-4366-9ea5-6fd315ac2169,254e186d-e548-440c-9963-696c01f632a9,aa910d36-74c0-4f27-a2f8-6ae33228bda2,86280252-bd0f-4554-8886-186fc606858a,782a43a4-4d1f-4663-b4ee-5ba07079c2af,6f4f6d6f-5063-4f8e-a6be-936909691912,3db902ce-75d3-43b0-ab53-409873173bc2,4929a447-e822-4058-b670-d63bf6e3e8fa,4664dc8a-d0ea-47c4-9373-22d37c3eece8,e2545ba5-4c3d-4987-9ef5-ece030065361,77549ae1-7fe2-46bd-a6ef-79c712874e2e,5014089a-5a6b-42a8-9624-d8a92f479aea,c46afdce-7615-46f1-a28d-d2ab8abd6774,da0cc37a-4029-4486-b7a8-9356e1e96b5f,b61280c4-ae59-442e-a6a5-6a0228514034,c604dc86-c471-438a-af33-86ad59cd0e99,64af1ac0-4a60-46bf-ba44-42ab9dd650fb,9fe8f87f-f320-47bd-94d3-e507a402b1af,731ddf90-a3db-463b-8255-56027f531125,af8c4c0b-0f33-468d-9c23-5cbd17be7d21,e8badec7-76a1-4f3d-90a9-463948603252,14d76d0f-1b81-4539-8ebb-31513f587b67,ee599d83-17c6-4ac8-8f74-f8a982f6f158,d2a456fd-eff9-4ac4-bd9e-1866ff84b313,474f8e01-1b82-43c8-aa60-d6e6b9ed1662,b25d9522-4c9a-4fc3-a935-83e3f1815710,027f9e2a-ff63-476e-9ba9-f40d3940f9aa,f32dae9a-a33c-4efb-9fbb-7a6dab4438d0,ee7d1b43-53f9-4d8f-8576-6daf6d160452,7ed22ef4-d677-4302-8571-2f8913f41be1,072075d7-2ee0-4015-b36b-0d7bea13fac1,5606d81d-7f7a-46ce-87b6-dfc7c39792e2,3b66e767-998b-49b4-97aa-e3558546e2ad,8e3103bf-b0d1-4469-bc93-9e7ed9ec53c2,44581f93-8310-4cbf-bd9d-f9cd080f763e, pattern=[METRICS]
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48606 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0-stdout MODEL_METRICS - PredictionTime.ms:510.32|#ModelName:benchmark,Level:Model|#hostname:ip-172-31-5-255,requestID:2b36ee81-486d-4ed5-89d2-6e7a0f0b985e,3c9e8aec-8b52-477b-bd31-5ebee8c187e8,fdc7492c-39d6-4989-9091-0441da7a7b97,69482893-ed55-40c0-abdd-f7b1f3a83600,566d050f-62f9-4f0e-8cce-903bcc42cc79,8b955f97-77e3-4bc5-ab9f-991204b9cb73,ba064e0b-1b42-4431-8063-c130889b87e4,aed2fe70-7a50-4aee-9a8d-97df4400dbd2,b8db7b58-2920-4d8c-b23c-37e1b93748e8,babcff60-ecaf-42f9-adcc-d5c64afde5b5,23311009-8db1-489b-b5fb-8ca8e7f7213a,fe484843-ae5f-46c8-bb30-87b6f722b94e,9fa28901-8708-4366-9ea5-6fd315ac2169,254e186d-e548-440c-9963-696c01f632a9,aa910d36-74c0-4f27-a2f8-6ae33228bda2,86280252-bd0f-4554-8886-186fc606858a,782a43a4-4d1f-4663-b4ee-5ba07079c2af,6f4f6d6f-5063-4f8e-a6be-936909691912,3db902ce-75d3-43b0-ab53-409873173bc2,4929a447-e822-4058-b670-d63bf6e3e8fa,4664dc8a-d0ea-47c4-9373-22d37c3eece8,e2545ba5-4c3d-4987-9ef5-ece030065361,77549ae1-7fe2-46bd-a6ef-79c712874e2e,5014089a-5a6b-42a8-9624-d8a92f479aea,c46afdce-7615-46f1-a28d-d2ab8abd6774,da0cc37a-4029-4486-b7a8-9356e1e96b5f,b61280c4-ae59-442e-a6a5-6a0228514034,c604dc86-c471-438a-af33-86ad59cd0e99,64af1ac0-4a60-46bf-ba44-42ab9dd650fb,9fe8f87f-f320-47bd-94d3-e507a402b1af,731ddf90-a3db-463b-8255-56027f531125,af8c4c0b-0f33-468d-9c23-5cbd17be7d21,e8badec7-76a1-4f3d-90a9-463948603252,14d76d0f-1b81-4539-8ebb-31513f587b67,ee599d83-17c6-4ac8-8f74-f8a982f6f158,d2a456fd-eff9-4ac4-bd9e-1866ff84b313,474f8e01-1b82-43c8-aa60-d6e6b9ed1662,b25d9522-4c9a-4fc3-a935-83e3f1815710,027f9e2a-ff63-476e-9ba9-f40d3940f9aa,f32dae9a-a33c-4efb-9fbb-7a6dab4438d0,ee7d1b43-53f9-4d8f-8576-6daf6d160452,7ed22ef4-d677-4302-8571-2f8913f41be1,072075d7-2ee0-4015-b36b-0d7bea13fac1,5606d81d-7f7a-46ce-87b6-dfc7c39792e2,3b66e767-998b-49b4-97aa-e3558546e2ad,8e3103bf-b0d1-4469-bc93-9e7ed9ec53c2,44581f93-8310-4cbf-bd9d-f9cd080f763e,timestamp:1683570588
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063981.4|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2550104.555|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,812 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2550104555, Backend time ns: 514093407
2023-05-08T18:29:48,812 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2550104555, Backend time ns: 514093407
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48628 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064168.871|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2550047.002|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,812 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2550047002, Backend time ns: 514189793
2023-05-08T18:29:48,812 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2550047002, Backend time ns: 514189793
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2550.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48618 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,812 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064089.746|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549877.292|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549877292, Backend time ns: 514295679
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549877292, Backend time ns: 514295679
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48634 "POST /predictions/benchmark HTTP/1.0" 200 3065
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064132.919|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549811.979|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549811979, Backend time ns: 514382834
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549811979, Backend time ns: 514382834
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48656 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064124.308|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549717.773|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549717773, Backend time ns: 514469418
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549717773, Backend time ns: 514469418
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48696 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064110.288|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549621.648|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549621648, Backend time ns: 514548493
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549621648, Backend time ns: 514548493
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48664 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064031.263|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549457.199|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549457199, Backend time ns: 514634658
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549457199, Backend time ns: 514634658
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48642 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064076.686|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549422.107|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549422107, Backend time ns: 514725983
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549422107, Backend time ns: 514725983
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48712 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064110.218|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549363.684|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549363684, Backend time ns: 514808577
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549363684, Backend time ns: 514808577
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48728 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064004.072|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549175.923|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549175923, Backend time ns: 514888492
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549175923, Backend time ns: 514888492
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48736 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064002.822|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549094.859|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549094859, Backend time ns: 514968336
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549094859, Backend time ns: 514968336
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48750 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063994.562|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2549004.724|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549004724, Backend time ns: 515059751
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2549004724, Backend time ns: 515059751
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2549.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48714 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3064011.013|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548931.16|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548931160, Backend time ns: 515149777
2023-05-08T18:29:48,813 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548931160, Backend time ns: 515149777
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48776 "POST /predictions/benchmark HTTP/1.0" 200 3063
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063861.294|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,813 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548691.536|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548691536, Backend time ns: 515236431
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548691536, Backend time ns: 515236431
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48680 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063816.101|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548559.839|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548559839, Backend time ns: 515321446
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548559839, Backend time ns: 515321446
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48740 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063886.415|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548543.878|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548543878, Backend time ns: 515403111
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548543878, Backend time ns: 515403111
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48796 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063950.569|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548526.347|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548526347, Backend time ns: 515510167
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548526347, Backend time ns: 515510167
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48764 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063943.769|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548413.321|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548413321, Backend time ns: 515592061
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548413321, Backend time ns: 515592061
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48786 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063912.286|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548280.823|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548280823, Backend time ns: 515696957
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548280823, Backend time ns: 515696957
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48790 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063827.362|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548110.154|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548110154, Backend time ns: 515781272
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548110154, Backend time ns: 515781272
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48812 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063820.842|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2548018.779|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548018779, Backend time ns: 515869827
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2548018779, Backend time ns: 515869827
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2548.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48860 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063801.531|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547910.383|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547910383, Backend time ns: 515952011
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547910383, Backend time ns: 515952011
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48842 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063801.831|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547825.758|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547825758, Backend time ns: 516034086
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547825758, Backend time ns: 516034086
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48880 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063814.541|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547755.484|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547755484, Backend time ns: 516120481
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547755484, Backend time ns: 516120481
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48850 "POST /predictions/benchmark HTTP/1.0" 200 3063
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063760.949|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547619.267|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547619267, Backend time ns: 516200635
2023-05-08T18:29:48,814 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547619267, Backend time ns: 516200635
2023-05-08T18:29:48,814 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48864 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063756.728|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547535.222|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547535222, Backend time ns: 516286110
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547535222, Backend time ns: 516286110
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48868 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063724.756|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547419.056|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547419056, Backend time ns: 516373544
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547419056, Backend time ns: 516373544
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48890 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063745.547|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547348.652|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547348652, Backend time ns: 516462769
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547348652, Backend time ns: 516462769
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48898 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063726.417|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547243.317|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547243317, Backend time ns: 516543163
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547243317, Backend time ns: 516543163
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48920 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063696.954|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547130.89|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547130890, Backend time ns: 516628908
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547130890, Backend time ns: 516628908
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48914 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063653.142|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2547004.003|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547004003, Backend time ns: 516722723
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2547004003, Backend time ns: 516722723
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2547.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48928 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063682.274|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546935.419|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546935419, Backend time ns: 516809528
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546935419, Backend time ns: 516809528
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48940 "POST /predictions/benchmark HTTP/1.0" 200 3063
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063520.465|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546691.016|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546691016, Backend time ns: 516916174
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546691016, Backend time ns: 516916174
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48950 "POST /predictions/benchmark HTTP/1.0" 200 3063
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063504.514|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546567.529|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546567529, Backend time ns: 516994928
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546567529, Backend time ns: 516994928
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48828 "POST /predictions/benchmark HTTP/1.0" 200 3063
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063574.037|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546559.898|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546559898, Backend time ns: 517096964
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546559898, Backend time ns: 517096964
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48936 "POST /predictions/benchmark HTTP/1.0" 200 3063
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063649.102|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546532.397|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546532397, Backend time ns: 517177598
2023-05-08T18:29:48,815 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546532397, Backend time ns: 517177598
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48942 "POST /predictions/benchmark HTTP/1.0" 200 3063
2023-05-08T18:29:48,815 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063593.889|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546393.589|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546393589, Backend time ns: 517265483
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546393589, Backend time ns: 517265483
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48952 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063579.849|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546294.154|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546294154, Backend time ns: 517344988
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546294154, Backend time ns: 517344988
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48962 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063548.196|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546182.907|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546182907, Backend time ns: 517429052
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546182907, Backend time ns: 517429052
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48958 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063549.857|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546100.643|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546100643, Backend time ns: 517510647
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546100643, Backend time ns: 517510647
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48964 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063547.986|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2546012.298|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546012298, Backend time ns: 517618733
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2546012298, Backend time ns: 517618733
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2546.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48970 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063511.674|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2545872.6|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2545872600, Backend time ns: 517697927
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2545872600, Backend time ns: 517697927
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48974 "POST /predictions/benchmark HTTP/1.0" 200 3064
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063501.114|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2545779.555|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2545779555, Backend time ns: 517780592
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2545779555, Backend time ns: 517780592
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48988 "POST /predictions/benchmark HTTP/1.0" 200 3063
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3063509.944|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2545709.061|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2545709061, Backend time ns: 517863447
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2545709061, Backend time ns: 517863447
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2545.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:49002 "POST /predictions/benchmark HTTP/1.0" 200 2523
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2522777.926|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2004889.138|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2004889138, Backend time ns: 517948031
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2004889138, Backend time ns: 517948031
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2004.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48072 "POST /predictions/benchmark HTTP/1.0" 200 2523
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2522838.909|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2004871.087|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2004871087, Backend time ns: 518026626
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2004871087, Backend time ns: 518026626
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2004.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 ACCESS_LOG - /127.0.0.1:48998 "POST /predictions/benchmark HTTP/1.0" 200 2523
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2522882.992|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:2004837.145|#model_name:benchmark,model_version:default|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2004837145, Backend time ns: 518103830
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.job.Job - Waiting time ns: 2004837145, Backend time ns: 518103830
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - QueueTime.Milliseconds:2004.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:48,816 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 513
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 513
2023-05-08T18:29:48,816 [INFO ] W-29500-benchmark_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
2023-05-08T18:29:48,821 [DEBUG] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.ModelVersionedRefs - Removed model: benchmark version: 1.0
2023-05-08T18:29:48,821 [DEBUG] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.ModelVersionedRefs - Removed model: benchmark version: 1.0
2023-05-08T18:29:48,821 [DEBUG] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.WorkerThread - W-29500-benchmark_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-05-08T18:29:48,821 [DEBUG] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.WorkerThread - W-29500-benchmark_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2023-05-08T18:29:48,822 [WARN ] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-benchmark_1.0-stderr
2023-05-08T18:29:48,822 [WARN ] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-benchmark_1.0-stderr
2023-05-08T18:29:48,822 [WARN ] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-benchmark_1.0-stdout
2023-05-08T18:29:48,822 [WARN ] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-benchmark_1.0-stdout
2023-05-08T18:29:48,822 [INFO ] W-29500-benchmark_1.0-stdout MODEL_LOG - Frontend disconnected.
2023-05-08T18:29:48,822 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-05-08T18:29:48,822 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2023-05-08T18:29:48,823 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-benchmark_1.0-stdout
2023-05-08T18:29:48,822 [WARN ] W-29500-benchmark_1.0-stderr MODEL_LOG - Traceback (most recent call last):
2023-05-08T18:29:48,823 [INFO ] W-29500-benchmark_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-benchmark_1.0-stdout
2023-05-08T18:29:48,823 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-05-08T18:29:48,823 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2023-05-08T18:29:48,824 [INFO ] W-29500-benchmark_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-benchmark_1.0-stderr
2023-05-08T18:29:48,824 [INFO ] W-29500-benchmark_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-29500-benchmark_1.0-stderr
2023-05-08T18:29:48,824 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-benchmark_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-05-08T18:29:48,824 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - W-29500-benchmark_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2023-05-08T18:29:48,823 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_SCALED_DOWN
2023-05-08T18:29:48,823 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_SCALED_DOWN
2023-05-08T18:29:48,822 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_SCALED_DOWN
2023-05-08T18:29:48,822 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_SCALED_DOWN
2023-05-08T18:29:48,824 [WARN ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-benchmark_1.0-stderr
2023-05-08T18:29:48,824 [WARN ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-benchmark_1.0-stderr
2023-05-08T18:29:48,824 [WARN ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-benchmark_1.0-stdout
2023-05-08T18:29:48,824 [WARN ] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-29500-benchmark_1.0-stdout
2023-05-08T18:29:48,825 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-05-08T18:29:48,825 [DEBUG] W-29500-benchmark_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2023-05-08T18:29:48,822 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_SCALED_DOWN
2023-05-08T18:29:48,823 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_SCALED_DOWN
2023-05-08T18:29:48,823 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_SCALED_DOWN
2023-05-08T18:29:48,822 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 29500 Worker disconnected. WORKER_SCALED_DOWN
2023-05-08T18:29:48,943 [INFO ] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.ModelManager - Model benchmark unregistered.
2023-05-08T18:29:48,943 [INFO ] epollEventLoopGroup-3-11 org.pytorch.serve.wlm.ModelManager - Model benchmark unregistered.
2023-05-08T18:29:48,943 [INFO ] epollEventLoopGroup-3-11 ACCESS_LOG - /127.0.0.1:60784 "DELETE /models/benchmark HTTP/1.1" 200 122
2023-05-08T18:29:48,944 [INFO ] epollEventLoopGroup-3-11 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:ip-172-31-5-255,timestamp:1683570588
